["```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.layers import Input, Dense, Lambda, Layer\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras import metrics\nfrom keras.datasets import mnist\n```", "```py\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nimage_size = x_train.shape[1]\noriginal_dim=image_size * image_size\nlatent_dim= 2\nintermediate_dim= 256\nepochs=50\nepsilon_std=1.0\n\n#preprocessing training arrays\n\nx_train=np.reshape(x_train, [-1, original_dim])\nx_test=np.reshape(x_test, [-1, original_dim])\nx_train=x_train.astype('float 32')/255\nx_test=x_test.astype('float 32')/255\n```", "```py\n#Encoder module\ninput_layer= Input(shape=(original_dim,))\nintermediate_layer= Dense(intermediate_dim, activation='relu', name='Intermediate layer')(input_layer)\nz_mean=Dense(latent_dim, name='z-mean')(intermediate_layer)\nz_log_var=Dense(latent_dim, name='z_log_var')(intermediate_layer)\n```", "```py\n#Decoder module\ndecoder_h= Dense(intermediate_dim, activation='relu')\ndecoder_mean= Dense(original_dim, activation='sigmoid')\nh_decoded=decoder_h(z)\nx_decoded_mean=decoder_mean(h_decoded)\n```", "```py\n# 2D visualization of latent space\n\nx_test_encoded = encoder_network.predict(x_test, batch_size=256)\nplt.figure(figsize=(8, 8))\nplt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test, cmap='Paired')\nplt.colorbar()\nplt.show()\n```", "```py\n# Plot many\nplt.figure(figsize=(5, 4))\nfor i in range(20):\n    plt.subplot(4, 5, i+1)\n    plt.imshow(x_train[i].reshape(32,32,3), cmap='gray')\n    plt.xticks([])\n    plt.yticks([])\nplt.tight_layout()\nplt.show()\n```", "```py\n# Input Placeholder\ndef gen(latent_dim, leaky_alpha, init_stddev ):\n    input_img = Input(shape=(latent_dim,))  # adapt this if using `channels_first` image data format\n\n# Encoder part\nx = Dense(32*32*3)(input_img)\nx = Reshape((4, 4, 192))(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = LeakyReLU(alpha=leaky_alpha)(x)\nx = Conv2DTranspose(256, kernel_size=5, strides=2, padding='same',\n                       kernel_initializer=RandomNormal(stddev=init_stddev))(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = LeakyReLU(alpha=leaky_alpha)(x)\nx = Conv2DTranspose(128, kernel_size=5, strides=2, padding='same',\nkernel_initializer=RandomNormal(stddev=init_stddev))(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = LeakyReLU(alpha=leaky_alpha)(x)\nx = Conv2DTranspose(3, kernel_size=5, strides=2, padding='same',\nkernel_initializer=RandomNormal(stddev=init_stddev), activation='tanh')(x)\ngenerator = Model(input_img, x)\ngenerator.summary()\nreturn generator\n```", "```py\ndef disc(leaky_alpha, init_stddev):\ndisc_input = Input(shape=(32,32,3)) \nx = Conv2D(64, kernel_size=5, strides=2, padding='same', kernel_initializer=RandomNormal(stddev=init_stddev))(disc_input)\nx = LeakyReLU(alpha=leaky_alpha)(x)\nx = Conv2D(128, kernel_size=5, strides=2, padding='same',\nkernel_initializer=RandomNormal(stddev=init_stddev))(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = LeakyReLU(alpha=leaky_alpha)(x)\nx = Conv2D(256,kernel_size=5, strides=2, padding='same',\nkernel_initializer=RandomNormal(stddev=init_stddev))(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = LeakyReLU(alpha=leaky_alpha)(x)\nx = Flatten()(x)\nx = Dropout(0.2)(x)\nx = Dense(1, activation='sigmoid')(x)\ndiscriminator = Model(disc_input, x)\ndiscriminator.summary()\nreturn discriminator\n```", "```py\ndef make_DCGAN(sample_size, \n               g_learning_rate,\n               g_beta_1,\n               d_learning_rate,\n               d_beta_1,\n               leaky_alpha,\n               init_std):\n    # clear first\n    K.clear_session()\n\n    # generator\n    generator = gen(sample_size, leaky_alpha, init_std)\n\n    # discriminator\n    discriminator = disc(leaky_alpha, init_std)\n    discriminator_optimizer = Adam(lr=d_learning_rate, beta_1=d_beta_1) #keras.optimizers.RMSprop(lr=d_learning_rate, clipvalue=1.0, decay=1e-8) \n    discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')\n\n    # GAN\n    gan = Sequential([generator, discriminator])\n    gan_optimizer = Adam(lr=g_learning_rate, beta_1=g_beta_1) #keras.optimizers.RMSprop(lr=g_learning_rate, clipvalue=1.0, decay=1e-8)\n    gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n\n    return generator, discriminator, gan\n```", "```py\ndef make_latent_samples(n_samples, sample_size):\n    #return np.random.uniform(-1, 1, size=(n_samples, sample_size))\n    return np.random.normal(loc=0, scale=1, size=(n_samples, sample_size))\ndef make_trainable(model, trainable):\n    for layer in model.layers:\n        layer.trainable = trainable\ndef make_labels(size):\n    return np.ones([size, 1]), np.zeros([size, 1])\n```", "```py\ndef show_results(losses):\n    labels = ['Classifier', 'Discriminator', 'Generator']\n    losses = np.array(losses)    \n\n    fig, ax = plt.subplots()\n    plt.plot(losses.T[0], label='Discriminator Net')\n    plt.plot(losses.T[1], label='Generator Net')\n    plt.title(\"Losses during training\")\n    plt.legend()\n    plt.show()\n\ndef show_images(generated_images):     \nn_images = len(generated_images)     \nrows = 4     cols = n_images//rows          \n\nplt.figure(figsize=(cols, rows))     \nfor i in range(n_images):         \nimg = deprocess(generated_images[i])         \nplt.subplot(rows, cols, i+1)         \nplt.imshow(img, cmap='gray')         \nplt.xticks([])         \nplt.yticks([])     \nplt.tight_layout()     \nplt.show()\n\n```", "```py\ndef train(\n    g_learning_rate,   # learning rate for the generator\n    g_beta_1,          # the exponential decay rate for the 1st moment estimates in Adam optimizer\n    d_learning_rate,   # learning rate for the discriminator\n    d_beta_1,          # the exponential decay rate for the 1st moment estimates in Adam optimizer\n    leaky_alpha,\n    init_std,\n    smooth=0.1,        # label smoothing\n    sample_size=100,   # latent sample size (i.e. 100 random numbers)\n    epochs=200,\n    batch_size=128,    # train batch size\n    eval_size=16):      # evaluate size\n\n    # labels for the batch size and the test size\n    y_train_real, y_train_fake = make_labels(batch_size)\n    y_eval_real,  y_eval_fake  = make_labels(eval_size)\n\n    # create a GAN, a generator and a discriminator\n    generator, discriminator, gan = make_DCGAN(\n        sample_size, \n        g_learning_rate, \n        g_beta_1,\n        d_learning_rate,\n        d_beta_1,\n        leaky_alpha,\n        init_std)\n\n    losses = []\n    for epoch_indx in range(epochs):\n        for i in tqdm(range(len(X_train_real)//batch_size)):\n            # real images\n            X_batch_real = X_train_real[i*batch_size:(i+1)*batch_size]\n\n            # latent samples and the generated images\n            latent_samples = make_latent_samples(batch_size, sample_size)\n            X_batch_fake = generator.predict_on_batch(latent_samples)\n\n            # train the discriminator to detect real and fake images\n            make_trainable(discriminator, True)\n            discriminator.train_on_batch(X_batch_real, y_train_real * (1 - smooth))\n            discriminator.train_on_batch(X_batch_fake, y_train_fake)\n\n            # train the generator via GAN\n            make_trainable(discriminator, False)\n            gan.train_on_batch(latent_samples, y_train_real)\n\n        # evaluate\n        X_eval_real = X_test_real[np.random.choice(len(X_test_real), eval_size, replace=False)]\n\n        latent_samples = make_latent_samples(eval_size, sample_size)\n        X_eval_fake = generator.predict_on_batch(latent_samples)\n\n        d_loss  = discriminator.test_on_batch(X_eval_real, y_eval_real)\n        d_loss += discriminator.test_on_batch(X_eval_fake, y_eval_fake)\n        g_loss  = gan.test_on_batch(latent_samples, y_eval_real) # we want the fake to be realistic!\n\n        losses.append((d_loss, g_loss))\n\n        print(\"At epoch:{:>3}/{},\\nDiscriminator Loss:{:>7.4f} \\nGenerator Loss:{:>7.4f}\".format(\n            epoch_indx+1, epochs, d_loss, g_loss))\n\n        if (epoch_indx+1)%1==0:\n            show_images(X_eval_fake)\n\n    show_results(losses)\n    return generator\n```", "```py\ndef train(\n    g_learning_rate,   # learning rate for the generator\n    g_beta_1,          # the exponential decay rate for the 1st moment estimates in Adam optimizer\n    d_learning_rate,   # learning rate for the discriminator\n    d_beta_1,          # the exponential decay rate for the 1st moment estimates in Adam optimizer\n    leaky_alpha,\n    init_std,\n    smooth=0.1,        # label smoothing\n    sample_size=100,   # latent sample size (i.e. 100 random numbers)\n    epochs=200,\n    batch_size=128,    # train batch size\n    eval_size=16):      # evaluate size\n```", "```py\n# labels for the batch size and the test size\n    y_train_real, y_train_fake = make_labels(batch_size)\n    y_eval_real,  y_eval_fake  = make_labels(eval_size)\n```", "```py\n# create a GAN, a generator and a discriminator\n    generator, discriminator, gan = make_DCGAN(\n        sample_size, \n        g_learning_rate, \n        g_beta_1,\n        d_learning_rate,\n        d_beta_1,\n        leaky_alpha,\n        init_std)\n```", "```py\n    losses = []\n    for epoch_indx in range(epochs):\n        for i in tqdm(range(len(X_train_real)//batch_size)):\n            # real images\n            X_batch_real = X_train_real[i*batch_size:(i+1)*batch_size]\n\n            # latent samples and the generated images\n            latent_samples = make_latent_samples(batch_size, sample_size)\n            X_batch_fake = generator.predict_on_batch(latent_samples)\n\n            # train the discriminator to detect real and fake images\n            make_trainable(discriminator, True)\n            discriminator.train_on_batch(X_batch_real, y_train_real * (1 - smooth))\n            discriminator.train_on_batch(X_batch_fake, y_train_fake)\n```", "```py\n# train the generator via GAN\nmake_trainable(discriminator, False)\ngan.train_on_batch(latent_samples, y_train_real)\n```", "```py\n# evaluate\n        X_eval_real = X_test_real[np.random.choice(len(X_test_real), eval_size, replace=False)]\n\n        latent_samples = make_latent_samples(eval_size, sample_size)\n        X_eval_fake = generator.predict_on_batch(latent_samples)\n\n        d_loss  = discriminator.test_on_batch(X_eval_real, y_eval_real)\n        d_loss += discriminator.test_on_batch(X_eval_fake, y_eval_fake)\n        g_loss  = gan.test_on_batch(latent_samples, y_eval_real) # we want the fake to be realistic!\n\n        losses.append((d_loss, g_loss))\n\n        print(\"At epoch:{:>3}/{},\\nDiscriminator Loss:{:>7.4f} \\nGenerator Loss:{:>7.4f}\".format(\n            epoch_indx+1, epochs, d_loss, g_loss))\n\n        if (epoch_indx+1)%1==0:\n            show_images(X_eval_fake)\n\n    show_results(losses)\n    return generator\n```"]