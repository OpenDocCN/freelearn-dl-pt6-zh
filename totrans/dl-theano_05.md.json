["```py\nconda install keras\n```", "```py\n>>> import keras\n*Using Theano backend.*\n*Using cuDNN version 5110 on context None*\n*Preallocating 10867/11439 Mb (0.950000) on cuda0*\n*Mapped name None to device cuda0: Tesla K80 (0000:83:00.0)*\n*Mapped name dev0 to device cuda0: Tesla K80 (0000:83:00.0)*\n*Using cuDNN version 5110 on context dev1*\n*Preallocating 10867/11439 Mb (0.950000) on cuda1*\n*Mapped name dev1 to device cuda1: Tesla K80 (0000:84:00.0)*\n\n```", "```py\n{\n    \"epsilon\": 1e-07,\n    \"floatx\": \"float32\",\n    \"image_data_format\": \"channels_last\",\n    \"backend\": \"theano\"\n}\n```", "```py\nKERAS_BACKEND=theano python\n\n```", "```py\nKERAS_BACKEND=theano THEANO_FLAGS=device=cuda,floatX=float32,mode=FAST_RUN python\n\n```", "```py\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\n\ninputs = Input(shape=(784,))\n\nx = Dense(64, activation='relu')(inputs)\npredictions = Dense(10, activation='softmax')(x)\nmodel = Model(inputs=inputs, outputs=predictions)\n```", "```py\n>>> model.input_shape\n*(None, 784)*\n\n>>> model.get_input_shape_at(0)\n*(None, 784)*\n\n>>> model.output_shape\n*(None, 10)*\n\n>>> model.get_output_shape_at(0)\n*(None, 10)*\n\n>>> model.name\n*'sequential_1'*\n\n>>> model.input\n*/dense_3_input*\n\n>>> model.output\n*Softmax.0*\n\n>>> model.get_output_at(0)\n*Softmax.0*\n\n>>> model.layers\n*[<keras.layers.core.Dense object at 0x7f0abf7d6a90>, <keras.layers.core.Dense object at 0x7f0abf74af90>]*\n\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\n\nmodel = Sequential()\nmodel.add(Dense(units=64, input_dim=784, activation='relu'))\nmodel.add(Dense(units=10, activation='softmax'))\n```", "```py\nmodel2 = Sequential()\nmodel2.add(model)\nmodel2.add(Dense(units=10, activation='softmax'))\n```", "```py\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.fit(data, labels)\n```", "```py\nwget http://alt.qcri.org/semeval2014/task9/data/uploads/semeval2013_task2_train.zip\nwget http://alt.qcri.org/semeval2014/task9/data/uploads/semeval2013_task2_dev.zip\nwget http://alt.qcri.org/semeval2014/task9/data/uploads/semeval2013_task2_test_fixed.zip\nunzip semeval2013_task2_train.zip\nunzip semeval2013_task2_dev.zip\nunzip semeval2013_task2_test_fixed.zip\n```", "```py\npip install bs4\npython download_tweets.py train/cleansed/twitter-train-cleansed-A.tsv > sem_eval2103.train\npython download_tweets.py dev/gold/twitter-dev-gold-A.tsv > sem_eval2103.dev\npython download_tweets.py SemEval2013_task2_test_fixed/gold/twitter-test-gold-A.tsv > sem_eval2103.test\n```", "```py\nimport re\nfrom nltk.tokenize import TweetTokenizer\n\ndef process(tweet):\n  tknz = TweetTokenizer()\n  tokens = tknz.tokenize(tweet)\n  tweet = \" \".join(tokens)\n  tweet = tweet.lower()\n  tweet = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', '<url>', tweet) # URLs\n  tweet = re.sub(r'(?:@[\\w_]+)', '<user>', tweet)  # user-mentions\n  tweet = re.sub(r'(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)', '<hashtag>', tweet)  # hashtags\n  tweet = re.sub(r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', '<number>', tweet)  # numbers\n  return tweet.split(\" \")\n```", "```py\ntweet = 'RT @mhj: just an example! :D http://example.com #NLP'\nprint(process(tweet))\n```", "```py\n[u'rt', u'\\<user\\>', u':', u'just', u'an', u'example', u'!', u':d', u'\\<url\\>', u'\\<hashtag\\>']\n```", "```py\ndef read_data(file_name):\n  tweets = []\n  labels = []\n  polarity2idx = {'positive': 0, 'negative': 1, 'neutral': 2}\n  with open(file_name) as fin:\n    for line in fin:\n      _, _, _, _, polarity, tweet = line.strip().split(\"\\t\")\n      tweet = process(tweet)\n      cls = polarity2idx[polarity]\n      tweets.append(tweet)\n      labels.append(cls)\n  return tweets, labels\n\ntrain_file = 'sem_eval2103.train'\ndev_file = 'sem_eval2103.dev'\n\ntrain_tweets, y_train = read_data(train_file)\ndev_tweets, y_dev = read_data(dev_file)\n```", "```py\ndef get_vocabulary(data):\n  max_len = 0\n  index = 0\n  word2idx = {'<unknown>': index}\n  for tweet in data:\n    max_len = max(max_len, len(tweet))\n    for word in tweet:\n      if word not in word2idx:\n        index += 1\n        word2idx[word] = index\n  return word2idx, max_len\n\nword2idx, max_len = get_vocabulary(train_tweets)\nvocab_size = len(word2idx)\n```", "```py\ndef transfer(data, word2idx):\n  transfer_data = []\n  for tweet in data:\n    tweet2vec = []\n    for word in tweet:\n      if word in word2idx:\n        tweet2vec.append(word2idx[word])\n      else:\n        tweet2vec.append(0)\n    transfer_data.append(tweet2vec)\n  return transfer_data\n\nX_train = transfer(train_tweets, word2idx)\nX_dev  = transfer(dev_tweets, word2idx)\n```", "```py\ndel train_tweets, dev_tweets\n```", "```py\nfrom keras.preprocessing.sequence import pad_sequences\nX_train = pad_sequences(X_train, maxlen=max_len, truncating='post')\nX_dev = pad_sequences(X_dev, maxlen=max_len, truncating='post')\n```", "```py\nfrom keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train)\ny_dev = to_categorical(y_dev)\n```", "```py\nfrom keras.layers import Embedding\nd = 100\nemb_layer = Embedding(vocab_size + 1, output_dim=d, input_length=max_len)\n```", "```py\nfrom keras.models import Sequential\nmodel = Sequential()\nmodel.add(emb_layer)\n```", "```py\nfrom keras.layers import LSTM\nrnn_size = 64\nlstm = LSTM(rnn_size, input_shape=(max_len, d))\n```", "```py\nlstm = LSTM(rnn_size, input_dim=d, input_length=max_len)\n```", "```py\nlstm = LSTM(rnn_size)\n```", "```py\nfrom keras.layers import Bidirectional\nbi_lstm = Bidirectional(lstm)\nmodel.add(bi_lstm)\n```", "```py\nfrom keras.layers import Dense, Activation\n\nnb_classes = 3\nfc = Dense(nb_classes)\nclassifier = Activation('softmax')\nmodel.add(fc)\nmodel.add(classifier)\n```", "```py\nprint(model.summary())\nWhich will end with the results:\nUsing Theano backend:\n__________________________________________________________________________________________\nLayer (type)                      Output Shape        Param #         Connected to                     \n=========================================================================================\nembedding_1 (Embedding)           (None, 30, 100)     10000100    embedding_input_1[0][0]          \n_________________________________________________________________________________________\nbidirectional_1 (Bidirectional)   (None, 128)            84480          embedding_1[0][0]                \n__________________________________________________________________________________________\ndense_1 (Dense)                   (None, 3)                387      bidirectional_1[0][0]            \n__________________________________________________________________________________________\nactivation_1 (Activation)         (None, 3)                  0              dense_1[0][0]                    \n=========================================================================================\nTotal params: 10,084,967\nTrainable params: 10,084,967\nNon-trainable params: 0\n__________________________________________________________________________________________\n```", "```py\nmodel.compile(optimizer='rmsprop',\n          loss='categorical_crossentropy',\n          metrics=['accuracy'])\n```", "```py\nmodel.fit(x=X_train, y=y_train, batch_size=10, epochs=30, validation_data=[X_dev, y_dev])\n```", "```py\ntest_file = 'sem_eval2103.test'\ntest_tweets, y_test = read_data(test_file)\n\nX_test  = transfer(test_tweets, word2idx)\n\ndel test_twee \n\nX_test = pad_sequences(X_test, maxlen=max_len, truncating='post')\n\ny_test = to_categorical(y_test)\n\ntest_loss, test_acc = model.evaluate(X_test, y_test)\n\nprint(\"Testing loss: {:.5}; Testing Accuracy: {:.2%}\" .format(test_loss, test_acc))\n```", "```py\nmodel.save('bi_lstm_sentiment.h5')\n```", "```py\nfrom keras.models import load_model\nloaded_model = load_model('bi_lstm_sentiment.h5')\n```", "```py\ntest_loss, test_acc = loaded_model.evaluate(X_test, y_test)\nprint(\"Testing loss: {:.5}; Testing Accuracy: {:.2%}\" .format(test_loss, test_acc))\n```", "```py\npython bilstm.py\n```"]