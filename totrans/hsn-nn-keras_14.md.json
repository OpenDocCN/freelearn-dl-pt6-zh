["```py\n \"import numpy as np\\n\",\n \"import matplotlib.pyplot as plt\\n\",\n \"% matplotlib inline\\n\",\n \"\\n\",\n \"\\n\",\n \"from keras import applications\\n\",\n \"from keras import optimizers\\n\",\n \"from keras.models import Sequential, Model \\n\",\n \"from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Input\\n\",\n \"from keras import backend as k \\n\",\n \"from keras.datasets import cifar10\\n\",\n \"from keras import utils\"\n```", "```py\nimg_width, img_height = 32, 32\nmodel = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\nmodel.summary()\n```", "```py\nmodel2= Model(inputs=model.input, outputs=   \n              model.get_layer('block3_pool').output) \nmodel2.summary()\n```", "```py\n #Adding custom Layers\n num_classes = 10\n\n x = model2.output\n x = Flatten()(x)\n x = Dense(1024, activation=\"relu\")(x)\n x = Dropout(0.5)(x)\n x = Dense(1024, activation=\"relu\")(x)\n predictions = Dense(num_classes, activation=\"softmax\")(x)\n```", "```py\n# creating the final model\nmodel_final = Model(input = model2.input, output = predictions)\nmodel_final.summary()\n```", "```py\n# Freeze the layers that dont need to train\nfor layer in model2.layers[:4]:\n    layer.trainable = False\n```", "```py\n(x_train, y_train),(x_test, y_test)=cifar10.load_data() \nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\ny_train = utils.to_categorical(y_train, num_classes)\ny_test = utils.to_categorical(y_test, num_classes)\n```", "```py\n# compile the model\nmodel_final.compile(loss = \"categorical_crossentropy\", optimizer =  \n      optimizers.Adam(lr=0.0001), metrics=[\"accuracy\"])\n```"]