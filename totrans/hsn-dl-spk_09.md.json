["```py\nsepal_length,sepal_width,petal_length,petal_width,species\n 5.1,3.5,1.4,0.2,0\n 4.9,3.0,1.4,0.2,0\n 4.7,3.2,1.3,0.2,0\n 4.6,3.1,1.5,0.2,0\n 5.0,3.6,1.4,0.2,0\n 5.4,3.9,1.7,0.4,0\n ...\n```", "```py\nval numLinesToSkip = 1\n val delimiter = \",\"\n val recordReader = new CSVRecordReader(numLinesToSkip, delimiter)\n recordReader.initialize(new FileSplit(new ClassPathResource(\"iris.csv\").getFile))\n```", "```py\nval labelIndex = 4\n val numClasses = 3\n val batchSize = 150\n\n val iterator: DataSetIterator = new RecordReaderDataSetIterator(recordReader, batchSize, labelIndex, numClasses)\n val allData: DataSet = iterator.next\n allData.shuffle()\n```", "```py\nval iterator: DataSetIterator = new RecordReaderDataSetIterator(recordReader, batchSize, labelIndex, numClasses)\n val allData: DataSet = iterator.next\n allData.shuffle()\n val testAndTrain: SplitTestAndTrain = allData.splitTestAndTrain(0.70)\n\n val trainingData: DataSet = testAndTrain.getTrain\n val testData: DataSet = testAndTrain.getTest\n```", "```py\nval normalizer: DataNormalization = new NormalizerStandardize\n normalizer.fit(trainingData)\n normalizer.transform(trainingData)\n normalizer.transform(testData)\n```", "```py\nval conf = new NeuralNetConfiguration.Builder()\n   .seed(seed)\n   .activation(Activation.TANH)\n   .weightInit(WeightInit.XAVIER)\n   .l2(1e-4)\n   .list\n   .layer(0, new DenseLayer.Builder().nIn(numInputs).nOut(3)\n     .build)\n   .layer(1, new DenseLayer.Builder().nIn(3).nOut(3)\n     .build)\n   .layer(2, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n     .activation(Activation.SOFTMAX)\n     .nIn(3).nOut(outputNum).build)\n   .backprop(true).pretrain(false)\n   .build\n```", "```py\nval model = new MultiLayerNetwork(conf)\n model.init()\n model.setListeners(new ScoreIterationListener(100))\n```", "```py\nfor(idx <- 0 to 2000) {\n   model.fit(trainingData)\n }\n```", "```py\nval eval = new Evaluation(3)\n val output = model.output(testData.getFeatureMatrix)\n eval.eval(testData.getLabels, output)\n println(eval.stats)\n```", "```py\nprintln(eval.confusionToString)\n```", "```py\neval.getConfusionMatrix.toCSV\n```", "```py\neval.getConfusionMatrix.toHTML\n```", "```py\nval testData = new ClassPathResource(\"/mnist_png/testing\").getFile\n val testSplit = new FileSplit(testData, NativeImageLoader.ALLOWED_FORMATS, randNumGen)\n val testRR = new ImageRecordReader(height, width, channels, labelMaker)\n testRR.initialize(testSplit)\n val testIter = new RecordReaderDataSetIterator(testRR, batchSize, 1, outputNum)\n testIter.setPreProcessor(scaler)\n```", "```py\nval testDataList = mutable.ArrayBuffer.empty[DataSet]\n while (testIter.hasNext) {\n     testDataList += testIter.next\n }\n\n val paralleltesnData = sc.parallelize(testDataList)\n```", "```py\nval sparkNet = new SparkDl4jMultiLayer(sc, conf, tm)\n\n var numEpochs: Int = 15\n var i: Int = 0\n for (i <- 0 until numEpochs) {\n     sparkNet.fit(paralleltrainData)\n     val eval = sparkNet.evaluate(parallelTestData)\n     println(eval.stats)\n     println(\"Completed Epoch {}\", i)\n     trainIter.reset\n     testIter.reset\n }\n```", "```py\nval eval = new RegressionEvaluation(3)\n val output = model.output(testData.getFeatureMatrix)\n eval.eval(testData.getLabels, output)\n println(eval.stats)\n```", "```py\nval size:Int = 1\n val eval: EvaluationBinary = new EvaluationBinary(size)\n```"]