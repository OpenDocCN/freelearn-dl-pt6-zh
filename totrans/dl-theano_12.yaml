- en: Chapter 12. Learning Features with Unsupervised Generative Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter focuses on a new type of model, the generative models, which include
    **Restricted Boltzmann Machines**, **Deep Belief Networks**, **Variational Auto
    Encoders**, **Autoregressive models, and Generative Adversarial** Networks. For
    the first nets, we've limited the presentation to the theory, while the last is
    explained in detail with practical code and advice.
  prefs: []
  type: TYPE_NORMAL
- en: These nets do not require any labels to be trained, which is called *unsupervised
    learning*. Unsupervised learning helps compute features from the data, without
    the bias of the labels. These models are generative in the sense that they are
    trained to generate new data that sounds real.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following points will be covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Generative models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restricted Boltzmann Machines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep belief networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative adversarial models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A generative model in neural processing is a model that generates data given
    a noise vector *z* as input:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generative models](img/00233.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The purpose of the training is to find the parameters to generate data as close
    as possible to the real data.
  prefs: []
  type: TYPE_NORMAL
- en: Applications of generative networks include data dimensionality reduction, synthetic
    data generation, unsupervised feature learning, and pre-training / training efficiency.
    Pre-training helps generalization because pre-training focuses on the patterns
    in the data, and less on the data-label relation.
  prefs: []
  type: TYPE_NORMAL
- en: Restricted Boltzmann Machines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A Restricted Boltzmann Machine is the simplest generative net, composed of
    one fully connected hidden layer, as shown in the picture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Restricted Boltzmann Machines](img/00234.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The full Boltzmann Machines have also hidden-to-hidden and visible-to-visible
    loop connections, while the *Restricted* version does not have any.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the general case, RBM are defined as *energy-based models*, which means
    that they define a probability distribution through an energy function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Restricted Boltzmann Machines](img/00235.jpeg)![Restricted Boltzmann Machines](img/00236.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Z* is the **partition function**, and *E(v)* is the **free energy** function
    (does not depend on the hidden state).'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Minimizing the negative log likelihood is equivalent to minimizing the energy
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The RBM defines the energy function as a linearity in the parameters of the
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Restricted Boltzmann Machines](img/00237.jpeg)![Restricted Boltzmann Machines](img/00238.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The relation between the energy and the free energy is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Restricted Boltzmann Machines](img/00239.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the case of the RBM:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Restricted Boltzmann Machines](img/00240.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Here ![Restricted Boltzmann Machines](img/00241.jpeg) denotes the sum over possible
    values of the i-th hidden neuron.
  prefs: []
  type: TYPE_NORMAL
- en: 'The RBM are usually considered in the particular case where `v` and `h` are
    binomial values in *{0,1}*, so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Restricted Boltzmann Machines](img/00242.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The model is symmetric, following the symmetry in the model: hidden and visible
    have the same place in the energy function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Restricted Boltzmann Machines](img/00243.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: RBM works as a simple stochastic fully connected layer in both directions (from
    input to hidden, and from hidden to input).
  prefs: []
  type: TYPE_NORMAL
- en: 'The gradient or derivative of the negative log-likelihood for the RBM has two
    terms, defined as **positive and negative phases**, where the first term increases
    the probability of data, and the second term decreases the probability of generated
    samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Restricted Boltzmann Machines](img/00244.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Here, the sum is over all possible inputs ![Restricted Boltzmann Machines](img/00245.jpeg)
    weighted by its probability (the expectation). At the minima, any increase in
    the free energy of our data sample will decrease the expectation of the total
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Empirically, such a sum in the negative phase can be transformed into a sum
    over *N* observed (*v,h*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Restricted Boltzmann Machines](img/00246.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: To compute such a sum in practice, the probability of observing the sample (*v,h*)
    has to satisfy *p(v | h)* given by the above formula as well as *p(h | v)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sampling is performed via the contrastive divergence algorithm, in practice:
    *v* is sampled from the dataset, while *h* is drawn following its above distribution
    given *v*. This operation is repeated, to produce a new *v* given *h*, then a
    new *h* given *v*. In practice, this is sufficient to achieve samples closely
    distributed to the real distribution. These observed samples for *v* and *h* are
    referred to as **negative particles**, and the second term in the cost function
    decreases the probability of these generated samples, while the first term increases
    the probability of the data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what the computation of the partition function with the negative particules
    would look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The pictures of the filters trained on MNIST dataset after 15 epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Restricted Boltzmann Machines](img/00247.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'And a mini-batch of negative particles (1,000 steps of sampling between each
    row):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Restricted Boltzmann Machines](img/00248.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Deep belief bets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **deep belief network** (**DBN**) is a stack of multiple RBMs to increase
    their representative power and better capture patterns in the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The training occurs layer by layer, first considering there is only one RBM
    with the hidden state ![Deep belief bets](img/00249.jpeg). Once the weights of
    the RBM have been trained, these weights are kept fixed and the hidden layer of
    the first RBM ![Deep belief bets](img/00249.jpeg) is considered as the visible
    layer for a second RBM, with one hidden state ![Deep belief bets](img/00250.jpeg).
    Each new RBM will capture patterns that have not been captured by the previous
    RBM as in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deep belief bets](img/00251.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: It can be shown that each add-on of a new RBM on top of the stack decreases
    the negative log likelihood.
  prefs: []
  type: TYPE_NORMAL
- en: As last step, it is possible to use these weights in a classification network,
    by simply adding a linear layer and a softmax layer on top of the final hidden
    state, and fine-tuning all the weights via gradient descent training, as usual.
  prefs: []
  type: TYPE_NORMAL
- en: 'The application to data dimensionality remains the same, with the unrolling
    of all layers to produce a decoder network, with weights equal to the transpose
    of the weights in the encoder network (initial multi-layer RBM):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deep belief bets](img/00252.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Such an unrolled network is called an **auto encoder**.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, training directly via a gradient descent without the greedy layer
    by layer training would require finding the right initialization, which could
    be a lot trickier, as the weight initialization has to be close enough to the
    solution. That is why the commonly used approach for auto encoders is to train
    each RBM separately.
  prefs: []
  type: TYPE_NORMAL
- en: Generative adversarial networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since the partition function in the previous models is untractable and requires
    contrastive divergence algorithm with Gibbs sampling, game theory has recently
    delivered a new class of methods for learning generative models, the **Generative
    adversarial networks** (**GANs**), which enjoys great success today.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generative adversarial networks are composed of two models that are alternatively
    trained to compete with each other. The generator network **G** is optimized to
    reproduce the true data distribution, by generating data that is difficult for
    the discriminator **D** to differentiate from real data. Meanwhile, the second
    network D is optimized to distinguish real data and synthetic data generated by
    G. Overall, the training procedure is similar to a two-player min-max game with
    the following objective function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generative adversarial networks](img/00253.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *x* is real data sampled from real data distribution, and *z* the noise
    vector of the generative model. In some ways, the discriminator and the generator
    can be seen as the police and the thief: to be sure the training works correctly,
    the police is trained twice as much as the thief.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's illustrate GANs with the case of images as data. In particular, let's
    again take our example from [Chapter 2](part0026_split_000.html#OPEK1-ccdadb29edc54339afcb9bdf9350ba6b
    "Chapter 2. Classifying Handwritten Digits with a Feedforward Network"), *Classifying
    Handwritten Digits with a Feedforward Network* about MNIST digits, and consider
    training a generative adversarial network, to generate images, conditionally on
    the digit we want.
  prefs: []
  type: TYPE_NORMAL
- en: 'The GAN method consists of training the generative model using a second model,
    the discriminative network, to discriminate input data between real and fake.
    In this case, we can simply reuse our MNIST image classification model as discriminator,
    with two classes, `real` or `fake`, for the prediction output, and also condition
    it on the label of the digit that is supposed to be generated. To condition the
    net on the label, the digit label is concatenated with the inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note the use of two leaky rectified linear units, with a leak of 0.2, as activation
    for the first two convolutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'To generate an image given noise and label, the generator network consists
    of a stack of deconvolutions, using an input noise vector z that consists of 100
    real numbers ranging from 0 to 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generative adversarial networks](img/00254.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To create a deconvolution in Theano, a dummy convolutional forward pass is
    created, which gradient is used as deconvolution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Real data is given by the tuple (X,Y), while generated data is built from noise
    and label (Z,Y):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Generator and discriminator models compete during adversarial learning:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The discriminator is trained to label real data as real (`1`) and label generated
    data as generated (`0`), hence minimizing the following cost function:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The generator is trained to deceive the discriminator as much as possible.
    The training signal for the generator is provided by the discriminator network
    (p_gen) to the generator:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The same as usual follows. Cost with respect to the parameters for each model
    is computed and training optimizes the weights of each model alternatively, with
    two times more the discriminator. In the case of GANs, competition between discriminator
    and generator does not lead to decreases in each loss.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the first epoch:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generative adversarial networks](img/00255.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To the 45th epoch:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generative adversarial networks](img/00256.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Generated examples look closer to real ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generative adversarial networks](img/00257.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Improve GANs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GANs are recent and very promising but still undergoing heavy research today.
    Yet, there are ways to improve the previous results.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, as for RBM and other networks, GANs can be stacked in order to increase
    their generative power. As an example, the StackGan model proposes to use two
    stacked GANs for high quality image generation: the first GAN generates a coarse
    and low resolution image, while the second uses this generated sample as the input
    to generate an image of higher definition and realism, in which details of the
    objects are precised.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the main issues with GAN is the **model collapse**, which makes them
    difficult to train. Model collapse occurs when the generator begins to ignore
    the input noise and learns to generate only one sample, always the same. Diversity
    in the generation has collapsed. One very nice way to deal with this comes from
    the S-GAN model, and consists of adding a third net to train with the generator.
    The purpose of this net is to predict back the noise given the input:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Improve GANs](img/00258.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To optimize this third net with the generator, an entropy loss is added to
    the generator loss, to encourage the generated images *x* to be sufficiently dependent
    on the noise *z*. In other words, the conditional entropy *H(x | z)* has to be
    as low as possible:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Improve GANs](img/00259.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: This third net predicts an auxiliary distribution Q to approximate the true
    posterior *P(z | x)* and can be proved to be a variational higher bound for *H(x
    | z)*. Such a loss function helps the generator not to ignore the input noise.
  prefs: []
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Last but not least, such generative adversarial networks can be used to enhance
    supervised learning itself.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose the objective is to classify *K* classes, for which an amount of labeled
    data is available. It is possible to add some generated samples to the dataset,
    which come from a generative model, and consider them as belonging to a *(K+1)th*
    class, the fake data class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Decomposing the training cross-entropy loss of the new classifier between the
    two sets (real data and fake data) leads to the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Semi-supervised learning](img/00260.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![Semi-supervised learning](img/00261.jpeg) is the probability predicted
    by the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Semi-supervised learning](img/00262.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that if we know that the data is real:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Semi-supervised learning](img/00263.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'And training on real data (K classes) would have led to the loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Semi-supervised learning](img/00264.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Hence the loss of the global classifier can be rewritten:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Semi-supervised learning](img/00265.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The second term of the loss corresponds to the standard unsupervised loss for
    GAN:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Semi-supervised learning](img/00266.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The interaction introduced between the supervised and the unsupervised loss
    is still not well understood but, when the classification is not trivial, an unsupervised
    loss helps.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can refer to the following topics for more insights:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Deeplearning.net tutorial on RBM*: [http://deeplearning.net/tutorial/rbm.html](http://deeplearning.net/tutorial/rbm.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Deeplearning.net tutorial on Deep Belief Nets*: [http://deeplearning.net/tutorial/DBN.html](http://deeplearning.net/tutorial/DBN.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Deeplearning.net tutorial on generating with RBM-RNN*: [http://deeplearning.net/tutorial/rnnrbm.html](http://deeplearning.net/tutorial/rnnrbm.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Modeling Temporal Dependencies in High-Dimensional Sequences: Application
    to Polyphonic Music Generation and Transcription*, Nicolas Boulanger-Lewandowski,
    Yoshua Bengio, Pascal Vincent, 2012'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative Adversarial Networks, Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi
    Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio,
    2014
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Gans will* *change the world*, Nikolai Yakovenko, 2016 [https://medium.com/@Moscow25/](https://medium.com/@Moscow25/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Pixel Recurrent Neural Networks*, Aaron van den Oord, Nal Kalchbrenner, Koray
    Kavukcuoglu, 2016'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*InfoGAN: Interpretable Representation Learning by Information Maximizing Generative
    Adversarial Nets,* Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever,
    Pieter Abbeel, 2016'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial
    Networks*, Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaolei Huang, Xiaogang
    Wang, Dimitris Metaxas, 2016'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Stacked Generative Advanced Networks*, Xun Huang, Yixuan Li, Omid Poursaeed,
    John Hopcroft, Serge Belongie, 2016'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Adversarial Learning for Neural Dialogue Generation*, Jiwei Li, Will Monroe,
    Tianlin Shi, Sébastien Jean, Alan Ritter, Dan Jurafsky, 2017'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Improved Techniques for Training GANs*, Tim Salimans, Ian Goodfellow, Wojciech
    Zaremba, Vicki Cheung, Alec Radford, Xi Chen, 2016'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Unsupervised Representation Learning with Deep Convolutional Generative Adversarial
    Networks*, Alec Radford, Luke Metz, Soumith Chintala, 2015'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative adversarial networks are a very active area of research today. They
    belong to the family of generative models, which includes RBM and deep belief
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: Generative models aim at generating more data, or learning better features for
    supervised and other tasks in an unsupervised way.
  prefs: []
  type: TYPE_NORMAL
- en: Generative models can be conditioned on some environmental input, and try to
    find the hidden variables behind the real data.
  prefs: []
  type: TYPE_NORMAL
- en: These models, the most advanced, complete the overview of deep learning nets
    with Theano. The next chapter will look at some advanced concepts to extend Theano
    and the future of deep learning.
  prefs: []
  type: TYPE_NORMAL
