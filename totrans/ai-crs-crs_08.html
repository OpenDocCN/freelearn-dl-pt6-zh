<html><head></head><body>
		<div id="_idContainer264">
			<h1 class="chapterNumber sigil_not_in_toc">8</h1>
			<h1 class="chapterTitle" xml:lang="en-GB" id="sigil_toc_id_107" lang="en-GB"><a id="_idTextAnchor158"/>AI for Logistics – Robots in a Warehouse</h1>
</div>

			<p class="normal">It's time for the next step on our AI journey. I 
told you at the beginning of this book that AI has tremendous value to 
bring to transport and logistics, with self-driving delivery vehicles 
that speed up logistical processes. They're a huge boost to the economy 
through the e-commerce industry.</p>
			<p class="normal">In this new chapter, we'll build an AI for just 
that kind of application. The model we'll use for this will, of course, 
be Q-learning (we're saving deep Q-learning for the self-driving car). 
Q-learning is a<a id="_idIndexMarker200"/> simple, but powerful, AI 
model that can optimize the flows of movement in a warehouse, which is 
the real-world problem you'll solve here. In order to facilitate this 
journey, you'll work on an environment you're already familiar with: the
 maze we saw in the previous chapter.</p>
			<p class="normal">The difference is that, this time, the maze will 
actually be the warehouse of a business. It could be any business: an 
e-commerce business, a retail business, or any business that sells 
products to customers and that has a warehouse to store large amounts of
 products to be sold.</p>
			<p class="normal">Let's have a look again at this maze, now a warehouse:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_08_01.png" alt=""/></figure>
			<p class="packt_figref">Figure 1: The warehouse</p>
			<p class="normal">Inside this <a id="_idIndexMarker201"/>warehouse, the products are stored in 12 different locations, labeled by the following letters from <strong class="bold">A</strong> to <strong class="bold">L</strong>:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_08_02.png" alt=""/></figure>
			<p class="packt_figref">Figure 2: Locations in the warehouse</p>
			<p class="normal">When orders are <a id="_idIndexMarker202"/>placed
 by customers, a robot moves around the warehouse to collect the 
products for delivery. That will be your AI! Here's what it looks like:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_08_03.png" alt=""/></figure>
			<p class="packt_figref">Figure 3: Warehouse robot</p>
			<p class="normal">The 12 locations are all connected to a computer 
system, which ranks in real time the product collection priorities for 
these 12 locations. As an example, let's say that at a specific time, <em class="italics">t</em>, it returns the following ranking:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_08_04.png" alt=""/></figure>
			<p class="packt_figref">Figure 4: Top priority locations</p>
			<p class="normal">Location <strong class="bold">G</strong> has <a id="_idIndexMarker203"/>priority 1, which means it's the top priority, as it contains a product that must be <a id="_idIndexMarker204"/>collected and delivered immediately. Our robot must move to location <strong class="bold">G</strong>
 by the shortest route depending on where it is. Our goal is to actually
 build an AI that will return that shortest route, wherever the robot 
is.</p>
			<p class="normal">But we could do even better. Here, locations <strong class="bold">K</strong> and <strong class="bold">L</strong>
 are in the top 3 priorities. Hence, it would be great to implement an 
option for our robot to go via some intermediary locations before 
reaching its final top priority location.</p>
			<p class="normal">The way the system computes the priorities of the 
locations is outside the scope of this case study. The reason for this 
is that there can be many ways, from simple rules or algorithms, to 
deterministic computations, to machine learning, to compute these 
priorities. But most of these ways would not be AI as we know it today. 
What we really want to focus on in this exercise is the core AI, 
encompassing Reinforcement Learning and Q-learning. We can just say for 
the purposes of this example that location <strong class="bold">G</strong>
 is the top priority because one of the most loyal platinum-level 
customers of the company placed an urgent order of a product stored in 
location <strong class="bold">G</strong>, which therefore must be delivered as soon as possible.</p>
			<p class="normal">In conclusion, our mission is to build an AI that 
will always take the shortest route to the top priority location, 
whatever the location it starts from, and have the option to go by an 
intermediary location which is in the top three priorities.<a id="_idTextAnchor159"/></p>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_108" lang="en-GB"><a id="_idTextAnchor160"/>Building the environment</h2>
			<p class="normal">When building an AI, the first<a id="_idIndexMarker205"/> thing we always have to do is define the environment. Defining an environment always requires the following three <a id="_idIndexMarker206"/>elements:</p>
			<ul>
				<li class="list">Defining the states</li>
				<li class="list">Defining the actions</li>
				<li class="list">Defining the rewards</li>
			</ul>
			<p class="normal">These three elements have already been defined in 
the previous chapter on Q-learning, but let's quickly remind ourselves 
what they ar<a id="_idTextAnchor161"/>e.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_109" lang="en-GB"><a id="_idTextAnchor162"/>The states</h3>
			<p class="normal">The state, at a<a id="_idIndexMarker207"/> specific time <em class="italics">t</em>, is the location where the robot is at that time <em class="italics">t</em>. However, remember, you have to encode the location names so that our AI can do the math. </p>
			<p class="normal">At the risk of disappointing you, given all the 
crazy hype about AI, let's remain realistic and understand that 
Q-learning is nothing more than a bunch of math equations; just like any
 other AI model. Let's make the encoding integers start at 0, simply 
because indexes in Python start at 0:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_08_05.png" alt=""/></figure>
			<p class="packt_figref">Figure 5: Location to state mapping</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_110" lang="en-GB"><a id="_idTextAnchor163"/>The actions</h3>
			<p class="normal">The actions are the<a id="_idIndexMarker208"/> 
next possible destinations to which the robot can go. You can encode 
these destinations with the same indexes as the states. Hence, the total
 list of actions that the AI can perform is the following:</p>
			<pre class="programlisting language-markup"><code class="hljs lsl">actions = [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>,<span class="hljs-number">10</span>,<a id="_idTextAnchor164"/><span class="hljs-number">11</span>]
</code></pre>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_111" lang="en-GB"><a id="_idTextAnchor165"/>The rewards</h3>
			<p class="normal">Remember, when<a id="_idIndexMarker209"/> in a specific location, there are some actions that the robot cannot perform. For example, if the robot is in location <strong class="bold">J</strong>,
 it can perform the actions 5, 8, and 10, but it cannot perform the 
other actions. You can specify that by attributing a reward of 0 to the 
actions it cannot perform, and a reward of 1 to the actions it can 
perform. </p>
			<p class="normal">That brings you to building the following matrix of rewards:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_08_06.png" alt=""/></figure>
			<p class="packt_figref">Figure 6: Rewards matrix</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_112" lang="en-GB"><a id="_idTextAnchor166"/>AI solution refresher</h3>
			<p class="normal">It never hurts to get <a id="_idIndexMarker210"/>a little refresher of a model<a id="_idIndexMarker211"/>
 before implementing it! Let's remind ourselves of the steps of the 
Q-learning process; this time, adapting it to your new problem. Let's 
welcome Q-learning back on stage:</p>
			<h4 class="title" xml:lang="en-GB" id="sigil_toc_id_113" lang="en-GB"><a id="_idTextAnchor167"/>Initialization (first iteration)</h4>
			<p class="normal">For all pairs of states <em class="italics">s</em> and <a id="_idIndexMarker212"/>actions <em class="italics">a</em>, the Q-values are initialized to 0:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/Image15036.png" style="height: 1.25em;" alt=""/></figure>
			<h4 class="title" xml:lang="en-GB" id="sigil_toc_id_114" lang="en-GB"><a id="_idTextAnchor168"/>Next iterations</h4>
			<p class="normal">At each iteration <em class="italics">t</em> ≥ 1, the AI will<a id="_idIndexMarker213"/> repeat the following steps:</p>
			<ol>
				<li class="list">It selects a random state <span class="mediaobject"><img src="../Images/B14110_08_002.png" alt=""/></span> from the possible states:<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_08_003.png" style="height: 1.75em;" alt=""/></figure></li>
				<li class="list">It performs a random action <span class="mediaobject"><img src="../Images/B14110_08_004.png" alt=""/></span> that can lead to a next possible state, that is, such that <span class="mediaobject"><img src="../Images/B14110_08_005.png" alt=""/></span>:<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_08_006.png" style="height: 1.75em;" alt=""/></figure></li>
				<li class="list">It reaches the next state <span class="mediaobject"><img src="../Images/B14110_08_007.png" alt=""/></span> and gets the reward <span class="mediaobject"><img src="../Images/B14110_08_008.png" alt=""/></span>.</li>
				<li class="list">It computes the temporal difference <span class="mediaobject"><img src="../Images/B14110_08_009.png" alt=""/></span>:
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_08_010.png" style="height: 2.25em;" alt=""/></figure>
			</li>
				<li class="list">It updates the Q-value by applying the Bellman equation:
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_08_011.png" style="height: 1.75em;" alt=""/></figure>
</li>
</ol>
			<p class="normal">We repeat these steps over 1,000 iterations. Why 
1,000? The choice of 1,000 comes from my experimentation with this 
particular environment. I chose a number that's large enough for the<a id="_idIndexMarker214"/>
 Q-values to converge over the training. 100 wasn't large enough, but 
1,000 was. Usually, you can just pick a very large number, for example, 
5,000, and you will get convergence (that is, the Q-values will no 
longer update). However, that depends on the complexity of the problem. 
If you are dealing with a much more complex environment, for example, if
 you had hundreds of locations in the warehouse, you'd need a much 
higher number of training iterations.</p>
			<p class="normal">That's the whole process. Now, you're going to implement it in Python from scratch!</p>
			<p class="normal">Are you ready? Let's do this.</p>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_115" lang="en-GB">Im<a id="_idTextAnchor169"/>plementation</h2>
			<p class="normal">Alright, let's smash this. But first, try to smash 
this yourself without me. Of course, this is a journey we'll take 
together, but I really don't mind if you take some steps ahead of me. 
The faster you become independent in AI, the sooner you'll do wonders 
with it. Try to implement the Q-learning process mentioned previously, 
exactly as it is. It's okay if you don't implement everything; what 
matters is that you try.</p>
			<p class="normal">That's enough coaching; no matter<a id="_idIndexMarker215"/> how successful you were, let's go through the solution.</p>
			<p class="normal">First, start by importing the libraries that you'll use in this implementation. There's only one needed this time: the <code class="Code-In-Text--PACKT-">numpy</code> library, which offers a practical way of working with arrays and mathematical operations. Give it the shortcut <code class="Code-In-Text--PACKT-">np</code>.</p>
			<pre class="programlisting language-markup"><code class="hljs capnproto"><span class="hljs-comment"># AI for Logistics - Robots in a warehouse</span>
<span class="hljs-comment"># Importing the libraries</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
</code></pre>
			
			
			<p class="normal">Then, set the parameters of your model. These include the discount factor <em class="italics">γ</em> and the learning rate <img src="../Images/B14110_08_0311.png" alt=""/>, which are the only parameters of the Q-learning model. Give them the values of <code class="Code-In-Text--PACKT-">0.75</code> and <code class="Code-In-Text--PACKT-">0.9 </code>respectively, which I've arbitrarily picked but are usually a good choice. These <a id="_idIndexMarker216"/>are decent values to start with if you don't know what to use. However, you'll get the same result with similar values.</p>
			<pre class="programlisting language-markup"><code class="hljs ini"><span class="hljs-comment"># Setting the parameters gamma and alpha for the Q-Learning</span>
<span class="hljs-attr">gamma</span> = <span class="hljs-number">0.75</span>
<span class="hljs-attr">alpha</span> = <span class="hljs-number">0.9</span>
</code></pre>
			
			
			<p class="normal">The two previous code sections were simply the 
introductory sections, before you really start to build your AI model. 
The next step is to start the first part of our implementation.</p>
			<p class="normal">Try to remember what you have to do now, as a first general step of building an AI.</p>
			<p class="normal">You build the environment!</p>
			<p class="normal">I just wanted to highlight that, once again; it's really compulsory. The environment will be the first part of your code:</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_116" lang="en-GB"><a id="_idTextAnchor170"/>Part 1 – Building the environment</h3>
			<p class="normal">Let's look at the whole <a id="_idIndexMarker217"/>structure of this implementation so that you can take a step back already. Your code will be structured in three parts:</p>
			<ul>
				<li class="list"><strong class="bold">Part 1</strong> – Building the environment</li>
				<li class="list"><strong class="bold">Part 2</strong> – Building the AI solution with Q-learning (training)</li>
				<li class="list"><strong class="bold">Part 3</strong> – Going into production (inference)</li>
			</ul>
			<p class="normal">Let's start with part 1. For that, you define the 
states, the actions, and the rewards. Begin by defining the states, with
 a Python dictionary mapping the location's names (in letters from A to 
L) into the states (in indexes from 0 to 11). Call this dictionary <code class="Code-In-Text--PACKT-">location_to_state</code>:</p>
			<pre class="programlisting language-markup"><code class="hljs yaml"><span class="hljs-comment"># PART 1 - BUILDING THE ENVIRONMENT</span>
<span class="hljs-comment"># Defining the states</span>
<span class="hljs-string">location_to_state</span> <span class="hljs-string">=</span> <span class="hljs-string">{'A':</span> <span class="hljs-number">0</span><span class="hljs-string">,</span>
                     <span class="hljs-attr">'B':</span> <span class="hljs-number">1</span><span class="hljs-string">,</span>
                     <span class="hljs-attr">'C':</span> <span class="hljs-number">2</span><span class="hljs-string">,</span>
                     <span class="hljs-attr">'D':</span> <span class="hljs-number">3</span><span class="hljs-string">,</span>
                     <span class="hljs-attr">'E':</span> <span class="hljs-number">4</span><span class="hljs-string">,</span>
                     <span class="hljs-attr">'F':</span> <span class="hljs-number">5</span><span class="hljs-string">,</span>
                     <span class="hljs-attr">'G':</span> <span class="hljs-number">6</span><span class="hljs-string">,</span>
                     <span class="hljs-attr">'H':</span> <span class="hljs-number">7</span><span class="hljs-string">,</span>
                     <span class="hljs-attr">'I':</span> <span class="hljs-number">8</span><span class="hljs-string">,</span>
                     <span class="hljs-attr">'J':</span> <span class="hljs-number">9</span><span class="hljs-string">,</span>
                     <span class="hljs-attr">'K':</span> <span class="hljs-number">10</span><span class="hljs-string">,</span>
                     <span class="hljs-attr">'L':</span> <span class="hljs-number">11</span><span class="hljs-string">}</span>
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">Then, define the actions with a simple list of 
indexes from 0 to 11. Remember that each action index corresponds to the
 next location where that action leads to:</p>
			<pre class="programlisting language-markup"><code class="hljs lsl"># Defining the actions
actions = [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>,<span class="hljs-number">10</span>,<span class="hljs-number">11</span>]
</code></pre>
			
			<p class="normal">Finally, define the<a id="_idIndexMarker218"/> rewards, by creating a matrix of rewards where the rows correspond to the current states <span class="mediaobject"><img src="../Images/B14110_08_012.png" alt=""/></span>, the columns correspond to the actions <span class="mediaobject"><img src="../Images/B14110_08_013.png" alt=""/></span> leading to the next state , and the cells contain the rewards <span class="mediaobject"><img src="../Images/B14110_08_015.png" alt=""/></span>. If a cell  contains a 1, that means the AI can perform the action <span class="mediaobject"><img src="../Images/B14110_08_016.png" alt=""/></span> from the current state, <span class="mediaobject"><img src="../Images/B14110_08_018.png" alt=""/></span> to reach the next state . If a cell <span class="mediaobject"><img src="../Images/B14110_08_020.png" alt=""/></span> contains a 0, that means the AI cannot perform the action <span class="mediaobject"><img src="../Images/B14110_08_021.png" alt=""/></span> from the current state <span class="mediaobject"><img src="../Images/B14110_08_022.png" alt=""/></span> to reach any next state <span class="mediaobject"><img src="../Images/B14110_08_023.png" alt=""/></span>.</p>

			<p class="normal">Now, you might remember this very important question, the answer of which is at the heart of Reinforcement Learning.</p>
			<p class="normal">How will you let the AI know that it has to go to that top priority location <strong class="bold">G</strong>?</p>
			<p class="normal">Everything works with the reward.</p>
			<p class="normal">I must insist, again, that you remember this. If you attribute a high reward to location <strong class="bold">G</strong>, then the AI, through<a id="_idIndexMarker219"/>
 the Q-learning process, will learn to catch that high reward in the 
most efficient way because it is larger than the rewards of getting to 
the other locations.</p>
			<p class="normal">Remember this very important rule: the AI, when it 
is powered by Q-learning (or deep Q-learning, as you'll soon learn), 
will always learn to reach the highest reward by the quickest route that
 does not penalize the AI with negative rewards. That's why the trick to
 reach location <strong class="bold">G</strong> is simply to attribute it a higher reward than the other locations.</p>
			<p class="normal">Start by manually putting a high reward, which can 
be any high number as long as it is larger than 1, inside the cell 
corresponding to location <strong class="bold">G</strong>; location <strong class="bold">G</strong> is the top priority location where the robot has to go in order to collect the products.</p>
			<p class="normal">Since location <strong class="bold">G</strong> has encoded index state 6, put a <code class="Code-In-Text--PACKT-">1000</code>
 reward in the cell of row 6 and column 6. Later on, we will improve 
your solution by implementing an automatic way of going to the top 
priority location, without having to manually update the matrix of 
rewards and leaving it initialized with 0s and 1s just as it should be. 
For now, here's your matrix of rewards, including the manual update.</p>
			<pre class="programlisting language-markup"><code class="hljs angelscript"># Defining the rewards
R = np.<span class="hljs-built_in">array</span>([[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1000</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]])
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">That completes this first part. Now, let's begin the second part of your implementation.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_117" lang="en-GB">Part 2 – <a id="_idTextAnchor171"/>Building the AI Solution with Q-learning</h3>
			<p class="normal">To build your AI solution, follow the Q-learning algorithm exactly as it was provided previously. If you<a id="_idIndexMarker220"/> had any trouble when you tried implementing Q-learning <a id="_idIndexMarker221"/>on
 your own, now is your chance for revenge. Literally, all that's about 
to follow is only and exactly the same Q-learning process translated 
into code.</p>
			<p class="normal">Now you've got that in your mind, try coding it on your own again. You can do it!</p>
			<p class="normal">Congratulations if you tried, no matter how it came out. Next, let's check if you got it right.</p>
			<p class="normal">First, initialize all the Q-values by creating your
 matrix of Q-values full of 0s, in which the rows correspond to the 
current states <span class="mediaobject"><img src="../Images/B14110_08_012.png" alt=""/></span>, the columns correspond to the actions <span class="mediaobject"><img src="../Images/B14110_08_013.png" alt=""/></span> leading to the next state <span class="mediaobject"><img src="../Images/B14110_08_014.png" alt=""/></span>, and the cells contain the Q-values <span class="mediaobject"><img src="../Images/B14110_08_027.png" alt=""/></span>.</p>
			<pre class="programlisting language-markup"><code class="hljs ini"><span class="hljs-comment"># PART 2 - BUILDING THE AI SOLUTION WITH Q-LEARNING</span>

<span class="hljs-comment"># Initializing the Q-values</span>
<span class="hljs-attr">Q</span> = np.array(np.zeros([<span class="hljs-number">12</span>,<span class="hljs-number">12</span>]))
</code></pre>
			
			
			<p class="normal">Then implement the Q-learning process with a for 
loop over 1,000 iterations, repeating the exact same steps of the 
Q-learning process 1,000 times.</p>
			<pre class="programlisting language-markup"><code class="hljs properties"><span class="hljs-comment"># Implementing the Q-Learning process</span>
<span class="hljs-attr">for</span> <span class="hljs-string">i in range(1000):</span>
    <span class="hljs-attr">current_state</span> = <span class="hljs-string">np.random.randint(0,12)</span>
    <span class="hljs-attr">playable_actions</span> = <span class="hljs-string">[]</span>
    <span class="hljs-attr">for</span> <span class="hljs-string">j in range(12):</span>
        <span class="hljs-attr">if</span> <span class="hljs-string">R[current_state, j] &gt; 0:</span>
            <span class="hljs-attr">playable_actions.append(j)</span>
    <span class="hljs-attr">next_state</span> = <span class="hljs-string">np.random.choice(playable_actions)</span>
    <span class="hljs-attr">TD</span> = <span class="hljs-string">R[current_state, next_state] + gamma * Q[next_state, np.argmax(Q[next_state,])] - Q[current_state, next_state]</span>
    <span class="hljs-meta">Q[current_state,</span> <span class="hljs-string">next_state] = Q[current_state, next_state] + alpha * TD</span>
</code></pre>
			
			
			
			
			
			
			
			
			
			<p class="normal">Now you've reached the first really exciting step 
of the journey. You're actually ready to launch the Q-learning process 
and get your final Q-values. Execute the whole code you've implemented 
so far, and visualize the Q-values with the following simple print 
statements:</p>
			<pre class="programlisting language-markup"><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">"Q-values:"</span>)</span></span>
<span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(Q.astype(int)</span></span>)
</code></pre>
			
			<p class="normal">Here's what I got:</p>
			<pre class="programlisting language-markup"><code class="hljs angelscript">Q-values:
[[   <span class="hljs-number">0</span> <span class="hljs-number">1661</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>]
 [<span class="hljs-number">1246</span>    <span class="hljs-number">0</span> <span class="hljs-number">2213</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span> <span class="hljs-number">1246</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>]
 [   <span class="hljs-number">0</span> <span class="hljs-number">1661</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span> <span class="hljs-number">2970</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>]
 [   <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span> <span class="hljs-number">2225</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>]
 [   <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>  <span class="hljs-number">703</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>]
 [   <span class="hljs-number">0</span> <span class="hljs-number">1661</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>  <span class="hljs-number">931</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>]
 [   <span class="hljs-number">0</span>    <span class="hljs-number">0</span> <span class="hljs-number">2213</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span> <span class="hljs-number">3968</span> <span class="hljs-number">2225</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>]
 [   <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span> <span class="hljs-number">1661</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span> <span class="hljs-number">2968</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span> <span class="hljs-number">1670</span>]
 [   <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>  <span class="hljs-number">528</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>  <span class="hljs-number">936</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>]
 [   <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span> <span class="hljs-number">1246</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>  <span class="hljs-number">703</span>    <span class="hljs-number">0</span> <span class="hljs-number">1246</span>    <span class="hljs-number">0</span>]
 [   <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>  <span class="hljs-number">936</span>    <span class="hljs-number">0</span> <span class="hljs-number">1661</span>]
 [   <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span> <span class="hljs-number">2225</span>    <span class="hljs-number">0</span>    <span class="hljs-number">0</span> <span class="hljs-number">1246</span>    <span class="hljs-number">0</span>]]
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">If you're working on <a id="_idIndexMarker222"/>Spyder in Anaconda, then for more visual clarity<a id="_idIndexMarker223"/>
 you can even check the matrix of Q-values directly in Variable 
Explorer, by double-clicking on Q. Then, to get the Q-values as 
integers, you can click on <strong class="screen-text">Format</strong> and enter a float formatting of <code class="Code-In-Text--PACKT-">%.0f</code>. You get the following, which is a bit clearer since you can see the indexes of the rows and columns in your Q matrix:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_08_07.png" alt=""/></figure>
			<p class="packt_figref">Figure 7: Matrix of Q-values</p>
			<p class="normal">Now that you have your matrix of Q-values, you're ready to go into production—you can move on<a id="_idIndexMarker224"/> to the third <a id="_idIndexMarker225"/>part of the implementation.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_118" lang="en-GB">Part 3 –<a id="_idTextAnchor172"/> Going into production</h3>
			<p class="normal">In other words, you're<a id="_idIndexMarker226"/>
 going into inference mode! In this part, you'll compute the optimal 
path from any starting location to any ending top priority location. The
 idea here is to implement a <code class="Code-In-Text--PACKT-">route</code>
 function, that takes as inputs a starting location and an ending 
location and that returns as output the shortest route inside a Python 
list. The starting location corresponds to wherever our autonomous 
warehouse robot is at a given time, and the ending location corresponds 
to where the robot has to go as a top priority.</p>
			<p class="normal">Since you'll want to input the locations with their
 names (in letters), as opposed to their states (in indexes), you'll 
need a dictionary that maps the location states (in indexes) to the 
location names (in letters). That's the first thing to do here in this 
third part, using a trick to invert your previous dictionary, <code class="Code-In-Text--PACKT-">location_to_state</code>, since you simply want to get the exact inverse mapping from this dictionary:</p>
			<pre class="programlisting language-markup"><code class="hljs pf"><span class="hljs-comment"># PART 3 - GOING INTO PRODUCTION</span>

<span class="hljs-comment"># Making a mapping from the states to the locations</span>
state_to_location = {<span class="hljs-keyword">state</span>: location <span class="hljs-keyword">for</span> location, <span class="hljs-keyword">state</span> <span class="hljs-keyword">in</span> location_to_state.items()}
</code></pre>
			
			
			<p class="normal">Now, please focus— if the dots haven't perfectly 
connected in your mind, now is the time when they will. I'll show you 
the exact steps of how the robot manages to figure out the shortest 
route.</p>
			<p class="normal">Your robot is going to go from location <strong class="bold">E</strong> to location <strong class="bold">G</strong>.
 Here's the explanation of exactly how it does that—I'll enumerate the 
different steps of the process. Follow along on the matrix of Q-values 
as I explain:</p>
			<ol>
				<li class="list" value="1">The AI starts at the starting location <strong class="bold">E</strong>.</li>
				<li class="list">The AI gets the state of location <strong class="bold">E</strong>, which according to your <code class="Code-In-Text--PACKT-">location_to_state</code> mapping is <span class="mediaobject"><img src="../Images/B14110_08_028.png" alt=""/></span>.</li>
				<li class="list">On the row of index <span class="mediaobject"><img src="../Images/B14110_08_028.png" alt=""/></span> in our matrix of Q-values, the AI chooses the column that has the maximum Q-value (<code class="Code-In-Text--PACKT-">703</code>).</li>
				<li class="list">This column has index 8, so the AI performs the action of index 8, which leads it to the next state <span class="mediaobject"><img src="../Images/B14110_08_030.png" alt=""/></span>.</li>
				<li class="list">The AI gets the location of state 8, which according to our <code class="Code-In-Text--PACKT-">state_to_location</code> mapping is location <strong class="bold">I</strong>. Since the next location is location <strong class="bold">I</strong>, <strong class="bold">I</strong> is appended to the AI's list containing the optimal path.</li>
				<li class="list">Then, starting from <a id="_idIndexMarker227"/>the new location <strong class="bold">I</strong>, the AI repeats the same previous five steps until it reaches our final destination, location <strong class="bold">G</strong>.</li>
			</ol>
			<p class="normal">That's it! That's exactly what you have to 
implement. You have to generalize this to any starting and ending 
locations, and the best way to do that is through a function taking two 
inputs:</p>
			<ol>
				<li class="list" value="1"><code class="Code-In-Text--PACKT-">starting_location</code>: The location at which the AI starts</li>
				<li class="list"><code class="Code-In-Text--PACKT-">ending_location</code>: The top priority location to which it has to go</li>
			</ol>
			<p class="normal">and returning the optimal route. Since we're talking about a route, you can call that function <code class="Code-In-Text--PACKT-">route()</code>.</p>
			<p class="normal">An important thing to understand inside this <code class="Code-In-Text--PACKT-">route()</code>
 function is that since you don't know how many locations the AI will 
have to go through between the starting and ending locations, you have 
to make a <code class="Code-In-Text--PACKT-">while</code> loop which 
will repeat the 5-step process described previously, and that will stop 
as soon as it reaches the top priority end location.</p>
			<pre class="programlisting language-markup"><code class="hljs routeros"><span class="hljs-comment"># Making the final function that will return the optimal route</span>
def route(starting_location, ending_location):
   <span class="hljs-built_in"> route </span>= [starting_location]
    next_location = starting_location
    <span class="hljs-keyword">while</span> (next_location != ending_location):
        starting_state = location_to_state[starting_location]
        next_state = np.argmax(Q[starting_state,])
        next_location = state_to_location[next_state]
        route.append(next_location)
        starting_location = next_location
    return<span class="hljs-built_in"> route
</span></code></pre>
			
			
			
			
			
			
			
			
			
			
			<p class="normal">Congratulations! Your AI is now ready. Not only 
does it have the training process implemented, but also the code to run 
in inference mode. The only thing that's not great so far is that you 
still have to manually update the matrix of rewards; but no worries, 
we'll get to that later on. Before we get to that, let's first check 
that you have an intermediary victory here, and then we can get to work 
on improvements.</p>
			<pre class="programlisting language-markup"><code class="hljs routeros"><span class="hljs-comment"># Printing the final route</span>
<span class="hljs-builtin-name">print</span>(<span class="hljs-string">'Route:'</span>)
route(<span class="hljs-string">'E'</span>, <span class="hljs-string">'G'</span>)
</code></pre>
			
			
			<p class="normal">The following is the output:</p>
			<pre class="programlisting language-markup"><code class="hljs prolog"><span class="hljs-symbol">Route</span>:
<span class="hljs-symbol">Out</span>[<span class="hljs-number">1</span>]: [<span class="hljs-string">'E'</span>, <span class="hljs-string">'I'</span>, <span class="hljs-string">'J'</span>, <span class="hljs-string">'F'</span>,<a id="_idTextAnchor173"/> <span class="hljs-string">'B'</span>, <span class="hljs-string">'C'</span>, <span class="hljs-string">'G'</span>]
<span class="hljs-symbol">Out</span>[<span class="hljs-number">2</span>]: [<span class="hljs-string">'E'</span>, <span class="hljs-string">'I'</span>, <span class="hljs-string">'J'</span>, <span class="hljs-string">'K'</span>, <span class="hljs-string">'L'</span>, <span class="hljs-string">'H'</span>, <span class="hljs-string">'G'</span>]
</code></pre>
			
			
			<p class="normal">That's perfect—I ran the code twice when testing it
 to go from E to G, which is why you see the two preceding outputs. The 
two possible optimal paths were returned: one passing by F, and the 
other one passing by K.</p>
			<p class="normal">That's a good start. You <a id="_idIndexMarker228"/>have a first version of your AI model that functions well. Now let's improve your AI, and take it to the next level.</p>
			<p class="normal">You can improve the AI in two ways. Firstly, by 
automating the reward attribution to the top priority location so that 
you don't have to do it manually. Secondly, by adding a feature that 
gives the AI the option to go by an intermediate location before going 
to the top priority location—that intermediate location should be in the
 top three priority locations.</p>
			<p class="normal">In our top priority locations ranking, the second 
top priority location is location K. Therefore, in order to optimize the
 warehouse flows, your autonomous warehouse robot must go via location K
 to collect products on its way to the top priority location G. One way 
to do this is to have the option to go by an intermediate location in 
the process of your <code class="Code-In-Text--PACKT-">route()</code> function. This is exactly what you'll implement as a second improvement.</p>
			<p class="normal">First, let's implement the first improvement, the one that automates the reward attribution.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_119" lang="en-GB"><a id="_idTextAnchor174"/>Improvement 1 – Automating reward attribution</h3>
			<p class="normal">The way to do<a id="_idIndexMarker229"/> this is in three steps.</p>
			<p class="normal"><strong class="bold">Step 1</strong>: Go back to 
the original matrix of rewards, as it was before with only 1s and 0s. 
Part 1 of the code becomes the following, and will be included in the 
final code:</p>
			<pre class="programlisting language-markup"><code class="hljs angelscript"># PART <span class="hljs-number">1</span> - BUILDING THE ENVIRONMENT

# Defining the states
location_to_state = {<span class="hljs-string">'A'</span>: <span class="hljs-number">0</span>,
                     <span class="hljs-string">'B'</span>: <span class="hljs-number">1</span>,
                     <span class="hljs-string">'C'</span>: <span class="hljs-number">2</span>,
                     <span class="hljs-string">'D'</span>: <span class="hljs-number">3</span>,
                     <span class="hljs-string">'E'</span>: <span class="hljs-number">4</span>,
                     <span class="hljs-string">'F'</span>: <span class="hljs-number">5</span>,
                     <span class="hljs-string">'G'</span>: <span class="hljs-number">6</span>,
                     <span class="hljs-string">'H'</span>: <span class="hljs-number">7</span>,
                     <span class="hljs-string">'I'</span>: <span class="hljs-number">8</span>,
                     <span class="hljs-string">'J'</span>: <span class="hljs-number">9</span>,
                     <span class="hljs-string">'K'</span>: <span class="hljs-number">10</span>,
                     <span class="hljs-string">'L'</span>: <span class="hljs-number">11</span>}

# Defining the actions
actions = [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>,<span class="hljs-number">10</span>,<span class="hljs-number">11</span>]

# Defining the rewards
R = np.<span class="hljs-built_in">array</span>([[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]])
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal"><strong class="bold">Step 2</strong>: In part 2 of the code, make a copy (call it <code class="Code-In-Text--PACKT-">R_new</code>) of your rewards matrix, inside which the <code class="Code-In-Text--PACKT-">route()</code> function can automatically update the reward in the cell of the ending location.</p>
			<p class="normal">Why do you have to <a id="_idIndexMarker230"/>make
 a copy? Because you have to keep the original matrix of rewards 
initialized with 1s and 0s for future modifications when you want to go 
to a new priority location. So, how will the <code class="Code-In-Text--PACKT-">route()</code>
 function automatically update the reward in the cell of the ending 
location? That's an easy one: since the ending location is one of the 
inputs of the <code class="Code-In-Text--PACKT-">route()</code> function, then by using your <code class="Code-In-Text--PACKT-">location_to_state</code> dictionary, you can very easily find that cell and update its reward to <code class="Code-In-Text--PACKT-">1000</code>. Here's how you do that:</p>
			<pre class="programlisting language-markup"><code class="hljs ruby"><span class="hljs-comment"># Making a function that returns the shortest route from a starting to ending location</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">route</span><span class="hljs-params">(starting_location, ending_location)</span></span>:
    R_new = np.copy(R)
    ending_state = location_to_state[ending_location]
    R_new[ending_state, ending_state] = <span class="hljs-number">1000</span>
</code></pre>
			
			
			
			
			<p class="normal"><strong class="bold">Step 3</strong>: You must include the whole Q-learning algorithm (including the initialization step) inside the <code class="Code-In-Text--PACKT-">route()</code> function, right after we make that update of the reward in your copy (<code class="Code-In-Text--PACKT-">R_new</code>) of the rewards matrix. In your previous implementation, the Q-learning process <a id="_idIndexMarker231"/>happened
 on the original version of the rewards matrix. Now that original 
version needs to stay as it is, that is, initialized to 1s and 0s only. 
Therefore, you must include the Q-learning process inside the <code class="Code-In-Text--PACKT-">route()</code> function, and make it happen on your copy of the rewards matrix <code class="Code-In-Text--PACKT-">R_new</code>, instead of the original rewards matrix <code class="Code-In-Text--PACKT-">R</code>. Here's how you do that:</p>
			<pre class="programlisting language-markup"><code class="hljs routeros"><span class="hljs-comment"># Making a function that returns the shortest route from a starting to ending location</span>
def route(starting_location, ending_location):
    R_new = np.copy(R)
    ending_state = location_to_state[ending_location]
    R_new[ending_state, ending_state] = 1000
    Q = np.array(np.zeros([12,12]))
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(1000):
        current_state = np.random.randint(0,12)
        playable_actions = []
        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(12):
            <span class="hljs-keyword">if</span> R_new[current_state, j] &gt; 0:
                playable_actions.append(j)
        next_state = np.random.choice(playable_actions)
        TD = R_new[current_state, next_state] + gamma * Q[next_state, np.argmax(Q[next_state,])] - Q[current_state, next_state]
        Q[current_state, next_state] = Q[current_state, next_state] + alpha * TD
   <span class="hljs-built_in"> route </span>= [starting_location]
    next_location = starting_location
    <span class="hljs-keyword">while</span> (next_location != ending_location):
        starting_state = location_to_state[starting_location]
        next_state = np.argmax(Q[starting_state,])
        next_location = state_to_location[next_state]
        route.append(next_location)
        starting_location = next_location
    return<span class="hljs-built_in"> route
</span></code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">Perfect; part 2 is now ready! Here's part 2 of the final code in full:</p>
			<pre class="programlisting language-markup"><code class="hljs routeros"><span class="hljs-comment"># PART 2 - BUILDING THE AI SOLUTION WITH Q-LEARNING</span>

<span class="hljs-comment"># Making a mapping from the states to the locations</span>
state_to_location = {state: location <span class="hljs-keyword">for</span> location, state <span class="hljs-keyword">in</span> location_to_state.items()}

<span class="hljs-comment"># Making a function that returns the shortest route from a starting to ending location</span>
def route(starting_location, ending_location):
    R_new = np.copy(R)
    ending_state = location_to_state[ending_location]
    R_new[ending_state, ending_state] = 1000
    Q = np.array(np.zeros([12,12]))
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(1000):
        current_state = np.random.randint(0,12)
        playable_actions = []
        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(12):
            <span class="hljs-keyword">if</span> R_new[current_state, j] &gt; 0:
                playable_actions.append(j)
        next_state = np.random.choice(playable_actions)
        TD = R_new[current_state, next_state] + gamma * Q[next_state, np.argmax(Q[next_state,])] - Q[current_state, next_state]
        Q[current_state, next_state] = Q[current_state, next_state] + alpha * TD
   <span class="hljs-built_in"> route </span>= [starting_location]
    next_location = starting_location
    <span class="hljs-keyword">while</span> (next_location != ending_location):
        starting_state = location_to_state[starting_location]
        next_state = np.argmax(Q[starting_state,])
        next_location = state_to_location[next_state]
        route.append(next_location)
        starting_location = next_location
    return<span class="hljs-built_in"> route
</span></code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">If you execute this <a id="_idIndexMarker232"/>new code several times with the start and end points of <strong class="bold">E</strong> and <strong class="bold">G</strong>, you'll get the same two possible optimal paths as before. You can also play around with the <code class="Code-In-Text--PACKT-">route()</code> function and try out different starting and ending points. Try it out!</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_120" lang="en-GB"><a id="_idTextAnchor175"/>Improvement 2 – Adding an intermediate goal</h3>
			<p class="normal">Now, let's tackle the <a id="_idIndexMarker233"/>second improvement. There are three possible solutions to the problem of adding the option to go by the intermediate location <strong class="bold">K</strong>,
 the second top priority location. When you see them, you'll understand 
what I meant when I told you that everything in Reinforcement Learning 
works by the rewards. </p>
			<p class="normal">Only one of the solutions works from every starting
 point, but I'd like to give you all three solutions to help reinforce 
your intuition. To help with that, here's a reminder of our warehouse 
layout:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_08_08.png" alt=""/></figure>
			<p class="packt_figref">Figure 8: Locations in the warehouse</p>
			<p class="normal"><strong class="bold">Solution 1</strong>: Give a high reward to the action leading from location <strong class="bold">J</strong> to location <strong class="bold">K</strong>.
 This high reward must be larger than 1, and below 1,000. It must be 
larger than 1 so that the Q-learning process favors the action leading 
from <strong class="bold">J</strong> to <strong class="bold">K</strong>, as opposed to the action leading from <strong class="bold">J</strong> to <strong class="bold">F</strong>,
 which has a reward of 1. It must also be below 1,000 so that the 
highest reward stays on the top priority location, to make sure the AI 
ends up there. For example, in your rewards matrix you can give a high 
reward of <code class="Code-In-Text--PACKT-">500</code> to the cell in the row of index 9 and the column of index 10, since that cell corresponds to the action leading from location <strong class="bold">J</strong> (state index 9) to location <strong class="bold">K</strong> (state index 10). That way, your AI robot will always go by location <strong class="bold">K</strong> when going from location <strong class="bold">E</strong> to location <strong class="bold">G</strong>. Here's how the matrix of rewards would look in that case:</p>
			<pre class="programlisting language-markup"><code class="hljs angelscript"># Defining the rewards
R = np.<span class="hljs-built_in">array</span>([[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">500</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]])
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">This solution does not work in every case, and actually only works for starting points <strong class="bold">E</strong>, <strong class="bold">I</strong>, and <strong class="bold">J</strong>. That's because the <code class="Code-In-Text--PACKT-">500</code> weight can only affect the decision of the AI as to whether or not it should go from <strong class="bold">J</strong> to <strong class="bold">K</strong>; it doesn't change how likely it is for the AI to go to <strong class="bold">J</strong> in the first place.</p>
			<p class="normal"><strong class="bold">Solution 2</strong>: Give a bad<a id="_idIndexMarker234"/> reward to the action leading from location <strong class="bold">J</strong> to location <strong class="bold">F</strong>.
 This bad reward just has to be below 0. By punishing this action with a
 bad reward, the Q-learning process will never favor the action leading 
from <strong class="bold">J</strong> to <strong class="bold">F</strong>. For example, in your rewards matrix, you can give a bad reward of <code class="Code-In-Text--PACKT-">-500</code> to the cell in the row of index 9 and the column of index 5, since that cell corresponds to the action leading from location <strong class="bold">J</strong> (state index 9) to location <strong class="bold">F</strong> (state index 5). That way, your autonomous warehouse robot will never go from location <strong class="bold">J</strong> to location <strong class="bold">F</strong> on its way to location <strong class="bold">G</strong>. Here's how the matrix of rewards would look in that case:</p>
			<pre class="programlisting language-markup"><code class="hljs angelscript"># Defining the rewards
R = np.<span class="hljs-built_in">array</span>([[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">-500</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
              [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]])
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">This solution does not work in every case, and actually only works for starting points <strong class="bold">E</strong>, <strong class="bold">I</strong>, and <strong class="bold">J</strong>. Just as in solution 1, that's because the <code class="Code-In-Text--PACKT-">-500</code> weight can only affect the decision of the AI as to whether or not it should go from <strong class="bold">J</strong> to <strong class="bold">F</strong>; it doesn't change how likely it is for the AI to go to <strong class="bold">J</strong> in the first place.</p>
			<p class="normal"><strong class="bold">Solution 3</strong>: Make an additional <code class="Code-In-Text--PACKT-">best_route()</code> function, taking as inputs the three starting, intermediary, and ending locations, which will call your previous <code class="Code-In-Text--PACKT-">route()</code>
 function twice; the first time from the starting location to the 
intermediary location, and a second time from the intermediary location 
to the ending location.</p>
			<p class="normal">The first two solutions<a id="_idIndexMarker235"/>
 are easy to implement manually, but tricky to implement automatically. 
It is easy to automatically get the index of the intermediary location 
via which you want the AI to go, but it's difficult to get the index of 
the location that leads to that intermediary location, since it depends 
on the starting location and ending location. If you try to implement 
either the first or second solution, you'll see what I mean. Besides, 
solutions 1 and 2 do not work as global solutions. </p>
			<p class="normal">Only solution 3 guarantees that the AI will visit an intermediate location before going to the final location.</p>
			<p class="normal">Accordingly, we'll implement solution 3, which can be coded in just two extra lines of code, and which I included in <em class="italics">Part 3 – Going into production</em>:</p>
			<pre class="programlisting language-markup"><code class="hljs python"><span class="hljs-comment"># PART 3 - GOING INTO PRODUCTION</span>

<span class="hljs-comment"># Making the final function that returns the optimal route</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">best_route</span><span class="hljs-params">(starting_location, intermediary_location, ending_location)</span>:</span>
    <span class="hljs-keyword">return</span> route(starting_location, intermediary_location) + route(intermediary_location, ending_location)[<span class="hljs-number">1</span>:]

<span class="hljs-comment"># Printing the final route</span>
print(<span class="hljs-string">'Route:'</span>)
best_route(<span class="hljs-string">'E'</span>, <span class="hljs-string">'K'</span>, <span class="hljs-string">'G'</span>)
</code></pre>
			
			
			
			
			
			
			<p class="normal">Easy, right? Sometimes, the best solutions are the 
simplest ones. That's definitely the case here. As you can see, included
 in Part 3 is the code that runs the ultimate test. This test will be 
successful if the AI goes through location <strong class="bold">K</strong> while taking the shortest route from location <strong class="bold">E</strong> to location <strong class="bold">G</strong>. To test it, execute this whole new code as many times as you want; you'll always get the same, expected output:</p>
			<pre class="programlisting language-markup"><code class="hljs less"><span class="hljs-attribute">Route</span>:
[<span class="hljs-string">'E'</span>, <span class="hljs-string">'I'</span>, <span class="hljs-string">'J'</span>, <span class="hljs-string">'K'</span>, <span class="hljs-string">'L'</span>, <span class="hljs-string">'H'</span>, <span class="hljs-string">'G'</span>]
</code></pre>
			
			<p class="normal">Congratulations! You've developed a fully 
functional AI, powered by Q-learning, which solves an optimization 
problem for logistics. Using this AI robot, we can now go from any 
location to any new top priority location, while optimizing our paths to
 collect products in a second priority intermediary location. Not bad! 
If you get bored with logistics, feel free to imagine yourself back in 
the maze, and try the <code class="Code-In-Text--PACKT-">best_route()</code>
 function with whatever starting and ending points you would like, so 
you can see how flexible the AI you've created is. Have fun with it! 
And, of course, you have the full code available for you on the <a id="_idIndexMarker236"/>GitHub page.</p>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_121" lang="en-GB"><a id="_idTextAnchor176"/>Summary</h2>
			<p class="normal">In this chapter, you've implemented a Q-learning 
solution to a business problem. You had to find the best route to a 
certain location in your warehouse. Not only have you done that, but 
you've also implemented additional code that allowed your AI to make as 
many intermediary stops as you wanted. Based on the obtained rewards, 
your AI was able to find the best route going through these stops. That 
was Q-learning for warehouse robots. Now, let's move on to deep 
Q-learning!</p>
</body></html>