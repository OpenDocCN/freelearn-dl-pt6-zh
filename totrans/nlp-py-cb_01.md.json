["```py\nfrom nltk.corpus import reuters\n```", "```py\nfiles = reuters.fileids()\nprint(files)\n```", "```py\n['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833', 'test/14839',\n```", "```py\nwords16097 = reuters.words(['test/16097'])\nprint(words16097)\n```", "```py\n['UGANDA', 'PULLS', 'OUT', 'OF', 'COFFEE', 'MARKET', ...]\n```", "```py\nwords20 = reuters.words(['test/16097'])[:20]\nprint(words20)\n```", "```py\n['UGANDA', 'PULLS', 'OUT', 'OF', 'COFFEE', 'MARKET', '-', 'TRADE', 'SOURCES', 'Uganda', \"'\", 's', 'Coffee', 'Marketing', 'Board', '(', 'CMB', ')', 'has', 'stopped']\n```", "```py\nreutersGenres = reuters.categories()\nprint(reutersGenres)\n```", "```py\n['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', ...\n```", "```py\nfor w in reuters.words(categories=['bop','cocoa']):\n  print(w+' ',end='')\n  if(w is '.'):\n    print()\n```", "```py\n['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833', 'test/14839', ...\n['UGANDA', 'PULLS', 'OUT', 'OF', 'COFFEE', 'MARKET', ...]\n['UGANDA', 'PULLS', 'OUT', 'OF', 'COFFEE', 'MARKET', '-', 'TRADE', 'SOURCES', 'Uganda', \"'\", 's', 'Coffee', 'Marketing', 'Board', '(', 'CMB', ')', 'has', 'stopped']\n['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', ...\nSOUTH KOREA MOVES TO SLOW GROWTH OF TRADE SURPLUS South Korea ' s trade surplus is growing too fast and the government has started taking steps to slow it down , Deputy Prime Minister Kim Mahn-je said .\nHe said at a press conference that the government planned to increase investment , speed up the opening of the local market to foreign imports, and gradually adjust its currency to hold the surplus \" at a proper level .\" But he said the government would not allow the won to appreciate too much in a short period of time .\nSouth Korea has been under pressure from Washington to revalue the won .\nThe U .\nS .\nWants South Korea to cut its trade surplus with the U .\nS ., Which rose to 7 .\n4 billion dlrs in 1986 from 4 .\n3 billion dlrs in 1985 .\n.\n.\n.\n```", "```py\nfrom nltk.corpus import CategorizedPlaintextCorpusReader\n```", "```py\nreader = CategorizedPlaintextCorpusReader(r'/Volumes/Data/NLP-CookBook/Reviews/txt_sentoken', r'.*\\.txt', cat_pattern=r'(\\w+)/*')\nprint(reader.categories())\nprint(reader.fileids())\n```", "```py\n['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt',....]\n[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of',...]]\n```", "```py\nposFiles = reader.fileids(categories='pos')\nnegFiles = reader.fileids(categories='neg')\n```", "```py\nfrom random import randint\nfileP = posFiles[randint(0,len(posFiles)-1)]\nfileN = negFiles[randint(0, len(posFiles) - 1)]\nprint(fileP)\nprint(fileN)\n```", "```py\nfor w in reader.words(fileP):\n  print(w + ' ', end='')\n  if (w is '.'):\n    print()\nfor w in reader.words(fileN):\n  print(w + ' ', end='')\n  if (w is '.'):\n    print()\n```", "```py\n['neg', 'pos']\n['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', ...]\npos/cv182_7281.txt\nneg/cv712_24217.txt\nthe saint was actually a little better than i expected it to be , in some ways .\nin this theatrical remake of the television series the saint...\n```", "```py\nimport nltk\nfrom nltk.corpus import brown\n```", "```py\nprint(brown.categories())\n```", "```py\n['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n```", "```py\ngenres = ['fiction', 'humor', 'romance']\nwhwords = ['what', 'which', 'how', 'why', 'when', 'where', 'who']\n```", "```py\nfor i in range(0,len(genres)):genre = genres[i]\nprint()\nprint(\"Analysing '\"+ genre + \"' wh words\")\ngenre_text = brown.words(categories = genre)\n```", "```py\nfdist = nltk.FreqDist(genre_text)\n```", "```py\nfor wh in whwords:\nprint(wh + ':', fdist[wh], end=' ')\n```", "```py\n['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n\nAnalysing 'fiction' wh words\n\nwhat: 128 which: 123 how: 54 why: 18 when: 133 where: 76 who: 103\n\nAnalysing 'humor' wh words\n\nwhat: 36 which: 62 how: 18 why: 9 when: 52 where: 15 who: 48\n\nAnalysing 'romance' wh words\n\nwhat: 121 which: 104 how: 60 why: 34 when: 126 where: 54 who: 89\n```", "```py\nimport nltk\nfrom nltk.corpus import webtext\nprint(webtext.fileids())\n```", "```py\n['firefox.txt', 'grail.txt', 'overheard.txt', 'pirates.txt', 'singles.txt', 'wine.txt']\n```", "```py\nfileid = 'singles.txt'\nwbt_words = webtext.words(fileid)\nfdist = nltk.FreqDist(wbt_words)\n```", "```py\nprint('Count of the maximum appearing token \"',fdist.max(),'\" : ', fdist[fdist.max()])\n```", "```py\nprint('Total Number of distinct tokens in the bag : ', fdist.N())\n```", "```py\nprint('Following are the most common 10 words in the bag')\n print(fdist.most_common(10))\n```", "```py\nprint('Frequency Distribution on Personal Advertisements')\n print(fdist.tabulate())\n```", "```py\nfdist.plot(cumulative=True)\n```", "```py\n['firefox.txt', 'grail.txt', 'overheard.txt', 'pirates.txt', 'singles.txt', 'wine.txt']\n\nCount of the maximum appearing token \" , \" : 539\n\nTotal Number of distinct tokens in the bag : 4867\n\nFollowing are the most common 10 words in the bag\n\n[(',', 539), ('.', 353), ('/', 110), ('for', 99), ('and', 74), ('to', \n\n4), ('lady', 68), ('-', 66), ('seeks', 60), ('a', 52)]\n\nFrequency Distribution on Personal Advertisements\n\n, . / for and to lady .........\n\n539 353 110 99 74 74 .........\n\nNone\n```", "```py\nfrom nltk.corpus import wordnet as wn\nchair = 'chair'\n```", "```py\nchair_synsets = wn.synsets(chair)\nprint('Synsets/Senses of Chair :', chair_synsets, '\\n\\n')\n```", "```py\nSynsets/Senses of Chair : [Synset('chair.n.01'), Synset('professorship.n.01'), Synset('president.n.04'), Synset('electric_chair.n.01'), Synset('chair.n.05'), Synset('chair.v.01'), Synset('moderate.v.01')]\n```", "```py\nfor synset in chair_synsets:\n  print(synset, ': ')\n  print('Definition: ', synset.definition())\n  print('Lemmas/Synonymous words: ', synset.lemma_names())\n  print('Example: ', synset.examples(), '\\n')\n```", "```py\nSynset('chair.v.01') :\n\nDefinition: act or preside as chair, as of an academic department in a university\n\nLemmas/Synonymous words: ['chair', 'chairman']\n\nExample: ['She chaired the department for many years']\n```", "```py\nSynsets/Senses of Chair : [Synset('chair.n.01'), Synset('professorship.n.01'), Synset('president.n.04'), Synset('electric_chair.n.01'), Synset('chair.n.05'), Synset('chair.v.01'), Synset('moderate.v.01')]\n\nSynset('chair.n.01') :\n\nDefinition: a seat for one person, with a support for the back\n\nLemmas/Synonymous words: ['chair']\n\nExample: ['he put his coat over the back of the chair and sat down']\n\nSynset('professorship.n.01') :\n\nDefinition: the position of professor\n\nLemmas/Synonymous words: ['professorship', 'chair']\n\nExample: ['he was awarded an endowed chair in economics']\n\nSynset('president.n.04') :\n\nDefinition: the officer who presides at the meetings of an organization\n\nLemmas/Synonymous words: ['president', 'chairman', 'chairwoman', \n\nchair', 'chairperson']\n\nExample: ['address your remarks to the chairperson']\n\nSynset('electric_chair.n.01') :\n\nDefinition: an instrument of execution by electrocution; resembles an ordinary seat for one person\n\nLemmas/Synonymous words: ['electric_chair', 'chair', 'death_chair', 'hot_seat']\n\nExample: ['the murderer was sentenced to die in the chair']\n\nSynset('chair.n.05') :\n\nDefinition: a particular seat in an orchestra\n\nLemmas/Synonymous words: ['chair']\n\nExample: ['he is second chair violin']\n\nSynset('chair.v.01') :\n\nDefinition: act or preside as chair, as of an academic department in a university\n\nLemmas/Synonymous words: ['chair', 'chairman']\n\nExample: ['She chaired the department for many years']\n\nSynset('moderate.v.01') :\n\nDefinition: preside over\n\nLemmas/Synonymous words: ['moderate', 'chair', 'lead']\n\nExample: ['John moderated the discussion']\n```", "```py\nfrom nltk.corpus import wordnet as wn\nwoman = wn.synset(woman.n.02')\nbed = wn.synset('bed.n.01')\n```", "```py\nprint(woman.hypernyms())\nwoman_paths = woman.hypernym_paths()\n```", "```py\n[Synset('adult.n.01'), Synset('female.n.02')]\n```", "```py\nfor idx, path in enumerate(woman_paths):\n  print('\\n\\nHypernym Path :', idx + 1)\nfor synset in path:\n  print(synset.name(), ', ', end='')\n```", "```py\nHypernym Path : 1\n\nentity.n.01 , physical_entity.n.01 , causal_agent.n.01 , person.n.01 , adult.n.01 , woman.n.01\n```", "```py\ntypes_of_beds = bed.hyponyms()\nprint('\\n\\nTypes of beds(Hyponyms): ', types_of_beds)\n```", "```py\nTypes of beds(Hyponyms): [Synset('berth.n.03'), Synset('built-in_bed.n.01'), Synset('bunk.n.03'), Synset('bunk_bed.n.01'), Synset('cot.n.03'), Synset('couch.n.03'), Synset('deathbed.n.02'), Synset('double_bed.n.01'), Synset('four-poster.n.01'), Synset('hammock.n.02'), Synset('marriage_bed.n.01'), Synset('murphy_bed.n.01'), Synset('plank-bed.n.01'), Synset('platform_bed.n.01'), Synset('sickbed.n.01'), Synset('single_bed.n.01'), Synset('sleigh_bed.n.01'), Synset('trundle_bed.n.01'), Synset('twin_bed.n.01'), Synset('water_bed.n.01')]\n```", "```py\nprint(sorted(set(lemma.name() for synset in types_of_beds for lemma in synset.lemmas())))\n```", "```py\nOutput: [Synset('adult.n.01'), Synset('female.n.02')]\nHypernym Path : 1\nentity.n.01 , physical_entity.n.01 , causal_agent.n.01 , person.n.01 , adult.n.01 , woman.n.01 ,\nHypernym Path : 2\nentity.n.01 , physical_entity.n.01 , object.n.01 , whole.n.02 , living_thing.n.01 , organism.n.01 , person.n.01 , adult.n.01 , woman.n.01 ,\nHypernym Path : 3\nentity.n.01 , physical_entity.n.01 , causal_agent.n.01 , person.n.01 , female.n.02 , woman.n.01 ,\nHypernym Path : 4\nentity.n.01 , physical_entity.n.01 , object.n.01 , whole.n.02 , living_thing.n.01 , organism.n.01 , person.n.01 , female.n.02 , woman.n.01 ,\n\nTypes of beds(Hyponyms): [Synset('berth.n.03'), Synset('built-in_bed.n.01'), Synset('bunk.n.03'), Synset('bunk_bed.n.01'), Synset('cot.n.03'), Synset('couch.n.03'), Synset('deathbed.n.02'), Synset('double_bed.n.01'), Synset('four-poster.n.01'), Synset('hammock.n.02'), Synset('marriage_bed.n.01'), Synset('murphy_bed.n.01'), Synset('plank-bed.n.01'), Synset('platform_bed.n.01'), Synset('sickbed.n.01'), Synset('single_bed.n.01'), Synset('sleigh_bed.n.01'), Synset('trundle_bed.n.01'), Synset('twin_bed.n.01'), Synset('water_bed.n.01')]\n\n['Murphy_bed', 'berth', 'built-in_bed', 'built_in_bed', 'bunk', 'bunk_bed', 'camp_bed', 'cot', 'couch', 'deathbed', 'double_bed', 'four-poster', 'hammock', 'marriage_bed', 'plank-bed', 'platform_bed', 'sack', 'sickbed', 'single_bed', 'sleigh_bed', 'truckle', 'truckle_bed', 'trundle', 'trundle_bed', 'twin_bed', 'water_bed']\n```", "```py\nfrom nltk.corpus import wordnet as wn\ntype = 'n'\n```", "```py\nsynsets = wn.all_synsets(type)\n```", "```py\nlemmas = []\nfor synset in synsets:\n  for lemma in synset.lemmas():\n    lemmas.append(lemma.name())\n```", "```py\nlemmas = set(lemmas)\n```", "```py\ncount = 0\nfor lemma in lemmas:\n  count = count + len(wn.synsets(lemma, type))\n```", "```py\nprint('Total distinct lemmas: ', len(lemmas))\nprint('Total senses :',count)\nprint('Average Polysemy of ', type,': ' , count/len(lemmas))\n```", "```py\nOutput: Total distinct lemmas: 119034\nTotal senses : 152763\nAverage Polysemy of n : 1.2833560159282222\n```"]