<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Working with Caffe</h1>
                </header>
            
            <article>
                
<p class="mce-root">In <a href="270a3617-74cd-4e64-98f7-eb0c4e3cbcf6.xhtml">Chapter 2</a>, <em>Composing Networks</em>, and <a href="3c2dd7d3-b762-49a3-a5d6-0b791eadadb2.xhtml">Chapter 3</a>, <em>Training Networks</em>, we learned how to compose networks and train them, respectively. In this chapter, we will examine the relationship between Caffe2 and Caffe and look at how to use Caffe models in Caffe2 and vice versa.</p>
<p>The objectives of this chapter are as follows:</p>
<ul>
<li>The relationship between Caffe and Caffe2</li>
<li>Introduction to AlexNet</li>
<li>Building and installing Caffe</li>
<li>Caffe model file formats</li>
<li>Caffe2 model file formats</li>
<li>Converting a Caffe model to Caffe2</li>
<li>Converting a Caffe2 model to Caffe</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The relationship between Caffe and Caffe2</h1>
                </header>
            
            <article>
                
<p>At the <em>NIPS</em> academic conference held in 2012, Alex Krizhevsky and his collaborators, one of whom was the neural network pioneer, Geoffrey Hinton, presented a record breaking result at the <strong><span>ImageNet Large-Scale Visual Recognition Competition</span></strong> (<strong>ILSVRC</strong>). Research teams competed in various image recognition tasks that used the ImageNet dataset. Krizhevsky's results on the image classification task were 10.8% better than the state of the art. He had used GPUs for the first time to train a CNN with many layers. This network structure would popularly be called <strong>AlexNet</strong> later. The design of such a deep neural network with a large number of layers is the reason why this field came to be called deep learning. Krizhevsky shared the entire source code of his network, now called <strong>cuda-convnet</strong>, along with its highly GPU-optimized training code.</p>
<p class="mce-root"/>
<p>Soon after this, <strong>Yangqing Jia</strong>, and his collaborators from the UC <strong><span>Berkeley Vision and Learning Center</span></strong> (<strong><span>BVLC</span></strong>) tried to replicate these results, releasing their software as <em>DeCaf</em>. This library was later polished and streamlined and released as <strong>Caffe</strong>.</p>
<p>Unlike most of the buggy and poorly designed research code of its time, Caffe was a well-designed deep learning library that made it easy to compose a network using a prototxt text file. It was modular by design, making it easy for researchers to add new layers and training algorithms. This made Caffe popular during the period 2012 to 2016. Most of the groundbreaking networks and models in the field of image recognition were released in Caffe. This is why Caffe is an important deep learning framework, and you might still find several classic models only available for Caffe.</p>
<p>In the meantime, there was growing interest in alternatives to Caffe. This was because Caffe was beginning to show its limitations. Although a Python API was added late in 2014, Caffe was primarily a C++ library. This C++ requirement meant slow speed of experimentation and development. Caffe was also primarily designed for image recognition problems. Practitioners found it difficult to add features for solving other problems, such as speech recognition. Other useful features, such as the utilization of different precision data types and quantization and multi-GPU training, were not present in Caffe. These features were later grafted painfully onto Caffe, but were not optimal in terms of engineering and maintenance.</p>
<p>These issues resulted in a new breed of deep learning libraries that were written with ease of use, distributed training, and customization in mind, <span>gaining in popularity</span>. These included TensorFlow and PyTorch.</p>
<p>Yangqing Jia moved from university to Facebook and he led the creation of a modern deep learning library, Caffe2, the subject of this book. Because he had created Caffe too, Caffe2 borrowed a lot of the good ideas from Caffe and was built to interoperate with Caffe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction to AlexNet</h1>
                </header>
            
            <article>
                
<p>We mentioned AlexNet in the earlier section that introduced Caffe. AlexNet was a seminal network structure because of the large number of layers it employed for the first time, and for showing how such a deep neural network could be trained in a reasonable time by utilizing GPUs.</p>
<p class="mce-root"><span>Figure 4.1 shows the network structure of AlexNet generated by Caffe's network visualization tool, </span><kbd>draw_net.py</kbd> <span>. This tool uses the GraphViz library to render the graph layout:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-474 image-border" src="assets/e15f1dfa-f5a9-45f4-87e2-7f78bca94187.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 4.1: Network structure of AlexNet using the GraphViz layout</div>
<p>In this visualization, layers are drawn as rectangles and data tensors between layers are drawn as elongated octagons. For example, the first layer rectangle after the input layer depicts a convolution layer named <kbd>conv1</kbd>. It uses kernels of size <img class="fm-editor-equation" src="assets/df3f5ab1-5fa4-40aa-884f-7cb8ddb104f5.png" style="width:3.17em;height:0.83em;"/>, a stride of <kbd>4</kbd>, and a padding of <kbd>0</kbd>.</p>
<p>Examining the AlexNet structure in <em>Figure 4.1</em> we can see that AlexNet is similar in spirit to the LeNet model we looked at in <a href="3c2dd7d3-b762-49a3-a5d6-0b791eadadb2.xhtml">Chapter 3</a>, <em>Training Networks</em>. Compared to LeNet, however, it has many more convolution layers and fully connected layers at the end. Furthermore, it has replaced the use of traditional tanh and sigmoid layers with ReLU. Krizhevsky describes in his paper how these changes, along with some training innovations and the use of GPUs, made training such a deep network tractable.</p>
<p>In the rest of this chapter, we will use AlexNet as the example model to learn how to understand Caffe and Caffe2 network description languages, and how to convert between the two.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building and installing Caffe</h1>
                </header>
            
            <article>
                
<p>The version of Caffe maintained by BVLC can be freely downloaded from <a href="https://github.com/BVLC/caffe">https://github.com/BVLC/caffe</a>. A GPU-optimized fork of Caffe maintained by NVIDIA can be downloaded from <a href="https://github.com/NVIDIA/caffe">https://github.com/NVIDIA/caffe</a>. For the remainder of this discussion, we will use BVLC Caffe, though NVIDIA Caffe should also build and work similarly.</p>
<p>Note that Caffe offers building using CMake or Make. We look at the CMake build process in this book. If you want Caffe to use the GPU, you will need to have CUDA and cuDNN libraries already installed.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing Caffe prerequisites</h1>
                </header>
            
            <article>
                
<p>Install the following prerequisites:</p>
<ol>
<li>First, install the libraries that Caffe depends on:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo apt install libboost-all-dev libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="2">
<li>For BLAS on CPU, the best performance comes from installing Intel's MKL libraries. (Steps to install MKL were described in <a href="5f3ecee9-fc6c-4a3f-bc8f-3bffb7cb2269.xhtml">Chapter 1</a>, <em>Introduction and Installation</em>.) If you do not have MKL, or you are not using an Intel CPU, then you can install either ATLAS or OpenBLAS:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo apt install libatlas-base-dev libopenblas-dev</strong></pre>
<ol start="3">
<li>To build the Python interface to Caffe, make sure these packages are installed:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo apt install libboost-python-dev python-skimage python-protobuf</strong></pre>
<p>We are now ready to build Caffe from source.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building Caffe</h1>
                </header>
            
            <article>
                
<p>To build Caffe, observe the following steps:</p>
<ol>
<li>Since we have chosen to use CMake, the building process is simple and straightforward:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ mkdir build</strong><br/><strong>$ cd build</strong><br/><strong>$ cmake ..</strong><br/><strong>$ make</strong></pre>
<ol start="2">
<li>To build and run the Caffe unit tests, execute the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ make runtest</strong></pre>
<div class="packt_infobox">This can take a substantial amount of time to finish.</div>
<ol start="3">
<li>To build the Python interface to Caffe<span>, execute the following command</span>:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ make pycaffe</strong><br/><strong>$ make install</strong></pre>
<ol start="4">
<li>By default, the install directory will be a subdirectory inside the <kbd>build</kbd> directory. Add this <kbd>build/install/python</kbd> path to the <kbd>PYTHONPATH</kbd> environment variable before you import Caffe into Python.</li>
</ol>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Caffe model file formats</h1>
                </header>
            
            <article>
                
<p>To be able to use Caffe models in Caffe2, we first need to understand the model file formats that Caffe can export to. Caffe exports a trained model into two files, as follows:</p>
<ol>
<li>The structure of the neural network is stored as a <kbd>.prototxt</kbd> file</li>
<li>The weights of the layers of the neural network are stored as a <kbd>.caffemodel</kbd> file</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Prototxt file</h1>
                </header>
            
            <article>
                
<p>The prototxt is a text file that holds information about the structure of the neural network:</p>
<ul>
<li>A list of layers in the neural network</li>
<li>The parameters of each layer, such as its name, type, input dimensions, and output dimensions</li>
<li>The connections between the layers</li>
</ul>
<p>Caffe exports a neural network by serializing it using the Google <strong>Protocol Buffers</strong> (<strong>ProtoBuf</strong>) serialization library. The prototxt file is a serialization of the neural network structure in the ProtoBuf text format.</p>
<p>We can look at the prototxt files of some of the popular CNN networks in the <kbd>models</kbd> directory in the Caffe source code. (Refer to the <em>Building and Installing Caffe</em> section on how to get Caffe source code.) You might find several prototxt filenames there, each of which has a different purpose.</p>
<p>Here is a description of what some of the typical Caffe prototxt filenames mean:</p>
<ul>
<li><kbd>deploy.prototxt</kbd>: This file describes the structure of the network that can be deployed for inference. It does not include the extra layers that are typically required for training a network. (We looked at extra layers or operators added to network for training in <a href="3c2dd7d3-b762-49a3-a5d6-0b791eadadb2.xhtml">Chapter 3</a>, <em>Training Networks</em>.) This is the prototxt file we typically want, if we wish to take a pretrained Caffe model and use it for inference in Caffe2.</li>
<li><kbd>train_val.prototxt</kbd>: This file describes the structure of the network that was used for training. It includes all the extra layers that were added to aid in the training and validation process. This is the prototxt file we typically want, if we wish to take a pretrained Caffe model and continue training or fine-tuning it in Caffe2.</li>
</ul>
<p>Now, let's look at AlexNet as an example. (AlexNet was introduced earlier in this chapter.) A version of the AlexNet pretrained model is available in the Caffe source code in the <kbd>models/bvlc_alexnet</kbd> directory.</p>
<p>Here are the first two layers from the <kbd>deploy.prototxt</kbd> file of AlexNet:</p>
<pre><strong>$ head -26 models/bvlc_alexnet/deploy.prototxt</strong><br/>name: "AlexNet"<br/>layer {<br/>  name: "data"<br/>  type: "Input"<br/>  top: "data"<br/>  input_param { shape: { dim: 10 dim: 3 dim: 227 dim: 227 } }<br/>}<br/>layer {<br/>  name: "conv1"<br/>  type: "Convolution"<br/>  bottom: "data"<br/>  top: "conv1"<br/>  param {<br/>    lr_mult: 1<br/>    decay_mult: 1<br/>  }<br/>  param {<br/>    lr_mult: 2<br/>    decay_mult: 0<br/>  }<br/>  convolution_param {<br/>    num_output: 96<br/>    kernel_size: 11<br/>    stride: 4<br/>  }<br/>}</pre>
<p>We can see that the <kbd>prototxt</kbd> file format is easy to read and modify by humans. Note that the network is named <kbd>"AlexNet"</kbd>. We can see two layers in the preceding code snippet named <kbd>"data"</kbd> and <kbd>"conv1"</kbd>. The <kbd>"data"</kbd> layer is an <kbd>Input</kbd> layer and we can see that it requires input to be of dimensions <img class="fm-editor-equation" src="assets/c45f6c81-95fe-4555-ad87-e7ad610e6c4a.png" style="width:8.92em;height:0.92em;"/>. The <kbd>"conv1"</kbd> layer is a <kbd>Convolution</kbd> layer and we can see many of its parameters, including a kernel size of <img class="fm-editor-equation" src="assets/09207daa-bfd8-4c9e-b002-9670976ba764.png" style="width:3.25em;height:0.83em;"/> and stride of size <img class="fm-editor-equation" src="assets/4a34b802-04cc-4c4e-8a3d-382d36dcabfd.png" style="width:2.00em;height:0.75em;"/>.</p>
<p>The syntax used for describing a neural network as a Caffe prototxt file is, itself, described in a <kbd>caffe.proto</kbd> text file. This is a file written in the Google protocol buffer language. You can find this file in the Caffe source code at <kbd>src/caffe/proto/caffe.proto</kbd>.</p>
<p>As an example, here is a partial description of <kbd>ConvolutionParameter</kbd> from the <kbd>caffe.proto</kbd> file:</p>
<pre>message ConvolutionParameter {<br/>  optional uint32 num_output = 1; // The number of outputs for the layer<br/>  optional bool bias_term = 2 [default = true]; // whether to have bias <br/>  //terms<br/><br/>  // Pad, kernel size, and stride are all given as a single value for equal<br/>  // dimensions in all spatial dimensions, or once per spatial dimension.<br/>  repeated uint32 pad = 3; // The padding size; defaults to 0<br/>  repeated uint32 kernel_size = 4; // The kernel size<br/>  repeated uint32 stride = 6; // The stride; defaults to 1<br/>  optional uint32 pad_h = 9 [default = 0]; // The padding height (2D only)<br/>  optional uint32 pad_w = 10 [default = 0]; // The padding width (2D only)<br/><br/>  optional uint32 group = 5 [default = 1]; // The group size for group conv<br/><br/>  // ... Omitted other details.<br/>  // ... Find all details in caffe.proto<br/>}</pre>
<p>By looking at this, we can start to understand the convolution layer parameters in the <kbd>deploy.prototxt</kbd> easily, for example, what the parameters <kbd>num_outputs</kbd>, <kbd>kernel_size</kbd>, and <kbd>stride</kbd> mean.</p>
<p>In this way, you can understand any Caffe prototxt file that you come across. It is essentially a list of layers, with names and parameters and links to previous and later layers. For information about a particular layer type, refer to the <kbd>caffe.proto</kbd> file.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Caffemodel file</h1>
                </header>
            
            <article>
                
<p>The <kbd>caffemodel</kbd> file is a binary file that holds the weights of the layers of a neural network. This file is a serialization of the trained neural network in the <strong>ProtoBuf binary format</strong>. A binary format is used because of the need to store floating point or integer values that represent the weights. This file is typically large, in the order of hundreds of megabytes, and so it typically needs to be downloaded separately.</p>
<p>For each of the popular models that Caffe provides along with its source code, there is a corresponding <kbd>readme.md</kbd> file that has the details required to download the <kbd>caffemodel</kbd> file for that network. As an example, Figure 4.2 shows the <kbd>readme.md</kbd> of the AlexNet model:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-296 image-border" src="assets/23c3070a-8b79-40b6-8d40-1e0719b290f9.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 4.2: readme.md of the AlexNet model</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Downloading Caffe model files</h1>
                </header>
            
            <article>
                
<p>Caffe provides a Python script in <kbd>scripts/download_model_binary.py</kbd> in its source code that can be used to download the caffemodel files of a model. This script needs to be provided with the model directory as input. For example, to download the <kbd>caffemodel</kbd> file for AlexNet, we can invoke the following command:</p>
<pre><strong>$ python scripts/download_model_binary.py models/bvlc_alexnet/</strong></pre>
<p>This script looks for a <kbd>readme.md</kbd> in the input model directory (like the one in <em>Figure 4.2</em>), figures out the caffemodel URL from the preamble in the <kbd>readme.md</kbd>, downloads the <kbd>caffemodel</kbd> file, and ensures that the downloaded file is correct by matching its SHA1 hash to the hash provided in the preamble.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Caffe2 model file formats</h1>
                </header>
            
            <article>
                
<p>To be able to use Caffe models in Caffe2, we also need to understand the model file formats that Caffe2 can import. Just like Caffe, Caffe2 also uses Protobuf for serialization and deserialization of its model files. Caffe2 imports a trained model from two files:</p>
<ol>
<li>The structure of the neural network stored as a <kbd>predict_net.pb</kbd> file or as a <kbd>predict_net.pbtxt</kbd> file</li>
<li>The weights of the operators of the neural network stored as a <kbd>init_net.pb</kbd> file</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">predict_net file</h1>
                </header>
            
            <article>
                
<p>The <kbd>predict_net</kbd> binary file, which is usually named <kbd>predict_net.pb</kbd>, holds the list of operators in the neural network, the parameters of each operator, and the connections between the operators. This file is a serialization of the neural network structure in the ProtoBuf binary format.</p>
<p>We can observe that Caffe2 uses a binary serialization file compared to a text serialization file used by Caffe. This is not too much trouble in Caffe2 because it has a Python API that can be used to easily understand the network structure after importing the file.</p>
<p>Optionally, we can also use <kbd>predict_net</kbd> text file, usually named <kbd>predict_net.pbtxt</kbd>, which is a text file that is equivalent to the <kbd>predict_net</kbd> binary file, but stored in the ProtoBuf text format.</p>
<p>Continuing with our AlexNet example, the first convolution layer of that network would appear as a convolution operator in <kbd>predict_net.pbtxt</kbd>, shown as follows:</p>
<pre>name: "AlexNet"<br/>op {<br/>  input: "data"<br/>  input: "conv1_w"<br/>  input: "conv1_b"<br/>  output: "conv1"<br/>  type: "Conv"<br/>  arg {<br/>    name: "stride"<br/>    i: 4<br/>  }<br/>  arg {<br/>    name: "pad"<br/>    i: 0<br/>  }<br/>  arg {<br/>    name: "kernel"<br/>    i: 11<br/>  }<br/>}</pre>
<p>Note how the <kbd>predict_net</kbd> text file is quite easy for humans to read, just like the prototxt text file of Caffe.</p>
<p>The syntax used for describing a neural network as a Caffe2 <kbd>predict_net</kbd> file is itself described in a <kbd>caffe2.proto</kbd> text file. This is a file written in the Google protocol buffer language. You can find this file in the Caffe2 source code at <kbd>proto/caffe2.proto</kbd>.</p>
<p>Here is the definition of the operator from <kbd>caffe2.proto</kbd>:</p>
<pre>// Operator Definition.<br/>message OperatorDef {<br/>  repeated string input = 1; // the name of the input blobs<br/>  repeated string output = 2; // the name of output top blobs<br/>  optional string name = 3; // the operator name. This is optional.<br/>  // the operator type. This is needed to create the object from the <br/>  //operator<br/>  // registry.<br/>  optional string type = 4;<br/>  repeated Argument arg = 5;<br/><br/>  // The device option that the operator should run under.<br/>  optional DeviceOption device_option = 6;<br/><br/>  // Optionally, one can specify an engine when there are multiple<br/>  // implementations available simultaneously for one device type.<br/>  // If one specifies an engine but that engine does not exist in the <br/>  //compiled<br/>  // Caffe2 binary, Caffe2 will fall back to the default engine of that <br/>  //device<br/>  // type.<br/>  optional string engine = 7;<br/><br/>  // ... Omitted other details.<br/>  // ... Find all details in caffe2.proto<br/>}</pre>
<p>We can see how Caffe2 defines an operator in more general terms, instead of focusing on defining each and every operator (or layer) explicitly as Caffe did.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">init_net file</h1>
                </header>
            
            <article>
                
<p>The <kbd>init_net binary file</kbd>, which is typically named <kbd>init_net.pb</kbd>, holds the weights of the operators of a neural network. This file is a serialization of the trained neural network in the ProtoBuf binary format. Just like the Caffe <kbd>caffemodel</kbd> file, this file too can be typically large, in the order of hundreds of megabytes. It is named <kbd>init_net</kbd> because the weights inside the file can be used to initialize the operators in the network.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Converting a Caffe model to Caffe2</h1>
                </header>
            
            <article>
                
<p>To be able to use a Caffe model in Caffe2, we need to convert it from its Caffe formats to Caffe2 file formats. Caffe2 provides a script named <kbd>python/caffe_translator.py</kbd> that can be used for this purpose.</p>
<p>For example, we can convert our AlexNet files from Caffe to Caffe2 by invoking the script as follows:</p>
<pre><strong>$ python python/caffe_translator.py</strong> <strong>path_to_caffe/models/bvlc_alexnet/deploy.prototxt path_to_caffe/models/bvlc_alexnet/bvlc_alexnet.caffemodel --init_net init_net.pb --predict_net predict_net.pb</strong></pre>
<p>Running this script generates three files, <kbd>predict_net.pb</kbd>, <kbd>predict_net.pbtxt</kbd>, and <kbd>init_net.pb</kbd>, for AlexNet:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-475 image-border" src="assets/a9e99589-e2ad-46ee-94e0-e5fab9850175.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 4.3: AlexNet network structure in Caffe2</div>
<p><em>Figure 4.3</em> shows the AlexNet network structure in Caffe2 after it was converted from the Caffe model. This graph visualization was generated using the <kbd>Caffe2 net_drawer.py</kbd> tool that utilizes GraphViz for the network layout. You can find more information about Caffe2 model visualization using <kbd>net_drawer</kbd> in <a href="91e4cdcf-24f6-4426-ac95-b6845c020d83.xhtml">Chapter 7</a>, <em>Caffe2 at the Edge and in the cloud</em>.</p>
<p>From the diagram, we can see that every Caffe layer is replaced with a Caffe2 operator. The operators are drawn in rectangles and both weights and data tensors are drawn as elongated octagons. By looking at the first convolution operator, we note how it has three tensors—one for the data (named <kbd>data</kbd>), and two for the weights and bias for that operator (named <kbd>conv1_w</kbd> and <kbd>conv1_b</kbd>).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Converting a Caffe2 model to Caffe</h1>
                </header>
            
            <article>
                
<p>In the previous sections in this chapter, we focused on how to convert a Caffe model to a Caffe2 model. Since Caffe is not being actively developed now, and Caffe2 was, in part, created to supersede Caffe2, this path of migrating a Caffe model to Caffe2 is what the majority of users are interested in.</p>
<p>However, if you need to use a Caffe2 model in Caffe, then that process is bound to be more arduous. There does not seem to be any direct way to convert a Caffe2 model to Caffe. If you are sure that the Caffe2 operators and their arguments are fully supported in Caffe, then you could try going through an intermediary format such as ONNX (see <a href="4481e225-7882-4625-9d42-63ba41e74b4f.xhtml">Chapter 5</a>, <em>Working with Other Frameworks</em>).</p>
<p>If the ONNX route is not feasible, then you might have to resort to executing the following tasks <span>manually</span>:</p>
<ol>
<li>Export Caffe2 operators, arguments, and weights of the model</li>
<li>Create a Caffe network manually, matching Caffe2 operators to corresponding Caffe layers</li>
<li>Implement new Caffe layers in C++ if there isn't a layer matching an operator</li>
<li>Load weights manually to Caffe layers and use this Caffe network for inference</li>
</ol>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we introduced the Caffe deep learning framework and examined the relationship between Caffe and Caffe2. We examined the Caffe and Caffe2 model file formats. Using AlexNet as an example network, we looked at how to convert a Caffe model to Caffe2 format. Finally, we looked at the difficulties in converting a Caffe2 model to Caffe.</p>
<p>Caffe is a DL framework that has reached its end of life and no new features are being added to it. In the next chapter, we will look at contemporary DL frameworks, such as TensorFlow and PyTorch, and see how we can exchange models to and from Caffe2 and these other frameworks.</p>


            </article>

            
        </section>
    </body></html>