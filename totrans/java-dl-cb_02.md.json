["```py\nString[] allowedFormats=new String[]{\".JPEG\"};\n FileSplit fileSplit = new FileSplit(new File(\"temp\"), allowedFormats,true)\n\n```", "```py\nFileSplit fileSplit = new FileSplit(new File(\"temp\"));\n CollectionInputSplit collectionInputSplit = new CollectionInputSplit(fileSplit.locations());\n```", "```py\nNumberedFileInputSplit numberedFileInputSplit = new NumberedFileInputSplit(\"numberedfiles/file%d.txt\",1,4);\n numberedFileInputSplit.locationsIterator().forEachRemaining(System.out::println);\n```", "```py\nTransformSplit.URITransform uriTransform = URI::normalize;\n\n List<URI> uriList = Arrays.asList(new URI(\"file://storage/examples/./cats.txt\"),\n new URI(\"file://storage/examples//dogs.txt\"),\n new URI(\"file://storage/./examples/bear.txt\"));\n\n TransformSplit transformSplit = new TransformSplit(new CollectionInputSplit(uriList),uriTransform);\n```", "```py\nInputSplit transformSplit = TransformSplit.ofSearchReplace(new CollectionInputSplit(inputFiles),\"-in.csv\",\"-out.csv\");      \n```", "```py\nRecordReader reader = new CSVRecordReader(numOfRowsToSkip,deLimiter);\n recordReader.initialize(new FileSplit(file));\n```", "```py\nImageRecordReader imageRecordReader = new ImageRecordReader(imageHeight,imageWidth,channels,parentPathLabelGenerator);\nimageRecordReader.initialize(trainData,transform);\n```", "```py\nRecordReader recordReader = new TransformProcessRecordReader(recordReader,transformProcess);\n```", "```py\nRecordReader codecReader = new CodecRecordReader();\n codecReader.initialize(conf,split);\n```", "```py\nRecordReader recordReader = new RegexSequenceRecordReader((\\d{2}/\\d{2}/\\d{2}) (\\d{2}:\\d{2}:\\d{2}) ([A-Z]) (.*)\",skipNumLines);\n recordReader.initialize(new NumberedFileInputSplit(path/log%d.txt));\n```", "```py\nCSVSequenceRecordReader seqReader = new CSVSequenceRecordReader(skipNumLines, delimiter);\n seqReader.initialize(new FileSplit(file));\n```", "```py\nRecordReader recordReader = new JacksonLineRecordReader(fieldSelection, new ObjectMapper(new JsonFactory()));\n recordReader.initialize(new FileSplit(new File(\"json_file.txt\")));\n```", "```py\nINDArray factor = org.nd4j.linalg.dimensionalityreduction.PCA.pca_factor(inputFeatures, projectedDimension, normalize);\n INDArray reduced = inputFeatures.mmul(factor);\n```", "```py\n  Schema schema = new Schema.Builder()\n .addColumnString(\"RowNumber\")\n .addColumnInteger(\"CustomerId\")\n .addColumnString(\"Surname\")\n .addColumnInteger(\"CreditScore\")\n .addColumnCategorical(\"Geography\",  \n  Arrays.asList(\"France\",\"Germany\",\"Spain\"))\n .addColumnCategorical(\"Gender\", Arrays.asList(\"Male\",\"Female\"))\n .addColumnsInteger(\"Age\", \"Tenure\")\n .addColumnDouble(\"Balance\")\n .addColumnsInteger(\"NumOfProducts\",\"HasCrCard\",\"IsActiveMember\")\n .addColumnDouble(\"EstimatedSalary\")\n .build();\n```", "```py\nDataAnalysis analysis = AnalyzeLocal.analyze(mySchema, csvRecordReader);\n System.out.println(analysis);\n```", "```py\nDataQualityAnalysis quality = AnalyzeLocal.analyzeQuality(mySchema, csvRecordReader);\n System.out.println(quality);\n```", "```py\nTransformProcess transformProcess = new TransformProcess.Builder(schema)\n .removeColumns(\"RowNumber\",\"CustomerId\",\"Surname\")\n .categoricalToInteger(\"Gender\")\n .categoricalToOneHot(\"Geography\")\n .removeColumns(\"Geography[France]\")\n .build();\n```", "```py\nTransformProcessRecordReader transformProcessRecordReader = new TransformProcessRecordReader(recordReader,transformProcess);\n```", "```py\nFilter filter = new ConditionFilter(new NaNColumnCondition(\"columnName\"));\n\n```", "```py\nFilter filter =  new ConditionFilter(new NullWritableColumnCondition(\"columnName\"));  \n\n```", "```py\nString serializedTransformString = transformProcess.toJson()\n```", "```py\nString serializedTransformString = transformProcess.toYaml()\n```", "```py\nTransformProcess tp = TransformProcess.fromJson(serializedTransformString)\n\n```", "```py\nTransformProcess tp = TransformProcess.fromYaml(serializedTransformString)\n```", "```py\nRecordReader reader = new CSVRecordReader(0,',');\n reader.initialize(new FileSplit(file)); \n\n```", "```py\nList<List<Writable>> transformed = LocalTransformExecutor.execute(recordReader, transformProcess)\n```", "```py\nJavaRDD<List<Writable>> transformed = SparkTransformExecutor.execute(inputRdd, transformProcess)\n```", "```py\nList<List<List<Writable>>> transformed = LocalTransformExecutor.executeSequence(sequenceRecordReader, transformProcess)\n\n```", "```py\nList<List<Writable>> transformed = LocalTransformExecutor.executeJoin(joinCondition, leftReader, rightReader) \n\n```", "```py\nDataSetIterator iterator = new RecordReaderDataSetIterator(recordReader,batchSize);\n\n```", "```py\nDataNormalization dataNormalization = new NormalizerStandardize();\ndataNormalization.fit(iterator);\n```", "```py\niterator.setPreProcessor(dataNormalization);\n```"]