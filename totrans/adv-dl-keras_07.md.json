["```py\n$ sudo pip3 install git+https://www.github.com/keras-team/keras-contrib.git\n\n```", "```py\ndef encoder_layer(inputs,\n                  filters=16,\n                  kernel_size=3,\n                  strides=2,\n                  activation='relu',\n                  instance_norm=True):\n    \"\"\"Builds a generic encoder layer made of Conv2D-IN-LeakyReLU\n    IN is optional, LeakyReLU may be replaced by ReLU\n\n    \"\"\"\n\n    conv = Conv2D(filters=filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same')\n\n    x = inputs\n    if instance_norm:\n        x = InstanceNormalization()(x)\n    if activation == 'relu':\n        x = Activation('relu')(x)\n    else:\n        x = LeakyReLU(alpha=0.2)(x)\n    x = conv(x)\n    return x\n\ndef decoder_layer(inputs,\n                  paired_inputs,\n                  filters=16,\n                  kernel_size=3,\n                  strides=2,\n                  activation='relu',\n                  instance_norm=True):\n    \"\"\"Builds a generic decoder layer made of Conv2D-IN-LeakyReLU\n    IN is optional, LeakyReLU may be replaced by ReLU\n    Arguments: (partial)\n    inputs (tensor): the decoder layer input\n    paired_inputs (tensor): the encoder layer output \n          provided by U-Net skip connection &\n          concatenated to inputs.\n    \"\"\"\n\n    conv = Conv2DTranspose(filters=filters,\n                           kernel_size=kernel_size,\n                           strides=strides,\n                           padding='same')\n\n    x = inputs\n    if instance_norm:\n        x = InstanceNormalization()(x)\n    if activation == 'relu':\n        x = Activation('relu')(x)\n    else:\n        x = LeakyReLU(alpha=0.2)(x)\n    x = conv(x)\n    x = concatenate([x, paired_inputs])\n    return x\n```", "```py\ndef build_generator(input_shape,\n                    output_shape=None,\n                    kernel_size=3,\n                    name=None):\n    \"\"\"The generator is a U-Network made of a 4-layer encoder\n    and a 4-layer decoder. Layer n-i is connected to layer i.\n\n    Arguments:\n    input_shape (tuple): input shape\n    output_shape (tuple): output shape\n    kernel_size (int): kernel size of encoder & decoder layers\n    name (string): name assigned to generator model\n\n    Returns:\n    generator (Model):\n\n    \"\"\"\n\n    inputs = Input(shape=input_shape)\n    channels = int(output_shape[-1])\n    e1 = encoder_layer(inputs,\n                       32,\n                       kernel_size=kernel_size,\n                       activation='leaky_relu',\n                       strides=1)\n    e2 = encoder_layer(e1,\n                       64,\n                       activation='leaky_relu',\n                       kernel_size=kernel_size)\n    e3 = encoder_layer(e2,\n                       128,\n                       activation='leaky_relu',\n                       kernel_size=kernel_size)\n    e4 = encoder_layer(e3,\n                       256,\n                       activation='leaky_relu',\n                       kernel_size=kernel_size)\n\n    d1 = decoder_layer(e4,\n                       e3,\n                       128,\n                       kernel_size=kernel_size)\n    d2 = decoder_layer(d1,\n                       e2,\n                       64,\n                       kernel_size=kernel_size)\n    d3 = decoder_layer(d2,\n                       e1,\n                       32,\n                       kernel_size=kernel_size)\n    outputs = Conv2DTranspose(channels,\n                              kernel_size=kernel_size,\n                              strides=1,\n                              activation='sigmoid',\n                              padding='same')(d3)\n\n    generator = Model(inputs, outputs, name=name)\n\n    return generator\n```", "```py\ndef build_discriminator(input_shape,\n                        kernel_size=3,\n                        patchgan=True,\n                        name=None):\n    \"\"\"The discriminator is a 4-layer encoder that outputs either\n    a 1-dim or a n x n-dim patch of probability that input is real \n\n    Arguments:\n    input_shape (tuple): input shape\n    kernel_size (int): kernel size of decoder layers\n    patchgan (bool): whether the output is a patch or just a 1-dim\n    name (string): name assigned to discriminator model\n\n    Returns:\n    discriminator (Model):\n\n    \"\"\"\n\n    inputs = Input(shape=input_shape)\n    x = encoder_layer(inputs,\n                      32,\n                      kernel_size=kernel_size,\n                      activation='leaky_relu',\n                      instance_norm=False)\n    x = encoder_layer(x,\n                      64,\n                      kernel_size=kernel_size,\n                      activation='leaky_relu',\n                      instance_norm=False)\n    x = encoder_layer(x,\n                      128,\n                      kernel_size=kernel_size,\n                      activation='leaky_relu',\n                      instance_norm=False)\n    x = encoder_layer(x,\n                      256,\n                      kernel_size=kernel_size,\n                      strides=1,\n                      activation='leaky_relu',\n                      instance_norm=False)\n\n    # if patchgan=True use nxn-dim output of probability\n    # else use 1-dim output of probability\n    if patchgan:\n        x = LeakyReLU(alpha=0.2)(x)\n        outputs = Conv2D(1,\n                         kernel_size=kernel_size,\n                         strides=1,\n                         padding='same')(x)\n    else:\n        x = Flatten()(x)\n        x = Dense(1)(x)\n        outputs = Activation('linear')(x)\n\n    discriminator = Model(inputs, outputs, name=name)\n\n    return discriminator\n```", "```py\ndef build_cyclegan(shapes,\n                   source_name='source',\n                   target_name='target',\n                   kernel_size=3,\n                   patchgan=False,\n                   identity=False\n                   ):\n    \"\"\"Build the CycleGAN\n\n    1) Build target and source discriminators\n    2) Build target and source generators\n    3) Build the adversarial network\n\n    Arguments:\n    shapes (tuple): source and target shapes\n    source_name (string): string to be appended on dis/gen models\n    target_name (string): string to be appended on dis/gen models\n    kernel_size (int): kernel size for the encoder/decoder or dis/gen\n                       models\n    patchgan (bool): whether to use patchgan on discriminator\n    identity (bool): whether to use identity loss\n\n    Returns:\n    (list): 2 generator, 2 discriminator, and 1 adversarial models \n\n    \"\"\"\n\n    source_shape, target_shape = shapes\n    lr = 2e-4\n    decay = 6e-8\n    gt_name = \"gen_\" + target_name\n    gs_name = \"gen_\" + source_name\n    dt_name = \"dis_\" + target_name\n    ds_name = \"dis_\" + source_name\n\n    # build target and source generators\n    g_target = build_generator(source_shape,\n                               target_shape,\n                               kernel_size=kernel_size,\n                               name=gt_name)\n    g_source = build_generator(target_shape,\n                               source_shape,\n                               kernel_size=kernel_size,\n                               name=gs_name)\n    print('---- TARGET GENERATOR ----')\n    g_target.summary()\n    print('---- SOURCE GENERATOR ----')\n    g_source.summary()\n\n    # build target and source discriminators\n    d_target = build_discriminator(target_shape,\n                                   patchgan=patchgan,\n                                   kernel_size=kernel_size,\n                                   name=dt_name)\n    d_source = build_discriminator(source_shape,\n                                   patchgan=patchgan,\n                                   kernel_size=kernel_size,\n                                   name=ds_name)\n    print('---- TARGET DISCRIMINATOR ----')\n    d_target.summary()\n    print('---- SOURCE DISCRIMINATOR ----')\n    d_source.summary()\n\n    optimizer = RMSprop(lr=lr, decay=decay)\n    d_target.compile(loss='mse',\n                     optimizer=optimizer,\n                     metrics=['accuracy'])\n    d_source.compile(loss='mse',\n                     optimizer=optimizer,\n                     metrics=['accuracy'])\n    # freeze the discriminator weights in the adversarial model\n    d_target.trainable = False\n    d_source.trainable = False\n\n    # build the computational graph for the adversarial model\n    # forward cycle network and target discriminator\n    source_input = Input(shape=source_shape)\n    fake_target = g_target(source_input)\n    preal_target = d_target(fake_target)\n    reco_source = g_source(fake_target)\n\n    # backward cycle network and source discriminator\n    target_input = Input(shape=target_shape)\n    fake_source = g_source(target_input)\n    preal_source = d_source(fake_source)\n    reco_target = g_target(fake_source)\n\n    # if we use identity loss, add 2 extra loss terms\n    # and outputs\n    if identity:\n        iden_source = g_source(source_input)\n        iden_target = g_target(target_input)\n        loss = ['mse', 'mse', 'mae', 'mae', 'mae', 'mae']\n        loss_weights = [1., 1., 10., 10., 0.5, 0.5]\n        inputs = [source_input, target_input]\n        outputs = [preal_source,\n                   preal_target,\n                   reco_source,\n                   reco_target,\n                   iden_source,\n                   iden_target]\n    else:\n        loss = ['mse', 'mse', 'mae', 'mae']\n        loss_weights = [1., 1., 10., 10.]\n        inputs = [source_input, target_input]\n        outputs = [preal_source,\n                   preal_target,\n                   reco_source,\n                   reco_target]\n\n    # build adversarial model\n    adv = Model(inputs, outputs, name='adversarial')\n    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n    adv.compile(loss=loss,\n                loss_weights=loss_weights,\n                optimizer=optimizer,\n                metrics=['accuracy'])\n    print('---- ADVERSARIAL NETWORK ----')\n    adv.summary()\n\n    return g_source, g_target, d_source, d_target, adv\n```", "```py\ndef train_cyclegan(models, data, params, test_params, test_generator):\n    \"\"\" Trains the CycleGAN. \n\n    1) Train the target discriminator\n    2) Train the source discriminator\n    3) Train the forward and backward cyles of adversarial networks\n\n    Arguments:\n    models (Models): Source/Target Discriminator/Generator,\n                     Adversarial Model\n    data (tuple): source and target training data\n    params (tuple): network parameters\n    test_params (tuple): test parameters\n    test_generator (function): used for generating predicted target\n                    and source images\n    \"\"\"\n\n    # the models\n    g_source, g_target, d_source, d_target, adv = models\n    # network parameters\n    batch_size, train_steps, patch, model_name = params\n    # train dataset\n    source_data, target_data, test_source_data, test_target_data = data\n\n    titles, dirs = test_params\n\n    # the generator image is saved every 2000 steps\n    save_interval = 2000\n    target_size = target_data.shape[0]\n    source_size = source_data.shape[0]\n\n    # whether to use patchgan or not\n    if patch > 1:\n        d_patch = (patch, patch, 1)\n        valid = np.ones((batch_size,) + d_patch)\n        fake = np.zeros((batch_size,) + d_patch)\n    else:\n        valid = np.ones([batch_size, 1])\n        fake = np.zeros([batch_size, 1])\n\n    valid_fake = np.concatenate((valid, fake))\n    start_time = datetime.datetime.now()\n\n    for step in range(train_steps):\n        # sample a batch of real target data\n        rand_indexes = np.random.randint(0, target_size, size=batch_size)\n        real_target = target_data[rand_indexes]\n\n        # sample a batch of real source data\n        rand_indexes = np.random.randint(0, source_size, size=batch_size)\n        real_source = source_data[rand_indexes]\n        # generate a batch of fake target data fr real source data\n        fake_target = g_target.predict(real_source)\n\n        # combine real and fake into one batch\n        x = np.concatenate((real_target, fake_target))\n        # train the target discriminator using fake/real data\n        metrics = d_target.train_on_batch(x, valid_fake)\n        log = \"%d: [d_target loss: %f]\" % (step, metrics[0])\n\n        # generate a batch of fake source data fr real target data\n        fake_source = g_source.predict(real_target)\n        x = np.concatenate((real_source, fake_source))\n        # train the source discriminator using fake/real data\n        metrics = d_source.train_on_batch(x, valid_fake)\n        log = \"%s [d_source loss: %f]\" % (log, metrics[0])\n\n        # train the adversarial network using forward and backward\n        # cycles. the generated fake source and target data attempts\n        # to trick the discriminators\n        x = [real_source, real_target]\n        y = [valid, valid, real_source, real_target]\n        metrics = adv.train_on_batch(x, y)\n        elapsed_time = datetime.datetime.now() - start_time\n        fmt = \"%s [adv loss: %f] [time: %s]\"\n        log = fmt % (log, metrics[0], elapsed_time)\n        print(log)\n        if (step + 1) % save_interval == 0:\n            if (step + 1) == train_steps:\n                show = True\n            else:\n                show = False\n\n            test_generator((g_source, g_target),\n                           (test_source_data, test_target_data),\n                           step=step+1,\n                           titles=titles,\n                           dirs=dirs,\n                           show=show)\n\n    # save the models after training the generators\n    g_source.save(model_name + \"-g_source.h5\")\n    g_target.save(model_name + \"-g_target.h5\")\n```", "```py\ndef graycifar10_cross_colorcifar10(g_models=None):\n    \"\"\"Build and train a CycleGAN that can do grayscale <--> color\n       cifar10 images\n    \"\"\"\n\n    model_name = 'cyclegan_cifar10'\n    batch_size = 32\n    train_steps = 100000\n    patchgan = True\n    kernel_size = 3\n    postfix = ('%dp' % kernel_size) if patchgan else ('%d' % kernel_size)\n\n    data, shapes = cifar10_utils.load_data()\n    source_data, _, test_source_data, test_target_data = data\n    titles = ('CIFAR10 predicted source images.',\n              'CIFAR10 predicted target images.',\n              'CIFAR10 reconstructed source images.',\n              'CIFAR10 reconstructed target images.')\n    dirs = ('cifar10_source-%s' % postfix, 'cifar10_target-%s' %Â postfix)\n\n   # generate predicted target(color) and source(gray) images\n    if g_models is not None:\n        g_source, g_target = g_models\n        other_utils.test_generator((g_source, g_target),\n                                   (test_source_data, test_target_data),\n                                   step=0,\n                                   titles=titles,\n                                   dirs=dirs,\n                                   show=True)\n        return\n\n    # build the cyclegan for cifar10 colorization\n    models = build_cyclegan(shapes,\n                            \"gray-%s\" % postfix,\n                            \"color-%s\" % postfix,\n                            kernel_size=kernel_size,\n                            patchgan=patchgan)\n    # patch size is divided by 2^n since we downscaled the input\n    # in the discriminator by 2^n (ie. we use strides=2 n times)\n    patch = int(source_data.shape[1] / 2**4) if patchgan else 1\n    params = (batch_size, train_steps, patch, model_name)\n    test_params = (titles, dirs)\n    # train the cyclegan\n    train_cyclegan(models,\n                   data,\n                   params,\n                   test_params,\n                   other_utils.test_generator)\n```", "```py\npython3 cyclegan-7.1.1.py --cifar10_g_source=cyclegan_cifar10-g_source.h5 --cifar10_g_target=cyclegan_cifar10-g_target.h5\n\n```", "```py\n$ sudo pip3 install git+https://www.github.com/keras-team/keras-contrib.git\n\n```", "```py\ndef mnist_cross_svhn(g_models=None):\n    \"\"\"Build and train a CycleGAN that can do mnist <--> svhn\n    \"\"\"\n\n    model_name = 'cyclegan_mnist_svhn'\n    batch_size = 32\n    train_steps = 100000\n    patchgan = True\n    kernel_size = 5\n    postfix = ('%dp' % kernel_size) if patchgan else ('%d' % kernel_size)\n\n    data, shapes = mnist_svhn_utils.load_data()\n    source_data, _, test_source_data, test_target_data = data\n    titles = ('MNIST predicted source images.',\n              'SVHN predicted target images.',\n              'MNIST reconstructed source images.',\n              'SVHN reconstructed target images.')\n    dirs = ('mnist_source-%s' % postfix, 'svhn_target-%s' % postfix)\n\n    # genrate predicted target(svhn) and source(mnist) images\n    if g_models is not None:\n        g_source, g_target = g_models\n        other_utils.test_generator((g_source, g_target),\n                                   (test_source_data, test_target_data),\n                                   step=0,\n                                   titles=titles,\n                                   dirs=dirs,\n                                   show=True)\n        return\n\n    # build the cyclegan for mnist cross svhn\n    models = build_cyclegan(shapes,\n                            \"mnist-%s\" % postfix,\n                            \"svhn-%s\" % postfix,\n                            kernel_size=kernel_size,\n                            patchgan=patchgan)\n    # patch size is divided by 2^n since we downscaled the input\n    # in the discriminator by 2^n (ie. we use strides=2 n times)\n    patch = int(source_data.shape[1] / 2**4) if patchgan else 1\n    params = (batch_size, train_steps, patch, model_name)\n    test_params = (titles, dirs)\n    # train the cyclegan\n    train_cyclegan(models,\n                   data,\n                   params,\n                   test_params,\n                   other_utils.test_generator)\n```", "```py\npython3 cyclegan-7.1.1.py --mnist_svhn_g_source=cyclegan_mnist_svhn-g_source.h5 --mnist_svhn_g_target=cyclegan_mnist_svhn-g_target.h5\n\n```"]