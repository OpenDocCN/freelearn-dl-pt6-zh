<html><head></head><body>
		<div id="_idContainer351">
			<h1 class="chapterNumber sigil_not_in_toc">9</h1>
			<h1 class="chapterTitle" xml:lang="en-GB" id="sigil_toc_id_122" lang="en-GB"><a id="_idTextAnchor177"/>Going Pro with Artificial Brains – Deep Q-Learning</h1>
</div>

			<p class="normal">This next AI model is fantastic, because it is the 
first AI model that is really inspired by human intelligence. I hope 
you're ready to go pro on the next exciting step in your AI journey; 
this book is not only a crash course on AI, but also an introduction to 
deep learning.</p>
			<p class="normal">Today, some of the top AI models integrate deep 
learning. They form a new branch of AI called deep Reinforcement 
Learning. The model we'll cover in this chapter belongs to that branch, 
and is called deep Q-learning. You already know what Q-learning is all 
about, but you might not know anything about deep learning and <strong class="bold">Artificial Neural Networks</strong> (<strong class="bold">ANNs</strong>); we'll start with<a id="_idIndexMarker237"/>
 them. Of course, if you are an expert in deep learning, you can skip 
the first sections of this chapter, but consider that a little refresher
 never hurt anyone.</p>
			<p class="normal">Before we start going through the theory, you'll 
begin with real, working code written in Python. You'll create some AI 
first, and then I'll help you understand it afterwards. Right now, we're
 going to build an ANN to predict house prices.</p>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_123" lang="en-GB"><a id="_idTextAnchor178"/>Predicting house prices</h2>
			<p class="normal">What we want to do is<a id="_idIndexMarker238"/> predict how much a certain house might cost, based on some variables. In order to do so you need to follow these four steps:</p>
			<ol>
				<li class="list">Get some historical data on house sales; for this example, you'll use a dataset of about 20,000 houses in Seattle.</li>
				<li class="list">Import this data to your code while applying some scaling to your variables (I'll explain scaling to you as we go).</li>
				<li class="list">Build an Artificial Neural Network using any library—you'll use Keras, as it is simple and reliable.</li>
				<li class="list">Train your ANN and get the results.</li>
			</ol>
			<p class="normal">Now that you<a id="_idIndexMarker239"/> know the
 structure of your future code, you can start writing it. Since all the 
libraries that you'll use are available in Google Colab, you can easily 
use it to perform this task.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_124" lang="en-GB"><a id="_idTextAnchor179"/>Uploading the dataset</h3>
			<p class="normal">Start by creating a new<a id="_idIndexMarker240"/>
 Google Colab notebook. Once we have created your new notebook, before 
you start coding anything, you have to upload your dataset. You can find
 this dataset, called <code class="Code-In-Text--PACKT-">kc_house_data.csv</code>, on the GitHub repository in the <code class="Code-In-Text--PACKT-">Chapter 09</code> folder.</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_01.png" alt=""/></figure>
			<p class="packt_figref">Figure 1: GitHub – Chapter 09</p>
			<p class="normal">Once you have done that, you can upload it to Colab by doing the following:</p>
			<ol>
				<li class="list" value="1">Click this little arrow here:<figure class="mediaobject"><img src="../Images/B14110_09_02.png" alt=""/></figure><p class="packt_figref">Figure 2: Google Colab – Uploading files (1/3)</p></li>
				<li class="list">In the window<a id="_idIndexMarker241"/> that pops up, go to <strong class="screen-text">Files</strong>. You should get something like this:<figure class="mediaobject"><img src="../Images/B14110_09_03.png" alt=""/></figure><p class="packt_figref">Figure 3: Google Colab – Uploading files (2/3)</p></li>
				<li class="list">Click on <strong class="screen-text">UPLOAD</strong> and then select the file location where you saved the <code class="Code-In-Text--PACKT-">kc_house_data</code> dataset.</li>
				<li class="list">After you have done that, you should get a new folder with our dataset, like this:
			<figure class="mediaobject"><img src="../Images/B14110_09_04.png" alt=""/></figure>
			<p class="packt_figref">Figure 4: Google Colab – Uploading files (3/3)</p>
</li>
</ol>
			<p class="normal">Great! Now you can <a id="_idIndexMarker242"/>start coding.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_125" lang="en-GB"><a id="_idTextAnchor180"/>Importing libraries</h3>
			<p class="normal">Every time you start <a id="_idIndexMarker243"/>coding something you ought to begin by importing the necessary libraries. Therefore, we start our code with these lines:</p>
			<pre class="programlisting language-markup"><code class="hljs clean"># Importing the libraries   #<span class="hljs-number">3</span>
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd   #<span class="hljs-number">4</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np   #<span class="hljs-number">5</span>
<span class="hljs-keyword">import</span> keras   #<span class="hljs-number">6</span>
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split   #<span class="hljs-number">7</span>
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler   #<span class="hljs-number">8</span>
<span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Dense, Dropout   #<span class="hljs-number">9</span>
<span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential   #<span class="hljs-number">10</span>
<span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> Adam   #<span class="hljs-number">11</span>
</code></pre>
			
			
			
			
			
			
			
			
			<p class="normal">In lines 4 and 5, after the comment, you import the <code class="Code-In-Text--PACKT-">pandas</code> and <code class="Code-In-Text--PACKT-">numpy</code>
 libraries. Pandas will help you read the dataset and NumPy is very 
useful when you're dealing with arrays or lists; you'll use it to drop 
some unnecessary columns from your dataset.</p>
			<p class="normal">In the two subsequent lines you import two useful 
tools from the Scikit-Learn library. The first one is a tool that will 
help split the dataset into a training set and a test set (you should 
always have both of them; the AI model is trained on the training set 
and then tested on the test set) and the second one is a scaler that 
will help you later when scaling values.</p>
			<p class="normal">Lines 9, 10, and 11 are responsible for importing the <code class="Code-In-Text--PACKT-">keras</code> library, which you'll use in order to build a neural network. Each of these tools is used later in the code.</p>
			<p class="normal">Now that you have imported your libraries you can 
read the dataset. Do it by using the Pandas library you imported before,
 with this one line:</p>
			<pre class="programlisting language-markup"><code class="hljs ini"><span class="hljs-comment"># Importing the dataset   #13</span>
<span class="hljs-attr">dataset</span> = pd.read_csv(<span class="hljs-string">'kc_house_data.csv'</span>)   <span class="hljs-comment">#14</span>
</code></pre>
			
			<p class="normal">Since you used <code class="Code-In-Text--PACKT-">pd</code> as an abbreviation for the Pandas library when you imported it, you can use it to shorten<a id="_idIndexMarker244"/> your code. After you call the Pandas library with <code class="Code-In-Text--PACKT-">pd</code>, you can use one of its functions, <code class="Code-In-Text--PACKT-">read_csv</code>, which, as the name suggests, reads csv files. Then in the brackets you input the file name, which in your case is <code class="Code-In-Text--PACKT-">kc_house_data.csv</code>. No other arguments are needed.</p>
			<p class="normal">Now I have a little exercise for you! Have a look 
at the dataset and try to judge which of the variables will matter for 
our price prediction. Believe me, not all of them are relevant. I 
strongly suggest that you try to do it alone even though we'll discuss 
them in the next section.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_126" lang="en-GB"><a id="_idTextAnchor181"/>Excluding variables</h3>
			<p class="normal">Were you able to discern<a id="_idIndexMarker245"/> which variables are necessary and which are not? Don't worry if not; we'll explain them and their relevance right now.</p>
			<p class="normal">The following table explains every column in our dataset:</p>
			<table id="table001" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<strong class="heading">Variable</strong>
						</td>
						<td class="No-Table-Style">
							<strong class="heading">Description</strong>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Id</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Unique ID for each household</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Date</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Date when the house was sold</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Price</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">How much the house cost when sold</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Bedrooms</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Number of bedrooms</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Bathrooms</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Number of bathrooms; 0.5 represents room with a toilet but no shower</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Sqft_living</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Square footage of the apartment's interior living space</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Sqft_lot</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Square footage of the land space</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Floors</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Number of floors</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Waterfront</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">0 if the apartment doesn't overlooking the waterfront, 1 if it does</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">View</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Value in the range 0-4 depending on how good the view of the property is</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Condition</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Value from 1-5 defining the condition of the property</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Grade</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Value from 1-13 indicating the design and construction of the building</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Sqft_above</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">The square footage of the interior housing space that is above ground level</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Sqft_basement</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">The square footage of the basement</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Yr_built</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Year when the house was built </p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Yr_renovated</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Year<a id="_idIndexMarker246"/> when the house was renovated (0 if wasn't)</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Zipcode</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Zip code of the area house is located in</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Lat</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Latitude</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Long</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Longitude</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Sqft_living15</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">The square footage of the interior housing living space for the nearest 15 neighbors</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Sqft_lot15</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Square footage of the land lots of the nearest 15 neighbors</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="normal">It turns out that from those 21 variables, only 18 
count. That is because unique, category-like values do not have any 
impact on your prediction. That includes Id, Date, and Zipcode. Price is
 the target of your prediction, and therefore you should get rid of that
 from your variables as well. After all that, you have 17 independent 
variables.</p>
			<p class="normal">Now that we have <a id="_idIndexMarker247"/>explained
 all the variables and decided which are relevant and which are not, you
 can go back to your code. You're going to exclude these unnecessary 
variables and split the dataset into the features and the target (in our
 case the target is price).</p>
			<pre class="programlisting language-markup"><code class="hljs ini"><span class="hljs-comment"># Getting separately the features and the targets   #16</span>
<span class="hljs-attr">X</span> = dataset.iloc[:, <span class="hljs-number">3</span>:].values   <span class="hljs-comment">#17</span>
<span class="hljs-attr">X</span> = X[:, np.r_[<span class="hljs-number">0</span>:<span class="hljs-number">13</span>,<span class="hljs-number">14</span>:<span class="hljs-number">18</span>]]   <span class="hljs-comment">#18</span>
<span class="hljs-attr">y</span> = dataset.iloc[:, <span class="hljs-number">2</span>].values   <span class="hljs-comment">#19</span>
</code></pre>
			
			
			
			<p class="normal">On line 17, you take all rows and all columns 
starting with the fourth one (since you're excluding Id, Date, Price) 
from your dataset and call this new set <code class="Code-In-Text--PACKT-">X</code>. You use <code class="Code-In-Text--PACKT-">.iloc</code> to slice the dataset, and then take <code class="Code-In-Text--PACKT-">.values</code> to change it to a NumPy object. These will be your features.</p>
			<p class="normal">Next you need to exclude Zipcode, which quite 
unfortunately is in the middle of the features set. That's why you have 
to use a NumPy function (<code class="Code-In-Text--PACKT-">np.r_</code>) that separates <code class="Code-In-Text--PACKT-">X</code>,
 excludes the columns you choose (in this case it is column 14. 13 is 
the index of this column, since indexes in Python start with zero; it's 
also worth mentioning that upper bounds are excluded in Python notation,
 which is why we write <code class="Code-In-Text--PACKT-">0:13</code>), and then connects them once again to form a new array. In the next line, you get the target of your prediction and call it <code class="Code-In-Text--PACKT-">y</code>. This corresponds to the third column in your dataset, that is, Price.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_127" lang="en-GB"><a id="_idTextAnchor182"/>Data preparation</h3>
			<p class="normal">Now that you've separated <a id="_idIndexMarker248"/>your important features and target, you can split your <code class="Code-In-Text--PACKT-">X</code> and <code class="Code-In-Text--PACKT-">y</code> into training and test sets. We do that with the following line:</p>
			<pre class="programlisting language-markup"><code class="hljs nix"><span class="hljs-comment"># Splitting the dataset into a training set and a test set   #21</span>
X_train, X_test, y_train, <span class="hljs-attr">y_test</span> = train_test_split(X, y, <span class="hljs-attr">test_size</span> = <span class="hljs-number">0.2</span>, <span class="hljs-attr">random_state</span> = <span class="hljs-number">0</span>)   <span class="hljs-comment">#22</span>
</code></pre>
			
			<p class="normal">This is very important when doing any kind of 
machine learning. You always have to have a training set on which you 
train your model, and a test set on which you test it. You perform that 
operation using the <code class="Code-In-Text--PACKT-">train_test_split</code> function you imported before. After doing that, you get <code class="Code-In-Text--PACKT-">X_train</code>, which is of equal size to <code class="Code-In-Text--PACKT-">y_train</code>, and each of them are exactly 80% of our previous <code class="Code-In-Text--PACKT-">X</code> and <code class="Code-In-Text--PACKT-">y</code> set. <code class="Code-In-Text--PACKT-">X_test</code> and <code class="Code-In-Text--PACKT-">y_test</code> are made up of the remaining 20% of <code class="Code-In-Text--PACKT-">X</code> and <code class="Code-In-Text--PACKT-">y</code>.</p>
			<p class="normal">Now that you have both a training set and a test set, what do you think the next step is? Well, you have to scale your data.</p>
			<h4 class="title" xml:lang="en-GB" id="sigil_toc_id_128" lang="en-GB"><a id="_idTextAnchor183"/>Scaling data</h4>
			<p class="normal">Now you might be<a id="_idIndexMarker249"/> 
wondering why on earth you have to perform such an operation. You 
already have the data, so why not build and train the neural network 
already?</p>
			<p class="normal">There's a problem with that; if we leave the data 
as it is, you'll notice that your ANN does not learn. The reason for 
that is because different variables will impact your prediction more or 
less depending on their values.</p>
			<p class="normal">Take this graph illustrating what I mean, based on a property that has 3 bedrooms and 1,350 square feet of living area.</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_05.png" alt=""/></figure>
			<p class="packt_figref">Figure 5: Example for 3 bedrooms and 1350 square feet of living area</p>
			<p class="normal">You can clearly see that the number of bedrooms 
won't affect the prediction as much as Sqft_living will. Even we humans 
cannot see any difference between zero bedrooms and three bedrooms on 
this graph. </p>
			<p class="normal">One of many solutions to this problem is to scale 
all variables to be in a range between 0 and 1. We achieve this by 
calculating this equation:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_001.png" style="height: 3.5em;" alt=""/></figure>
			<p class="normal">where:</p>
			<ul>
				<li class="list"><em class="italics">x</em> – the value we are scaling in our case every value in a column</li>
				<li class="list"><em class="italics">x</em><sub>min</sub> – minimum value across all in a column</li>
				<li class="list"><em class="italics">x</em><sub>max</sub> – maximum <a id="_idIndexMarker250"/>value across all in a column</li>
				<li class="list"><em class="italics">x</em><sub>scaled</sub> – <em class="italics">x</em> after performing scaling</li>
			</ul>
			<p class="normal">After performing this scaling, our previous graph now looks something like this:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_06.png" alt=""/></figure>
			<p class="packt_figref">Figure 6: Same graph after scaling</p>
			<p class="normal">Now we can undoubtedly say that the number of 
bedrooms will have a similar impact to Sqft_living. We can clearly see 
the difference between zero bedrooms and three bedrooms.</p>
			<p class="normal">So, how do we implement that in code? Since you 
know the equation, I recommend that you try to do it yourself. Don't 
worry if you fail; I'll show you a very simple way to do it in the next 
paragraph.</p>
			<p class="normal">If you were able to scale the data on your own, 
then congratulations! If not, follow along through this next section to 
see the answer. You might have noticed that you imported a class of 
Scikit-learn library called <code class="Code-In-Text--PACKT-">MinMaxScaler</code>. You can use that class to scale the variables with the following code:</p>
			<pre class="programlisting language-markup"><code class="hljs ini"><span class="hljs-comment"># Scaling the features   #24</span>
<span class="hljs-attr">xscaler</span> = MinMaxScaler(feature_range = (<span class="hljs-number">0</span>,<span class="hljs-number">1</span>))   <span class="hljs-comment">#25</span>
<span class="hljs-attr">X_train</span> = xscaler.fit_transform(X_train)   <span class="hljs-comment">#26</span>
<span class="hljs-attr">X_test</span> = xscaler.transform(X_test)   <span class="hljs-comment">#27</span>
<span class="hljs-comment">#28</span>
<span class="hljs-comment"># Scaling the target   #29</span>
<span class="hljs-attr">yscaler</span> = MinMaxScaler(feature_range = (<span class="hljs-number">0</span>,<span class="hljs-number">1</span>))   <span class="hljs-comment">#30</span>
<span class="hljs-attr">y_train</span> = yscaler.fit_transform(y_train.reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))   <span class="hljs-comment">#31</span>
<span class="hljs-attr">y_test</span> = yscaler.transform(y_test.reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))   <span class="hljs-comment">#32</span>
</code></pre>
			
			
			
			
			
			
			
			
			<p class="normal">This code creates<a id="_idIndexMarker251"/> two scalers, one to scale the features and one to scale the targets. Call them <code class="Code-In-Text--PACKT-">xscaler</code> and <code class="Code-In-Text--PACKT-">yscaler</code>. The <code class="Code-In-Text--PACKT-">feature_range</code> argument is the range to which you want your data to be scaled (from 0 to 1 in your case).</p>
			<p class="normal">Then you use the <code class="Code-In-Text--PACKT-">fit_transform</code> method, which scales <code class="Code-In-Text--PACKT-">X_train</code> and <code class="Code-In-Text--PACKT-">y_train</code> and adjusts the scalers based on these sets (<code class="Code-In-Text--PACKT-">fit</code> part of this method sets <em class="italics">x</em><sub>min</sub> and <em class="italics">x</em><sub>max</sub>). After that you use the <code class="Code-In-Text--PACKT-">transform</code> method to scale <code class="Code-In-Text--PACKT-">X_test</code> and <code class="Code-In-Text--PACKT-">y_test</code> without adjusting <code class="Code-In-Text--PACKT-">yscaler</code> and <code class="Code-In-Text--PACKT-">xscaler</code>.</p>
			<p class="normal">When scaling the <code class="Code-In-Text--PACKT-">y</code> variables, you have to reshape them by using <code class="Code-In-Text--PACKT-">.reshape(-1,1)</code>
 in order to create a fake second dimension (so the code can treat this 
one-dimensional array as a two-dimensional array with one column). We 
need this fake second dimension to avoid a format error.</p>
			<p class="normal">If you still do not understand why we have to use 
scaling, please read this section once again. It'll also get clearer 
once we go through the theory.</p>
			<p class="normal">Finally, you can proceed to building a neural 
network! Keep in mind that all the theory behind it will be covered 
later in the chapter, so don't be scared if you have trouble 
understanding something.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_129" lang="en-GB"><a id="_idTextAnchor184"/>Building the neural network</h3>
			<p class="normal">To build the<a id="_idIndexMarker252"/> neural network, you can use a highly reliable and easy to use library called Keras. Let's get straight into coding it:</p>
			<pre class="programlisting language-markup"><code class="hljs reasonml"># Building the Artificial Neural Network   #<span class="hljs-number">34</span>
model = <span class="hljs-constructor">Sequential()</span>   #<span class="hljs-number">35</span>
model.add(<span class="hljs-constructor">Dense(<span class="hljs-params">units</span> = 64, <span class="hljs-params">kernel_initializer</span> = '<span class="hljs-params">uniform</span>', <span class="hljs-params">activation</span> = '<span class="hljs-params">relu</span>', <span class="hljs-params">input_dim</span> = 17)</span>)   #<span class="hljs-number">36</span>
model.add(<span class="hljs-constructor">Dense(<span class="hljs-params">units</span> = 16, <span class="hljs-params">kernel_initializer</span> = '<span class="hljs-params">uniform</span>', <span class="hljs-params">activation</span> = '<span class="hljs-params">relu</span>')</span>)   #<span class="hljs-number">37</span>
model.add(<span class="hljs-constructor">Dense(<span class="hljs-params">units</span> = 1, <span class="hljs-params">kernel_initializer</span> = '<span class="hljs-params">uniform</span>', <span class="hljs-params">activation</span> = '<span class="hljs-params">relu</span>')</span>)   #<span class="hljs-number">38</span>
model.compile(optimizer = <span class="hljs-constructor">Adam(<span class="hljs-params">lr</span> = 0.001)</span>, loss = 'mse', metrics = <span class="hljs-literal">['<span class="hljs-identifier">mean_absolute_error</span>']</span>)   #<span class="hljs-number">39</span>
</code></pre>
			
			
			
			
			
			<p class="normal">In line 35 of the code block you instantiate your model by using the <code class="Code-In-Text--PACKT-">Sequential</code> class from the Keras library. </p>
			<p class="normal">Next, you add a line that adds a new layer with 64 neurons to your neural network. <code class="Code-In-Text--PACKT-">kernel_initializer</code> is an argument that defines the way the initial weights are created in the layer, <code class="Code-In-Text--PACKT-">activation</code> is the activation function of this layer and <code class="Code-In-Text--PACKT-">input_dim</code> is the size of the input; in your case, these are the 17 features that define how much a house costs.</p>
			<p class="normal">Next, you add two more layers, one with 16 neurons and one with 1 neuron that will be the output of the neural networ<a id="_idTextAnchor185"/>k.</p>
			<p class="normal">In the final line of <a id="_idIndexMarker253"/>this snippet you use the <code class="Code-In-Text--PACKT-">compile</code> method, which describes how you want to train your net. Inside this <code class="Code-In-Text--PACKT-">compile</code> method, <code class="Code-In-Text--PACKT-">optimizer</code> is the tool that performs backpropagation, <code class="Code-In-Text--PACKT-">lr</code> is the learning rate—the speed at which the weights in the ANN are updated. <code class="Code-In-Text--PACKT-">loss</code> is how you want to calculate the error of the output (I have decided to go for the mean squared error <code class="Code-In-Text--PACKT-">mse</code>), and <code class="Code-In-Text--PACKT-">metrics</code> is just a value that will help you visualize performance—you can use mean absolute error.</p>
			<p class="normal">If you don't know what I'm talking about right now,
 what activations, losses, and optimizers are, you don't have to worry. 
You'll understand them soon, when we get to the theory later in the 
chapter.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_130" lang="en-GB"><a id="_idTextAnchor186"/>Training the neural network</h3>
			<p class="normal">Now that you've built <a id="_idIndexMarker254"/>your model, you can finally train it!</p>
			<pre class="programlisting language-markup"><code class="hljs jboss-cli"><span class="hljs-comment"># Training the Artificial Neural Network   #41</span>
model.fit<span class="hljs-params">(X_train, y_train, <span class="hljs-attr">batch_size</span> = 32, <span class="hljs-attr">epochs</span> = 100, <span class="hljs-attr">validation_data</span> = (X_test, y_test)</span>)   <span class="hljs-comment">#42</span>
</code></pre>
			
			<p class="normal">This simple one-liner is responsible for learning.</p>
			<p class="normal">As the first two arguments of this fit method, you input <code class="Code-In-Text--PACKT-">X_train</code> and <code class="Code-In-Text--PACKT-">y_train</code> which are the sets your model will be trained on. Then you have an argument called <code class="Code-In-Text--PACKT-">batch_size</code>; this defines after how many records in your dataset you update your weights (loss is summed up and back-propagated after <code class="Code-In-Text--PACKT-">batch_size</code> inputs). Next you have <code class="Code-In-Text--PACKT-">epochs</code>, and this value defines how many times you teach your model on the entire <code class="Code-In-Text--PACKT-">X_train</code> and <code class="Code-In-Text--PACKT-">y_train</code> set. The final argument is <code class="Code-In-Text--PACKT-">validation_data</code>, and there, as you can see, you put <code class="Code-In-Text--PACKT-">X_test</code> and <code class="Code-In-Text--PACKT-">y_test</code>. This means that after every epoch, your model will be tested on this set, but it won't learn from it.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_131" lang="en-GB"><a id="_idTextAnchor187"/>Displaying results</h3>
			<p class="normal">You're nearly there; you<a id="_idIndexMarker255"/>
 have just one last non-obligatory step to take. You calculate the 
absolute error on the test set and see its real, unscaled predictions 
(actual prices, not in the range (0,1)).</p>
			<pre class="programlisting language-markup"><code class="hljs makefile"><span class="hljs-comment"># Making predictions on the test set while reversing the scaling   #44</span>
y_test = yscaler.inverse_transform(y_test)   <span class="hljs-comment">#45</span>
prediction = yscaler.inverse_transform(model.predict(X_test))   <span class="hljs-comment">#46</span>
<span class="hljs-comment">#47</span>
<span class="hljs-comment"># Computing the error rate   #48</span>
error = abs(prediction - y_test)/y_test   <span class="hljs-comment">#49</span>
print(np.mean(error))   <span class="hljs-comment">#50</span>
</code></pre>
			
			
			
			
			
			
			<p class="normal">You rescale back your <code class="Code-In-Text--PACKT-">y_test</code>
 on line 45. Then, you make a prediction on your test set of features 
and rescale it back too, since the predictions are also scaled down.</p>
			<p class="normal">In the last two lines you calculate the absolute error using the formula:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_002.png" style="height: 3em;" alt=""/></figure>
			<p class="normal">Since both prediction and <code class="Code-In-Text--PACKT-">y_test</code> are NumPy arrays, you can divide them by simply using the <code class="Code-In-Text--PACKT-">/</code> symbol. In the last line, you calculate the mean error using a NumPy function.</p>
			<p class="normal">Superb! Now that you have it all finished, you can finally run this code and see the results.</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_07.png" alt=""/></figure>
			<p class="packt_figref">Figure 7: Results</p>
			<p class="normal">As you can see in the last line, your result is shown. In my case the average error was 13.5%. That is a really good result!</p>
			<p class="normal">Now we can get into<a id="_idIndexMarker256"/> the theory behind deep learning, and find out how a neural network really works.</p>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_132" lang="en-GB"><a id="_idTextAnchor188"/>Deep learning theory</h2>
			<p class="normal">Here is our plan of <a id="_idIndexMarker257"/>attack to go pro and tackle deep learning:</p>
			<ol>
				<li class="list" value="1">The neuron</li>
				<li class="list">The activation function</li>
				<li class="list">How do neural networks work?</li>
				<li class="list">How do neural networks learn?</li>
				<li class="list">Forward-propagation and back-propagation</li>
				<li class="list">Gradient descent, including Batch, Stochastic, and Mini-Batch methods</li>
			</ol>
			<p class="normal">I hope you're excited about this section—deep learning is an awesome and powerful field to s<a id="_idTextAnchor189"/>tudy.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_133" lang="en-GB"><a id="_idTextAnchor190"/>The neuron</h3>
			<p class="normal">The neuron is the<a id="_idIndexMarker258"/> basic building block of Artificial Neural Networks, and they are based<a id="_idIndexMarker259"/> on the neuron cells found the brain.</p>
			<h4 class="title" xml:lang="en-GB" id="sigil_toc_id_134" lang="en-GB"><a id="_idTextAnchor191"/>Biological neurons</h4>
			<p class="normal">In the following images<a id="_idIndexMarker260"/> are real-life neurons that have been <a id="_idIndexMarker261"/>smeared onto a slide, colored a little bit, and observed through a microscope:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_08.png" alt=""/></figure>
			<p class="packt_figref">Figure 8: The neuron</p>
			<p class="normal">As you can see, they have the structure of a 
central body with lots of different branches coming out of it. The 
question is: How can we recreate that in a machine? We really want to 
recreate it in a machine, since the whole purpose of deep learning is to
 mimic how the human brain works in the hope that by doing so we create 
something amazing: a powerful infrastructure for learning machines.</p>
			<p class="normal">Why do we hope for that? Because the human brain 
just happens to be one of the most powerful learning tools on the 
planet. We hope that if we recreate it, then we'll have something just 
as awesome as that.</p>
			<p class="normal">Our challenge right now, our very first step in 
creating artificial neural networks, is to recreate a neuron. So how do 
we do it? Well, first of all let's take a closer look at what a neuron 
actually is. </p>
			<p class="normal">In 1899, the neuroscientist Santiago Ramón y Cajal 
dyed neurons in actual brain tissue, and looked at them under a 
microscope. While he was looking at them, he drew what he saw, which was
 something very much like the slides we looked at before. Today, 
technology has advanced quite a lot, allowing us to see neurons much 
more closely and in more detail. That means that we can draw what they 
look like diagrammatically:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_09.png" alt=""/></figure>
			<p class="packt_figref">Figure 9: The neuron's structure</p>
			<p class="normal">This neuron <a id="_idIndexMarker262"/>exchanges signals between its neighbor neurons. The dendrites are the receivers of the signal and the axon is the<a id="_idIndexMarker263"/> transmitter of the signal.</p>
			<p class="normal">The dendrites of the neuron are connected to the 
axons of other neurons above it. When the neuron fires, the signal 
travels down its axon and passes on to the dendrites of the next neuron.
 That is how they are connected, and how a neuron works. Now we can move
 from neuroscience to technology.</p>
			<h4 class="title" xml:lang="en-GB" id="sigil_toc_id_135" lang="en-GB"><a id="_idTextAnchor192"/>Artificial neurons</h4>
			<p class="normal">Here's<a id="_idIndexMarker264"/> how a neuron<a id="_idIndexMarker265"/> is represented inside an Artificial Neural Network:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_10.png" alt=""/></figure>
			<p class="packt_figref">Figure 10: An Artificial Neural Network with a single neuron</p>
			<p class="normal">Just like a human neuron, it gets some input signals and it has an output signal. The blue arrow connecting the<a id="_idIndexMarker266"/> input signals to the neuron, and the neuron to the output signal, are like the synapses in the human neuron.</p>
			<p class="normal">Here in the<a id="_idIndexMarker267"/> 
artificial neuron, what exactly are the input and output signals going 
to be? The input signals are the scaled independent variables composing 
the states of the environment. For example, in the server cooling 
practical example we'll code later in this book (<em class="italics">Chapter 11</em>, <em class="italics">AI for Business – Minimize Costs with Deep Q-Learning</em>),
 these are the temperature of the server, the number of users, and the 
rate of data transmission. The output signal is the output values, which
 in a deep Q-learning model are always the Q-Values. Knowing all that, 
we can make a general representation of a neuron for machines:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_11.png" alt=""/></figure>
			<p class="packt_figref">Figure 11: Neuron – The output values</p>
			<p class="normal">To finish describing the neuron, we need to add the
 last element missing from this representation, which is also the most 
important one: the weights.</p>
			<p class="normal">Each synapse (blue arrow) is attributed a weight. The larger the weight, the stronger the signal is<a id="_idIndexMarker268"/>
 through the synapse. What is fundamental to understand is that these 
weights are what the machine updates over time to improve its 
predictions. Let's add them to the previous graphic, to make sure you 
can visualize them well:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_12.png" alt=""/></figure>
			<p class="packt_figref">Figure 12: Neuron – The weights</p>
			<p class="normal">That's the neuron. The<a id="_idIndexMarker269"/> next thing to understand is the activation function; the way the neuron decides what output to produce given a se<a id="_idTextAnchor193"/>t of inputs.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_136" lang="en-GB"><a id="_idTextAnchor194"/>The activation function</h3>
			<p class="normal">The activation<a id="_idIndexMarker270"/> function is the function <em class="italics"><img src="../Images/B14110_09_050.png" alt=""/></em>, operating inside<a id="_idIndexMarker271"/>
 the neuron, that takes as inputs the linear sum of the input values 
multiplied by their associated weights, and that returns the output 
value as shown in the following graphic:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_13.png" alt=""/></figure>
			<p class="packt_figref">Figure 13: The activation function</p>
			<p class="normal">such that:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_003.png" style="height: 4em;" alt=""/></figure>
			<p class="normal">Your next question<a id="_idIndexMarker272"/> is probably: what exactly is the function <em class="italics"><img src="../Images/B14110_09_050.png" alt=""/></em>?</p>
			<p class="normal">There can be many of them, but here we'll describe the three most used ones, including the one you'll use in<a id="_idIndexMarker273"/> the practical activity:</p>
			<ol>
				<li class="list" value="1">The threshold activation function</li>
				<li class="list">The sigmoid activation function</li>
				<li class="list">The rectifier activation function</li>
			</ol>
			<p class="normal">Let's push your expertise further by having a look at th<a id="_idTextAnchor195"/>em one by one.</p>
			<h4 class="title" xml:lang="en-GB" id="sigil_toc_id_137" lang="en-GB"><a id="_idTextAnchor196"/>The threshold activation function</h4>
			<p class="normal">The threshold <a id="_idIndexMarker274"/>activation function is simply <span id="_idIndexMarker275"/>defined by the following:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_004.png" style="height: 4em;" alt=""/></figure>
			<p class="normal">and can be<a id="_idIndexMarker276"/> represented by the following curve:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_14.png" alt=""/></figure>
			<p class="packt_figref">Figure 14: The threshold activation function</p>
			<p class="normal">This means that the<a id="_idIndexMarker277"/> signal passing through the neuron is discontinuous, and will only be activated if:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_0011.png" style="height: 4em;" alt=""/></figure>
			<p class="normal">Now let's have a look at the next activation 
function: the sigmoid activation function. The sigmoid activation 
function is the most effective and widely used one in Artificial Neural 
Networks, but mostly in the last hidden layer that leads to the<a id="_idTextAnchor197"/> output layer.</p>
			<h4 class="title" xml:lang="en-GB" id="sigil_toc_id_138" lang="en-GB"><a id="_idTextAnchor198"/>The sigmoid activation function</h4>
			<p class="normal">The sigmoid <a id="_idIndexMarker278"/>activation function is defined by<a id="_idIndexMarker279"/> the following:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_007.png" style="height: 3.5em;" alt=""/></figure>
			<p class="normal">and can be<a id="_idIndexMarker280"/> represented by the following curve:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_15.png" alt=""/></figure>
			<p class="packt_figref">Figure 15: The sigmoid activation function</p>
			<p class="normal">This means that the<a id="_idIndexMarker281"/> signal passing through the neuron is continuous and will always be activated. And the higher the value of:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_008.png" style="height: 4.5em;" alt=""/></figure>
			<p class="normal">the stronger the signal.</p>
			<p class="normal">Now let's have a look at another widely used 
activation function: the rectifier activation function. You'll find it 
in most of the deep neural networks, but mostly inside the early hidden 
layers, as opposed to the sigmoid function, which is rather used for the
 last hidden layer leading to th<a id="_idTextAnchor199"/>e output layer.</p>
			<h4 class="title" xml:lang="en-GB" id="sigil_toc_id_139" lang="en-GB"><a id="_idTextAnchor200"/>The rectifier activation function</h4>
			<p class="normal">The rectifier <a id="_idIndexMarker282"/>activation function is simply defined<a id="_idIndexMarker283"/> by the following:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_009.png" style="height: 2.5em;" alt=""/></figure>
			<p class="normal">and is therefore represented by the following curve:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_16.png" alt=""/></figure>
			<p class="packt_figref">Figure 16: The rectifier activation function</p>
			<p class="normal">This means that the signal passing through the neuron is continuous, and will only be activated if:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_0012.png" style="height: 4.5em;" alt=""/></figure>
			<p class="normal">The higher the weighted sum of inputs, the stronger the signal.</p>
			<p class="normal">That raises the question: which activation function
 should you choose, or, as it's more frequently asked, how do you know 
which one to choose?</p>
			<p class="normal">The good news is that the answer is simple. It 
actually depends on what gets returned as the dependent variable. If 
it's a binary outcome, 0 or 1, then a good choice would be the threshold
 activation<a id="_idIndexMarker284"/> function. If what you want 
returned is the probability that the dependent variable is 1, then the 
sigmoid activation function is an excellent choice, since its sigmoid 
curve is a perfect fit to model probabilities.</p>
			<p class="normal">To recap, here's the small blueprint highlighted in this figure:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_17.png" alt=""/></figure>
			<p class="packt_figref">Figure 17: Activation function blueprint</p>
			<p class="normal">Remember, the rectifier activation function should 
be used within the hidden layers of a deep neural network with more than
 one hidden layer, and the sigmoid activation function should be used in
 the last hidden layer leading to the output layer.</p>
			<p class="normal">Let's highlight this in the following figure so that you can visualize it and remember it better:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_18.png" alt=""/></figure>
			<p class="packt_figref">Figure 18: Different activation functions in different layers</p>
			<p class="normal">We're progressing <a id="_idIndexMarker285"/>fast!
 You already know quite a lot about deep learning. It's not over yet 
though—let's move on to the next section to explain how neural networks <a id="_idTextAnchor201"/>actually work.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_140" lang="en-GB"><a id="_idTextAnchor202"/>How do neural networks work?</h3>
			<p class="normal">To explain this, let's go<a id="_idIndexMarker286"/> back to the problem of predicting <a id="_idIndexMarker287"/>real
 estate prices. We had some independent variables which we were using to
 predict the price of houses and apartments. For simplicity's sake, and 
to be able to represent everything in a graph, let's say that our only 
independent variables (our predictors) are the following:</p>
			<ol>
				<li class="list" value="1">Area (square feet)</li>
				<li class="list">Number of bedrooms</li>
				<li class="list">Distance to city (miles)</li>
				<li class="list">Age</li>
			</ol>
			<p class="normal">Our dependent variable is the apartment price that we're predicting. Here's how the magic works in deep learning.</p>
			<p class="normal">A weight is attributed to each of the independent, 
scaled variables in such a way that the higher the weight is, the more 
of an effect the independent variable will have on the dependent 
variable; that is, the stronger a predictor it will be of the dependent 
variable.</p>
			<p class="normal">As soon as new inputs enter the neural network, the
 signals are forward-propagated from each of the inputs, reaching the 
neurons of the hidden layer.</p>
			<p class="normal">Inside each neuron of the hidden layer, the activation function is applied, so that the lower the weight <a id="_idIndexMarker288"/>of the input, the more the activation<a id="_idIndexMarker289"/>
 function blocks the signal coming from that input, and the higher the 
weight of that input, the more the activation function lets that signal 
go through. </p>
			<p class="normal">Finally, all the signals coming from the hidden 
neurons, more or less blocked by the activation functions, are forward 
propagated to the output layer, to return the final outcome: the price 
prediction.</p>
			<p class="normal">Here's a visualization of how that neural network works:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_19.png" alt=""/></figure>
			<p class="packt_figref">Figure 19: How Neural Networks work – Example in real estate price prediction</p>
			<p class="normal">That covers half of the story. Now we know how a neural network works, we need to find o<a id="_idTextAnchor203"/>ut how it learns.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_141" lang="en-GB"><a id="_idTextAnchor204"/>How do neural networks learn?</h3>
			<p class="normal">Neural <a id="_idIndexMarker290"/>networks learn <a id="_idIndexMarker291"/>by
 updating, over many iterations, the weights of all the inputs and 
hidden neurons (when having several hidden layers), always towards the 
same goal: to reduce the loss error between the predictions and the 
actual values.</p>
			<p class="normal">In order for neural networks to learn, we need the actual values, which are also called the targets. In our<a id="_idIndexMarker292"/>
 preceding example about real estate pricing, the actual values are the 
real prices of the houses and apartments taken from our dataset. These 
real prices depend on the independent variables listed<a id="_idIndexMarker293"/>
 previously (area, number of bedrooms, distance to city, and age), and 
the neural network learns to make better predictions of these prices, by
 running the following process:</p>
			<ol>
				<li class="list" value="1">The neural network forward propagates the signals coming from the inputs; independent variables <span class="mediaobject"><img src="../Images/B14110_09_011.png" alt=""/></span>, <span class="mediaobject"><img src="../Images/B14110_09_012.png" alt=""/></span>, <span class="mediaobject"><img src="../Images/B14110_09_013.png" alt=""/></span> and <span class="mediaobject"><img src="../Images/B14110_09_014.png" alt=""/></span>.</li>
				<li class="list">Then it gets the predicted price <span class="mediaobject"><img src="../Images/B14110_09_015.png" alt=""/></span> in the output layer.</li>
				<li class="list">Then it computes the loss error, <em class="italics">C</em>, between the predicted price <span class="mediaobject"><img src="../Images/B14110_09_016.png" alt=""/></span> (prediction) and the actual price <em class="italics">y</em> (target):<figure class="mediaobject"><img src="../Images/B14110_09_017.png" style="height: 3.5em;" alt=""/></figure></li>
				<li class="list">Then this loss error is back-propagated inside the neural network, from right to left in our representation.</li>
				<li class="list">Then, on each of the neurons, the neural network 
runs a technique called gradient descent (which we will discuss in the 
next section) to update the weights in the direction of loss reduction, 
that is, into new weights which reduce the loss error <em class="italics">C</em>.</li>
				<li class="list">Then this whole process is repeated many times, 
with each time new inputs and new targets, until we get the desired 
performance (early stopping) or the last iteration (the number of 
iterations chosen in the implementation).</li>
			</ol>
			<p class="normal">Let's show the two<a id="_idIndexMarker294"/> main phases, forward-propagation <a id="_idIndexMarker295"/>and back-propagation, of this whole process in two separate graphics in the next section.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_142" lang="en-GB"><a id="_idTextAnchor205"/>Forward-propagation and back-propagation</h3>
			<p class="normal"><strong class="bold">Phase 1: Forward-propagation</strong>:</p>
			<p class="normal">Here's how the <a id="_idIndexMarker296"/>signal is forward-propagated throughout the artificial <a id="_idIndexMarker297"/>neural network, from the inputs to the output:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_20.png" alt=""/></figure>
			<p class="packt_figref">Figure 20: Forward-propagation</p>
			<p class="normal">Once the signal's been propagated through the entire network, the loss error <em class="italics">C</em> is calculated so that it can be back-propagated.</p>
			<p class="normal"><strong class="bold">Phase 2: Back-propagation</strong>:</p>
			<p class="normal">And after forward-propagation comes back-propagation, during which the loss error <em class="italics">C</em> is propagated back into the neural network from the output to the inputs.</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_21.png" alt=""/></figure>
			<p class="packt_figref">Figure 21: Back-propagation</p>
			<p class="normal">During back-propagation, the <a id="_idIndexMarker298"/>weights are updated to reduce the loss error <em class="italics">C</em> between the<a id="_idIndexMarker299"/>
 predictions (output value) and the targets (actual value). How are they
 updated? This is where gradient descent comes into play.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_143" lang="en-GB"><a id="_idTextAnchor206"/>Gradient Descent</h3>
			<p class="normal">Gradient descent is <a id="_idIndexMarker300"/>an optimization technique that helps us<a id="_idIndexMarker301"/> find the minimum of a cost function, like the preceding loss error <em class="italics">C</em> we had:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_018.png" style="height: 3.5em;" alt=""/></figure>
			<p class="normal">Let's visualize it in the most intuitive way, like the following ball in a bowl (with a little math sprinkled on top):</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_22.png" alt=""/></figure>
			<p class="packt_figref">Figure 22: Gradient Descent (1/4)</p>
			<p class="normal">Imagine this is a cross section of a bowl, into 
which we drop a small red ball and let it find its way down to the 
bottom of the bowl. After some time, it will stop rolling, when it finds
 the sweet spot at the bottom of the bowl.</p>
			<p class="normal">You can think about gradient descent in the same 
way. It starts somewhere in the bowl (initial values of parameters) and 
tries to find the bottom of the bowl, or in other words, the minimum of a
 cost function.</p>
			<p class="normal">Let's go through the example that is shown in the 
preceding image. The initial values of the parameters have set our ball 
at the position shown. Based on that we get some predictions, which we 
compare to our target values. The difference between these two sets is 
our loss for the current set of parameters.</p>
			<p class="normal">Then we calculate the first derivative of the cost function, with respect to the parameters. This is where the name <strong class="bold">gradient</strong>
 comes from. Here, this first derivative gives us the slope of the 
tangent to the curve where the ball is. If the gradient of the slope is 
negative, like<a id="_idIndexMarker302"/> on the preceding image, we 
take the next step to the right side. If the gradient of the slope is 
positive, we take the next step to the left side.</p>
			<p class="normal">The name <strong class="bold">descent</strong> thus comes from the fact that we always take the next step that points downhill, as represented in the following graphic:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_23.png" alt=""/></figure>
			<p class="packt_figref">Figure 23: Gradient Descent (2/4)</p>
			<p class="normal">In the next position our ball rests on a positive slope, so we have to take the next step to the left:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_24.png" alt=""/></figure>
			<p class="packt_figref">Figure 24: Gradient Descent (3/4)</p>
			<p class="normal">Eventually, by<a id="_idIndexMarker303"/> repeating the same steps, the ball will end up at the bottom of the bowl:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_25.png" alt=""/></figure>
			<p class="packt_figref">Figure 25: Gradient Descent (4/4)</p>
			<p class="normal">And that's it! That's how gradient descent operates
 in one dimension (one parameter). Now you might ask: "Great, but how 
does this scale?" We saw an example of one-dimensional optimization, but
 what about two or even three dimensions?</p>
			<p class="normal">It's an excellent question. gradient descent 
guarantees that this approach scales on as many dimensions as needed, 
provided the cost function is convex. In fact, if the cost function is 
convex, gradient descent will find the absolute minimum of the cost 
function. Following is an example in two dimensions:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_26.png" alt=""/></figure>
			<p class="packt_figref">Figure 26: Gradient Descent – Convergence guaranteed for convex cost functions</p>
			<p class="normal">However, if the<a id="_idIndexMarker304"/> cost function is not convex, gradient descent will only find a local minimum. Here is an example in three dimensions:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_27.png" alt=""/></figure>
			<p class="packt_figref">Figure 27: Example of non-convergence (right) for a non-convex function (left)</p>
			<p class="normal">Now that we understand what gradient descent is all about, we can study the most advanced and most effective versions of it:</p>
			<ol>
				<li class="list" value="1">Batch gradient descent</li>
				<li class="list">Stochastic gradient descent</li>
				<li class="list">Mini-batch gradient descent</li>
			</ol>
			<p class="normal">"Gradient descent", "batch<a id="_idIndexMarker305"/>
 gradient descent", "mini batch gradient descent", "stochastic gradient 
descent," there are so many terms and someone like you who's just 
starting may find themselves very confused. Don't worry—I've got your 
back.</p>
			<p class="normal">The main difference between all of these versions 
of gradient descent is just the way we feed our data to a model, and how
 often we update our parameters (weights) to move our small red ball. 
Let's start by explaining batch gradient descent.</p>
			<h4 class="title" xml:lang="en-GB" id="sigil_toc_id_144" lang="en-GB"><a id="_idTextAnchor207"/>Batch gradient descent</h4>
			<p class="normal">Batch gradient<a id="_idIndexMarker306"/> 
descent is when we have a batch of inputs (as opposed to a single input)
 feeding the neural network, forward-propagating them to<a id="_idIndexMarker307"/>
 obtain in the end a batch of predictions, which themselves are compared
 to a batch of targets. The global loss error between the predictions 
and the targets of the two batches is then computed as the sum of the 
loss errors between each prediction and its associated target.</p>
			<p class="normal">That global loss is back-propagated into the neural
 network, where gradient descent or stochastic gradient descent is 
performed to update all the weights, according to how much they were 
responsible for that global loss error.</p>
			<p class="normal">Here is an example of batch gradient descent. The 
problem to solve is about predicting the score (from 0 to 100 %) 
students get in an exam, based on the time spent studying (Study Hrs) 
and the time spent sleeping (Sleep Hrs):</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_28.png" alt=""/></figure>
			<p class="packt_figref">Figure 28: Batch Gradient Descent</p>
			<p class="normal">An important thing to note on this preceding 
graphic is that these are not multiple neural networks, but a single one
 represented by separate weight updates. As we can see in this example <a id="_idIndexMarker308"/>of batch gradient descent, we feed all of our data into the model at once.</p>
			<p class="normal">This produces collective <a id="_idIndexMarker309"/>updates
 of the weights and fast optimization of the network. However, there is a
 bad side to this as well. There is, once again, the possibility of 
getting stuck in a local minimum, as we can see in the following 
graphic:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_29.png" alt=""/></figure>
			<p class="packt_figref">Figure 29: Getting stuck in a local minimum</p>
			<p class="normal">We explained the reason why this happens a bit 
earlier: it is because the cost function in the preceding graphic is not
 convex, and this type of optimization (simple gradient descent) 
requires the cost function to be convex. If that is not the case, we can
 find ourselves stuck in a local minimum and never find the global 
minimum with the optimal parameters. On the other hand, here is an 
example of a convex cost function, the same one as we saw earlier:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_30.png" alt=""/></figure>
			<p class="packt_figref">Figure 30: An example of a convex function</p>
			<p class="normal">In simple terms, a function<a id="_idIndexMarker310"/> is convex if it has only one global minimum. And the graph of a convex function <a id="_idIndexMarker311"/>has
 the bowl shape. However, in most problems, including business problems,
 the cost function will not be convex (as in the following graphic 
example in 3D), and thus not allow simple gradient descent to perform 
well. This is where stochastic gradient descent comes into play.</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_31.png" alt=""/></figure>
			<p class="packt_figref">Figure 31: Example of non-convergence (right) for a non-convex function (left)</p>
			<h4 class="title" xml:lang="en-GB" id="sigil_toc_id_145" lang="en-GB"><a id="_idTextAnchor208"/>Stochastic gradient descent</h4>
			<p class="normal"><strong class="bold">Stochastic Gradient Descent</strong> (<strong class="bold">SGD</strong>) comes to save<a id="_idIndexMarker312"/> the day. It<a id="_idIndexMarker313"/>
 provides better results overall, preventing the algorithm from getting 
stuck in a local minimum. However, as its name suggests, it is 
stochastic, or in other words, random.</p>
			<p class="normal">Because of this<a id="_idIndexMarker314"/> 
property, no matter how many times you run the algorithm, the process 
will always be slightly different, regardless of the initialization.</p>
			<p class="normal">SGD does not run on the whole dataset at once, but instead input by input. The process goes like this:</p>
			<ol>
				<li class="list" value="1">Input a single observation.</li>
				<li class="list">Forward propagate that input to get a single prediction.</li>
				<li class="list">Compute<a id="_idIndexMarker315"/> the loss error between the prediction (output) and the target (actual value).</li>
				<li class="list">Back-propagate the loss error into the neural network.</li>
				<li class="list">Update the weights with gradient descent.</li>
				<li class="list">Repeat steps 1 to 5 through the whole dataset.</li>
			</ol>
			<p class="normal">Let's show the first three iterations on the first 
three single inputs for the example we looked at earlier, predicting the
 scores in an exam:</p>
			<p class="normal"><strong class="bold">First input row of observation</strong>:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_32.png" alt=""/></figure>
			<p class="packt_figref">Figure 32: Stochastic Gradient Descent – First input row of observation</p>
			<p class="normal"><strong class="bold">Second input row of observation</strong>:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_33.png" alt=""/></figure>
			<p class="packt_figref">Figure 33: Stochastic Gradient Descent – Second input row of observation</p>
			<p class="normal"><strong class="bold">Third input row of observation</strong>:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_34.png" alt=""/></figure>
			<p class="packt_figref">Figure 34: Stochastic Gradient Descent – Third input row of observation</p>
			<p class="normal">Each of the preceding<a id="_idIndexMarker316"/> three graphics is an example of one weight's update run by SGD. As we can see, each time<a id="_idIndexMarker317"/>
 we only input a single row of observation from our dataset to the 
neural network, then we update the weights accordingly and proceed to 
the next input row of observation.</p>
			<p class="normal">At first glance, SGD seems slower, because we input
 each row separately. In reality, it's much faster, because we don't 
have to load the whole dataset in the memory, nor wait for the whole 
dataset to pass through the model updating the weights.</p>
			<p class="normal">To finish this<a id="_idIndexMarker318"/> section, let's recap the difference <a id="_idIndexMarker319"/>between batch gradient descent and SGD with the following graphic:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_35.png" alt=""/></figure>
			<p class="packt_figref">Figure 35: Batch Gradient Descent vs. Stochastic Gradient Descent</p>
			<p class="normal">Now we can consider a middle-ground approach; mini-batch gradient descent.</p>
			<h4 class="title" xml:lang="en-GB" id="sigil_toc_id_146" lang="en-GB"><a id="_idTextAnchor209"/>Mini-batch gradient descent</h4>
			<p class="normal">Mini-batch gradient <a id="_idIndexMarker320"/>descent uses the best from both worlds, combining batch gradient descent with SGD. This is<a id="_idIndexMarker321"/>
 done by feeding the artificial neural network with small batches of 
data, instead of feeding single input rows of observations one by one or
 the whole dataset at once.</p>
			<p class="normal">This approach is faster than classic SGD, and still
 prevents you from getting stuck in a local minimum. Mini-batch gradient
 descent also helps if you don't have enough computing resources to load
 the whole dataset in the memory, or enough processing power to get the 
full benefit of SGD.</p>
			<p class="normal">That's all for neural networks! Now you're ready to combine your knowledge of neural networks with your<a id="_idTextAnchor210"/> knowledge of Q-learning.</p>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_147" lang="en-GB"><a id="_idTextAnchor211"/>Deep Q-learning</h2>
			<p class="normal">You've toured the foundations of deep learning, and you already know Q-learning; since deep Q-learning <a id="_idIndexMarker322"/>consists of combining Q-learning and deep learning, you're ready to get an intuitive grasp of deep Q-learning and crush it.</p>
			<p class="normal">Before we start, try to guess some of how this is 
going to work. I would like you to take a moment and think about how you
 could integrate Q-learning into an ANN.</p>
			<p class="normal">First things first, you might have guessed what the
 inputs and outputs of the neural network are going to be. The input of 
the artificial neural network is of course going to be the input state, 
which could be a 1-dimensional vector encoding what is happening in the 
environment, or an image (like the ones seen by a self-driving car). And
 the output is going to be the set of Q-values for each action, meaning 
it is going to be a 1-dimensional vector of several Q-values, one for 
each action that can be performed. Then, just like before, the AI takes 
the action that has the maximum Q-value, and performs it.</p>
			<p class="normal">Very simply, that means that instead of predicting 
the Q-values through iterative updates with the Bellman equation (simple
 Q-learning), we'll predict them with an ANN that takes as inputs the 
input states, and returns as output the Q-values of the different 
actions.</p>
			<p class="normal">That raises the question: it's good that we know 
what to predict, but what are going to be the targets (actual values) of
 these predictions when we are training the AI? As a reminder, the 
target is the actual value, or what you want your prediction to be 
ideally: the closer your prediction is to the target, the more it is 
correct. That's why we compute the loss error <em class="italics">C</em>
 between the prediction and the target, in order to reduce it through 
back-propagation with stochastic or mini-batch gradient descent.</p>
			<p class="normal">When we were doing simple property price 
prediction, it was obvious what the targets were. They were simply the 
prices in the dataset that were available to us. But what about the 
targets of Q-values when you are training a self-driving car, for 
example? It's not that obvious, even though it is an explicit function 
of the Q-values and the reward.</p>
			<p class="normal">The answer is a fundamental formula in deep Q-learning. The target of an input state <span class="mediaobject"><img src="../Images/B14110_09_019.png" alt=""/></span> is:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_020.png" style="height: 2.5em;" alt=""/></figure>
			<p class="normal">where <span class="mediaobject"><img src="../Images/B14110_09_021.png" alt=""/></span> is the last reward obtained and <span class="mediaobject"><img src="../Images/B14110_09_022.png" alt=""/></span> is the discount factor, as seen previously.</p>
			<p class="normal">Do you recognize<a id="_idIndexMarker323"/> the formula of the target? If you remember Q-learning, you should have no problem answering this question.</p>
			<p class="normal">It's in the temporal difference, of course! Remember, the temporal difference is defined by:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_07_019.png" style="height: 2.5em;" alt=""/></figure>
			<p class="normal">So now it's obvious. The target is simply the first element at the left of the temporal difference:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_024.png" style="height: 2.5em;" alt=""/></figure>
			<p class="normal">so that we get:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_025.png" style="height: 2em;" alt=""/></figure>
			<p class="normal">Note that at the beginning, the Q-values are null, so the target is simply the reward.</p>
			<p class="normal">There's one more piece to the puzzle before we can say that we really understand deep Q-learning;<a id="_idTextAnchor212"/> the Softmax method.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_148" lang="en-GB"><a id="_idTextAnchor213"/>The Softmax method</h3>
			<p class="normal">This is the missing piece before we're ready to assemble everything for deep Q-learning. The Softmax method is<a id="_idIndexMarker324"/> the way we're going to select the <a id="_idIndexMarker325"/>action
 to perform after predicting the Q-values. In Q-learning, that was 
simple; the action performed was the one with the highest Q-value. That <a id="_idIndexMarker326"/>was the argmax method. In deep Q-learning, things are different. The problems are usually more complex, and so, in order to<a id="_idIndexMarker327"/> find an optimal solution, we must go through a process called <strong class="bold">Exploration</strong>.</p>
			<p class="normal">Exploration consists of the following: instead of 
performing the action that has the maximum Q-value (which is called 
Exploitation), we're going to give each action a probability 
proportional to<a id="_idIndexMarker328"/> its Q-value, such that the
 higher the Q-value, the higher the probability. This creates, exactly, a
 distribution of the performable actions. Then finally, the action 
performed will be selected as a random draw from that distribution. Let 
me explain with an example.</p>
			<p class="normal">Let's imagine we are building a self-driving car (we actually will, in <em class="italics">Chapter 10, AI for Autonomous Vehicles - Build a Self-Driving Car</em>). Let's say that the possible actions to perform are simple: move forward, turn left or turn right.</p>
			<p class="normal">Then, at a specific time, let's say that our AI predicts the following Q-values:</p>
			<table id="table002" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">Move Forward</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Turn Left</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">Turn Right</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="content">24</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">38</p>
						</td>
						<td class="No-Table-Style">
							<p class="content">11</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="normal">The way we can create the distribution of 
probabilities we need is by dividing each Q-value by the sum of the 
three Q-values, which results each time in the probability of a 
particular action. Let's perform those sums:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_026.png" style="height: 3em;" alt=""/></figure>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><span style="vertical-align: top; font-size:1.05em;">Probability of Turning Left</span><img src="../Images/B14110_09_027.png" style="height: 3em" alt=""/></figure>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_028.png" style="height: 3em" alt=""/></figure>
			<p class="normal">Perfect—the probabilities sum to 1 and they are 
proportional to the Q-values. That gives us a distribution of the 
actions. To perform an action, the Softmax method takes a random draw 
from this distribution, such that:</p>
			<ul>
				<li class="list">The action of Moving Forward has a 33% chance of being selected.</li>
				<li class="list">The action of Turning Left has a 52% chance of being selected.</li>
				<li class="list">The action of Turning Right has a 15% chance of being selected.</li>
			</ul>
			<p class="normal">Can you feel the <a id="_idIndexMarker329"/>difference
 between Softmax and argmax, and do you understand why it is called 
Exploration instead of Exploitation? With argmax, the action <em class="italics">Turn Left</em> would be the one performed with absolute certainty. That's Exploitation. But with Softmax, even though the action <em class="italics">Turn Left</em> is the one with the highest chance of being selected, there's still a chance that the other actions might be selected.</p>
			<p class="normal">Now, of course, the question is: why do we want to 
do that? It's simply because we want to explore the other actions, in 
case they lead to transitions resulting in higher rewards than we would 
obtain with pure exploitation. That often happens with complex problems,
 which are the ones for which deep Q-learning is used to find a 
solution. deep Q-learning finds that solution thanks to its advanced 
model, but also through exploration of the actions. This is a technique 
in AI called Policy Exploration.</p>
			<p class="normal">As before, the next step is a step back. We're going to recap how deep Q-learning works.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_149" lang="en-GB">De<a id="_idTextAnchor214"/>ep Q-learning recap</h3>
			<p class="normal">Deep Q-learning<a id="_idIndexMarker330"/> consists of combining Q-learning with an ANN.</p>
			<p class="normal">Inputs are encoded vectors, each one defining a 
state of the environment. These inputs go into an ANN, where the output 
contains the predicted Q-values for each action.</p>
			<p class="normal">More precisely, if there are <em class="italics">n</em> possible actions the AI could take, the output of the artificial neural network is a 1D vector comprised of <em class="italics">n</em>
 elements, each one corresponding to the Q-values of each action that 
could be performed in the current state. Then, the action performed is 
chosen via the Softmax method.</p>
			<p class="normal">Hence, in each state <span class="mediaobject"><img src="../Images/B14110_09_029.png" alt=""/></span>:</p>
			<ol>
				<li class="list" value="1">The prediction is the Q-value <span class="mediaobject"><img src="../Images/B14110_09_030.png" alt=""/></span>, where <span class="mediaobject"><img src="../Images/B14110_09_031.png" alt=""/></span> is performed by the Softmax method.</li>
				<li class="list">The target is <span class="mediaobject"><img src="../Images/B14110_09_032.png" alt=""/></span>.</li>
				<li class="list">The loss error between the prediction and the target is the square of the temporal difference:
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_033.png" style="height: 3.5em" alt=""/></figure>
</li>
</ol>
			<p class="normal">This loss error is<a id="_idIndexMarker331"/> 
back-propagated into the neural network, and the weights are updated 
according to how much they contributed to the error, through stochastic 
or mini-batch gradient descent.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_150" lang="en-GB">Exper<a id="_idTextAnchor215"/>ience replay</h3>
			<p class="normal">You might noticed that<a id="_idIndexMarker332"/> so far we have only considered transitions from one state <span class="mediaobject"><img src="../Images/B14110_07_018.png" alt=""/></span> to the next state <span class="mediaobject"><img src="../Images/B14110_09_035.png" alt=""/></span>. The problem with this is that <span class="mediaobject"><img src="../Images/B14110_09_036.png" alt=""/></span> is most of the time very correlated with <span class="mediaobject"><img src="../Images/B14110_09_037.png" alt=""/></span>; therefore, the neural network is not learning much.</p>
			<p class="normal">This could be improved if, instead of only considering the last transition each time, we considered the last <em class="italics">m</em> transitions, where <em class="italics">m</em> is a large number. This set of the last <em class="italics">m</em>
 transitions is what is called the experience replay memory, or simply 
memory. From this memory we sample some random transitions into small 
batches. Then we train the neural network with these batches to then 
update the weights through mini-batch gradient descent.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_151" lang="en-GB">The whol<a id="_idTextAnchor216"/>e deep Q-learning algorithm</h3>
			<p class="normal">Let's summarize the<a id="_idIndexMarker333"/> different steps of the whole deep Q-learning process.</p>
			<p class="normal">Initialization:</p>
			<ol>
				<li class="list" value="1">Initialize the memory of the experience replay to an empty list <em class="italics">M</em>.</li>
				<li class="list">Choose a maximum size for the memory.</li>
			</ol>
			<p class="normal">At each time <em class="italics">t</em>, we repeat the following process, until the end of the epoch:</p>
			<ol>
				<li class="list" value="1">Predict the Q-values of the current state <span class="mediaobject"><img src="../Images/B14110_09_038.png" alt=""/></span>.</li>
				<li class="list">Perform the action selected by the Softmax method:<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_039.png" style="height: 2.5em" alt=""/></figure></li>
				<li class="list">Get the reward <span class="mediaobject"><img src="../Images/B14110_09_040.png" alt=""/></span>.</li>
				<li class="list">Reach the next state <span class="mediaobject"><img src="../Images/B14110_09_041.png" alt=""/></span>.</li>
				<li class="list">Append the transition <span class="mediaobject"><img src="../Images/B14110_09_042.png" alt=""/></span> to the memory <em class="italics">M</em>.</li>
				<li class="list">Take a random batch <strong class="bold"><img src="../Images/B14110_09_043.png" alt=""/></strong> of transitions. For all the transitions <span class="mediaobject"><img src="../Images/B14110_09_044.png" alt=""/></span> of the random batch <span class="mediaobject"><img src="../Images/B14110_09_045.png" alt=""/></span>:<ul><li class="Bullet-Within-Bullet--PACKT-">Get the predictions: <span class="mediaobject"><img src="../Images/B14110_09_046.png" alt=""/></span></li>
<li class="Bullet-Within-Bullet--PACKT-">Get the targets: <span class="mediaobject"><img src="../Images/B14110_09_047.png" alt=""/></span></li>
<li class="Bullet-Within-Bullet--PACKT-">Compute the loss between the predictions and the targets, over the whole batch <span class="mediaobject"><img src="../Images/B14110_09_048.png" alt=""/></span>:
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_09_049.png" style="height: 3.5em" alt=""/></figure></li>
				<li class="Bullet-Within-Bullet-End--PACKT-">Back-propagate this 
loss error back into the neural network, and through stochastic gradient
 descent, update the weights according to how much they contributed to 
the loss error.</li>
			</ul>
</li>
</ol>
			<p class="normal">You've just unlocked the full deep Q-learning 
process! That means that you are now able to build powerful real-world 
AI applications in many fields. Here's a tour of some of the 
applications <a id="_idIndexMarker334"/>where deep Q-learning can create significant added value:</p>
			<ol>
				<li class="list" value="1"><strong class="bold">Energy</strong>: It 
was a deep Q-learning model that the DeepMind AI used to reduce Google's
 Data Center cooling bill by 40%. Also, deep Q-learning can optimize the
 functioning of smart grids; in other words, it can make smart grids 
even smarter.</li>
				<li class="list"><strong class="bold">Transport</strong>: Deep Q-learning can optimize traffic light control in order to reduce traffic.</li>
				<li class="list"><strong class="bold">Autonomous Vehicles</strong>: Deep Q-learning can be used to build self-driving cars, which we will illustrate in the next chapter of this book.</li>
				<li class="list"><strong class="bold">Robotics</strong>: Today, many advanced robots are built with deep Q-learning.</li>
				<li class="list"><strong class="bold">And much more</strong>: Chemistry, recommender systems, advertising, and many more—even video games, as you'll discover in <em class="italics">Chapter 13</em>, <em class="italics">AI for Games – Become the Master at Snake</em>, when you use deep convolutional Q-learning to train an AI to play Snake.</li>
			</ol>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_152" lang="en-GB"><a id="_idTextAnchor217"/>Summary</h2>
			<p class="normal">You learne<a id="_idTextAnchor218"/>d a lot in 
this chapter; we first discussed ANNs. ANNs are built from neurons put 
in multiple layers. Each neuron from one layer is connected to every 
neuron from the previous layer, and every layer has its own activation 
function—a function that decides how much each output signal should be 
blocked.</p>
			<p class="normal">The step in which an ANN works out the prediction 
is called forward-propagation and the step in which it learns is called 
back-propagation. There are three main types of back-propagation: batch 
gradient descent, stochastic gradient descent, and the best one, 
mini-batch gradient descent, which mixes the advantages of both previous
 methods.</p>
			<p class="normal">The last thing we talked about in this chapter was 
deep Q-learning. This method uses Neural Networks to predict the 
Q-Values of taking certain actions. We also mentioned the experience 
replay memory, which stores a huge chunk of experience for our AI.</p>
			<p class="normal">In the next chapter, you'll put all of this into practice by coding your very own self-driving car.</p>
</body></html>