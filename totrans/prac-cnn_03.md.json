["```py\noutput[i] = reduce(value[strides * i:strides * i + ksize]),\n```", "```py\ntf.nn.max_pool(value, ksize, strides, padding, data_format, name) \n```", "```py\nimport tensorflow as tf\n\ndef maxpool2d(x, k=2): \n   return tf.nn.max_pool(x,  \n               ksize=[1, k, k, 1],  \n               strides=[1, k, k, 1],  \n               padding='SAME') \n```", "```py\nimport tensorflow as tf \nx = tf.constant([[2., 4., 6., 8.,], \n                 [10., 12., 14., 16.]]) \n```", "```py\nx = tf.reshape(x, [1, 2, 4, 1]) \n```", "```py\nVALID = tf.nn.max_pool(x, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID') \n```", "```py\nSAME = tf.nn.max_pool(x, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME') \n```", "```py\nprint(VALID.get_shape())  \nprint(SAME.get_shape())  \n>>> \n(1, 1, 2, 1) \n(1, 1, 2, 1) \n```", "```py\nconv2d(\n     input,\n     filter,\n     strides,\n     padding,\n     use_cudnn_on_gpu=True,\n     data_format='NHWC',\n     dilations=[1, 1, 1, 1],\n     name=None\n )\n```", "```py\ndef conv_layer(data, weights, bias, strides=1): \n   x = tf.nn.conv2d(x,  \n               weights,  \n               strides=[1, strides, strides, 1],  \n               padding='SAME') \n   x = tf.nn.bias_add(x, bias) \n   return tf.nn.relu(x) \n```", "```py\nimport time \nimport math \nimport random \nimport os \nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport tensorflow as tf \nimport Preprocessor \nimport cv2 \nimport LayersConstructor \nfrom sklearn.metrics import confusion_matrix \nfrom datetime import timedelta \nfrom sklearn.metrics.classification import accuracy_score \nfrom sklearn.metrics import precision_recall_fscore_support \n```", "```py\nnum_channels = 3 \n```", "```py\nimg_size = 128 \n```", "```py\nimg_size_flat = img_size * img_size * num_channels \n```", "```py\nimg_shape = (img_size, img_size)  \n```", "```py\nclasses = ['dogs', 'cats']  \nnum_classes = len(classes) \n```", "```py\nbatch_size = 14  \n```", "```py\nvalidation_size = 0.16  \n```", "```py\nearly_stopping = None   \n```", "```py\ntrain_path = '/home/DoG_CaT/data/train/' \ntest_path = '/home/DoG_CaT/data/test/' \ncheckpoint_dir = \"models/\" \n```", "```py\ndata = Preprocessor.read_train_sets(train_path, img_size, classes, validation_size=validation_size) \n```", "```py\ndef read_train_sets(train_path, image_size, classes, validation_size=0): \n  class DataSets(object): \n      pass \n      data_sets = DataSets() \n      images, labels, ids, cls = load_train(train_path, image_size, classes) \n      images, labels, ids, cls = shuffle(images, labels, ids, cls) \n\n      if isinstance(validation_size, float): \n          validation_size = int(validation_size * images.shape[0]) \n          validation_images = images[:validation_size] \n          validation_labels = labels[:validation_size] \n          validation_ids = ids[:validation_size] \n          validation_cls = cls[:validation_size] \n          train_images = images[validation_size:] \n          train_labels = labels[validation_size:] \n          train_ids = ids[validation_size:] \n          train_cls = cls[validation_size:] \n          data_sets.train = DataSet(train_images, train_labels, train_ids, train_cls) \n          data_sets.valid = DataSet(validation_images, validation_labels, validation_ids, validation_cls) \n  return data_sets \n```", "```py\ndef load_train(train_path, image_size, classes): \n    images = [] \n    labels = [] \n    ids = [] \n    cls = [] \n\n    print('Reading training images') \n    for fld in classes:    \n        index = classes.index(fld) \n        print('Loading {} files (Index: {})'.format(fld, index)) \n        path = os.path.join(train_path, fld, '*g') \n        files = glob.glob(path) \n        for fl in files: \n            image = cv2.imread(fl) \n            image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR) \n            images.append(image) \n            label = np.zeros(len(classes)) \n            label[index] = 1.0 \n            labels.append(label) \n            flbase = os.path.basename(fl) \n            ids.append(flbase) \n            cls.append(fld) \n    images = np.array(images) \n    labels = np.array(labels) \n    ids = np.array(ids) \n    cls = np.array(cls) \n    return images, labels, ids, cls \n```", "```py\nclass DataSet(object): \n\n  def next_batch(self, batch_size): \n    \"\"\"Return the next `batch_size` examples from this data set.\"\"\" \n    start = self._index_in_epoch \n    self._index_in_epoch += batch_size \n    if self._index_in_epoch > self._num_examples: \n      # Finished epoch \n      self._epochs_completed += 1 \n      start = 0 \n      self._index_in_epoch = batch_size \n      assert batch_size <= self._num_examples \n    end = self._index_in_epoch \n    return self._images[start:end], self._labels[start:end], self._ids[start:end], self._cls[start:end] \n```", "```py\ntest_images, test_ids = Preprocessor.read_test_set(test_path, img_size) \n```", "```py\ndef read_test_set(test_path, image_size): \n  images, ids  = load_test(test_path, image_size) \n  return images, ids \n```", "```py\ndef load_test(test_path, image_size): \n  path = os.path.join(test_path, '*g') \n  files = sorted(glob.glob(path)) \n\n  X_test = [] \n  X_test_id = [] \n  print(\"Reading test images\") \n  for fl in files: \n      flbase = os.path.basename(fl) \n      img = cv2.imread(fl) \n      img = cv2.resize(img, (image_size, image_size), cv2.INTER_LINEAR) \n      X_test.append(img) \n      X_test_id.append(flbase) \n  X_test = np.array(X_test, dtype=np.uint8) \n  X_test = X_test.astype('float32') \n  X_test = X_test / 255 \n  return X_test, X_test_id \n```", "```py\ndef plot_images(images, cls_true, cls_pred=None): \n    if len(images) == 0: \n        print(\"no images to show\") \n        return  \n    else: \n        random_indices = random.sample(range(len(images)), min(len(images), 9))         \n        images, cls_true  = zip(*[(images[i], cls_true[i]) for i in random_indices])     \n    fig, axes = plt.subplots(3, 3) \n    fig.subplots_adjust(hspace=0.3, wspace=0.3) \n    for i, ax in enumerate(axes.flat): \n        # Plot image. \n        ax.imshow(images[i].reshape(img_size, img_size, num_channels)) \n        if cls_pred is None: \n            xlabel = \"True: {0}\".format(cls_true[i]) \n        else: \n            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i]) \n        ax.set_xlabel(xlabel)         \n        ax.set_xticks([]) \n        ax.set_yticks([])     \n    plt.show() \n```", "```py\nimages, cls_true  = data.train.images, data.train.cls \n```", "```py\n\nplot_images(images=images, cls_true=cls_true) \n```", "```py\nprint(\"Size of:\") \nprint(\"  - Training-set:tt{}\".format(len(data.train.labels)))  \nprint(\"  - Test-set:tt{}\".format(len(test_images))) \nprint(\"  - Validation-set:t{}\".format(len(data.valid.labels))) \n```", "```py\n>>>\nReading training images\n Loading dogs files (Index: 0)\n Loading cats files (Index: 1)\n Reading test images\n Size of:\n - Training-set: 21000\n - Test-set: 12500\n - Validation-set: 4000\n```", "```py\nfilter_size1 = 3  \nnum_filters1 = 32  \nfilter_size2 = 3  \nnum_filters2 = 32  \n```", "```py\nfilter_size3 = 3\nnum_filters3 = 64  \n```", "```py\nfc_size = 128     \n```", "```py\nlearning_rate=1e-4  \n```", "```py\ndef new_weights(shape): \n    return tf.Variable(tf.truncated_normal(shape, stddev=0.05)) \n```", "```py\ndef new_biases(length): \n    return tf.Variable(tf.constant(0.05, shape=[length])) \n```", "```py\ndef new_conv_layer(input,  num_input_channels, filter_size, num_filters,                    use_pooling=True):   \n    shape = [filter_size, filter_size, num_input_channels, num_filters] \n    weights = new_weights(shape=shape) \n    biases = new_biases(length=num_filters) \n    layer = tf.nn.conv2d(input=input, \n                         filter=weights, \n                         strides=[1, 1, 1, 1], \n                         padding='SAME') \n    layer += biases \n    if use_pooling: \n        layer = tf.nn.max_pool(value=layer, \n                               ksize=[1, 2, 2, 1], \n                               strides=[1, 2, 2, 1], \n                               padding='SAME') \n    layer = tf.nn.relu(layer) \n    return layer, weights \n```", "```py\n    layer_shape = layer.get_shape() \n    num_features = layer_shape[1:4].num_elements() \n    layer_flat = tf.reshape(layer, [-1, num_features]) \n    return layer_flat, num_features \n```", "```py\ndef new_fc_layer(input, num_inputs, num_outputs, use_relu=True):  \n    weights = new_weights(shape=[num_inputs, num_outputs]) \n    biases = new_biases(length=num_outputs) \n    layer = tf.matmul(input, weights) + biases \n    if use_relu: \n        layer = tf.nn.relu(layer) \n    return layer \n```", "```py\nx = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x') \nx_image = tf.reshape(x, [-1, img_size, img_size, num_channels]) \ny_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true') \ny_true_cls = tf.argmax(y_true, axis=1) \n```", "```py\nlayer_conv1, weights_conv1 =  \n    LayersConstructor.new_conv_layer(input=x_image, \n                   num_input_channels=num_channels, \n                   filter_size=filter_size1, \n                   num_filters=num_filters1, \n                   use_pooling=True) \n```", "```py\nlayer_conv2, weights_conv2 =  \n    LayersConstructor.new_conv_layer(input=layer_conv1, \n                   num_input_channels=num_filters1, \n                   filter_size=filter_size2, \n                   num_filters=num_filters2, \n                   use_pooling=True) \n```", "```py\nlayer_conv3, weights_conv3 =  \n    LayersConstructor.new_conv_layer(input=layer_conv2, \n                   num_input_channels=num_filters2, \n                   filter_size=filter_size3, \n                   num_filters=num_filters3, \n                   use_pooling=True) \n```", "```py\nlayer_flat, num_features = LayersConstructor.flatten_layer(layer_conv3) \n```", "```py\nlayer_fc1 = LayersConstructor.new_fc_layer(input=layer_flat, \n                         num_inputs=num_features, \n                         num_outputs=fc_size, \n                         use_relu=True) \n```", "```py\nlayer_fc2 = LayersConstructor.new_fc_layer(input=layer_fc1, \n                         num_inputs=fc_size, \n                         num_outputs=num_classes, \n                         use_relu=False) \n```", "```py\ny_pred = tf.nn.softmax(layer_fc2) \ny_pred_cls = tf.argmax(y_pred, axis=1) \ncross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc2,                                               labels=y_true) \n```", "```py\ncost_op= tf.reduce_mean(cross_entropy) \noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost_op) \ncorrect_prediction = tf.equal(y_pred_cls, y_true_cls) \naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n```", "```py\ninit_op = tf.global_variables_initializer() \n```", "```py\nsession = tf.Session() \nsession.run(init_op) \n```", "```py\ntrain_batch_size = batch_size \n```", "```py\nacc_list = [] \nval_acc_list = [] \n```", "```py\ntotal_iterations = 0 \niter_list = [] \n```", "```py\ndef optimize(num_iterations): \n    global total_iterations \n    best_val_loss = float(\"inf\") \n    patience = 0 \n    for i in range(total_iterations, total_iterations + num_iterations): \n        x_batch, y_true_batch, _, cls_batch = data.train.next_batch(train_batch_size) \n        x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(train_batch_size) \n        x_batch = x_batch.reshape(train_batch_size, img_size_flat) \n        x_valid_batch = x_valid_batch.reshape(train_batch_size, img_size_flat) \n        feed_dict_train = {x: x_batch, y_true: y_true_batch}         \n        feed_dict_validate = {x: x_valid_batch, y_true: y_valid_batch} \n        session.run(optimizer, feed_dict=feed_dict_train)         \n\n        if i % int(data.train.num_examples/batch_size) == 0:  \n            val_loss = session.run(cost, feed_dict=feed_dict_validate) \n            epoch = int(i / int(data.train.num_examples/batch_size)) \n            acc, val_acc = print_progress(epoch, feed_dict_train, feed_dict_validate, val_loss) \n            acc_list.append(acc) \n            val_acc_list.append(val_acc) \n            iter_list.append(epoch+1) \n\n            if early_stopping:     \n                if val_loss < best_val_loss: \n                    best_val_loss = val_loss \n                    patience = 0 \n                else: \n                    patience += 1 \n                if patience == early_stopping: \n                    break \n    total_iterations += num_iterations \n```", "```py\ndef plot_example_errors(cls_pred, correct): \n    incorrect = (correct == False)     \n    images = data.valid.images[incorrect]     \n    cls_pred = cls_pred[incorrect] \n    cls_true = data.valid.cls[incorrect]     \n    plot_images(images=images[0:9], cls_true=cls_true[0:9], cls_pred=cls_pred[0:9]) \n```", "```py\ndef print_validation_accuracy(show_example_errors=False, show_confusion_matrix=False): \n    num_test = len(data.valid.images) \n    cls_pred = np.zeros(shape=num_test, dtype=np.int) \n    i = 0 \n    while i < num_test: \n        # The ending index for the next batch is denoted j. \n        j = min(i + batch_size, num_test) \n        images = data.valid.images[i:j, :].reshape(batch_size, img_size_flat)    \n        labels = data.valid.labels[i:j, :] \n        feed_dict = {x: images, y_true: labels} \n        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict) \n        i = j \n\n    cls_true = np.array(data.valid.cls) \n    cls_pred = np.array([classes[x] for x in cls_pred])  \n    correct = (cls_true == cls_pred) \n    correct_sum = correct.sum() \n    acc = float(correct_sum) / num_test \n\n    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\" \n    print(msg.format(acc, correct_sum, num_test)) \n\n    if show_example_errors: \n        print(\"Example errors:\") \n        plot_example_errors(cls_pred=cls_pred, correct=correct)     \n```", "```py\n optimize(num_iterations=1000) \n```", "```py\nAccuracy on Test-Set: 78.8% (3150 / 4000) \nPrecision: 0.793378626929 \nRecall: 0.7875 \nF1-score: 0.786639298213 \n```", "```py\n>>> \nAccuracy on Test-Set: 81.1% (3244 / 4000) \nPrecision: 0.811057239265 \nRecall: 0.811 \nF1-score: 0.81098298755 \n```", "```py\ntest_cat = cv2.imread('Test_image/cat.jpg') \ntest_cat = cv2.resize(test_cat, (img_size, img_size), cv2.INTER_LINEAR) / 255 \npreview_cat = plt.imshow(test_cat.reshape(img_size, img_size, num_channels)) \n\ntest_dog = cv2.imread('Test_image/dog.jpg') \ntest_dog = cv2.resize(test_dog, (img_size, img_size), cv2.INTER_LINEAR) / 255 \npreview_dog = plt.imshow(test_dog.reshape(img_size, img_size, num_channels)) \n```", "```py\ndef sample_prediction(test_im):     \n    feed_dict_test = { \n        x: test_im.reshape(1, img_size_flat), \n        y_true: np.array([[1, 0]]) \n    } \n    test_pred = session.run(y_pred_cls, feed_dict=feed_dict_test) \n    return classes[test_pred[0]] \nprint(\"Predicted class for test_cat: {}\".format(sample_prediction(test_cat))) \nprint(\"Predicted class for test_dog: {}\".format(sample_prediction(test_dog))) \n\n>>>  \nPredicted class for test_cat: cats \nPredicted class for test_dog: dogs \n```", "```py\nsession.close() \n```", "```py\ntraining = tf.placeholder(tf.bool)\nx = tf.layers.dense(input_x, units=100)\nx = tf.layers.batch_normalization(x, training=training)\nx = tf.nn.relu(x)\n```", "```py\nextra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\nsess.run([train_op, extra_update_ops], ...)\n```", "```py\ntf.nn.dropout (x, keep_prob, noise_shape, seed, name)\n```", "```py\nimport tensorflow as tf X = [1.5, 0.5, 0.75, 1.0, 0.75, 0.6, 0.4, 0.9] \ndrop_out = tf.nn.dropout(X, 0.5) \nsess = tf.Session() with sess.as_default(): \n    print(drop_out.eval()) \nsess.close() \n```", "```py\n[ 3\\. 0\\. 1.5 0\\. 0\\. 1.20000005 0\\. 1.79999995]\n```", "```py\noptimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost_op)\n```", "```py\nTrain_IMAGE_DIR = \"<path>/BelgiumTSC_Training/\"\nTest_IMAGE_DIR = \"\"<path>/BelgiumTSC_Testing/\"\n```", "```py\ndef load_data(data_dir):\n    # All subdirectories, where each folder represents a unique label\n    directories = [d for d in os.listdir(data_dir)if os.path.isdir(os.path.join(data_dir, d))]\n\n    # Iterate label directories and collect data in two lists, labels and images.\n    labels = []\n    images = []\n    for d in directories:label_dir = os.path.join(data_dir, d)\n    file_names = [os.path.join(label_dir, f) \n                for f in os.listdir(label_dir) if f.endswith(\".ppm\")]\n\n    # For each label, load it's images and add them to the images list.\n    # And add the label number (i.e. directory name) to the labels list.\n    for f in file_names:images.append(skimage.data.imread(f))\n    labels.append(int(d))\n    return images, labels\n```", "```py\n# Load training and testing datasets.\ntrain_data_dir = os.path.join(Train_IMAGE_DIR, \"Training\")\ntest_data_dir = os.path.join(Test_IMAGE_DIR, \"Testing\")\n\nimages, labels = load_data(train_data_dir)\n```", "```py\nprint(\"Unique classes: {0} \\nTotal Images: {1}\".format(len(set(labels)), len(images)))\n```", "```py\n>>>\nUnique classes: 62\nTotal Images: 4575\n```", "```py\n# Make a histogram with 62 bins of the `labels` data and show the plot: \nplt.hist(labels, 62)\nplt.xlabel('Class')\nplt.ylabel('Number of training examples')\nplt.show()\n```", "```py\ndef display_images_and_labels(images, labels):\n    unique_labels = set(labels)\n    plt.figure(figsize=(15, 15))\n    i = 1\n    for label in unique_labels:\n        # Pick the first image for each label.\n        image = images[labels.index(label)]\n        plt.subplot(8, 8, i) # A grid of 8 rows x 8 column\n        splt.axis('off')\n        plt.title(\"Label {0} ({1})\".format(label, labels.count(label)))\n        i += 1        \n        _= plt.imshow(image)\n        plt.show()\ndisplay_images_and_labels(images, labels)\n```", "```py\nfor img in images[:5]:\n    print(\"shape: {0}, min: {1}, max: {2}\".format(img.shape, img.min(), img.max()))\n```", "```py\n>>>\nshape: (87, 84, 3), min: 12, max: 255\nshape: (289, 169, 3), min: 0, max: 255\nshape: (205, 76, 3), min: 0, max: 255\nshape: (72, 71, 3), min: 14, max: 185\nshape: (231, 228, 3), min: 0, max: 255\n```", "```py\nimages32 = [skimage.transform.resize(img, (32, 32), mode='constant') \n\nfor img in images]for img in images32[:5]:\n    print(\"shape: {0}, min: {1}, max: {2}\".format(img.shape, img.min(), img.max()))\n```", "```py\n>>>\nshape: (32, 32, 3), min: 0.06642539828431372, max: 0.9704350490196079\nshape: (32, 32, 3), min: 0.0, max: 1.0\nshape: (32, 32, 3), min: 0.03172870710784261, max: 1.0\nshape: (32, 32, 3), min: 0.059474571078431314, max: 0.7036305147058846\nshape: (32, 32, 3), min: 0.01506204044117481, max: 1.0\n```", "```py\nlabels_array = np.array(labels)\nimages_array = np.array(images32)\nprint(\"labels: \", labels_array.shape, \"nimages: \", images_array.shape)\n```", "```py\n>>>\nlabels: (4575,)\nimages: (4575, 32, 32, 3)\n```", "```py\ngraph = tf.Graph()\nwith graph.as_default():\n    # Placeholders for inputs and labels.\n    images_X = tf.placeholder(tf.float32, [None, 32, 32, 3]) # each image's 32x32 size\n    labels_X = tf.placeholder(tf.int32, [None])\n\n    # Initializer: Xavier\n     biasInit = tf.contrib.layers.xavier_initializer(uniform=True, seed=None, dtype=tf.float32)\n\n    # Convolution layer 1: number of neurons 128 and kernel size is 6x6.\n     conv1 = tf.contrib.layers.conv2d(images_X, num_outputs=128, kernel_size=[6, 6],     \n            biases_initializer=biasInit)\n\n    # Batch normalization layer 1: can be applied as a normalizer \n    # function for conv2d and fully_connected\n    bn1 = tf.contrib.layers.batch_norm(conv1, center=True, scale=True, is_training=True)\n\n    # Max Pooling (down sampling) with strides of 2 and kernel size of 2\n    pool1 = tf.contrib.layers.max_pool2d(bn1, 2, 2)\n\n    # Convolution layer 2: number of neurons 256 and kernel size is 6x6.\n    conv2 = tf.contrib.layers.conv2d(pool1, num_outputs=256, kernel_size=[4, 4], stride=2,     \n        biases_initializer=biasInit)\n\n    # Batch normalization layer 2: \n    bn2 = tf.contrib.layers.batch_norm(conv2, center=True, scale=True, is_training=True)\n\n    # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n    pool2 = tf.contrib.layers.max_pool2d(bn2, 2, 2)\n\n    # Flatten the input from [None, height, width, channels] to \n    # [None, height * width * channels] == [None, 3072]\n    images_flat = tf.contrib.layers.flatten(pool2)\n\n    # Fully connected layer 1\n    fc1 = tf.contrib.layers.fully_connected(images_flat, 512, tf.nn.relu)\n\n    # Batch normalization layer 3\n    bn3 = tf.contrib.layers.batch_norm(fc1, center=True, scale=True, is_training=True)\n\n    # apply dropout, if is_training is False, dropout is not applied\n    fc1 = tf.layers.dropout(bn3, rate=0.25, training=True)\n\n    # Fully connected layer 2 that generates logits of size [None, 62]. \n    # Here 62 means number of classes to be predicted.\n    logits = tf.contrib.layers.fully_connected(fc1, 62, tf.nn.relu)\n```", "```py\nloss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels_X))\n```", "```py\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\nwith tf.control_dependencies(update_ops):\n    # Create an optimizer, which acts as the training op.train =             \n    tf.train.AdamOptimizer(learning_rate=0.10).minimize(loss_op)\n```", "```py\ninit_op = tf.global_variables_initializer()\n```", "```py\nsession = tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True))\nsession.run(init_op)\nfor i in range(300):\n    _, loss_value = session.run([train, loss_op], feed_dict={images_X: images_array, labels_X: \n    labels_array})\n    if i % 10 == 0:\n        print(\"Loss: \", loss_value)\n```", "```py\n>>>\nLoss: 4.7910895\nLoss: 4.3410876\nLoss: 4.0275432\n...\nLoss: 0.523456\n```", "```py\nrandom_indexes = random.sample(range(len(images32)), 10)\nrandom_images = [images32[i]\nfor i in random_indexes]\n    random_labels = [labels[i]\nfor i in random_indexes]\n```", "```py\npredicted = session.run([predicted_labels], feed_dict={images_X: random_images})[0]\nprint(random_labels)\nprint(predicted)\n```", "```py\n>>>\n[38, 21, 19, 39, 22, 22, 45, 18, 22, 53]\n[20  21  19  51  22  22  45  53  22  53]\n```", "```py\nfig = plt.figure(figsize=(5, 5))\nfor i in range(len(random_images)):\n    truth = random_labels[i]\n    prediction = predicted[i]\n    plt.subplot(5, 2,1+i)\n    plt.axis('off')color='green' \n    if truth == prediction \n    else\n     'red'plt.text(40, 10, \"Truth: {0}nPrediction: {1}\".format(truth, prediction), fontsize=12,     \n    color=color)\nplt.imshow(random_images[i])\n>>> \n```", "```py\n# Load the test dataset.\ntest_X, test_y = load_data(test_data_dir)\n\n# Transform the images, just as we did with the training set.\ntest_images32 = [skimage.transform.resize(img, (32, 32), mode='constant') \nfor img in test_X]\n    display_images_and_labels(test_images32, test_y)\n\n# Run predictions against the test \nsetpredicted = session.run([predicted_labels], feed_dict={images_X: test_images32})[0]\n\n# Calculate how many matches\nmatch_count = sum([int(y == y_) for y, y_ in zip(test_y, predicted)])\naccuracy = match_count / len(test_y)print(\"Accuracy: {:.3f}\".format(accuracy))\n```", "```py\n>>\nAccuracy: 87.583 \n```", "```py\nsession.close()\n```"]