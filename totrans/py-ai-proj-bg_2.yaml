- en: Prediction with Random Forests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we're going to look at classification techniques with random
    forests. We're going to use scikit-learn, just like we did in the previous chapter.
    We're going to look at examples of predicting bird species from descriptive attributes
    and then use a confusion matrix on them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a detailed list of the topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Classification and techniques for evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting bird species with random forests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Confusion matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random forests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Random forests are extensions of decision trees and are a kind of ensemble method.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble methods can achieve high accuracy by building several classifiers and
    running a each one independently. When a classifier makes a decision, you can
    make use of the most common and the average decision. If we use the most common
    method, it is called **voting**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a diagram depicting the ensemble method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00031.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: You can think of each classifier as being specialized for a unique perspective
    on the data. Each classifier may be a different type. For example, you can combine
    a decision tree and a logistic regression and a neural net, or the classifiers
    may be the same type but trained on different parts or subsets of the training
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'A random forest is a collection or ensemble of decision trees. Each tree is
    trained on a random subset of the attributes, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00032.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: These decision trees are typical decision trees, but there are several of them.
    The difference, compared with a single decision tree, particularly in a random
    forest, is that each tree is only allowed to look at some of the attributes, typically
    a small number relative to the total number of attributes available. Each tree
    is specialized to just those attributes. These specialized trees are collected
    and each offers a vote for its prediction. Whichever outcome gets the most votes
    from the ensemble of specialized trees is the winner. That is the final prediction
    of the random forest.
  prefs: []
  type: TYPE_NORMAL
- en: Usage of random forest
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We should consider using a random forest when there is a sufficient number of
    attributes to make trees and the accuracy is paramount. When there are fewer trees,
    the interpretability is difficult compared to a single decision tree. You should
    avoid using random forests if interpretability is important because if there are
    too many trees, the models are quite large and can take a lot of memory during
    training and prediction. Hence, resource-limited environments may not be able
    to use random forests. The next section will explain the prediction of bird species
    using random forests.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting bird species with random forests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here we will be using random forests to predict a bird's species. We will use
    the Caltech-UC San Diego dataset ([http://www.vision.caltech.edu/visipedia/CUB-200-2011.html](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html)),
    which contains about 12,000 photos of birds from 200 different species. Here we
    are not going to look at the pictures because that would need a **convolutional
    neural network** (**CNN**) and this will be covered in later chapters. CNNs can
    handle pictures much better than a random forest. Instead, we will be using attributes
    of the birds such as size, shape, and color.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are just some of the species in the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00033.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Some, such as the **American Crow** and the **Fish Crow**, are almost indistinguishable,
    at least visually. The attributes for each photo, such as color and size, have
    actually been labeled by humans. Caltech and UCSD used human workers on Amazon's
    Mechanical Turk to label the dataset. Researchers often use Mechanical Turk, which
    is a website service in which a person gets paid a tiny amount of money for each
    photo they label to improve the dataset using human insight rather than machine
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: If you have your own dataset that needs lots of human-provided labels, you might
    consider spending some money on Mechanical Turk to complete that task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of a single photo and its labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00034.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/browse/Summer_Tanager.html
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the Summer Tanager is marked as having a red throat, a solid
    belly pattern, a perching-like shape, and so on. The dataset includes information
    about how long it took each person to decide on the labels and how confident the
    person is with their decisions, but we're not going to use that information.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data is split into several files. We''ll discuss those files before jumping
    into the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00035.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The `classes.txt` file shows class IDs with the bird species names. The `images.txt`
    file shows image IDs and filenames. The species for each photo is given in the
    `image_class_labels.txt` file, which connects the class IDs with the image IDs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `attributes.txt` file gives the name of each attribute, which ultimately
    is not going to be that important to us. We''re only going to need the attribute
    IDs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00036.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, the most important file is `image_attribute_labels.txt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00037.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: It connects each image with its attributes in a binary value that's either present
    or absent for that attribute. Users on Mechanical Turk produced each row in this
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00038.gif)'
  prefs: []
  type: TYPE_IMG
- en: We will first load the CSV file with all the image attribute labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are few things that need to be noted:'
  prefs: []
  type: TYPE_NORMAL
- en: Space separation for all the values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No header column or row
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ignore the messages or warnings, such as `error_bad_lines= False` and `warn_bad_lines=
    False`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use columns `0`, `1`, and `2`, which have the image ID, the attribute ID, and
    the present or non-present value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You don't need to worry about the attributes and the time taken to select them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, at the top of that dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00039.gif)'
  prefs: []
  type: TYPE_IMG
- en: Image ID number 1 does not have attributes 1, 2, 3, or 4, but it does have attribute
    5.
  prefs: []
  type: TYPE_NORMAL
- en: 'The shape will tell us how many rows and columns we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00040.gif)'
  prefs: []
  type: TYPE_IMG
- en: It has 3.7 million rows and three columns. This is not the actual formula that
    you want. You want attributes to be the columns, not rows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00041.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore, we have to use pivot, just like Excel has a pivot method:'
  prefs: []
  type: TYPE_NORMAL
- en: Pivot on the image ID and make one row for each image ID. There will be only
    one row for image number one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Turn the attributes into distinct columns, and the values will be ones or twos.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can now see that each image ID is just one row and each attribute is its
    own column, and we have the ones and the twos:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00042.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s feed this data into a random forest. In the previous example, we have
    312 columns and 312 attributes, which is ultimately about 12,000 images or 12,000
    different examples of birds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00043.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we need to load the answers, such as whether it''s a bird and which species
    it is. Since it is an image class labels file, the separators are spaces. There
    is no header row and the two columns are `imgid` and `label`. We will be using `set_index(''imgid'')`
    to have the same result produced by `imgatt2.head()`, where the rows are identified
    by the image ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00044.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s what it looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00045.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'The `imgid` column has `1`, `2`, `3`, `4`, and `5`, all are labeled as `1`.
    They''re all albatrossed at the top of the file. As seen, there are about 12,000
    rows, which is perfect:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00046.gif)'
  prefs: []
  type: TYPE_IMG
- en: This is the same number as the attributes data. We will be using join.
  prefs: []
  type: TYPE_NORMAL
- en: In the join, we will use the index on the image ID to join the two data frames.
    Effectively, what we're going to get is that the label is stuck on as the last
    column.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be now shuffling and then be splitting off the attributes. In other
    words, we want to drop the label from the label. So, here are the attributes,
    with the first 312 columns and the last column being a label:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00047.gif)'
  prefs: []
  type: TYPE_IMG
- en: After shuffling, we have the first row as image 527, the second row as image
    1532, and so forth. The attributes in the label data are in agreement. On the
    first row, it's image 527, which is the number 10\. You will not know which bird
    it is, but it's of the kind, and these are its attributes. But it is finally in
    the right form. We need to do a training test split.
  prefs: []
  type: TYPE_NORMAL
- en: 'There were 12,000 rows, so let''s take the first 8,000 and call them training,
    and the call rest of them testing (4,000). We''ll get the answers using `RandomForestClassifier`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00048.gif)'
  prefs: []
  type: TYPE_IMG
- en: Max features show the number of different columns each tree can look at.
  prefs: []
  type: TYPE_NORMAL
- en: For an instance, if we say something like, *look at two attributes*, that's
    probably not enough to actually figure out which bird it is. Some birds are unique,
    so you might need a lot more attributes. Later if we say `max_features=50` and
    the number of estimators denote the number of trees created. The fit actually
    builds it.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00049.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s predict a few cases. Let''s use attributes from the first five rows
    of the training set, which will predict species 10, 28, 156, 10, and 43\. After
    testing, we get 44% accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00050.gif)'
  prefs: []
  type: TYPE_IMG
- en: Even 44% accuracy is not the best result. There are 200 species, so having 0.5%
    accuracy is much better than randomly guessing.
  prefs: []
  type: TYPE_NORMAL
- en: Making a confusion matrix for the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s make a confusion matrix to see which birds the dataset confuses. The
    `confusion_matrix` function from scikit-learn will produce the matrix, but it''s
    a pretty big matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00051.gif)'
  prefs: []
  type: TYPE_IMG
- en: Two hundred by two hundred is not easy to understand in a numeric form like
    this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s some code from the scikit-learn documentation that allows us to plot
    the matrix and the color in the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00052.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We will need the actual names of the birds on the matrix so that we know the
    species that are being confused for each other. So, let''s load the classes file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00053.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Plot the matrix. This is the confusion matrix for this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00054.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'The output looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00055.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The output is unreadable because there are 200 rows and columns. But if we
    open it separately and then start zooming in, on the *y* axis you will see the
    actual birds, and on the *x* axis, you will see the predicted birds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00056.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'For example, the common yellow throat is the true one. Looking at the following
    graph, we can see that the common yellow throat is confused with the black-footed
    albatross. When we zoom out, we will see the confusion:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00057.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: It's like a square of confusion that was there between the common yellow throat
    and the black-footed albatross. Some features are terns, such as the arctic tern,
    black tern, Caspian tern, and the common tern. Terns are apparently easy to confuse
    because they look similar.
  prefs: []
  type: TYPE_NORMAL
- en: 'This set is a little bit confused too:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00058.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: This is the set regarding sparrows. The confusion matrix tells us the things
    that we expect, that is, birds that look similar are confused with each other.
    There are little squares of confusion, as seen in the previous screenshot.
  prefs: []
  type: TYPE_NORMAL
- en: For the most part, you don't want to confuse an albatross with a common yellow
    throat because this means that the dataset doesn't know with what it's doing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the bird''s names are sorted, lesser is the square of confusion. Let''s
    compare this with the simple decision tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00059.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the accuracy is 27%, which is less than the previous 44% accuracy. Therefore,
    the decision tree is worse. If we use a **Support Vector Machine** (**SVM**),
    which is the neural network approach, the output is 29%:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00060.gif)'
  prefs: []
  type: TYPE_IMG
- en: The random forest is still better.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s perform cross-validation to make sure that we split the training test
    in different ways. The output is still 44% for the random forest, 25% for our
    decision tree, and 27% for SVM, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00061.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The best results are reflected through random forests since we had some options
    and questions with random forests.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, how many different questions can each tree ask? How many attributes
    does it look at, and how many trees are there? Well, there are a lot of parameters
    to look through, so let''s just make a loop and try them all:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00062.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'These are all the accuracies, but it would be better to visualize this in a
    graph, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00063.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We can see that increasing the number of trees produces a better outcome. Also,
    increasing the number of features produces better outcomes if you are able to
    see more features, but ultimately, if you're at about 20 to 30 features and you
    have about 75 to 100 trees, that's about as good as you're going to get an accuracy
    of 45%.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about random forests and classify bird species .
    Later, we discussed the confusion matrix and different graphs that gave us output
    based on random trees, decision trees, and SVM.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll go look at comment classification using bag-of-words
    models and Word2Vec models.
  prefs: []
  type: TYPE_NORMAL
