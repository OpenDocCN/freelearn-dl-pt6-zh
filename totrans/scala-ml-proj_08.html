<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Clients Subscription Assessment for Bank Telemarketing using Deep Neural Networks</h1>
                </header>
            
            <article>
                
<p class="chapter-content">In this chapter, we will see two examples of how to build very robust and accurate predictive models for predictive analytics using H2O on a bank marketing dataset. The data is related to the direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. The goal of this end-to-end project is to predict that the client will subscribe to a term deposit.</p>
<p class="chapter-content">Throughout this project, the following topics will be covered in this chapter:</p>
<ul>
<li>Client subscription assessment</li>
<li>Dataset description</li>
<li>Exploratory analysis of the dataset</li>
<li>Client subscription assessment using H2O</li>
<li>Tuning hyperparameters</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Client subscription assessment through telemarketing</h1>
                </header>
            
            <article>
                
<p class="mce-root">Some time ago, due to the global financial crisis, getting credit in international markets became more restricted for banks. This turned attention to internal customers and their deposits to gather funds. This led to a demand for information about a client's behavior for their deposits and their response to telemarketing campaigns conducted by the banks periodically. Often, more than one contact to the same client is required in order to assess whether the product (bank term deposit) will be (<strong>yes</strong>) or will be (<strong>no</strong>) subscribed.</p>
<p class="mce-root">The aim of this project is to implement an ML model that predicts that the client will subscribe to a term deposit (variable <kbd>y</kbd>). In short, this is a binary classification problem. Now, before we start implementing our application, we need to know about the dataset. Then we will see an explanatory analysis of the dataset.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dataset description</h1>
                </header>
            
            <article>
                
<p class="mce-root">There are two sources that I would like to acknowledge. This dataset was used in a research paper published by Moro et al, <em>A Data-Driven Approach to Predict the Success of Bank Telemarketing</em>, Decision Support Systems, Elsevier, June 2014. Later on, it was donated to the UCI Machine Learning repository and can be downloaded from <a href="https://archive.ics.uci.edu/ml/datasets/bank+marketing"><span class="URLPACKT">https://archive.ics.uci.edu/ml/datasets/bank+marketing</span></a>. According to the dataset description, there are four datasets:</p>
<ul>
<li><kbd>bank-additional-full.csv</kbd>: This includes all examples (41,188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed by Moro et al, 2014</li>
<li><kbd>bank-additional.csv</kbd>: This includes 10% of the examples (4,119), randomly selected from 1 and 20 inputs</li>
<li><kbd>bank-full.csv</kbd>: This includes all the examples and 17 inputs, ordered by date (an older version of this dataset with fewer inputs)</li>
<li><kbd>bank.csv</kbd>: This includes 10% of the examples and 17 inputs randomly selected from three (an older version of this dataset with fewer inputs)</li>
</ul>
<p class="mce-root">There are 21 attributes in the dataset. The independent variables, that is, features, can be further categorized as bank-client-related data (attributes 1 to 7), related to the last contact with the current campaign (attributes 8 to 11), other attributes (attributes 12 to 15), and social and economic context attributes (attributes 16 to 20). The dependent variable is specified by <kbd>y</kbd>, the last attribute (21):</p>
<table class="table">
<tbody>
<tr>
<td><strong>ID</strong></td>
<td><strong>Attribute</strong></td>
<td><strong>Explanation</strong></td>
</tr>
<tr>
<td>1</td>
<td><kbd>age</kbd></td>
<td>Age in numbers.</td>
</tr>
<tr>
<td>2</td>
<td><kbd>job</kbd></td>
<td>This is the type of job in a categorical format, with these possible values: <kbd>admin</kbd>, <kbd>blue-collar</kbd>, <kbd>entrepreneur</kbd>, <kbd>housemaid</kbd>, <kbd>management</kbd>, <kbd>retired</kbd>, <kbd>self-employed</kbd>, <kbd>services</kbd>, <kbd>student</kbd>, <kbd>technician</kbd>, <kbd>unemployed</kbd>, and <kbd>unknown</kbd>.</td>
</tr>
<tr>
<td>3</td>
<td><kbd>marital</kbd></td>
<td>This is the marital status in a categorical format<span>, with these possible </span>values: <kbd>divorced</kbd>, <kbd>married</kbd>, <kbd>single</kbd>, and <kbd>unknown</kbd>. Here, <kbd>divorced</kbd> means divorced or widowed.</td>
</tr>
<tr>
<td>4</td>
<td><kbd>education</kbd></td>
<td>This is the educational background in categorical format, with possible values as follows: <kbd>basic.4y</kbd>, <kbd>basic.6y</kbd>, <kbd>basic.9y</kbd>, <kbd>high.school</kbd>, <kbd>illiterate</kbd>, <kbd>professional.course</kbd>, <kbd>university.degree</kbd>, and <kbd>unknown</kbd>.</td>
</tr>
<tr>
<td>5</td>
<td><kbd>default</kbd></td>
<td>This is a categorical format with possible values in credit in default as <kbd>no</kbd>, <kbd>yes</kbd>, and <kbd>unknown</kbd>.</td>
</tr>
<tr>
<td>6</td>
<td><kbd>housing</kbd></td>
<td>Does the customer have a housing loan?</td>
</tr>
<tr>
<td>7</td>
<td><kbd>loan</kbd></td>
<td>The personal loan in a categorical format, with possible values as <kbd>no</kbd>, <kbd>yes</kbd>, and <kbd>unknown</kbd>.</td>
</tr>
<tr>
<td>8</td>
<td><kbd>contact</kbd></td>
<td>This is the contact communication type in a categorical format. The possible values are <kbd>cellular</kbd> and <kbd>telephone</kbd>.</td>
</tr>
<tr>
<td>9</td>
<td><kbd>month</kbd></td>
<td>This is the last contact month of the year in a categorical format with possible values <kbd>jan</kbd>, <kbd>feb</kbd>, <kbd>mar</kbd>, ..., <kbd>nov</kbd>, and <kbd>dec</kbd>.</td>
</tr>
<tr>
<td>10</td>
<td><kbd>day_of_week</kbd></td>
<td>This is the last contact day of the week in a categorical format with possible values <kbd>mon</kbd>, <kbd>tue</kbd>, <kbd>wed</kbd>, <kbd>thu</kbd>, and <kbd>fri</kbd>.</td>
</tr>
<tr>
<td>11</td>
<td><kbd>duration</kbd></td>
<td>This is the last contact duration, in seconds (numerical value). This attribute highly affects the output target (for example, if <kbd>duration=0</kbd>, then <kbd>y=no</kbd>). Yet, the duration is not known before a call is performed. Also, after the end of the call, <kbd>y</kbd> is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.</td>
</tr>
<tr>
<td>12</td>
<td><kbd>campaign</kbd></td>
<td>This is the number of contacts performed during this campaign and for this client.</td>
</tr>
<tr>
<td>13</td>
<td><kbd>pdays</kbd></td>
<td>This is the number of days that passed by after the client was last contacted by a previous campaign (numeric; 999 means client was not previously contacted).</td>
</tr>
<tr>
<td>14</td>
<td><kbd>previous</kbd></td>
<td>This is the number of contacts performed before this campaign and for this client (numeric).</td>
</tr>
<tr>
<td>15</td>
<td><kbd>poutcome</kbd></td>
<td>The outcome of the previous marketing campaign (categorical: <kbd>failure</kbd>, <kbd>nonexistent</kbd>, and <kbd>success</kbd>).</td>
</tr>
<tr>
<td>16</td>
<td><kbd>emp.var.rate</kbd></td>
<td>Employment variation rate<span>—</span>quarterly indicator (numeric).</td>
</tr>
<tr>
<td>17</td>
<td><kbd>cons.price.idx</kbd></td>
<td>Consumer price index—monthly indicator (numeric).</td>
</tr>
<tr>
<td>18</td>
<td><kbd>cons.conf.idx</kbd></td>
<td>Consumer confidence index<span>—</span>monthly indicator (numeric).</td>
</tr>
<tr>
<td>19</td>
<td><kbd>euribor3m</kbd></td>
<td>Euribor 3 month rate<span>—</span>daily indicator (numeric).</td>
</tr>
<tr>
<td>20</td>
<td><kbd>nr.employed</kbd></td>
<td>Number of employees<span>—</span>quarterly indicator (numeric).</td>
</tr>
<tr>
<td>21</td>
<td><kbd>y</kbd></td>
<td>Signifies whether the client has subscribed a term deposit. It has possible binary (<kbd>yes</kbd> and <kbd>no</kbd>) values.</td>
</tr>
</tbody>
</table>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Table 1: Description of the bank marketing dataset</div>
<p class="mce-root">For the exploratory analysis of the dataset, we will be using Apache Zeppelin and Spark. We'll start by visualizing the distributions of the categorical features, and then the numeric features. At the end, we'll compute some statistics that describe numeric features. But before that, let's configure Zeppelin.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing and getting started with Apache Zeppelin</h1>
                </header>
            
            <article>
                
<p class="mce-root">Apache Zeppelin is a web-based notebook that enables you to do data analytics in an interactive way. Using Zeppelin, you can make beautiful, data-driven, interactive, and collaborative documents with SQL, Scala, and more. The Apache Zeppelin interpreter concept allows any language/data processing backend to be plugged into Zeppelin. Currently, Apache Zeppelin supports many interpreters such as Apache Spark, Python, JDBC, Markdown, and Shell.</p>
<p class="mce-root">Apache Zeppelin is a relatively newer technology from Apache Software Foundation that enables the data scientist, engineer, and practitioner to do data exploration, visualization, sharing, and collaboration with multiple programming language backends (such as Python, Scala, Hive, SparkSQL, Shell, Markdown, and more). Since using other interpreters is not the goal of this book, we'll be using Spark on Zeppelin, and all the codes will be written using Scala. In this section, therefore, we will show you how to configure Zeppelin using a binary package that contains only the Spark interpreter. Apache Zeppelin officially supports, and is tested in, the following environments:</p>
<table class="MsoTableGrid">
<tbody>
<tr>
<td><strong>Requirements</strong></td>
<td><strong>Value/Version</strong></td>
</tr>
<tr>
<td>Oracle JDK</td>
<td>1.7+<br/>
(set <kbd>JAVA_HOME</kbd>)</td>
</tr>
<tr>
<td>OS</td>
<td>Mac OS X<br/>
Ubuntu 14.X+<br/>
CentOS 6.X+<br/>
Windows 7 Pro SP1+</td>
</tr>
</tbody>
</table>
<p class="mce-root">As shown in the preceding table, Java is required to execute Spark code on Zeppelin. Therefore, if it is not set up, install and set up java on any of the platforms mentioned earlier. The latest release of Apache Zeppelin can be downloaded from <a href="https://zeppelin.apache.org/download.html">https://zeppelin.apache.org/download.html</a>. Each release has three options:</p>
<ul>
<li><strong>Binary package with all interpreters</strong>: Contains all the support for many interpreters. For example, Spark, JDBC, Pig, Beam, Scio, BigQuery, Python, Livy, HDFS, Alluxio, Hbase, Scalding, Elasticsearch, Angular, Markdown, Shell, Flink, Hive, Tajo, Cassandra, Geode, Ignite, Kylin, Lens, Phoenix, and PostgreSQL are currently supported in Zeppelin.</li>
<li><strong>Binary package with Spark interpreter</strong>: Usually, this contains only the Spark interpreter. It also contains an interpreter net-install script.</li>
<li><strong>Source</strong>: You can also build Zeppelin with all the latest changes from the GitHub repository (more on this later). To show you how to install and configure Zeppelin, we have downloaded the binary package from this site's mirror. Once you have downloaded it, unzip it somewhere on your machine. Suppose the path where you have unzipped the file is <kbd>/home/Zeppelin/</kbd>.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building from the source</h1>
                </header>
            
            <article>
                
<p class="mce-root">You can also build Zeppelin with all the latest changes from the GitHub repository. If you want to build from the source, you must first install the following dependencies:</p>
<ul>
<li><strong>Git</strong>: Any version</li>
<li><strong>Maven</strong>: 3.1.x or higher</li>
<li><strong>JDK</strong>: 1.7 or higher</li>
</ul>
<p class="mce-root">If you haven't installed Git and Maven yet, check out the Build requirements at <a href="http://zeppelin.apache.org/docs/latest/install/build.html#build-requirements" target="_blank">http://zeppelin.apache.org/docs/latest/install/build.html#build-requirements</a>. Due to page limitations, we have not discussed all the steps in detail. Interested readers should refer to this URL more details on Apache Zeppelin website at <a href="http://zeppelin.apache.org/" target="_blank">http://zeppelin.apache.org/</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Starting and stopping Apache Zeppelin</h1>
                </header>
            
            <article>
                
<p class="mce-root">On all UNIX-like platforms (such as Ubuntu, Mac, and so on), use the following command:</p>
<pre><strong>$ bin/zeppelin-daemon.sh start</strong></pre>
<p class="mce-root">If the preceding command is successfully executed, you should observe the following logs on the terminal:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="68" width="440" class="alignnone size-full wp-image-276 image-border" src="assets/f2e1f12f-b74a-47d1-93bb-e67096f361ad.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Figure 1: Starting Zeppelin from the Ubuntu terminal</div>
<p>If you are on Windows, use the following command:</p>
<pre><strong>$ binzeppelin.cmd</strong> </pre>
<p class="mce-root">After Zeppelin has started successfully, go to <kbd>http://localhost:8080</kbd> with your web browser and you will see that Zeppelin is running. More specifically, you'll see this on your browser:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="263" width="601" class="alignnone size-full wp-image-277 image-border" src="assets/25a4ebe1-b037-46ed-8396-897842d096bf.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Figure 2: Zeppelin is running on http://localhost:8080</div>
<p class="mce-root">Congratulations! You have successfully installed Apache Zeppelin! Now let's access Zeppelin on the browser at <kbd>http://localhost:8080/</kbd> and get started on our data analytics once we have configured the preferred interpreter. Now, to stop Zeppelin from the command line, issue this command:</p>
<pre><strong>$ bin/zeppelin-daemon.sh stop</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating notebooks</h1>
                </header>
            
            <article>
                
<p class="mce-root">Once you are on <kbd>http://localhost:8080/</kbd>, you can explore different options and menus that help you understand how to get familiar with Zeppelin. For more information on <span>Zeppelin and its user-friendly UI</span>, interested readers can refer to <a href="http://zeppelin.apache.org/docs/latest/" target="_blank">http://zeppelin.apache.org/docs/latest/</a>. Now let's first create a sample notebook and get started. As shown in the following figure, you can create a new notebook by clicking on the <span class="packt_screen">Create new note</span> option in <em>Figure 2</em>:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="182" width="375" class="alignnone size-full wp-image-278 image-border" src="assets/c900fcff-1938-4c1b-9163-da82e72ff41b.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Figure 3: Creating a sample Zeppelin notebook</div>
<p class="mce-root">As shown in <em>Figure 3</em>, the default interpreter is selected as Spark. In the drop-down list, you will see only Spark since you have downloaded the Spark-only binary package for Zeppelin.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploratory analysis of the dataset</h1>
                </header>
            
            <article>
                
<p class="mce-root">Well done! We have been able to install, configure, and get started with Zeppelin. Now let's get going. We will see how the variables are correlated with the label. We start by loading the dataset in Apache, as follows:</p>
<pre class="mce-root"><strong>val</strong> trainDF = spark.read.option("inferSchema", "true")<br/>            .format("com.databricks.spark.csv")<br/>            .option("delimiter", ";")<br/>            .option("header", "true")<br/>            .load("data/bank-additional-full.csv")<br/>trainDF.registerTempTable("trainData")</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Label distribution</h1>
                </header>
            
            <article>
                
<p class="mce-root">Let's see the class distribution. We will use the SQL interpreter for this. Just execute the following SQL query on the Zeppelin notebook:</p>
<pre class="mce-root">%sql select y, count(1) from trainData group by y order by y<br/>&gt;&gt;&gt;</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="330" width="596" class="alignnone size-full wp-image-279 image-border" src="assets/f96956b3-12cf-4c1e-9024-0f97366e8cf1.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Job distribution</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now let's see whether the job titles have any correlation with the subscription decision:</p>
<pre class="mce-root">%sql select job,y, count(1) from trainData group by job, y order by job, y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="905" width="1281" class="alignnone size-full wp-image-280 image-border" src="assets/532371f6-b5a0-4848-9ae2-d887205ec555.png"/></div>
<p>From the chart we can see that most of the clients have jobs as admin, blue-collar, or technician, while students and retired clients have the biggest <em>count(y) / count (n)</em> ratio.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Marital distribution</h1>
                </header>
            
            <article>
                
<p class="mce-root">Does marital status have a correlation with the subscription decision? Let's see:</p>
<pre class="mce-root">%sql select marital,y, count(1) from trainData group by marital,y order by marital,y<br/>&gt;&gt;&gt;</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-281 image-border" src="assets/1ff14701-0f9b-44b3-8397-eb053becfa63.png"/></div>
<p class="mce-root CDPAlignLeft CDPAlign">The distribution shows that the subscriptions are proportional to the number of instances regardless of the marital status of the client.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Education distribution</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now let's see whether educational status has a correlation with the subscription decision:</p>
<pre class="mce-root">%sql select education,y, count(1) from trainData group by education,y order by education,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-282 image-border" src="assets/37719635-692d-47e2-bc3a-2975491b4102.png"/></div>
<p class="mce-root">Thus, similar to marital status, the education level gives no clue about the subscriptions. Now let's keep exploring other variables.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Default distribution</h1>
                </header>
            
            <article>
                
<p class="mce-root">Let's check whether default credit has a correlation with the subscription decision:</p>
<pre class="mce-root">%sql select default,y, count(1) from trainData group by default,y order by default,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-283 image-border" src="assets/fae02864-02b6-43f0-a1a9-3ab41e0559ff.png"/></div>
<p class="mce-root">This chart shows there are almost no clients with default credit and clients with no default credit have a slight subscription ratio.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Housing distribution</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now let's see whether having a house has an interesting correlation with the subscription decision:</p>
<pre class="mce-root">%sql select housing,y, count(1) from trainData group by housing,y order by housing,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><span class="codeChar"><br/>
<img height="300" width="1291" class="alignnone size-full wp-image-289 image-border" src="assets/41a17ae7-7cc5-470e-9c42-04bf60185643.png"/><br/></span></div>
<p class="mce-root">The preceding figures say that housing also gives no clue about subscription.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Loan distribution</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now let's look at loan distribution:</p>
<pre class="mce-root">%sql select loan,y, count(1) from trainData group by loan,y order by loan,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-290 image-border" src="assets/0952fe25-77cb-45e5-a45a-59606d69a87f.png"/></div>
<p class="mce-root">The chart shows that most of the clients have no personal loan and loans have no effect on the subscription ratio.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Contact distribution</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now let's check whether the medium of contact has a significant correlation with the subscription decision:</p>
<pre class="mce-root">%sql select contact,y, count(1) from trainData group by contact,y order by contact,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-291 image-border" src="assets/91093805-6701-40b3-8197-760d5d51be4d.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Month distribution</h1>
                </header>
            
            <article>
                
<p class="mce-root">It might sound funny, but the month of telemarketing can have a significant correlation with the subscription decision:</p>
<pre class="mce-root">%sql select month,y, count(1) from trainData group by month,y order by month,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-288 image-border" src="assets/3d762f6c-9761-4bba-931f-1a56c2264df1.png"/></div>
<p class="mce-root">So, the preceding chart shows that the highest subscription ratios are obtained for months that have fewer instances (for example, December, March, October, and September).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Day distribution</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now, what about the day of the week and its correlation with the subscription decision:</p>
<pre class="mce-root">%sql select day_of_week,y, count(1) from trainData group by day_of_week,y order by day_of_week,y</pre>
<div class="CDPAlignCenter CDPAlign"><img src="assets/83409632-61b3-45f3-bfca-d347404f5ce9.png"/></div>
<p class="mce-root">The day feature has a uniform distribution, so it's not that significant.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Previous outcome distribution</h1>
                </header>
            
            <article>
                
<p class="mce-root">What about the previous outcome and its correlation with the subscription decision:</p>
<pre class="mce-root">%sql select poutcome,y, count(1) from trainData group by poutcome,y order by poutcome,y</pre>
<div class="CDPAlignCenter CDPAlign"><img src="assets/63c6ed5f-083c-42c5-8f2b-15a6fa28cca1.png"/></div>
<p class="mce-root">The distribution shows that clients with a successful outcome from the previous marketing campaign will most likely subscribe. At the same time, those clients represent the minority of the dataset.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Age feature</h1>
                </header>
            
            <article>
                
<p>Let us see how age correlates with the subscription decision:</p>
<pre class="mce-root">%sql select age,y, count(1) from trainData group by age,y order by age,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-294 image-border" src="assets/131b8d6e-2689-49ce-b137-cfbfc515e96c.png"/></div>
<p class="mce-root">The normalized chart shows that most of the clients are aged between <strong>25</strong> and <strong>60</strong>.</p>
<p class="mce-root">The following chart shows that the bank gets a high subscription ratio with clients in the age interval <em>(25, 60)</em>.</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-295 image-border" src="assets/edd13366-b56b-4710-8695-f48b18c45f3f.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Duration distribution</h1>
                </header>
            
            <article>
                
<p>Let us now take a look at how the duration of calls is related to subscription:</p>
<pre class="mce-root">%sql select duration,y, count(1) from trainData group by duration,y order by duration,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-296 image-border" src="assets/ac6d0053-9163-4cdc-81da-7eab79b18b99.png"/></div>
<p class="chapter-content">The charts show that most of the calls are short and the subscription ratio is proportional to the call duration. The expanded version provides better insight:</p>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-297 image-border" src="assets/43a919d0-cf55-4db3-9fa9-26f3b90b2d42.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Campaign distribution</h1>
                </header>
            
            <article>
                
<p>Now we will see how campaign distribution is correlated to subscription:</p>
<pre class="mce-root">%sql select campaign, count(1), y from trainData group by campaign,y order by campaign,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-298 image-border" src="assets/57baabd2-03b5-41e0-972c-b4cbd34b151f.png"/></div>
<p class="chapter-content">The charts show that most of the clients are contacted less than five times and the more a client is contacted, the less he/she is likely to subscribe. Now the expanded version provides better insight:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/0a935ae2-27e5-4156-a391-ceb1c3e7bfc0.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pdays distribution</h1>
                </header>
            
            <article>
                
<p><span>Lets</span> us now take a look at how the <kbd>pdays</kbd> distribution is correlated to subscription:</p>
<pre class="mce-root">%sql select pdays, count(1), y from trainData group by pdays,y order by pdays,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-309 image-border" src="assets/23830f8d-4edf-4be9-a0ce-d255e0d5be8f.png"/></div>
<p class="chapter-content">The chart shows that most of the clients were not previously contacted.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Previous distribution</h1>
                </header>
            
            <article>
                
<p>In the following command, we can see how the previous distribution affects the subscription:</p>
<pre class="mce-root">%sql select previous, count(1), y from trainData group by previous,y order by previous,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-310 image-border" src="assets/c9251b02-5d01-4058-a0ea-4e682fd557d5.png"/></div>
<p class="chapter-content">Like the previous chart, this one confirms that most of the clients were not previously contacted for this campaign.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">emp_var_rate distributions</h1>
                </header>
            
            <article>
                
<p>The following command shows how <kbd>emp_var_rate</kbd> distributions correlate with the subscription:</p>
<pre class="mce-root">%sql select emp_var_rate, count(1), y from trainData group by emp_var_rate,y order by emp_var_rate,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-311 image-border" src="assets/c1bdd55d-b703-423e-8cfc-2f1b003b66c7.png"/></div>
<p class="chapter-content">The charts show that clients with a less common employment variation rate will be more likely to subscribe than other clients. Now the expanded version provides a better insight:</p>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="300" width="1291" class="alignnone size-full wp-image-312 image-border" src="assets/810f87cd-3a6a-4004-a436-784f78bb8091.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">cons_price_idx features</h1>
                </header>
            
            <article>
                
<p>The correlation between <kbd>con_price_idx</kbd> features and subscription can be computed by the following command:</p>
<pre class="mce-root">%sql select cons_price_idx, count(1), y from trainData group by cons_price_idx,y order by cons_price_idx,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/6cac30e0-83dc-4271-be8e-f136816db9a9.png"/></div>
<p class="chapter-content">The charts show that clients with a less common consumer price index are more likely to subscribe compared to other clients. Now, the expanded version provides better insight:</p>
<div class="chapter-content CDPAlignCenter CDPAlign"><img src="assets/e1158e07-d282-4269-b3de-bb6fcfbe9133.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">cons_conf_idx distribution</h1>
                </header>
            
            <article>
                
<p><span>The correlation between <kbd>cons_conf_idx</kbd> distribution and subscription can be computed by the following command:</span></p>
<pre class="mce-root">%sql select cons_conf_idx, count(1), y from trainData group by cons_conf_idx,y order by cons_conf_idx,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/d57b72e9-5e2d-4b6a-97e7-64d876d2f5c1.png"/></div>
<p class="chapter-content">Clients with less common consumer confidence index are more likely to subscribe compared to other clients.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Euribor3m distribution</h1>
                </header>
            
            <article>
                
<p>Let us see how <kbd>euribor3m</kbd> distribution is correlated to subscription:</p>
<pre class="mce-root">%sql select euribor3m, count(1), y from trainData group by euribor3m,y order by euribor3m,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/08a74d07-cf57-43a2-8d3c-f289b2137fd7.png"/></div>
<p class="chapter-content">This chart shows that the euribor 3-month rate has a large range and most of the clients cluster around four or five values of that feature.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">nr_employed distribution</h1>
                </header>
            
            <article>
                
<p>The correlation between <kbd>nr_employed</kbd> distribution and subscription can be seen with the help of the following command:</p>
<pre class="mce-root">%sql select nr_employed, count(1), y from trainData group by nr_employed,y order by nr_employed,y</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/2345643f-0898-408b-98b3-0b9c37b36312.png"/></div>
<p class="chapter-content">The chart shows that the subscription rate is inversely proportional to the number of employees.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Statistics of numeric features</h1>
                </header>
            
            <article>
                
<p>We will now take a look at the statistics of numeric features:</p>
<pre class="mce-root"><strong>import</strong> org.apache.spark.sql.types._<br/><br/><strong>val</strong> numericFeatures = trainDF.schema.filter(_.dataType != StringType)<br/><strong>val</strong> description = trainDF.describe(numericFeatures.map(_.name): _*)<br/><br/><strong>val</strong> quantils = numericFeatures<br/>                .map(f=&gt;trainDF.stat.approxQuantile(f.name,                 <br/>                Array(.25,.5,.75),0)).transposeval <br/><br/>rowSeq = Seq(Seq("q1"+:quantils(0): _*),<br/>            Seq("median"+:quantils(1): _*),<br/>            Seq("q3"+:quantils(2): _*))<br/><br/><strong>val</strong> rows = rowSeq.map(s=&gt; s match{ <br/>    <strong>case </strong>Seq(a:String,b:Double,c:Double,d:Double,<br/>             e:Double,f:Double,g:Double,                                              <br/>             h:Double,i:Double,j:Double,k:Double)=&gt; (a,b,c,d,e,f,g,h,i,j,k)})<br/>         <strong>val</strong> allStats = description.unionAll(sc.parallelize(rows).toDF)<br/>         allStats.registerTempTable("allStats")<br/><br/>%sql select * from allStats<br/>&gt;&gt;&gt;</pre>
<table class="MsoTableGrid">
<tbody>
<tr>
<td><kbd>summary</kbd></td>
<td><kbd>age</kbd></td>
<td><kbd>duration</kbd></td>
<td><kbd>campaign</kbd></td>
<td><kbd>pdays</kbd></td>
<td><kbd>previous</kbd></td>
</tr>
<tr>
<td><kbd>count</kbd></td>
<td>41188.00</td>
<td>41188.00</td>
<td>41188.00</td>
<td>41188.00</td>
<td>41188.00</td>
</tr>
<tr>
<td><kbd>mean</kbd></td>
<td>40.02</td>
<td>258.29</td>
<td>2.57</td>
<td>962.48</td>
<td>0.17</td>
</tr>
<tr>
<td><kbd>stddev</kbd></td>
<td>10.42</td>
<td>259.28</td>
<td>2.77</td>
<td>186.91</td>
<td>0.49</td>
</tr>
<tr>
<td><kbd>min</kbd></td>
<td>17.00</td>
<td>0.00</td>
<td>1.00</td>
<td>0.00</td>
<td>0.00</td>
</tr>
<tr>
<td><kbd>max</kbd></td>
<td>98.00</td>
<td>4918.00</td>
<td>56.00</td>
<td>999.00</td>
<td>7.00</td>
</tr>
<tr>
<td><kbd>q1</kbd></td>
<td>32.00</td>
<td>102.00</td>
<td>1.00</td>
<td>999.00</td>
<td>0.00</td>
</tr>
<tr>
<td><kbd>median</kbd></td>
<td>38.00</td>
<td>180.00</td>
<td>2.00</td>
<td>999.00</td>
<td>0.00</td>
</tr>
<tr>
<td><kbd>q3</kbd></td>
<td>47.00</td>
<td>319.00</td>
<td>3.00</td>
<td>999.00</td>
<td>0.00</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td><kbd>summary</kbd></td>
<td><kbd>emp_var_rate</kbd></td>
<td><kbd>cons_price_idx</kbd></td>
<td><kbd>cons_conf_idx</kbd></td>
<td><kbd>euribor3m</kbd></td>
<td><kbd>nr_employed</kbd></td>
</tr>
<tr>
<td><kbd>count</kbd></td>
<td>41188.00</td>
<td>41188.00</td>
<td>41188.00</td>
<td>41188.00</td>
<td>41188.00</td>
</tr>
<tr>
<td><kbd>mean</kbd></td>
<td>0.08</td>
<td>93.58</td>
<td>-40.50</td>
<td>3.62</td>
<td>5167.04</td>
</tr>
<tr>
<td><kbd>stddev</kbd></td>
<td>1.57</td>
<td>0.58</td>
<td>4.63</td>
<td>1.73</td>
<td>72.25</td>
</tr>
<tr>
<td><kbd>min</kbd></td>
<td>-3.40</td>
<td>92.20</td>
<td>-50.80</td>
<td>0.63</td>
<td>4963.60</td>
</tr>
<tr>
<td><kbd>max</kbd></td>
<td>1.40</td>
<td>94.77</td>
<td>-26.90</td>
<td>5.05</td>
<td>5228.10</td>
</tr>
<tr>
<td><kbd>q1</kbd></td>
<td>-1.80</td>
<td>93.08</td>
<td>-42.70</td>
<td>1.34</td>
<td>5099.10</td>
</tr>
<tr>
<td><kbd>median</kbd></td>
<td>1.10</td>
<td>93.75</td>
<td>-41.80</td>
<td>4.86</td>
<td>5191.00</td>
</tr>
<tr>
<td><kbd>q3</kbd></td>
<td>1.40</td>
<td>93.99</td>
<td>-36.40</td>
<td>4.96</td>
<td>5228.10</td>
</tr>
</tbody>
</table>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing a client subscription assessment model</h1>
                </header>
            
            <article>
                
<p class="mce-root">To predict a client subscription assessment, we use the deep learning classifier implementation from H2O. First, we set up and create a Spark session:</p>
<pre class="chapter-content"><strong>val</strong> spark = SparkSession.builder<br/>        .master("local[*]")<br/>        .config("spark.sql.warehouse.dir", "E:/Exp/") // change accordingly<br/>        .appName(s"OneVsRestExample")<br/>        .getOrCreate()</pre>
<p class="mce-root">Then we load the dataset as a data frame:</p>
<pre class="chapter-content">spark.sqlContext.setConf("spark.sql.caseSensitive", "false");<br/><strong>val</strong> trainDF = spark.read.option("inferSchema","true")<br/>            .format("com.databricks.spark.csv")<br/>            .option("delimiter", ";")<br/>            .option("header", "true")<br/>            .load("data/bank-additional-full.csv")</pre>
<p class="chapter-content">Although there are categorical features in this dataset, there is no need to use a <kbd>StringIndexer</kbd> since the categorical features have small domains. By indexing them, an order relationship that does not exist is introduced. Thus, a better solution is to use One Hot Encodng, and it turns out that H2O, by default, uses this encoding strategy for enumerations.</p>
<p class="chapter-content">In the dataset description, I have already stated that the <kbd>duration</kbd> feature is only available after the label is known. So it can't be used for prediction. Therefore, we should drop it as unavailable before calling the client:</p>
<pre>val withoutDuration = trainDF.drop("duration")</pre>
<p class="chapter-content">So far, we have used Sparks built-in methods for loading the dataset and dropping unwanted features, but now we need to set up <kbd>h2o</kbd> and import its implicits:</p>
<pre class="chapter-content"><strong>implicit</strong> val h2oContext = H2OContext.getOrCreate(spark.sparkContext)<br/><strong>import</strong> h2oContext.implicits._implicit <br/><br/><strong>val</strong> sqlContext = SparkSession.builder().getOrCreate().sqlContext<br/><strong>import</strong> sqlContext.implicits._</pre>
<p class="chapter-content">We then shuffle the training dataset and transform it into an H2O frame:</p>
<pre class="chapter-content"><strong>val</strong> H2ODF: H2OFrame = withoutDuration.orderBy(rand())</pre>
<p class="mce-root">String features are then converted into categorical (type "2 Byte" stands for the String type of H2O):</p>
<pre class="chapter-content">H2ODF.types.zipWithIndex.foreach(c=&gt; if(c._1.toInt== 2) toCategorical(H2ODF,c._2))</pre>
<p class="chapter-content">In the preceding line of code, <kbd>toCategorical()</kbd> is a user-defined function used to transform a string feature into a categorical feature. Here's the signature of the method:</p>
<pre class="chapter-content"><strong>def</strong> toCategorical(f: Frame, i: Int): Unit = {f.replace(i,f.vec(i).toCategoricalVec)f.update()}</pre>
<p class="chapter-content">Now it's time to split the dataset into 60% training, 20% validation, and 20% test datasets:</p>
<pre class="chapter-content"><strong>val</strong> sf = new FrameSplitter(H2ODF, Array(0.6, 0.2), <br/>                            Array("train.hex", "valid.hex", "test.hex")<br/>                            .map(Key.make[Frame](_)), null)<br/><br/>water.H2O.submitTask(sf)<br/><strong>val</strong> splits = sf.getResultval (train, valid, test) = (splits(0), splits(1), splits(2))</pre>
<p class="chapter-content">Then we train the deep learning model using the training set and validate the training using the validation set, as follows:</p>
<pre class="chapter-content"><strong>val</strong> dlModel = buildDLModel(train, valid)</pre>
<p class="chapter-content">In the preceding line, <kbd>buildDLModel()</kbd> is a user-defined function that sets up a deep learning model and trains it using the train and validation data frames:</p>
<pre class="chapter-content"><strong>def</strong> buildDLModel(train: Frame, valid: Frame,epochs: Int = 10, <br/>                l1: Double = 0.001,l2: Double = 0.0,<br/>                hidden: Array[Int] = Array[Int](256, 256, 256)<br/>               )(implicit h2oContext: H2OContext): <br/>     DeepLearningModel = {import h2oContext.implicits._<br/>                // Build a model<br/>    <strong>val</strong> dlParams = new DeepLearningParameters()<br/>        dlParams._train = traindlParams._valid = valid<br/>        dlParams._response_column = "y"<br/>        dlParams._epochs = epochsdlParams._l1 = l2<br/>        dlParams._hidden = hidden<br/><br/>    <strong>val</strong> dl = new DeepLearning(dlParams, water.Key.make("dlModel.hex"))<br/>    dl.trainModel.get<br/>    }</pre>
<p class="chapter-content">In this code, we have instantiated a deep learning (that is, MLP) network of three hidden layers, L1 regularization and that intended to iterate the training for only 10 times. Note that these are hyperparameters and nothing is tuned. So feel free to change this and see the performance to get a set of the most optimized parameters. Once the training phase is completed, we print the training metrics (that is, AUC):</p>
<pre class="chapter-content">val auc = dlModel.auc()println("Train AUC: "+auc)<br/>println("Train classification error" + dlModel.classification_error())<br/>&gt;&gt;&gt;<br/>Train AUC: 0.8071186909427446<br/>Train classification error: 0.13293674881631662</pre>
<p class="chapter-content">About 81% accuracy does <span>not </span>seem good. We now evaluate the model on the test set. We predict the labels of the testing dataset:</p>
<pre class="chapter-content"><strong>val</strong> result = dlModel.score(test)('predict)</pre>
<p class="mce-root">Then we add the original labels to the result:</p>
<pre class="mce-root">result.add("actual",test.vec("y"))</pre>
<p class="chapter-content">Transform the result into a Spark DataFrame and print the confusion matrix:</p>
<pre class="chapter-content">val predict_actualDF = h2oContext.asDataFrame(result)predict_actualDF.groupBy("actual","predict").count.show<br/>&gt;&gt;&gt;</pre>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="121" width="158" src="assets/82558f0e-ad15-4fa7-bdd4-36432e211d52.png"/></div>
<p class="chapter-content">Now, the preceding confusion matrix can be represented by the following plot using Vegas:</p>
<pre class="chapter-content CDPAlignLeft CDPAlign">Vegas().withDataFrame(predict_actualDF)<br/>    .mark(Bar)<br/>     .encodeY(field="*", dataType=Quantitative, AggOps.Count, axis=Axis(title="",format=".2f"),hideAxis=true)<br/>    .encodeX("actual", Ord)<br/>    .encodeColor("predict", Nominal, scale=Scale(rangeNominals=List("#FF2800", "#1C39BB")))<br/>    .configMark(stacked=StackOffset.Normalize)<br/>    .show()<br/>&gt;&gt;&gt;</pre>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="212" width="338" src="assets/c8fe633b-61e1-4663-aaca-6ec8241b7655.png"/></div>
<div class="chapter-content packt_figref CDPAlignCenter CDPAlign">Figure 4: Graphical representation of the confusion matrix—normalized (left) versus un-normalized (right)</div>
<p class="chapter-content">Now let's see the overall performance summary on the test set—that is, test AUC:</p>
<pre class="chapter-content">val trainMetrics = ModelMetricsSupport.modelMetrics[ModelMetricsBinomial](dlModel, test)println(trainMetrics)<br/>&gt;&gt;&gt;</pre>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="187" width="446" src="assets/f70bf664-ff77-4418-8449-e73fd44992dd.png"/></div>
<p class="chapter-content">So the test accuracy in terms of AUC is 76%, which is not that great. But why don't we iterate the training an additional number of times (say, 1,000 times)? Well, I leave it up to you. But still, we can visually inspect the precision-recall curve to see how the evaluation phase went:</p>
<pre><strong>val</strong> auc = trainMetrics._auc//tp,fp,tn,fn<br/><strong>val</strong> metrics = auc._tps.zip(auc._fps).zipWithIndex.map(x =&gt; x match { <br/>    <strong>case</strong> ((a, b), c) =&gt; (a, b, c) })<br/><br/><strong>val</strong> fullmetrics = metrics.map(_ match { <br/>    <strong>case</strong> (a, b, c) =&gt; (a, b, auc.tn(c), auc.fn(c)) })<br/><br/><strong>val</strong> precisions = fullmetrics.map(_ match {<br/>     <strong>case</strong> (tp, fp, tn, fn) =&gt; tp / (tp + fp) })<br/><br/><strong>val</strong> recalls = fullmetrics.map(_ match { <br/>    <strong>case</strong> (tp, fp, tn, fn) =&gt; tp / (tp + fn) })<br/><br/><strong>val</strong> rows = for (i &lt;- 0 until recalls.length) <br/>    <strong>yield</strong> r(precisions(i), recalls(i))<br/><br/><strong>val</strong> precision_recall = rows.toDF()<br/><br/>//precision vs recall<br/>Vegas("ROC", width = 800, height = 600)<br/>    .withDataFrame(precision_recall).mark(Line)<br/>    .encodeX("re-call", Quantitative)<br/>    .encodeY("precision", Quantitative)<br/>    .show()<br/>&gt;&gt;&gt;</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="554" width="740" src="assets/f0e403c2-05c7-459c-b50d-34ab5e5340fa.png"/></div>
<div class="chapter-content CDPAlignCenter CDPAlign packt_figref">Figure 5: Precision-recall curve</div>
<p>We then compute and draw the sensitivity specificity curve:</p>
<pre class="chapter-content CDPAlignLeft CDPAlign"><strong>val</strong> sensitivity = fullmetrics.map(_ match { <br/>    <strong>case</strong> (tp, fp, tn, fn) =&gt; tp / (tp + fn) })<br/><br/><strong>val</strong> specificity = fullmetrics.map(_ match {<br/>    <strong>case</strong> (tp, fp, tn, fn) =&gt; tn / (tn + fp) })<br/><strong>val</strong> rows2 = for (i &lt;- 0 until specificity.length) <br/>    <strong>yield</strong> r2(sensitivity(i), specificity(i))<br/><strong>val</strong> sensitivity_specificity = rows2.toDF<br/><br/>Vegas("sensitivity_specificity", width = 800, height = 600)<br/>    .withDataFrame(sensitivity_specificity).mark(Line)<br/>    .encodeX("specificity", Quantitative)<br/>    .encodeY("sensitivity", Quantitative).show()<br/>&gt;&gt;&gt;</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="397" width="531" src="assets/0c6c8a6a-1879-4928-af84-cd455a2b3eec.png"/></div>
<div class="chapter-content CDPAlignCenter CDPAlign packt_figref">Figure 6: Sensitivity specificity curve</div>
<p class="chapter-content CDPAlignLeft CDPAlign">Now the sensitivity specificity curve tells us the relationship between correctly predicted classes from both labels. For example, if we have 100% correctly predicted fraud cases, there will be no correctly classified non-fraud cases and vice versa. Finally, it would be great to take a closer look at this a little differently, by manually going through different prediction thresholds and calculating how many cases were correctly classified in the two classes.</p>
<p class="chapter-content CDPAlignLeft CDPAlign">More specifically, we can visually inspect true positives, false positives, true negatives, and false negatives over different prediction thresholds, say <strong>0.0</strong> to <strong>1.0</strong>:</p>
<pre class="chapter-content CDPAlignLeft CDPAlign"><strong>val</strong> withTh = auc._tps.zip(auc._fps).zipWithIndex.map(x =&gt; x match {<br/>    <strong>case</strong> ((a, b), c) =&gt; (a, b, auc.tn(c), auc.fn(c), auc._ths(c)) })<br/><br/><strong>val</strong> rows3 = for (i &lt;- 0 until withTh.length) <br/>   <strong> yield</strong> r3(withTh(i)._1, withTh(i)._2, withTh(i)._3, withTh(i)._4, withTh(i)._5)</pre>
<p class="mce-root">First, let's draw the true positive one:</p>
<pre class="chapter-content CDPAlignLeft CDPAlign">Vegas("tp", width = 800, height = 600).withDataFrame(rows3.toDF)<br/>    .mark(Line).encodeX("th", Quantitative)<br/>    .encodeY("tp", Quantitative)<br/>    .show<br/>&gt;&gt;&gt;</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="375" width="512" src="assets/651bd9cd-c73d-453f-9ee9-3b8a3cff2c1c.png"/></div>
<div class="chapter-content CDPAlignCenter CDPAlign packt_figref">Figure 7: True positives across different prediction thresholds in [0.0, 1.0]</div>
<p class="chapter-content CDPAlignLeft CDPAlign">Secondly, let's draw the false positive one:</p>
<pre class="chapter-content CDPAlignLeft CDPAlign">Vegas("fp", width = 800, height = 600)<br/>    .withDataFrame(rows3.toDF).mark(Line)<br/>    .encodeX("th", Quantitative)<br/>    .encodeY("fp", Quantitative)<br/>    .show<br/>&gt;&gt;&gt;</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="554" width="740" src="assets/92ccd496-3fee-4774-b0ef-bfd227041d9d.png"/></div>
<div class="chapter-content CDPAlignCenter CDPAlign packt_figref">Figure 8: False positives across different prediction thresholds in [0.0, 1.0]</div>
<p class="chapter-content CDPAlignLeft CDPAlign">Then, it's the turn of the true negative ones:</p>
<pre class="chapter-content CDPAlignLeft CDPAlign">Vegas("tn", width = 800, height = 600)<br/>    .withDataFrame(rows3.toDF).mark(Line)<br/>    .encodeX("th", Quantitative)<br/>    .encodeY("tn", Quantitative)<br/>    .show<br/>&gt;&gt;&gt;</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="542" width="725" src="assets/bc6a1193-63f9-428f-9637-c077bc88c951.png"/></div>
<div class="chapter-content CDPAlignCenter CDPAlign packt_figref">Figure 9: False positives across different prediction thresholds in [0.0, 1.0]</div>
<p class="chapter-content CDPAlignLeft CDPAlign">Finally, let's draw the false negative ones as follows:</p>
<pre class="chapter-content CDPAlignLeft CDPAlign">Vegas("fn", width = 800, height = 600)<br/>    .withDataFrame(rows3.toDF).mark(Line)<br/>    .encodeX("th", Quantitative)<br/>    .encodeY("fn", Quantitative)<br/>    .show<br/>&gt;&gt;&gt;</pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="536" width="736" src="assets/721dfd31-3f89-4e42-9afa-9001575bec49.png"/></div>
<div class="chapter-content CDPAlignCenter CDPAlign packt_figref">Figure 10: False positives across different prediction thresholds in [0.0, 1.0]</div>
<p class="chapter-content CDPAlignLeft CDPAlign">Therefore, the preceding plots tell us that we can increase the number of correctly classified non-fraud cases without losing correctly classified fraud cases when we increase the prediction threshold from the default <strong>0.5</strong> to <strong>0.6</strong>.</p>
<p class="chapter-content CDPAlignLeft CDPAlign">Apart from these two auxiliary methods, I have defined three Scala case classes for computing <kbd>precision</kbd>, <kbd>recall</kbd>, <kbd>sensitivity</kbd>, <kbd>specificity</kbd>, true positives (<kbd>tp</kbd>), true negatives (<kbd>tn</kbd>), false positives (<kbd>fp</kbd>), false negatives (<kbd>fn</kbd>), and so on. The signature is as follows:</p>
<pre class="chapter-content CDPAlignCenter CDPAlign CDPAlignLeft"><strong>case class</strong> r(precision: Double, recall: Double)<br/><strong>case class</strong> r2(sensitivity: Double, specificity: Double)<br/><strong>case class</strong> r3(tp: Double, fp: Double, tn: Double, fn: Double, th: Double)</pre>
<p class="chapter-content CDPAlignCenter CDPAlign CDPAlignLeft">Finally, stop the Spark session and H2O context. The <span><kbd>stop()</kbd> method invocation will shut down the H2O context and Spark cluster respectively:</span></p>
<pre><span>h2oContext.stop(stopSparkContext = true)<br/>spark.stop()</span></pre>
<p class="mce-root"/>
<p class="chapter-content CDPAlignCenter CDPAlign CDPAlignLeft"><span>The first one especially is more important; otherwise, it sometimes does not stop the H2O flow but still holds the computing resources.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hyperparameter tuning and feature selection</h1>
                </header>
            
            <article>
                
<p class="mce-root">The flexibility of neural networks is also one of their main drawbacks: there are many hyperparameters to tweak. Even in a simple MLP, you can change the number of layers, the number of neurons per layer, the type of activation function to use in each layer, the number of epochs, the learning rate, weight initialization logic, drop-out keep probability, and so on. How do you know what combination of hyperparameters is best for your task?</p>
<p class="mce-root">Of course, you can use grid search with cross-validation to find the right hyperparameters for linear machine learning models, but for deep learning models, there are many hyperparameters to tune. And since training a neural network on a large dataset takes a lot of time, you will only be able to explore a tiny part of the hyperparameter space in a reasonable amount of time. Here are some useful insights.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Number of hidden layers</h1>
                </header>
            
            <article>
                
<p class="mce-root">For many problems, you can start with one or two hidden layers and it will work just fine using two hidden layers with the same total amount of neurons, in roughly the same amount of training time. For more complex problems, you can gradually ramp up the number of hidden layers until you start overfitting the training set. Very complex tasks, such as large image classification or speech recognition, typically require networks with dozens of layers and they need a large amount of training data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Number of neurons per hidden layer</h1>
                </header>
            
            <article>
                
<p class="mce-root">Obviously, the number of neurons in the input and output layers is determined by the type of input and output your task requires. For example, if your dataset has a shape of 28 x 28, it should expect to have input neurons of size 784, and the output neurons should be equal to the number of classes to be predicted.</p>
<p class="mce-root">We have seen in this project how it works in practice in the next example using MLP, where we set 256 neurons, four each for the hidden layers; that's just one hyperparameter to tune instead of one per layer. Just like the number of layers, you can try increasing the number of neurons gradually until the network starts overfitting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Activation functions</h1>
                </header>
            
            <article>
                
<p class="mce-root">In most cases, you can use the ReLU activation function in the hidden layers. It is a bit faster to compute than other activation functions, and gradient descent does not get stuck as much on plateaus compared to the logistic function or the hyperbolic tangent function, which usually saturated at one.</p>
<p class="mce-root">For the output layer, the softmax activation function is generally a good choice for classification tasks. For regression tasks, you can simply use no activation function. Other activation functions include Sigmoid and Tanh. The current implementation of the H2O-based deep learning model supports the following activation functions:</p>
<ul>
<li>ExpRectifier</li>
<li>ExpRectifierWithDropout</li>
<li>Maxout</li>
<li>MaxoutWithDropout</li>
<li>Rectifier</li>
<li>RectifierWthDropout</li>
<li>Tanh</li>
<li>TanhWithDropout</li>
</ul>
<p class="mce-root">Apart from Tanh (the default one in H2O), I have not tried any other activation functions for this project. However, you should definitely try.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Weight and bias initialization</h1>
                </header>
            
            <article>
                
<p class="mce-root">Initializing the weight and biases for the hidden layers is an important hyperparameter to be taken care of:</p>
<ul>
<li><strong>Do not do all-zero initialization</strong>: A reasonable-sounding idea might be to set all the initial weights to zero, but it does not work in practice because if every neuron in the network computes the same output, there will be no source of asymmetry between neurons as their weights are initialized to be the same.</li>
<li><strong>Small random numbers</strong>: It is also possible to initialize the weights of the neurons to small numbers but not identically zero. Alternatively, it is also possible to use small numbers drawn from a uniform distribution.</li>
<li><strong>Initializing the biases</strong>: It is possible, and common, to initialize the biases to zero since the asymmetry breaking is provided by small random numbers in the weights. Setting the biases to a small constant value, such as 0.01 for all biases, ensures that all ReLU units can propagate a gradient. However, it neither performs well nor does consistent improvement. Therefore, sticking to zero is recommended.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Regularization</h1>
                </header>
            
            <article>
                
<p class="mce-root">There are several ways of controlling the training of neural networks to prevent overfitting in the training phase, for example, L2/L1 regularization, max-norm constraints, and dropout:</p>
<ul>
<li><strong>L2 regularization</strong>: This is probably the most common form of regularization. Using the gradient descent parameter update, L2 regularization signifies that every weight will be decayed linearly towards zero.</li>
<li><strong>L1 regularization</strong>: For each weight <em>w</em>, we add the term λ∣w∣ to the objective. However, it is also possible to combine L1 and L2 regularization <em>to achieve</em> elastic net regularization.</li>
<li><strong>Max-norm constraints</strong>: Used to enforce an absolute upper bound on the magnitude of the weight vector for each hidden layer neuron. Projected gradient descent can <span>then </span>be used further to enforce the constraint.</li>
<li><strong>Dropout</strong>: When working with a neural network, we need another placeholder for dropout, which is a hyperparameter to be tuned and the training time but not the test time. It is implemented by only keeping a neuron active with some probability, say <em>p&lt;1.0</em>, or setting it to zero otherwise. The idea is to use a single neural net at test time without dropout. The weights of this network are scaled-down versions of the trained weights. If a unit is retained with <kbd>dropout_keep_prob</kbd> <em>&lt; 1.0</em> during training, the outgoing weights of that unit are multiplied by <em>p</em> at test time (<em>Figure 17</em>).</li>
</ul>
<p>Apart from these hyperparameters, another advantage of using H2O-based deep learning algorithms is that we can take the relative variable/feature importance. In previous chapters, we saw that by using the random forest algorithm in Spark, it is also possible to compute the variable importance.</p>
<p>So, the idea is that if your model does not perform well, it would be worth dropping the less important features and doing the training again. Now, it is possible to find the feature importance during supervised training. I have observed this feature importance:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="273" width="419" src="assets/39aee4cf-5a16-4e45-80de-72b7c9e6ca4e.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Figure 25: Relative variable importance</div>
<p class="mce-root CDPAlignLeft CDPAlign">Now the question would be: why don't you drop them and try training again to see if the accuracy has increased or not? Well, I leave it up to the readers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we saw how to develop a <strong>machine learning</strong> (<strong>ML</strong>) project using H2O on a bank marketing dataset for predictive analytics. We were able to predict that the client would subscribe to a term deposit with an accuracy of 80%. Furthermore, we saw how to tune typical neural network hyperparameters. Considering the fact that this small-scale dataset, final improvement suggestion would be using Spark based Random Forest, Decision trees or gradient boosted trees for better accuracy.</p>
<p class="mce-root">In the next chapter, we will use a dataset having more than 284,807 instances of credit card use, where only 0.172% of transactions are fraudulent—that is, highly unbalanced data. So it would make sense to use autoencoders to pretrain a classification model and apply anomaly detection to predict possible fraud transaction—that is, we expect our fraud cases to be anomalies within the whole dataset.</p>


            </article>

            
        </section>
    </body></html>