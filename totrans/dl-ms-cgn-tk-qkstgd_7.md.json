["```py\ncd ch7\njupyter notebook\n```", "```py\ncheckpoint_config = CheckpointConfig('solar.dnn', frequency=100, restore=True, preserve_all=False)\n\nhistory = loss.train(\n    train_datasource, \n    epoch_size=EPOCH_SIZE,\n    parameter_learners=[learner], \n    model_inputs_to_streams=input_map,\n    callbacks=[progress_writer, test_config, checkpoint_config],\n    minibatch_size=BATCH_SIZE,\n    max_epochs=EPOCHS)\n```", "```py\nfrom cntk import ModelFormat\n\nmodel.save('solar.onnx', format=ModelFormat.ONNX)\n```", "```py\nvar deviceDescriptor = DeviceDescriptor.CPUDevice;\nvar function = Function.Load(\"model.onnx\", deviceDescriptor, ModelFormat.ONNX);\n```", "```py\npublic IList<float> Predict(float petalWidth, float petalLength, float sepalWidth, float sepalLength)\n{\n    var features = _modelFunction.Inputs[0];\n    var output = _modelFunction.Outputs[0];\n\n    var inputMapping = new Dictionary<Variable, Value>();\n    var outputMapping = new Dictionary<Variable, Value>();\n\n    var batch = Value.CreateBatch(\n        features.Shape,\n        new float[] { sepalLength, sepalWidth, petalLength, petalWidth },\n        _deviceDescriptor);\n\n    inputMapping.Add(features, batch);\n    outputMapping.Add(output, null);\n\n    _modelFunction.Evaluate(inputMapping, outputMapping, _deviceDescriptor);\n\n    var outputValues = outputMapping[output].GetDenseData<float>(output);\n    return outputValues[0];\n}\n```", "```py\npip install --upgrade azureml-sdk[notebooks]\n```", "```py\n{\n    \"workspace_name\": \"<workspace name>\",\n    \"resource_group\": \"<resource group>\",\n    \"subscription_id\": \"<your subscription id>\"\n}\n```", "```py\nfrom azureml.core import Workspace, Experiment\n\nws = Workspace.from_config()\nexperiment = Experiment(name='classify-flowers', workspace=ws)\n```", "```py\nfrom cntk import default_options, input_variable\nfrom cntk.layers import Dense, Sequential\nfrom cntk.ops import log_softmax, sigmoid\n\nmodel = Sequential([\n    Dense(4, activation=sigmoid),\n    Dense(3, activation=log_softmax)\n])\n\nfeatures = input_variable(4)\nz = model(features)\n```", "```py\nimport pandas as pd\nimport numpy as np\n\ndf_source = pd.read_csv('iris.csv', \n    names=['sepal_length', 'sepal_width','petal_length','petal_width', 'species'], \n    index_col=False)\n\nX = df_source.iloc[:, :4].values\ny = df_source['species'].values\n```", "```py\nlabel_mapping = {\n    'Iris-setosa': 0,\n    'Iris-versicolor': 1,\n    'Iris-virginica': 2\n}\n\ndef one_hot(index, length):\n    result = np.zeros(length)\n    result[index] = 1.\n\ny = [one_hot(label_mapping[v], 3) for v in y]\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, stratify=y)\n```", "```py\nfrom cntk.losses import cross_entropy_with_softmax\nfrom cntk.metrics import classification_error\nfrom cntk.learners import sgd\nfrom cntk.train.trainer import Trainer\n\nlabel = input_variable(3)\n\nloss = cross_entropy_with_softmax(z, label)\nerror_rate = classification_error(z, label)\n\nlearner = sgd(z.parameters, 0.001)\ntrainer = Trainer(z, (loss, error_rate), [learner])\n```", "```py\nimport os\nfrom cntk import ModelFormat\n\nwith experiment.start_logging() as run:\n    for _ in range(10):\n        trainer.train_minibatch({ features: X_train, label: y_train })\n\n        run.log('average_loss', trainer.previous_minibatch_loss_average)\n        run.log('average_metric', trainer.previous_minibatch_evaluation_average)\n\n    test_metric = trainer.test_minibatch( {features: X_test, label: y_test })\n```", "```py\nz.save('outputs/model.onnx') # The z variable is the trained model\nrun.upload_file('model.onnx', 'outputs/model.onnx')\n```", "```py\nstored_model = run.register_model(model_name='classify_flowers', model_path='model.onnx')\n```", "```py\nimport os\nimport json\nimport numpy as np\nfrom azureml.core.model import Model\nimport onnxruntime\n\nmodel = None\n\ndef init():\n    global model\n\n    model_path = Model.get_model_path('classify_flowers')\n    model = onnxruntime.InferenceSession(model_path)\n\ndef run(raw_data):\n    data = json.loads(raw_data)\n    data = np.array(data).astype(np.float32)\n\n    input_name = model.get_inputs()[0].name\n    output_name = model.get_outputs()[0].name\n\n    prediction = model.run([output_name], { input_name: data})\n\n    # Select the first output from the ONNX model.\n    # Then select the first row from the returned numpy array.\n    prediction = prediction[0][0]\n\n    return json.dumps({'scores': prediction.tolist() })\n```", "```py\nfrom azureml.core.image import ContainerImage\n\nimage_config = ContainerImage.image_configuration(\n    execution_script=\"score.py\", \n    runtime=\"python\", \n    conda_file=\"conda_env.yml\")\n```", "```py\nname: project_environment\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2\n\n- pip:\n    # Required packages for AzureML execution, history, and data preparation.\n\n  - azureml-defaults\n  - onnxruntime\n```", "```py\nfrom azureml.core.webservice import AciWebservice, Webservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n\nservice = Webservice.deploy_from_model(workspace=ws,\n                                       name='classify-flowers-svc',\n                                       deployment_config=aciconfig,\n                                       models=[stored_model],\n                                       image_config=image_config)\n```", "```py\npip install --upgrade requests\n```", "```py\nimport requests\nimport json\n\nservice_url = \"<service-url>\"\ndata = [[1.4, 0.2, 4.9, 3.0]]\n\nresponse = requests.post(service_url, json=data)\n\nprint(response.json())\n```", "```py\n{\"scores\": [-2.27234148979187, -2.486853837966919, -0.20609207451343536]}\n```"]