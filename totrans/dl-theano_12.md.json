["```py\nW = shared_glorot_uniform((n_visible, n_hidden), name='W')\nhbias = shared_zeros(n_hidden, name='hbias')\nvbias = shared_zeros(n_visible, name='vbias')\nparams = [W, hbias, vbias]\n\ndef sample_h_given_v(v0_sample):\n    pre_sigmoid_h1 = T.dot(v0_sample, W) + hbias\n    h1_mean = T.nnet.sigmoid(pre_sigmoid_h1)\n    h1_sample = theano_rng.binomial(size=h1_mean.shape, n=1, p=h1_mean, dtype=theano.config.floatX)\n    return [pre_sigmoid_h1, h1_mean, h1_sample]\n\ndef sample_v_given_h(h0_sample):\n    pre_sigmoid_v1 = T.dot(h0_sample, W.T) + vbias\n    v1_mean = T.nnet.sigmoid(pre_sigmoid_v1)\n    v1_sample = theano_rng.binomial(size=v1_mean.shape, n=1, p=v1_mean, dtype=theano.config.floatX)\n    return [pre_sigmoid_v1, v1_mean, v1_sample]\n\ndef gibbs_hvh(h0_sample):\n    pre_sigmoid_v1, v1_mean, v1_sample = sample_v_given_h(h0_sample)\n    pre_sigmoid_h1, h1_mean, h1_sample = sample_h_given_v(v1_sample)\n    return [pre_sigmoid_v1, v1_mean, v1_sample,\n            pre_sigmoid_h1, h1_mean, h1_sample]\n\nchain_start = persistent_chain\n(\n    [\n        pre_sigmoid_nvs,\n        nv_means,\n        nv_samples,\n        pre_sigmoid_nhs,\n        nh_means,\n        nh_samples\n    ],\n    updates\n) = theano.scan(\n    gibbs_hvh,\n    outputs_info=[None, None, None, None, None, chain_start],\n    n_steps=k,\n    name=\"gibbs_hvh\"\n)\n\nchain_end = nv_samples[-1]\n\ndef free_energy(v_sample):\n    wx_b = T.dot(v_sample, W) + hbias\n    vbias_term = T.dot(v_sample, vbias)\n    hidden_term = T.sum(T.log(1 + T.exp(wx_b)), axis=1)\n    return -hidden_term - vbias_term\n\ncost = T.mean(free_energy(x)) - T.mean(free_energy(chain_end))\n```", "```py\ndef conv_cond_concat(x, y):\n    return T.concatenate([x, y*T.ones((x.shape[0], y.shape[1], x.shape[2], x.shape[3]))], axis=1)\n\ndef discrim(X, Y, w, w2, w3, wy):\n    yb = Y.dimshuffle(0, 1, 'x', 'x')\n    X = conv_cond_concat(X, yb)\n    h = T.nnet.relu(dnn_conv(X, w, subsample=(2, 2), border_mode=(2, 2)), alpha=0.2 )\n    h = conv_cond_concat(h, yb)\n    h2 =  T.nnet.relu(batchnorm(dnn_conv(h, w2, subsample=(2, 2), border_mode=(2, 2))), alpha=0.2)\n    h2 = T.flatten(h2, 2)\n    h2 = T.concatenate([h2, Y], axis=1)\n    h3 = T.nnet.relu(batchnorm(T.dot(h2, w3)))\n    h3 = T.concatenate([h3, Y], axis=1)\n    y = T.nnet.sigmoid(T.dot(h3, wy))\n    return y\n```", "```py\ndef deconv(X, w, subsample=(1, 1), border_mode=(0, 0), conv_mode='conv'):\n    img = gpu_contiguous(T.cast(X, 'float32'))\n    kerns = gpu_contiguous(T.cast(w, 'float32'))\n    desc = GpuDnnConvDesc(border_mode=border_mode, subsample=subsample,\nconv_mode=conv_mode)(gpu_alloc_empty(img.shape[0], kerns.shape[1], img.shape[2]*subsample[0], img.shape[3]*subsample[1]).shape, kerns.shape)\n    out = gpu_alloc_empty(img.shape[0], kerns.shape[1], img.shape[2]*subsample[0], img.shape[3]*subsample[1])\n    d_img = GpuDnnConvGradI()(kerns, img, out, desc)\n    return d_img\n\ndef gen(Z, Y, w, w2, w3, wx):\n    yb = Y.dimshuffle(0, 1, 'x', 'x')\n    Z = T.concatenate([Z, Y], axis=1)\n    h = T.nnet.relu(batchnorm(T.dot(Z, w)))\n    h = T.concatenate([h, Y], axis=1)\n    h2 = T.nnet.relu(batchnorm(T.dot(h, w2)))\n    h2 = h2.reshape((h2.shape[0], ngf*2, 7, 7))\n    h2 = conv_cond_concat(h2, yb)\n    h3 = T.nnet.relu(batchnorm(deconv(h2, w3, subsample=(2, 2), border_mode=(2, 2))))\n    h3 = conv_cond_concat(h3, yb)\n    x = T.nnet.sigmoid(deconv(h3, wx, subsample=(2, 2), border_mode=(2, 2)))\n    return x\n```", "```py\nX = T.tensor4()\nZ = T.matrix()\nY = T.matrix()\n\ngX = gen(Z, Y, *gen_params)\np_real = discrim(X, Y, *discrim_params)\np_gen = discrim(gX, Y, *discrim_params)\n```", "```py\n    d_cost = T.nnet.binary_crossentropy(p_real, \t\t\t\t\t\t\t\tT.ones(p_real.shape)).mean() \\\n    \t+ T.nnet.binary_crossentropy(p_gen, T.zeros(p_gen.shape)).mean()\n    ```", "```py\n    g_cost = T.nnet.binary_crossentropy(p_gen,T.ones(p_gen.shape)).mean()\n    ```"]