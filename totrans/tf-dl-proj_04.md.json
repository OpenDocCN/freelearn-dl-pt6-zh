["```py\nimport numpy as np\nimport tensorflow as tf\nimport math\nimport warnings\nimport matplotlib.pyplot as plt\nfrom scipy.misc import imresize\nfrom random import shuffle\nfrom distutils.version import LooseVersion\n```", "```py\nclass Dataset(object):\n    def __init__(self, data, labels=None, width=28, height=28, \n                                    max_value=255, channels=3):\n        # Record image specs\n        self.IMAGE_WIDTH = width\n        self.IMAGE_HEIGHT = height\n        self.IMAGE_MAX_VALUE = float(max_value)\n        self.CHANNELS = channels\n        self.shape = len(data), self.IMAGE_WIDTH, \n                                self.IMAGE_HEIGHT, self.CHANNELS\n        if self.CHANNELS == 3:\n            self.image_mode = 'RGB'\n            self.cmap = None\n        elif self.CHANNELS == 1:\n            self.image_mode = 'L'\n            self.cmap = 'gray'\n\n        # Resize if images are of different size\n        if data.shape[1] != self.IMAGE_HEIGHT or \\\n                            data.shape[2] != self.IMAGE_WIDTH:\n            data = self.image_resize(data, \n                   self.IMAGE_HEIGHT, self.IMAGE_WIDTH)\n\n        # Store away shuffled data\n        index = list(range(len(data)))\n        shuffle(index)\n        self.data = data[index]\n\n        if len(labels) > 0:\n            # Store away shuffled labels\n            self.labels = labels[index]\n            # Enumerate unique classes\n            self.classes = np.unique(labels)\n            # Create a one hot encoding for each class\n            # based on position in self.classes\n            one_hot = dict()\n            no_classes = len(self.classes)\n            for j, i in enumerate(self.classes):\n                one_hot[i] = np.zeros(no_classes)\n                one_hot[i][j] = 1.0\n            self.one_hot = one_hot\n        else:\n            # Just keep label variables as placeholders\n            self.labels = None\n            self.classes = None\n            self.one_hot = None\n\n    def image_resize(self, dataset, newHeight, newWidth):\n        \"\"\"Resizing an image if necessary\"\"\"\n        channels = dataset.shape[3]\n        images_resized = np.zeros([0, newHeight, \n                         newWidth, channels], dtype=np.uint8)\n        for image in range(dataset.shape[0]):\n            if channels == 1:\n                temp = imresize(dataset[image][:, :, 0],\n                               [newHeight, newWidth], 'nearest')\n                temp = np.expand_dims(temp, axis=2)\n            else:\n                temp = imresize(dataset[image], \n                               [newHeight, newWidth], 'nearest')\n            images_resized = np.append(images_resized, \n                            np.expand_dims(temp, axis=0), axis=0)\n        return images_resized\n```", "```py\ndef get_batches(self, batch_size):\n    \"\"\"Pulling batches of images and their labels\"\"\"\n    current_index = 0\n    # Checking there are still batches to deliver\n    while current_index < self.shape[0]:\n        if current_index + batch_size > self.shape[0]:\n            batch_size = self.shape[0] - current_index\n        data_batch = self.data[current_index:current_index \\\n                               + batch_size]\n        if len(self.labels) > 0:\n            y_batch = np.array([self.one_hot[k] for k in \\\n            self.labels[current_index:current_index +\\\n            batch_size]])\n        else:\n            y_batch = np.array([])\n        current_index += batch_size\n        yield (data_batch / self.IMAGE_MAX_VALUE) - 0.5, y_batch\n```", "```py\nclass CGan(object):\n    def __init__(self, dataset, epochs=1, batch_size=32, \n                 z_dim=96, generator_name='generator',\n                 alpha=0.2, smooth=0.1, \n                 learning_rate=0.001, beta1=0.35):\n\n        # As a first step, checking if the \n        # system is performing for GANs\n        self.check_system()\n\n        # Setting up key parameters\n        self.generator_name = generator_name\n        self.dataset = dataset\n        self.cmap = self.dataset.cmap\n        self.image_mode = self.dataset.image_mode\n        self.epochs = epochs\n        self.batch_size = batch_size\n        self.z_dim = z_dim\n        self.alpha = alpha\n        self.smooth = smooth\n        self.learning_rate = learning_rate\n        self.beta1 = beta1\n        self.g_vars = list()\n        self.trained = False\n\n    def check_system(self):\n        \"\"\"\n        Checking system suitability for the project\n        \"\"\"\n        # Checking TensorFlow version >=1.2\n        version = tf.__version__\n        print('TensorFlow Version: %s' % version)\n\n        assert LooseVersion(version) >= LooseVersion('1.2'),\\\n        ('You are using %s, please use TensorFlow version 1.2 \\\n                                         or newer.' % version)\n\n        # Checking for a GPU\n        if not tf.test.gpu_device_name():\n            warnings.warn('No GPU found installed on the system.\\\n                           It is advised to train your GAN using\\\n                           a GPU or on AWS')\n        else:\n            print('Default GPU Device: %s' % tf.test.gpu_device_name())\n```", "```py\n    def instantiate_inputs(self, image_width, image_height,\n                           image_channels, z_dim, classes):\n        \"\"\"\n        Instantiating inputs and parameters placeholders:\n        real input, z input for generation, \n        real input labels, learning rate\n        \"\"\"\n        inputs_real = tf.placeholder(tf.float32, \n                       (None, image_width, image_height,\n                        image_channels), name='input_real')\n        inputs_z = tf.placeholder(tf.float32, \n                       (None, z_dim + classes), name='input_z')\n        labels = tf.placeholder(tf.float32, \n                        (None, image_width, image_height,\n                         classes), name='labels')\n        learning_rate = tf.placeholder(tf.float32, None)\n        return inputs_real, inputs_z, labels, learning_rate\n```", "```py\n def leaky_ReLU_activation(self, x, alpha=0.2):\n     return tf.maximum(alpha * x, x)\n\n def dropout(self, x, keep_prob=0.9):\n     return tf.nn.dropout(x, keep_prob)\n```", "```py\n    def d_conv(self, x, filters, kernel_size, strides,\n               padding='same', alpha=0.2, keep_prob=0.5,\n               train=True):\n        \"\"\"\n        Discriminant layer architecture\n        Creating a convolution, applying batch normalization,     \n        leaky rely activation and dropout\n        \"\"\"\n        x = tf.layers.conv2d(x, filters, kernel_size, \n                          strides, padding, kernel_initializer=\\\n                          tf.contrib.layers.xavier_initializer())\n        x = tf.layers.batch_normalization(x, training=train)\n        x = self.leaky_ReLU_activation(x, alpha)\n        x = self.dropout(x, keep_prob)\n        return x\n```", "```py\n    def g_reshaping(self, x, shape, alpha=0.2, \n                    keep_prob=0.5, train=True):\n        \"\"\"\n        Generator layer architecture\n        Reshaping layer, applying batch normalization, \n        leaky rely activation and dropout\n        \"\"\"\n        x = tf.reshape(x, shape)\n        x = tf.layers.batch_normalization(x, training=train)\n        x = self.leaky_ReLU_activation(x, alpha)\n        x = self.dropout(x, keep_prob)\n        return x\n\n    def g_conv_transpose(self, x, filters, kernel_size, \n                         strides, padding='same', alpha=0.2, \n                         keep_prob=0.5, train=True):\n        \"\"\"\n        Generator layer architecture\n        Transposing convolution to a new size, \n        applying batch normalization,\n        leaky rely activation and dropout\n        \"\"\"\n        x = tf.layers.conv2d_transpose(x, filters, kernel_size,\n                                       strides, padding)\n        x = tf.layers.batch_normalization(x, training=train)\n        x = self.leaky_ReLU_activation(x, alpha)\n        x = self.dropout(x, keep_prob)\n        return x\n```", "```py\n def discriminator(self, images, labels, reuse=False):\n     with tf.variable_scope('discriminator', reuse=reuse):\n         # Input layer is 28x28x3 --> concatenating input\n         x = tf.concat([images, labels], 3)\n\n         # d_conv --> expected size is 14x14x32\n         x = self.d_conv(x, filters=32, kernel_size=5,\n                         strides=2, padding='same',\n                         alpha=0.2, keep_prob=0.5)\n\n         # d_conv --> expected size is 7x7x64\n         x = self.d_conv(x, filters=64, kernel_size=5,\n                         strides=2, padding='same',\n                         alpha=0.2, keep_prob=0.5)\n\n         # d_conv --> expected size is 7x7x128\n         x = self.d_conv(x, filters=128, kernel_size=5,\n                         strides=1, padding='same',\n                         alpha=0.2, keep_prob=0.5)\n\n         # Flattening to a layer --> expected size is 4096\n         x = tf.reshape(x, (-1, 7 * 7 * 128))\n\n         # Calculating logits and sigmoids\n         logits = tf.layers.dense(x, 1)\n         sigmoids = tf.sigmoid(logits)\n\n         return sigmoids, logits\n```", "```py\n    def generator(self, z, out_channel_dim, is_train=True):\n\n        with tf.variable_scope('generator', \n                                reuse=(not is_train)):\n            # First fully connected layer\n            x = tf.layers.dense(z, 7 * 7 * 512)\n\n            # Reshape it to start the convolutional stack\n            x = self.g_reshaping(x, shape=(-1, 7, 7, 512),\n                                 alpha=0.2, keep_prob=0.5,\n                                 train=is_train)\n\n            # g_conv_transpose --> 7x7x128 now\n            x = self.g_conv_transpose(x, filters=256,\n                                      kernel_size=5,\n                                      strides=2, padding='same',\n                                      alpha=0.2, keep_prob=0.5,  \n                                      train=is_train)\n\n            # g_conv_transpose --> 14x14x64 now\n            x = self.g_conv_transpose(x, filters=128,\n                                      kernel_size=5, strides=2,\n                                      padding='same', alpha=0.2,\n                                      keep_prob=0.5,\n                                      train=is_train)\n\n            # Calculating logits and Output layer --> 28x28x5 now\n            logits = tf.layers.conv2d_transpose(x,  \n                                         filters=out_channel_dim, \n                                         kernel_size=5, \n                                         strides=1, \n                                         padding='same')\n            output = tf.tanh(logits)\n\n            return output\n```", "```py\n    def loss(self, input_real, input_z, labels, out_channel_dim):\n\n        # Generating output\n        g_output = self.generator(input_z, out_channel_dim)\n        # Classifying real input\n        d_output_real, d_logits_real = self.discriminator(input_real, labels, reuse=False)\n        # Classifying generated output\n        d_output_fake, d_logits_fake = self.discriminator(g_output, labels, reuse=True)\n        # Calculating loss of real input classification\n        real_input_labels = tf.ones_like(d_output_real) * (1 - self.smooth) # smoothed ones\n        d_loss_real = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n                                                    labels=real_input_labels))\n        # Calculating loss of generated output classification\n        fake_input_labels = tf.zeros_like(d_output_fake) # just zeros\n        d_loss_fake = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n                                                    labels=fake_input_labels))\n        # Summing the real input and generated output classification losses\n        d_loss = d_loss_real + d_loss_fake # Total loss for discriminator\n        # Calculating loss for generator: all generated images should have been\n        # classified as true by the discriminator\n        target_fake_input_labels = tf.ones_like(d_output_fake) # all ones\n        g_loss = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n                                                    labels=target_fake_input_labels))\n\n        return d_loss, g_loss\n```", "```py\n    def rescale_images(self, image_array):\n        \"\"\"\n        Scaling images in the range 0-255\n        \"\"\"\n        new_array = image_array.copy().astype(float)\n        min_value = new_array.min()\n        range_value = new_array.max() - min_value\n        new_array = ((new_array - min_value) / range_value) * 255\n        return new_array.astype(np.uint8)\n\n    def images_grid(self, images, n_cols):\n        \"\"\"\n        Arranging images in a grid suitable for plotting\n        \"\"\"\n        # Getting sizes of images and defining the grid shape\n        n_images, height, width, depth = images.shape\n        n_rows = n_images // n_cols\n        projected_images = n_rows * n_cols\n        # Scaling images to range 0-255\n        images = self.rescale_images(images)\n        # Fixing if projected images are less\n        if projected_images < n_images:\n            images = images[:projected_images]\n        # Placing images in a square arrangement\n        square_grid = images.reshape(n_rows, n_cols, \n                                     height, width, depth)\n        square_grid = square_grid.swapaxes(1, 2)\n        # Returning a image of the grid\n        if depth >= 3:\n            return square_grid.reshape(height * n_rows, \n                                       width * n_cols, depth)\n        else:\n            return square_grid.reshape(height * n_rows, \n                                       width * n_cols)\n\n    def plotting_images_grid(self, n_images, samples):\n        \"\"\"\n        Representing the images in a grid\n        \"\"\"\n        n_cols = math.floor(math.sqrt(n_images))\n        images_grid = self.images_grid(samples, n_cols)\n        plt.imshow(images_grid, cmap=self.cmap)\n        plt.show()\n\n    def show_generator_output(self, sess, n_images, input_z, \n                              labels, out_channel_dim,\n                              image_mode):\n        \"\"\"\n        Representing a sample of the \n        actual generator capabilities\n        \"\"\"\n        # Generating z input for examples\n        z_dim = input_z.get_shape().as_list()[-1]\n        example_z = np.random.uniform(-1, 1, size=[n_images, \\\n                                       z_dim - labels.shape[1]])\n        example_z = np.concatenate((example_z, labels), axis=1)\n        # Running the generator\n        sample = sess.run(\n            self.generator(input_z, out_channel_dim, False),\n            feed_dict={input_z: example_z})\n        # Plotting the sample\n        self.plotting_images_grid(n_images, sample)\n\n    def show_original_images(self, n_images):\n        \"\"\"\n        Representing a sample of original images\n        \"\"\"\n        # Sampling from available images\n        index = np.random.randint(self.dataset.shape[0], \n                                  size=(n_images))\n        sample = self.dataset.data[index]\n        # Plotting the sample\n        self.plotting_images_grid(n_images, sample)\n```", "```py\n    def optimization(self):\n        \"\"\"\n        GAN optimization procedure\n        \"\"\"\n        # Initialize the input and parameters placeholders\n        cases, image_width, image_height,\\\n        out_channel_dim = self.dataset.shape\n        input_real, input_z, labels, learn_rate = \\    \n                        self.instantiate_inputs(image_width,\n                                               image_height,\n                                            out_channel_dim, \n                                                 self.z_dim, \n                                  len(self.dataset.classes))\n\n        # Define the network and compute the loss\n        d_loss, g_loss = self.loss(input_real, input_z, \n                                    labels, out_channel_dim)\n\n        # Enumerate the trainable_variables, split into G and D parts\n        d_vars = [v for v in tf.trainable_variables() \\\n                    if v.name.startswith('discriminator')]\n        g_vars = [v for v in tf.trainable_variables() \\\n                    if v.name.startswith('generator')]\n        self.g_vars = g_vars\n\n        # Optimize firt the discriminator, then the generatvor\n        with tf.control_dependencies(\\\n                     tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            d_train_opt = tf.train.AdamOptimizer(               \n                                             self.learning_rate,\n                   self.beta1).minimize(d_loss, var_list=d_vars)\n            g_train_opt = tf.train.AdamOptimizer(\n                                             self.learning_rate,\n                   self.beta1).minimize(g_loss, var_list=g_vars)\n\n        return input_real, input_z, labels, learn_rate, \n               d_loss, g_loss, d_train_opt, g_train_opt\n```", "```py\ndef train(self, save_every_n=1000):\n    losses = []\n    step = 0\n    epoch_count = self.epochs\n    batch_size = self.batch_size\n    z_dim = self.z_dim\n    learning_rate = self.learning_rate\n    get_batches = self.dataset.get_batches\n    classes = len(self.dataset.classes)\n    data_image_mode = self.dataset.image_mode\n\n    cases, image_width, image_height,\\\n    out_channel_dim = self.dataset.shape\n    input_real, input_z, labels, learn_rate, d_loss,\\ \n    g_loss, d_train_opt, g_train_opt = self.optimization()\n\n    # Allowing saving the trained GAN\n    saver = tf.train.Saver(var_list=self.g_vars)\n\n    # Preparing mask for plotting progression\n    rows, cols = min(5, classes), 5\n    target = np.array([self.dataset.one_hot[i] \\\n             for j in range(cols) for i in range(rows)])\n\n    with tf.Session() as sess:\n       sess.run(tf.global_variables_initializer())\n       for epoch_i in range(epoch_count):\n           for batch_images, batch_labels \\\n                     in get_batches(batch_size):\n                # Counting the steps\n                step += 1\n                # Defining Z\n                batch_z = np.random.uniform(-1, 1, size=\\\n                                      (len(batch_images), z_dim))\n                batch_z = np.concatenate((batch_z,\\\n                                           batch_labels), axis=1)\n                # Reshaping labels for generator\n                batch_labels = batch_labels.reshape(batch_size, 1, 1, classes)\n                batch_labels = batch_labels * np.ones((batch_size, image_width, image_height, classes))\n                # Sampling random noise for G\n                batch_images = batch_images * 2\n                # Running optimizers\n                _ = sess.run(d_train_opt, feed_dict={input_real: batch_images, input_z: batch_z,\n                                                         labels: batch_labels, learn_rate: learning_rate})\n                _ = sess.run(g_train_opt, feed_dict={input_z: batch_z, input_real: batch_images,\n                                                         labels: batch_labels, learn_rate: learning_rate})\n\n                # Cyclic reporting on fitting and generator output\n                if step % (save_every_n//10) == 0:\n                    train_loss_d = sess.run(d_loss,\n                                                {input_z: batch_z, input_real: batch_images, labels: batch_labels})\n                    train_loss_g = g_loss.eval({input_z: batch_z, labels: batch_labels})\n                    print(\"Epoch %i/%i step %i...\" % (epoch_i + 1, epoch_count, step),\n                              \"Discriminator Loss: %0.3f...\" % train_loss_d,\n                              \"Generator Loss: %0.3f\" % train_loss_g)\n                if step % save_every_n == 0:\n                    rows = min(5, classes)\n                    cols = 5\n                    target = np.array([self.dataset.one_hot[i] for j in range(cols) for i in range(rows)])\n                    self.show_generator_output(sess, rows * cols, input_z, target, out_channel_dim, data_image_mode)\n                    saver.save(sess, './'+self.generator_name+'/generator.ckpt')\n\n            # At the end of each epoch, get the losses and print them out\n            try:\n                train_loss_d = sess.run(d_loss, {input_z: batch_z, input_real: batch_images, labels: batch_labels})\n                train_loss_g = g_loss.eval({input_z: batch_z, labels: batch_labels})\n                print(\"Epoch %i/%i step %i...\" % (epoch_i + 1, epoch_count, step),\n                         \"Discriminator Loss: %0.3f...\" % train_loss_d,\n                          \"Generator Loss: %0.3f\" % train_loss_g)\n            except:\n                train_loss_d, train_loss_g = -1, -1\n\n            # Saving losses to be reported after training\n            losses.append([train_loss_d, train_loss_g])\n\n        # Final generator output\n        self.show_generator_output(sess, rows * cols, input_z, target, out_channel_dim, data_image_mode)\n        saver.save(sess, './' + self.generator_name + '/generator.ckpt')\n\n    return np.array(losses)\n```", "```py\ndef generate_new(self, target_class=-1, rows=5, cols=5, plot=True):\n        \"\"\"\n        Generating a new sample\n        \"\"\"\n        # Fixing minimum rows and cols values\n        rows, cols = max(1, rows), max(1, cols)\n        n_images = rows * cols\n\n        # Checking if we already have a TensorFlow graph\n        if not self.trained:\n            # Operate a complete restore of the TensorFlow graph\n            tf.reset_default_graph()\n            self._session = tf.Session()\n            self._classes = len(self.dataset.classes)\n            self._input_z = tf.placeholder(tf.float32, (None, self.z_dim + self._classes), name='input_z')\n            out_channel_dim = self.dataset.shape[3]\n            # Restoring the generator graph\n            self._generator = self.generator(self._input_z, out_channel_dim)\n            g_vars = [v for v in tf.trainable_variables() if v.name.startswith('generator')]\n            saver = tf.train.Saver(var_list=g_vars)\n            print('Restoring generator graph')\n            saver.restore(self._session, tf.train.latest_checkpoint(self.generator_name))\n            # Setting trained flag as True\n            self.trained = True\n\n        # Continuing the session\n        sess = self._session\n        # Building an array of examples examples\n        target = np.zeros((n_images, self._classes))\n        for j in range(cols):\n            for i in range(rows):\n                if target_class == -1:\n                    target[j * cols + i, j] = 1.0\n                else:\n                    target[j * cols + i] = self.dataset.one_hot[target_class].tolist()\n        # Generating the random input\n        z_dim = self._input_z.get_shape().as_list()[-1]\n        example_z = np.random.uniform(-1, 1, \n                    size=[n_images, z_dim - target.shape[1]])\n        example_z = np.concatenate((example_z, target), axis=1)\n        # Generating the images\n        sample = sess.run(\n            self._generator,\n            feed_dict={self._input_z: example_z})\n        # Plotting\n        if plot:\n            if rows * cols==1:\n                if sample.shape[3] <= 1:\n                    images_grid = sample[0,:,:,0]\n                else:\n                    images_grid = sample[0]\n            else:\n                images_grid = self.images_grid(sample, cols)\n            plt.imshow(images_grid, cmap=self.cmap)\n            plt.show()\n        # Returning the sample for later usage \n        # (and not closing the session)\n        return sample\n```", "```py\n    def fit(self, learning_rate=0.0002, beta1=0.35):\n        \"\"\"\n        Fit procedure, starting training and result storage\n        \"\"\"\n        # Setting training parameters\n        self.learning_rate = learning_rate\n        self.beta1 = beta1\n        # Training generator and discriminator\n        with tf.Graph().as_default():\n            train_loss = self.train()\n        # Plotting training fitting\n        plt.plot(train_loss[:, 0], label='Discriminator')\n        plt.plot(train_loss[:, 1], label='Generator')\n        plt.title(\"Training fitting\")\n        plt.legend()\n```", "```py\nimport numpy as np\nimport urllib.request\nimport tarfile\nimport os\nimport zipfile\nimport gzip\nimport os\nfrom glob import glob\nfrom tqdm import tqdm\n```", "```py\nfrom cGAN import Dataset, CGAN\n```", "```py\nclass TqdmUpTo(tqdm):\n    \"\"\"\n    Provides `update_to(n)` which uses `tqdm.update(delta_n)`.\n    Inspired by https://github.com/pypa/twine/pull/242\n    https://github.com/pypa/twine/commit/42e55e06\n    \"\"\"\n\n    def update_to(self, b=1, bsize=1, tsize=None):\n        \"\"\"\n        Total size (in tqdm units). \n        If [default: None] remains unchanged.\n        \"\"\"\n        if tsize is not None:\n            self.total = tsize\n        # will also set self.n = b * bsize\n        self.update(b * bsize - self.n)\n```", "```py\n%matplotlib inline\n```", "```py\nlabels_filename = 'train-labels-idx1-ubyte.gz'\nimages_filename = 'train-images-idx3-ubyte.gz'\n\nurl = \"http://yann.lecun.com/exdb/mnist/\"\nwith TqdmUpTo() as t: # all optional kwargs\n    urllib.request.urlretrieve(url+images_filename,  \n                               'MNIST_'+images_filename, \n                               reporthook=t.update_to, data=None)\nwith TqdmUpTo() as t: # all optional kwargs\n    urllib.request.urlretrieve(url+labels_filename, \n                               'MNIST_'+labels_filename, \n                               reporthook=t.update_to, data=None)\n```", "```py\nlabels_path = './MNIST_train-labels-idx1-ubyte.gz'\nimages_path = './MNIST_train-images-idx3-ubyte.gz'\n\nwith gzip.open(labels_path, 'rb') as lbpath:\n        labels = np.frombuffer(lbpath.read(), \n                               dtype=np.uint8, offset=8)\n\nwith gzip.open(images_path, 'rb') as imgpath:\n        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n        offset=16).reshape(len(labels), 28, 28, 1)\n\nbatch_size = 32\nz_dim = 96\nepochs = 16\n\ndataset = Dataset(images, labels, channels=1)\ngan = CGAN(dataset, epochs, batch_size, z_dim, generator_name='mnist')\n\ngan.show_original_images(25)\ngan.fit(learning_rate = 0.0002, beta1 = 0.35)\n```", "```py\nurl = \"http://fashion-mnist.s3-website.eu-central-\\\n       1.amazonaws.com/train-images-idx3-ubyte.gz\"\nfilename = \"train-images-idx3-ubyte.gz\"\nwith TqdmUpTo() as t: # all optional kwargs\n    urllib.request.urlretrieve(url, filename, \n                               reporthook=t.update_to, data=None)\nurl = \"http://fashion-mnist.s3-website.eu-central-\\\n       1.amazonaws.com/train-labels-idx1-ubyte.gz\"\nfilename = \"train-labels-idx1-ubyte.gz\"\n_ = urllib.request.urlretrieve(url, filename)\n```", "```py\nlabels_path = './train-labels-idx1-ubyte.gz'\nimages_path = './train-images-idx3-ubyte.gz'\nlabel_names = ['t_shirt_top', 'trouser', 'pullover', \n               'dress', 'coat', 'sandal', 'shirt', \n               'sneaker', 'bag', 'ankle_boots']\n\nwith gzip.open(labels_path, 'rb') as lbpath:\n        labels = np.frombuffer(lbpath.read(), \n                               dtype=np.uint8,\n                               offset=8)\n\nwith gzip.open(images_path, 'rb') as imgpath:\n        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n        offset=16).reshape(len(labels), 28, 28, 1)\n\nbatch_size = 32\nz_dim = 96\nepochs = 64\n\ndataset = Dataset(images, labels, channels=1)\ngan = CGAN(dataset, epochs, batch_size, z_dim, generator_name='zalando')\n\ngan.show_original_images(25)\ngan.fit(learning_rate = 0.0002, beta1 = 0.35)\n```", "```py\nurl = \"http://biometrics.nist.gov/cs_links/EMNIST/gzip.zip\"\nfilename = \"gzip.zip\"\nwith TqdmUpTo() as t: # all optional kwargs\n    urllib.request.urlretrieve(url, filename,  \n                               reporthook=t.update_to, \n                               data=None)\n```", "```py\nzip_ref = zipfile.ZipFile(filename, 'r')\nzip_ref.extractall('.')\nzip_ref.close()\n```", "```py\nif os.path.isfile(filename):\n    os.remove(filename)\n```", "```py\nlabels_path = './gzip/emnist-balanced-train-labels-idx1-ubyte.gz'\nimages_path = './gzip/emnist-balanced-train-images-idx3-ubyte.gz'\nlabel_names = []\n\nwith gzip.open(labels_path, 'rb') as lbpath:\n        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n         offset=8)\n\nwith gzip.open(images_path, 'rb') as imgpath:\n        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n                  offset=16).reshape(len(labels), 28, 28, 1)\n\nbatch_size = 32\nz_dim = 96\nepochs = 32\n\ndataset = Dataset(images, labels, channels=1)\ngan = CGAN(dataset, epochs, batch_size, z_dim,  \n           generator_name='emnist')\n\ngan.show_original_images(25)\ngan.fit(learning_rate = 0.0002, beta1 = 0.35)\n```", "```py\nimport pickle\npickle.dump(gan, open('mnist.pkl', 'wb'))\n```", "```py\nfrom CGan import Dataset, CGan\nimport pickle\ngan = pickle.load(open('mnist.pkl', 'rb'))\n```", "```py\nnclass = 8\n_ = gan.generate_new(target_class=nclass, \n                     rows=1, cols=1, plot=True)\n_ = gan.generate_new(target_class=nclass, \n                     rows=5, cols=5, plot=True)\nimages = gan.generate_new(target_class=nclass,\n                     rows=10, cols=10, plot=True)\nprint(images.shape)\n```"]