- en: POS Tagging and Grammars
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the in-built tagger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing your own tagger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training your own tagger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning to write your own grammar
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing a probabilistic context-free grammar--CFG
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing a recursive CFG
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter primarily focuses on learning the following subjects using Python
    NLTK:'
  prefs: []
  type: TYPE_NORMAL
- en: Taggers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CFG
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tagging is the process of classifying the words in a given sentence using **parts
    of speech** (**POS**). Software that helps achieve this is called **tagger**.
    NLTK has support for a variety of taggers. We will go through the following taggers
    as part of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: In-built tagger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Default tagger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regular expression tagger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lookup tagger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CFG describes a set of rules that can be applied to text in a formal language
    specification to generate newer sets of text.
  prefs: []
  type: TYPE_NORMAL
- en: 'CFG in a language comprises the following things:'
  prefs: []
  type: TYPE_NORMAL
- en: Starting token
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of tokens that are terminals (ending symbols)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of tokens that are non-terminals (non-ending symbols)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rules or productions that define rewrite rules that help transform non-terminals
    to either terminals or non-terminals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the in-built tagger
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the following recipe, we use the Python NLTK library to understand more about
    the POS tagging features in a given text.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will make use of the following technologies from the Python NLTK library:'
  prefs: []
  type: TYPE_NORMAL
- en: Punkt English tokenizer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Averaged perception tagger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The datasets for these taggers can be downloaded from your NLTK distribution
    by invoking `nltk.download()` from the Python prompt.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have a working Python (Python 3.6 is preferred) installed in your
    system along with the NLTK library and all its collections for optimal experience.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open atom editor (or favorite programming editor).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new file called `Exploring.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/60ff55a2-66f9-42da-8a22-035a143c1dc6.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the program using the Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/06bf1f75-3720-4b26-925b-fb807cebef24.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s go through the program that we have just written and dig into the
    details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the first instruction in our program, which instructs the Python interpreter
    to load the module from disk to memory and make the NLTK library available for
    use in the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we are creating a variable called `simpleSentence` and
    assigning a hard coded string to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we are invoking the NLTK built-in tokenizer function `word_tokenize()`;
    it breaks a given sentence into words and returns a Python `list` datatype. Once
    the result is computed by the function, we assign it to a variable called `wordsInSentence` using
    the `=` (equal to) operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we are calling the Python built-in `print()` function,
    which displays the given data structure on the screen. In our case, we are displaying
    the list of all words that are tokenized. See the output carefully; we are displaying
    a Python `list` data structure on screen, which consists of all the strings separated
    by commas, and all the list elements are enclosed in square brackets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction we are invoking the NLTK built-in tagger `pos_tag()`, which
    takes a list of words in the `wordsInSentence` variable and identifies the POS.
    Once the identification is complete, a list of tuples. Each tuple has the tokenized
    word and the POS identifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this instruction, we are invoking the Python built-in `print()` function,
    which prints the given parameter to the screen. In our case, we can see a list
    of tuples, where each tuple consists of the original word and POS identifier.
  prefs: []
  type: TYPE_NORMAL
- en: Writing your own tagger
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following recipe, we will explore the NLTK library by writing our own
    taggers. The following types of taggers will be written:'
  prefs: []
  type: TYPE_NORMAL
- en: Default tagger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regular expression tagger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lookup tagger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have a working Python (Python 3.6 is preferred) installed in your
    system along with the NLTK library and all its collections for optimal experience.
  prefs: []
  type: TYPE_NORMAL
- en: You should also have `python-crfsuite` installed to run this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open your atom editor (or favorite programming editor).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new file called `OwnTagger.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7ead53b2-d77f-44e1-b0d6-50863789a0ba.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the File.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the program using the Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will see the following output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/eb492d87-304b-4d3e-ad8b-4587cb0af1ed.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s go through the program that we have just written to understand
    more:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the first instruction in our program; it instructs the Python interpreter
    to load the module from disk to memory and make the NLTK library available for
    use in the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'All of these instructions are defining a new Python function that takes a string
    as input and prints the words in this sentence along with the default tag on screen.
    Let''s further understand this function to see what it''s trying to do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we are defining a new Python function called `learnDefaultTagger`;
    it takes a parameter named `simpleSentence`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we are calling the `word_tokenize` function from the NLTK
    library. We are passing `simpleSentence` as the first parameter to this function.
    Once the data is computed by this function, the return value is stored in the
    `wordsInSentence` variable. Which are list of words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we are creating an object of the `DefaultTagger()` class
    from the Python `nltk` library with `NN` as the argument passed to it. This will
    initialize the tagger and assign the instance to the `tagger` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we are calling the `tag()` function of the `tagger` object,
    which takes the tokenized words from the `wordsInSentence` variable and returns
    the list of tagged words. This is saved in `posEnabledTags`. Remember that all
    the words in the sentence will be tagged as `NN` as that''s what the tagger is
    supposed to do. This is like a very basic level of tagging without knowing anything
    about POS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Here we are calling Python's built-in `print()` function to inspect the contents
    of the `posEnabledTags` variable. We can see that all the words in the sentence
    will be tagged with `NN:`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: These are the instructions to create a new function called `learnRETagger()`,
    which takes a string as input and prints the list of all tokens in the string
    with properly identified tags using the regular expression tagger as output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try to understand one instruction at a time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We are defining a new Python function named `*learnRETagger*` to take a parameter
    called *`simpleSentence`.*
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to understand the next instruction, we should learn more about Python
    lists, tuples, and regular expressions:'
  prefs: []
  type: TYPE_NORMAL
- en: A Python list is a data structure that is an ordered set of elements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Python tuple is a immutable (read-only) data structure that is an ordered
    set of elements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Python regular expressions are strings that begin with the letter `r` and follow
    the standard PCRE notation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Even though this looks big, this is a single instruction that does many things:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a variable called `customPatterns`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining a new Python list datatype with `[`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding eight elements to this list
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each element in this list is a tuple that has two items in it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first item in the tuple is a regular expression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second item in the tuple is a string
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, translating the preceding instruction into a human-readable form, we have
    added eight regular expressions to tag the words in a sentence to be any of `ADJECTIVE`,
    `ADVERB`, `NOUN`, `VERB`, `INDEFINITE-ARTICLE`, `PREPOSITION`, `NUMBER`, or `None`
    type.
  prefs: []
  type: TYPE_NORMAL
- en: We do this by identifying certain patterns in English words identifiable as
    a given POS.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding example, these are the clues we are using to tag the POS of
    English words:'
  prefs: []
  type: TYPE_NORMAL
- en: Words that end with `ing` can be called `ADJECTIVE`, for example, `running`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Words that end with `ly` can be called `ADVERB`, for example, `willingly`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Words that end with `ion` can be called `NOUN`, for example, `intimation`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Words that end with `ate` or `en` can be called `VERB`, for example, `terminate`,
    `darken`, or `lighten`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Words that end with `an` can be called `INDEFINITE-ARTICLE`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Words such as `with`, `on`, or `at` are `PREPOSITION`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Words that are like, `-123.0`, `984` can be called `NUMBER`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are tagging everything else as `None`, which is a built-in Python datatype
    used to represent nothing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we are creating an instance of the NLTK built-in regular
    expression tagger `RegexpTagger`. We are passing the list of tuples in the `customPatterns`
    variable as the first parameter to the class to initialize the object. This object
    can be referenced in future with the variable named `tagger`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Following the general process, we first try to tokenize the string in `simpleSentence`
    using the NLTK built-in `word_tokenize()` function and store the list of tokens
    in the `wordsInSentence` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we are invoking the regular expression tagger''s `tag()` function to tag
    all the words that are in the `wordsInSentence` variable. The result of this tagging
    process is stored in the `posEnabledTags` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We are calling the Python built-in `print()` function to display the contents
    of the `posEnabledTags` data structure on screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a closer look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We are defining a new function, `learnLookupTagger`, which takes a string as
    parameter into the `simpleSentence` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we are calling `UnigramTagger` from the `nltk` library.
    This is a lookup tagger that takes the Python dictionary we have created and assigned
    to the `mapping` variable. Once the object is created, it''s available in the
    `tagger` variable for future use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are tokenizing the sentence using the NLTK built-in `word_tokenize()`
    function and capturing the result in the `wordsInSentence` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the sentence is tokenized, we call the `tag()` function of the tagger
    by passing the list of tokens in the `wordsInSentence` variable. The result of
    this computation is assigned to the `posEnabledTags` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we are printing the data structure in `posEnabledTags` on
    the screen for further inspection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We are creating a variable called `testSentence` and assigning a simple English
    sentence to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We call the `learnDefaultTagger` function created in this recipe by passing
    the `testSentence` as the first argument to it. Once this function execution completes,
    we will see the sentence POS tagged:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'In this expression, we are invoking the `learnRETagger()` function with the
    same test sentence in the `testSentence` variable. The output from this function
    is a list of tags that are tagged as per the regular expressions that we have
    defined ourselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The output from this function `learnLookupTagger` is list of all tags from the
    sentence `testSentence` that are tagged using the lookup dictionary that we have
    created.
  prefs: []
  type: TYPE_NORMAL
- en: Training your own tagger
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to train our own tagger and save the trained
    model to disk so that we can use it later for further computations.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have a working Python (Python 3.6 is preferred) installed in your
    system, along with the NLTK library and all its collections for optimal experience.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open your atom editor (or favorite programming editor).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new file called `Train3.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7fdeb930-8718-49f3-af6e-f3b66f77beee.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the program using the Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e2cf88f7-b8f8-4e8e-b538-ca05208ac5f3.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s understand how the program works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'In these two instructions, we are loading the `nltk` and `pickle` modules into
    the program. The `pickle` module implements powerful serialization and de-serialization
    algorithms to handle very complex Python objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'In these instructions, we are defining a function called `sampleData()` that
    returns a Python list. Basically, we are returning four sample strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We now define a function called `buildDictionary()`; it reads one string at
    a time from the list generated by the `sampleData()` function. Each string is
    tokenized using the `nltk.word_tokenize()` function. The resultant tokens are
    added to a Python dictionary, where the dictionary key is the word in the sentence
    and the value is POS. Once a dictionary is computed, it''s returned to the caller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'In these instructions, we are defining a function called `saveMyTagger()` that
    takes two parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`tagger`: An object to the POS tagger'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fileName`: This contains the name of the file to store the `tagger` object
    in'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We first open the file in **write binary** (**wb**) mode. Then, using `pickle`
    module''s `dump()` method, we store the entire tagger in the file and call the
    `close()` function on `fileHandle`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: In these instructions, we are defining a new function called `saveMyTraining`;
    it takes a single argument called `fileName`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are building an `nltk.UnigramTagger()` object with the model as output from
    the `buildDictionary()` function (which itself is built from the sample set of
    strings that we have defined). Once the `tagger` object is created, we call the
    `saveMyTagger()` function to save it to disk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are defining a new function, `loadMyTagger()`, which takes `fileName`
    as a single argument. This function reads the file from disk and passes it to
    the `pickle.load()` function which unserializes the tagger from disk and returns
    a reference to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'In these two instructions, we are defining two variables, `sentence` and `fileName`,
    which contain a sample string that we want to analyze and the file path at which
    we want to store the POS tagger respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the instruction that actually calls the function `saveMyTraining()`
    with `myTagger.pickle` as argument. So, we are basically storing the trained tagger
    in this file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we take the `myTagger.pickle` as argument of the `loadMyTagger()`
    function, which loads the tagger from disk, deserializes it, and creates an object,
    which further gets assigned to the `myTagger` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: In this instruction, we are calling the `tag()` function of the tagger that
    we have just loaded from disk. We use it to tokenize the sample string that we
    have created.
  prefs: []
  type: TYPE_NORMAL
- en: Once the processing is done, the output is displayed on the screen.
  prefs: []
  type: TYPE_NORMAL
- en: Learning to write your own grammar
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In automata theory, CFG consists of the following things:'
  prefs: []
  type: TYPE_NORMAL
- en: A starting symbol/ token
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of symbols/ tokens that are terminals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of symbols/ tokens that are non-terminals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A rule (or production) that defines the start symbol/token and the possible
    end symbols/tokens
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The symbol/token can be anything that is specific to the language that we consider.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: In the case of the English language, *a, b, c, d, e, f, g, h, i, j, k, l, m,
    n, o, p, q, r, s, t, u, v, w, x, y, z* are symbols/tokens/alphabets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of the decimal numbering system *0, 1, 2, 3, 4, 5, 6, 7, 8, 9 *are
    symbols/tokens/alphabets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generally, rules (or productions) are written in **Backus-Naur form** (**BNF**)
    notation.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have a working Python (Python 3.6 is preferred) installed on your
    system, along with the NLTK library.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open your atom editor (or your favorite programming editor).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new file called `Grammar.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/46df3271-f331-4d11-b97e-60d2883bbf79.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the program using the Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a1901496-60f9-4ce1-99b9-19fa547116b2.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s go through the program that we have just written and dig into the
    details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We are importing the `nltk` library into the current program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction imports the `string` module into the current program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction imports the `generate` function from the `nltk.parse.generate`
    module, which helps in generating strings from the CFG that we are going to create:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'We are defining a new grammar here. The grammar can contain the following production
    rules:'
  prefs: []
  type: TYPE_NORMAL
- en: The starting symbol is `ROOT`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `ROOT` symbol can produce `WORD` symbol
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `WORD` symbol can produce `' '` (empty space); this is a dead end production
    rule
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `WORD` symbol can produce `NUMBER` symbol followed by `LETTER` symbol
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `WORD` symbol can produce `LETTER` symbol followed by `NUMBER` symbol
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These instructions further extend the production rules.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '`NUMBER` can produce terminal alphabets `0`, `1`, `2`, or `3`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These instructions further extend the production rules.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '`LETTER` can produce lowercase alphabets `a`, `b`, `c`, or `d`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's try to understand what this grammar is for. This grammar represents the
    language wherein there are words such as `0a`, `1a`, `2a`, `a1`, `a3`, and so
    on.
  prefs: []
  type: TYPE_NORMAL
- en: 'All the production rules that we have stored so far in the list variable called `productions` are
    converted to a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'We are creating a new grammar object using the `nltk.CFG.fromstring()` method,
    which takes the `grammarString` variable that we have just created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'These instructions print the first five auto generated words that are present
    in this language, which is defined with the grammar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Writing a probabilistic CFG
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Probabilistic CFG is a special type of CFG in which the sum of all the probabilities
    for the non-terminal tokens (left-hand side) should be equal to one.
  prefs: []
  type: TYPE_NORMAL
- en: Let's write a simple example to understand more.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have a working Python (Python 3.6 is preferred) installed on your
    system, along with the NLTK library.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open your atom editor (or your favorite programming editor).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new file called `PCFG.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4e881933-b935-4459-8f08-a303c6d7e4a0.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the program using the Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1720a2bb-4c3f-4c2b-9eb7-73164094b88d.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s go through the program that we have just written and dig into the
    details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction imports the `nltk` module into our program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction imports the `generate` function from the `nltk.parse.genearate`
    module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are defining the grammar for our language, which goes like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Description** | **Content** |'
  prefs: []
  type: TYPE_TB
- en: '| Starting symbol | `ROOT` |'
  prefs: []
  type: TYPE_TB
- en: '| Non-terminals | `WORD`, `P1`, `P2`, `P3`, `P4` |'
  prefs: []
  type: TYPE_TB
- en: '| Terminals | `''A''`, `''B''`, `''C''`, `''D''`, `''E''`, `''F''`, `''G''`,
    `''H''` |'
  prefs: []
  type: TYPE_TB
- en: 'Once we have identified the tokens in the grammar, let''s see what the production
    rules look like:'
  prefs: []
  type: TYPE_NORMAL
- en: There is a `ROOT` symbol, which is the starting symbol for this grammar
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a `WORD` symbol that has a probability of `1.0`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a `WORD` symbol that can produce `P1` with a probability of `0.25`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a `WORD` symbol that can produce `P1 P2` with a probability of `0.25`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a `WORD` symbol that can produce `P1 P2 P3` with a probability of `0.25`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a `WORD` symbol that can produce `P1 P2 P3 P4` with a probability of
    `0.25`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `P1` symbol can produce symbol `'A'` with a `1.0` probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `P2` symbol can produce symbol `'B'` with a `0.5` probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `P2` symbol can produce symbol `'C'` with a `0.5` probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `P3` symbol can produce symbol `'D'` with a `0.3` probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `P3` symbol can produce symbol `'E'` with a `0.3` probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `P3` symbol can produce symbol `'F'` with a `0.4` probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `P4` symbol can produce symbol `'G'` with a `0.9` probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `P4` symbol can produce symbol `'H'` with a `0.1` probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you observe carefully, the sum of all the probabilities of the non-terminal
    symbols is equal to `1.0`. This is a mandatory requirement for the PCFG.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are joining the list of all the production rules into a string called the `grammarString` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction creates a `grammar` object using the `nltk.PCFG.fromstring` method
    and taking the `grammarString` as input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction uses the Python built-in `print()` function to display the
    contents of the `grammar` object on screen. This will summarize the total number
    of tokens and production rules we have in the grammar that we have just created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'We are printing 10 strings from this grammar using the NLTK built-in function
    `generate` and then displaying them on screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Writing a recursive CFG
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recursive CFGs are a special types of CFG where the Tokens on the left-hand
    side are present on the right-hand side of a production rule.
  prefs: []
  type: TYPE_NORMAL
- en: Palindromes are the best examples of recursive CFG. We can always write a recursive
    CFG for palindromes in a given language.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand more, let''s consider a language system with alphabets 0 and
    1; so palindromes can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '11'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '1001'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '010010'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No matter in whatever direction we read these alphabets (left to right or right
    to left), we always get the same value. This is the special feature of palindromes.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will write grammar to represent these palindromes and generate
    a few palindromes using the NLTK built-in string generation libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Let's write a simple example to understand more.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have a working Python (Python 3.6 is preferred) installed on your
    system, along with the NLTK library.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open your atom editor (or your favorite programming editor).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new file called `RecursiveCFG.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7adccfc0-5c94-41b2-9caf-5a8695e28f15.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the program using the Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3237ca32-26ba-44bc-81ff-305fa771527a.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s go through the program that we have just written and dig into the
    details. We are importing the `nltk` library into our program for future use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'We are also importing the `string` library into our program for future use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'We are importing the `generate` function from the `nltk.parse.generate` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We have created a new list data structure called `productions`, where there
    are two elements. Both the elements are strings that represent the two productions
    in our CFG:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'We are retrieving the list of decimal digits as a list in the `alphabets` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the digits 0 to 9, we add more productions to our list. These are the
    production rules that define palindromes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Once all the rules are generated, we concatenate them as strings to a variable, `grammarString`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we are creating a new `grammar` object by passing the
    newly constructed `grammarString` to the NLTK built-in `nltk.CFG.fromstring` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'In this instruction, we print the grammar that we have just created by calling
    the Python built-in `print()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'We are generating five palindromes using the `generate` function of the NLTK library
    and printing the same on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
