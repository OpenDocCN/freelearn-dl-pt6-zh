["```py\nval trainData = new ClassPathResource(\"/mnist_png/training\").getFile\nval trainSplit = new FileSplit(trainData, NativeImageLoader.ALLOWED_FORMATS, randNumGen)\nval labelMaker = new ParentPathLabelGenerator(); // parent path as the image label\nval trainRR = new ImageRecordReader(height, width, channels, labelMaker)\ntrainRR.initialize(trainSplit)\nval trainIter = new RecordReaderDataSetIterator(trainRR, batchSize, 1, outputNum)\n```", "```py\nval scaler = new ImagePreProcessingScaler(0, 1)\nscaler.fit(trainIter)\ntrainIter.setPreProcessor(scaler)\n```", "```py\nval channels = 1\nval outputNum = 10\n\nval conf = new NeuralNetConfiguration.Builder()\n      .seed(seed)\n      .iterations(iterations)\n      .regularization(true)\n      .l2(0.0005)\n      .learningRate(.01)\n      .weightInit(WeightInit.XAVIER)\n      .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n      .updater(Updater.NESTEROVS)\n      .momentum(0.9)\n      .list\n      .layer(0, new ConvolutionLayer.Builder(5, 5)\n        .nIn(channels)\n        .stride(1, 1)\n        .nOut(20)\n        .activation(Activation.IDENTITY)\n        .build)\n      .layer(1, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)\n        .kernelSize(2, 2)\n        .stride(2, 2)\n        .build)\n      .layer(2, new ConvolutionLayer.Builder(5, 5)\n        .stride(1, 1)\n        .nOut(50)\n        .activation(Activation.IDENTITY)\n        .build)\n      .layer(3, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)\n        .kernelSize(2, 2)\n        .stride(2, 2)\n        .build)\n      .layer(4, new DenseLayer.Builder()\n        .activation(Activation.RELU)\n        .nOut(500)\n        .build)\n      .layer(5, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n        .nOut(outputNum)\n        .activation(Activation.SOFTMAX).build)\n      .setInputType(InputType.convolutionalFlat(28, 28, 1))\n      .backprop(true).pretrain(false).build\n```", "```py\nval model: MultiLayerNetwork = new MultiLayerNetwork(conf)\nmodel.init()\n```", "```py\nmodel.setListeners(new ScoreIterationListener(1))\nfor (i <- 0 until nEpochs) {\n    model.fit(trainIter)\n    println(\"*** Completed epoch {} ***\", i)\n    ...\n}\n```", "```py\nval sparkConf = new SparkConf\nsparkConf.setMaster(master)\n        .setAppName(\"DL4J Spark MNIST Example\")\nval sc = new JavaSparkContext(sparkConf)\n```", "```py\nval trainDataList = mutable.ArrayBuffer.empty[DataSet]\nwhile (trainIter.hasNext) {\n    trainDataList += trainIter.next\n}\n\nval paralleltrainData = sc.parallelize(trainDataList)\n```", "```py\nvar batchSizePerWorker: Int = 16\nval tm = new ParameterAveragingTrainingMaster.Builder(batchSizePerWorker)\n    .averagingFrequency(5)\n    .workerPrefetchNumBatches(2)      \n    .batchSizePerWorker(batchSizePerWorker)\n    .build\n```", "```py\nval sparkNet = new SparkDl4jMultiLayer(sc, conf, tm)\n```", "```py\nvar numEpochs: Int = 15\nvar i: Int = 0\nfor (i <- 0 until numEpochs) {\n    sparkNet.fit(paralleltrainData)\n    println(\"Completed Epoch {}\", i)\n}\n```", "```py\ntm.deleteTempFiles(sc)\n```"]