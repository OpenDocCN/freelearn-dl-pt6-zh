<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Autoencoders for CNN</h1>
                </header>
            
            <article>
                
<p> In this chapter, we will cover the following topics:</p>
<ul>
<li>Introducing to Autoencoders</li>
<li>Convolutional Autoencoder</li>
<li>Applications of Autoencoders</li>
<li>An example of compression</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introducing to autoencoders</h1>
                </header>
            
            <article>
                
<p><span>An</span> autoencoder <span>is a regular neural network, an unsupervised learning model that takes an input and produces the same input in the output layer. So, there is no associated label in the training data. Generally, an autoencoder consists of two parts:</span></p>
<ul>
<li><span>Encoder network</span></li>
<li><span>Decoder network</span></li>
</ul>
<p><span>It learns all the required features from unlabeled training data, which is known as lower dimensional feature representation. In the following figure, the input data (<em>x</em>) is passed through an encoder that produces a compressed representation of the input data. Mathematically, in the equation, </span><em>z = h(x)</em>,<em> </em><em>z</em> is a feature vector, and is usually a smaller dimension than <em>x</em>.</p>
<p>Then, we take these produced features from the input data and pass them through a decoder network to reconstruct the original data. </p>
<p>An encoder can be a fully connected neural network or a <strong>convolutional neural network</strong> (<strong>CNN</strong>). A <span>decoder also uses the same kind of network as an encoder. </span>Here, we've explained and implemented the encoder and decoder function using ConvNet:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="330" src="assets/7c90369e-7ca4-48a3-b473-30c24faaecd6.png" width="247"/></div>
<p>Loss function: <em>||x - x||<sup>2</sup></em></p>
<div class="packt_tip">In this network, the size of the input and the output layers is the same.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Convolutional autoencoder</h1>
                </header>
            
            <article>
                
<p>A convolutional autoencoder is a neural network (a special case of an unsupervised learning model) that is trained to reproduce its input image in the output layer. An image is passed through an encoder, which is a ConvNet that produces a low-dimensional representation of the image. The decoder, which is another sample ConvNet, takes this compressed image and reconstructs the original image.</p>
<p>The encoder is used to compress the data and the decoder is used to reproduce the original image. Therefore, autoencoders may be used for data, compression. Compression logic is data-specific, meaning it is learned from data rather than predefined compression algorithms such as JPEG, MP3, and so on. Other applications of autoencoders can be image denoising (producing a cleaner image from a corrupted image), dimensionality reduction, and image search:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="100" src="assets/9a8a64d7-7d61-446e-96ac-808858df19af.png" width="548"/></div>
<p>This differs from regular ConvNets or neural nets in the sense that the input size and the target size must be the same.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applications</h1>
                </header>
            
            <article>
                
<p>Autoencoders are used for dimensionality reduction, or data compression, and image denoising. Dimensionality reduction, in turn, helps in improving runtime performance and consumes less memory. An image search can become highly efficient in low-dimension spaces.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">An example of compression</h1>
                </header>
            
            <article>
                
<p class="mce-root">The Network architecture comprises of an<span> encoder network, which is a typical convolutional pyramid. Each convolutional layer is followed by a max-pooling layer; this reduces the dimensions of the layers. </span></p>
<p class="mce-root"><span>The decoder converts the input from a sparse representation to a wide reconstructed image. A schematic of the network is shown here:</span></p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="392" src="assets/6c58f5c9-4f78-423e-a375-4e94c7b5a9e3.png" width="350"/></div>
<p>The encoder layer output image size is 4 x 4 x 8 = 128. The original image size was 28 x 28 x 1 = 784, so the compressed image vector is roughly 16% of the size of the original image. </p>
<p><span> Usually, you'll see </span>transposed convolution<span> layers used to increase the width and height of the layers. They work almost exactly the same as convolutional layers but in reverse. A stride in the input layer results in a larger stride in the transposed convolution layer. For example, if you have a 3 x 3 kernel, a 3 x 3 patch in the input layer will be reduced to one unit in a convolutional layer. Comparatively, one unit in the input layer will be expanded into a 3 x 3 path in a transposed convolution layer. The TensorFlow API provides us with an easy way to create the layers: </span><kbd>tf.nn.conv2d_transpose</kbd><span>, click here, <a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose" target="_blank">https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose</a>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>We began this chapter with a short introduction to autoencoders, and we implemented the encoder and decoder function with the help of ConvNets. </p>
<p>We then moved to convolutional autoencoders and learned how they are different from regular ConvNets and neural nets.</p>
<p>We walked through the different applications of autoencoders, with an example, and saw how an autoencoder enhances the efficiency of image searches in low-dimension spaces. </p>
<p>In the next chapter, we will study object detection with CNNs and learn the difference between object detection and object classification.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    </body></html>