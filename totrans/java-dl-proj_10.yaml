- en: Developing Movie Recommendation Systems Using Factorization Machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Factorization machines** (**FM**) are a set of algorithms that enhance the
    performance of linear models by incorporating second-order feature interactions
    that are absent in **matrix factorization** (**MF**) algorithms in a supervised
    way. Therefore, FMs are very robust compared to their classical counterpart—**collaborative
    filtering** (**CF**)—and are gaining popularity in personalization and recommendation
    systems because they can be used to discover latent features underlying the interactions
    between two different kinds of entities.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will develop a sample project for predicting both the rating
    and ranking to show their effectiveness. Nevertheless, we will see some theoretical
    background of recommendation systems using MF and CF before diving into the project''s
    implementation using RankSys library-based FMs. In summary, the following topics
    will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix factorization and the collaborative filtering approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing FM-based move recommendation systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequently asked questions (FAQs).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendation systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recommender techniques are nothing but information agents that try to predict
    items that users may be interested in and recommend the best ones to the target
    user. These techniques can be classified based on the information sources they
    use. For example, user features (age, gender, income, and location), item features
    (keywords, and genres), user-item ratings (explicit ratings, and transaction data),
    and other information about the user and item that are useful for the process
    of recommendation.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, a recommendation system; otherwise known as a **recommendation engine**
    (**RE**) is a subclass of information filtering systems that help to predict the
    rating or preference based on the rating provided by users to an item. In recent
    years, recommendation systems have become increasingly popular.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a couple of ways to develop REs to produce a list of recommendations,
    for example, collaborative and content-based filtering, knowledge-based, or the
    personality-based approach.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By using CF approaches, an RE can be built based on a user''s past behavior.
    Numerical ratings are given on consumed items. Sometimes, it can be based on the
    decisions made by other users who also have purchased the same items using some
    widely used data mining algorithms such as Apriori or FP-growth. In the following
    diagram, you can get some idea of the different recommendation systems:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/941dcf58-8778-4aa2-bb6d-caaf171215e3.png)'
  prefs: []
  type: TYPE_IMG
- en: A comparative view of different recommendation systems
  prefs: []
  type: TYPE_NORMAL
- en: 'Even though these are successful recommendation systems, CF-based approaches
    often suffer from the following three problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cold start:** Sometimes, they can become stuck when a large amount of data
    about users is required to make a more accurate recommendation system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability:** A large amount of computation power is often necessary to
    calculate recommendations using a dataset with millions of users and products.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sparsity:** This often happens with crowdsourced datasets when a huge number
    of items are sold on major e-commerce sites. All recommendation datasets are crowd-sourced
    in some sense. This is a general problem for almost all recommendation systems
    that have a sufficiently large number of items to offer to a sufficiently large
    number of users and need not be confined to e-commerce sites only.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this case, active users may rate only a small subset of the whole items sold,
    so even the most popular items have very few ratings. Accordingly, the user versus
    items matrix becomes very sparse. In other words, handling a large-scale sparse
    matrix is computationally very challenging.
  prefs: []
  type: TYPE_NORMAL
- en: To overcome these issues, a particular type of collaborative filtering algorithm
    uses matrix factorization, which is a low-rank matrix approximation technique.
    We will see an example of this later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Content-based filtering approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With content-based filtering approaches, a series of discrete characteristics
    of an item are utilized to recommend additional items with similar properties.
    Sometimes, it is based on a description of the item and a profile of the user's
    preferences. These approaches try to recommend items that are similar to those
    that a user liked in the past, or that are currently being used.
  prefs: []
  type: TYPE_NORMAL
- en: A key issue with content-based filtering is whether the system is able to learn
    user preferences from their actions regarding one content source and use them
    with other content types. When this type of RE is deployed, it can then be used
    to predict items or ratings for items that the user may have an interest in.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid recommender systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you have seen, there are several pros and cons of using collaborative filtering
    and content-based filtering approaches. Therefore, to overcome the limitations
    of these two approaches, recent trends have shown that a hybrid approach can be
    more effective and accurate. Sometimes, factorization approaches such as FM and
    **Singular Value Decomposition** (**SVD**) are used to make them robust.
  prefs: []
  type: TYPE_NORMAL
- en: Model-based collaborative filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Collaborative filtering methods are classified as memory-based, such as the
    user-based algorithm and model-based collaborative filtering (kernel mapping is
    recommended). In the model-based collaborative filtering technique, users and
    products are described by a small set of factors, also called **latent factors**
    (**LFs**). The LFs are then used to predict the missing entries. The **Alternating
    Least Squares** (**ALS**) algorithm is used to learn these latent factors.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to a memory-based approach, a model-based approach can handle the sparsity
    of the original matrix better. This is also scalable, faster, and can avoid overfitting
    issues. However, it is not flexible and adaptable because it is difficult to add
    data to the model. Now, let's take a look at an important element in the collaborative
    filtering approach, called the utility matrix.
  prefs: []
  type: TYPE_NORMAL
- en: The utility matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a collaborative filtering-based recommendation system, there are dimensions
    of entities: users and items (items refers to products, such as movies, games,
    and songs). As a user, you might have preferences for certain items. Therefore,
    these preferences must be motivated out of the data about items, users, or ratings.
    This data is often represented as a utility matrix, such as a user-item pair.
    This type of value can represent what is known about the degree of preference
    that the user has for a particular item.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows an example utility matrix that represents the rating
    users have given to movies on a 1-5 scale, with 5 being the highest rating. **HP1**,
    **HP2**, and **HP3** are acronyms for *Harry Potter I*, *II*, and *III*, **TW**
    stands for *Twilight*, and **SW1**, **SW2**, and **SW3** ;stands for *Star Wars
    episodes 1*, 2, and 3\. The letters **A**, **B**, **C**, and **D** represent the
    users:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a0963aa4-7115-4b60-834f-de08bdee83dc.png)'
  prefs: []
  type: TYPE_IMG
- en: Utility matrix (user versus movies matrix)
  prefs: []
  type: TYPE_NORMAL
- en: There are many blank entries for the user-movie pairs. This means that users
    have not rated those movies, which increases sparsity. Using this matrix, the
    goal is to predict the blanks in the utility matrix. Suppose we are curious to
    know whether user **A** would like **SW2**. This is difficult to predict since
    there is not much data in the matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, other properties regarding movies, such as the producer, director,
    leading actors, or even the similarity of their names, can be used to compute
    the similarity of the movies **SW1** and **SW2**. This similarity would drive
    us to conclude that since **A** did not like **SW1**, they are unlikely to enjoy
    **SW2** either.
  prefs: []
  type: TYPE_NORMAL
- en: However, this might not work for a larger dataset. Therefore, with much more
    data, we might observe that the people who rated both **SW1** and **SW2** were
    inclined to give them similar ratings. Finally, we can conclude that A would also
    give **SW2** a low rating, similar to **A**'s rating of **SW1**. This approach,
    however, has a serious drawback called the ;**cold-start problem**.
  prefs: []
  type: TYPE_NORMAL
- en: The cold-start problem in collaborative-filtering approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The term cold-start problem sounds funny, but, as the name implies, it derives
    from cars. In recommendation engines, however, the term cold-start simply means
    a circumstance that is not yet optimal for the engine to provide the best possible
    results.
  prefs: []
  type: TYPE_NORMAL
- en: In collaborative filtering approaches, the recommender system would identify
    users who share preferences with the active user and propose items that like-minded
    users have favored. Due to the cold-start problem, this approach would fail to
    consider items that no-one in the community has rated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recommendation engines using CF-based approaches recommend each item based
    on user actions. The more user actions an item has, the easier it is to tell which
    user would be interested in it and what other items are similar to it. As time
    progresses, the system will be able to give more and more accurate recommendations.
    At a certain stage, when new items or users are added to the user-item matrix,
    the following problem occurs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/09ebe6c2-f70c-4fbc-b0a0-1392572ad78f.png)'
  prefs: []
  type: TYPE_IMG
- en: Users versus items matrices sometimes lead to the cold-start problem
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the RE does not have enough knowledge about this new user or this
    new item yet. The content-based filtering approach, similar to FM, is a method
    that can be incorporated to alleviate the cold-start problem.
  prefs: []
  type: TYPE_NORMAL
- en: Factorization machines in recommender systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In real life, most recommendation problems assume that we have a rating dataset
    formed by a collection of (user, item, and rating) tuples. However, in many applications,
    we have plenty of item metadata (tags, categories, and genres) that can be used
    to make better predictions.
  prefs: []
  type: TYPE_NORMAL
- en: This is one of the benefits of using FMs with feature-rich datasets, because
    there is a natural way in which extra features can be included in the model, and
    higher-order interactions can be modeled using the dimensionality parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'A few recent types of research show which feature-rich datasets give better
    predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: Xiangnan He and Tat-Seng Chua, *Neural Factorization Machines for Sparse Predictive
    Analytics*. During proceedings of SIGIR '17, Shinjuku, Tokyo, Japan, August 07-11,
    2017
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jun Xiao, Hao Ye, Xiangnan He, Hanwang Zhang, Fei Wu and Tat-Seng Chua (2017).
    *Attentional Factorization Machines: Learning the Weight of Feature Interactions
    via Attention Networks* IJCAI, Melbourne, Australia, August 19-25, 2017'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These papers explain how to make existing data into a feature-rich dataset and
    how FMs were implemented on the dataset. Therefore, researchers are trying to
    use FMs to develop more accurate and robust REs. In the next section, we will
    start developing our project for movie recommendations using FMs. For that, we
    will be using Apache Spark and RankSys libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Existing recommendation algorithms require a consumption (product) or rating
    (movie) dataset in *(user, item, rating)* tuples. These types of dataset are mostly
    used by variations of CF algorithms. CF algorithms have been widely adopted and
    have proven to yield good results.
  prefs: []
  type: TYPE_NORMAL
- en: However, in many instances, we have plenty of item metadata (tags, categories,
    and genres) that can be used to make better predictions as well. Unfortunately,
    CF algorithms do not use these types of metadata.
  prefs: []
  type: TYPE_NORMAL
- en: 'FMs can make use of these feature-rich (meta) datasets. An FM can consume these
    extra features to model higher-order interactions specifying the dimensionality
    parameter *d*. Most importantly, FMs are also optimized for handling large-scale
    sparse datasets. Therefore, a second order FM model would suffice because there
    is not enough information to estimate interactions that are more complex:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0bbeea54-1a2c-47f3-b5ef-9fb02d82ad45.png)'
  prefs: []
  type: TYPE_IMG
- en: An example training dataset representing a personalization problem with the
    feature vectors x and the target y. Here, rows refer to movies, while columns
    include director, actor and genre info, and so on
  prefs: []
  type: TYPE_NORMAL
- en: Let's assume that the dataset of a prediction problem is described by a design
    matrix *X* ∈ℝ*^n*^(x*p*),. In the preceding diagram, the *i^(th)* row, x*[i]*∈ℝ*^(p
    ;)*of *X*, describes one case with *p* real-valued variables and where *y[i]*
    is the prediction target of the *i*^(th) case. Alternatively, we can describe
    this set as a set *S* of tuples *(x,y)*, where (again) *x* ∈ ℝ*^p* is a feature
    vector and *y* is its corresponding target or label.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, in figure 7, every row represents a feature vector *x[i]* with
    its corresponding target *y[i]*. For easier interpretation, the features are grouped
    into indicators for the active user (blue), the active item (red), other movies
    rated by the same user (orange), the time in months (green), and the last movie
    rated (brown).
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, the FM algorithm models all the nested interactions (up to order d*)*
    between *p* input variables in *x* using the following factorized interaction
    parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c81dc120-f418-47ad-bc34-ac5df6ece7bc.png)'
  prefs: []
  type: TYPE_IMG
- en: In this equation, the *vs* represent *k*-dimensional latent vectors associated
    with each variable (the users and the items), and the bracket operator represents
    the inner product. This kind of representation with data matrices and feature
    vectors is common in many machine learning approaches, for example, in linear
    regression or support vector machines (SVM).
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if you are familiar with the MF models, the preceding equation should
    look familiar: it contains a global bias as well as user/item-specific biases
    and includes user-item interactions. Now, if we assume that each *x(j)* vector
    is only non-zero at positions *u* and *i*, we get the classic MF model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1cc28cd9-dfb1-47b0-ae12-0c30b2d6f31d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Nevertheless, FMs can also be used for classification or regression and are
    much more computationally efficient on large, sparse datasets than traditional
    algorithms like linear regression. This property is why FM is widely used for
    recommendation: user count and item count are typically very large although the
    actual number of recommendations is very small (users do not rate all available
    items!).'
  prefs: []
  type: TYPE_NORMAL
- en: Developing a movie recommender system using FMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this project, we will show you how to do ranking prediction from the MovieLens
    1m dataset. First, we will prepare the dataset. Then, we will train the FM algorithm,
    which eventually predicts the rankings and ratings for movies. The project code
    has the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a6c66d50-7932-41f9-bfbf-5ed054c9579f.png)'
  prefs: []
  type: TYPE_IMG
- en: Movie rating and ranking prediction project structure
  prefs: []
  type: TYPE_NORMAL
- en: 'In summary, the project has the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '**EDA:** This package is used to do an exploratory analysis of the MovieLens
    1M dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tools, FMCore, and DataUtils:** These are the core FM libraries. For the
    purpose of this probject, I used (but extended) the `RankSys` library (see the
    `GitHub` repository at [https://github.com/RankSys/RankSys](https://github.com/RankSys/RankSys)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Preprocessing:** This package is used to convert the `MovieLens` 1M dataset
    into LibFM format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prediction:** This package is used for the movie rating and ranking prediction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GraphUtil:** This package visualizes some performance metrics over iteration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will go through all of these packages step by step. Nevertheless, knowing
    the dataset is a mandate.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset description and exploratory analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The MovieLens 1M small dataset was downloaded (and used with necessary permission)
    from the MovieLens website at [https://grouplens.org/datasets/movielens/](https://grouplens.org/datasets/movielens/).
    I sincerely acknowledge and thank F. Maxwell Harper and Joseph A. Konstan for
    making the datasets available for use. The dataset was published in *MovieLens
    Dataset: History and Context*. ACM Transactions on Interactive Intelligent Systems
    (TiiS) 5, 4, Article 19 (December 2015), 19 pages.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three files in the dataset: `movies.dat`, `ratings.dat`, and `users.dat`,
    which are related to movies, ratings, and users, respectively. These files contain
    1,000,209 anonymous ratings of approximately 3,900 movies made by 6,040 MovieLens
    users who joined MovieLens in 2000\. All of the ratings are contained in the `ratings.dat`
    file and are in the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The description is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`UserID`: This ranges between 1 and 6,040'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MovieID`: This ranges between 1 and 3,952'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Rating`: These are made on a 5-star scale'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Timestamp`: This is represented in seconds'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note that each user has rated at least 20 movies. Movie information, on the
    other hand, is in the `movies.dat` file and is in the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The description is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Title`: These are identical to titles provided by IMDb (with the release year)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Genres`: These are comma-separated (,), and each movie is categorized as action,
    adventure, animation, children''s, comedy, crime, drama, war, documentary, fantasy,
    film-noir, horror, musical, mystery, romance, sci-fi, thriller, and western'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, user information is in the `users.dat` file and is in the following
    format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'All demographic information is provided voluntarily by the users and is not
    checked for accuracy. Only users who have provided some demographic information
    are included in this dataset. An M for male and F for female denote gender. Age
    is chosen from the following ranges:'
  prefs: []
  type: TYPE_NORMAL
- en: '1: Under 18'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '18: 18-24'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '25: 25-34'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '35: 35-44'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '45: 45-49'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '50: 50-55'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '56: 56+'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Occupation is chosen from the following choices:'
  prefs: []
  type: TYPE_NORMAL
- en: '0: Other, or not specified'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '1: Academic/educator'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '2: Artist'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '3: Clerical/admin'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '4: College/grad student'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '5: Customer service'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '6: Doctor/healthcare'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '7: Executive/managerial'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '8: Farmer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '9: Homemaker'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '10: K-12 student'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '11: Lawyer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '12: Programmer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '13: Retired'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '14: Sales/marketing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '15: Scientist'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '16: Self-employed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '17: Technician/engineer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '18: Tradesman/craftsman'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '19: Unemployed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '20: Writer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that we know the dataset, we can play with the datasets toward exploratory
    analysis. First, we will create a Spark session as the gateway to the Spark program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will load and parse the `rating.dat` file to do some exploratory analysis.
    The following lines of code should return the DataFrame rating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9aea1ec0-6fe1-45bf-8814-da645acbe6da.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we will load the `movies.dat` and prepare the movies DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8f533e03-9994-428f-b125-bc49b54234ef.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, we will register both DataFrames as temporary tables to make querying
    easier. To register both Datasets, the following lines of code need to be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that this will help to make in-memory querying faster by creating a temporary
    view as a table in-memory. Then, we will opt to explore some rating and movie-related
    statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's get the maximum and minimum ratings along with the count of users
    who have rated a movie. However, you need to perform a SQL query on the rating
    table we just created in-memory in the previous step. Making a query here is simple,
    and it is similar to making a query from a MySQL database or RDBMS.
  prefs: []
  type: TYPE_NORMAL
- en: However, if you are not familiar with SQL-based queries, you are suggested to
    look at the SQL query specification to find out how to perform a selection using
    `SELECT` from a particular table, how to perform the ordering using `ORDER`, and
    how to perform a joining operation using the `JOIN` keyword.
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, if you know the SQL query, you should get a new dataset by using a complex
    SQL query as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4bc62580-9bc3-4f30-846b-b540e7625346.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, to get an insight, we need to know more about the users and their ratings.
    Let''s find the top 10 most active users and how many times they have rated a
    movie:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5cbda7d6-4e4c-41d8-9dae-4d925e40931c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, let''s have a look at a particular user and find the movies that,
    say, user 668, rated higher than 4:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cbdb75b4-cb1c-493d-ac42-d3425b5250ae.png)'
  prefs: []
  type: TYPE_IMG
- en: Movie rating prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we perform the rating prediction using FM algorithms that learn using
    `PointWiseGradientDescent`. We start with preprocessing and converting data into
    the LibFM format. To run this rating prediction using the following order of execution:'
  prefs: []
  type: TYPE_NORMAL
- en: First, execute `MovieLensFormaterWithMetaData.java` ;to generate the `MovieLens`
    data in the `LibFM` format.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, execute `SplitDataWithMetaData.java` to prepare the training, test, and
    validation sets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, execute ;`MovieRatingPrediction.java`, which is the main class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Converting the dataset into LibFM format
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The FM-based model that we are going to reuse can consume the training data
    only in LibFM format, which is more or less the same as LibSVM. Therefore, first,
    we must format the MovieLens 1M dataset sp that the training dataset contains
    both users, movies, and existing rating information.
  prefs: []
  type: TYPE_NORMAL
- en: The LibFM format is similar to the LibSVM format but has some basic differences.
    For more information, interested readers can take a look at [http://www.libfm.org/libfm-1.42.manual.pdf](http://www.libfm.org/libfm-1.42.manual.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: 'At the same time, new features will be generated by the user information and
    movie information. First, we will define the input (this will be updated according
    to users, movies, and ratings) and output file path as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we define the data path and the output folder, where the generated data
    in LibFM format will be saved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we define the target column, which is to be predicted by the FM model.
    Additionally, we also delete the timestamp column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we set the separator as `::` and offset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we read and parse the user''s data (that is, `users.dat`) and create
    three `Map<Integer, String>` for the user''s genre, the user''s age, and the user''s
    occupation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we parse the movie dataset to create a `Map<Integer, String>` for movies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we parse the rating dataset to create a `Map<Integer, String>` for existing
    ratings. Additionally, we define the output filename where the rating data in
    the LibFM format will be saved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we start adding attributes such as gender information, age, occupation,
    and movie class information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'In the previous code block, `:1` ;stands for which movie the user has provided
    a rating for. Finally, we add the metadata information, `userid` and `movieid`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the resulting rating dataset (once `MovieLensFormaterWithMetaData.java`
    is executed) in LibFM format will be saved in the `formatted_data` directory as
    `ratings.libfm` ;having the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/260b022e-5277-4ad9-ba90-c0104a8266db.png)'
  prefs: []
  type: TYPE_IMG
- en: Training and test set preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have seen how to convert rating, movie, and metadata, we can now
    start creating training, test, and validation sets from the data in LibFM format.
    First, we set the path of the LibFM files to be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we show the output directory to write the split training, validation,
    and test sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we instantiate the `BufferedWriter` that is going to be used for writing
    the split files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we close the file pointers to release the resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the resulting rating datasets (once `SplitDataWithMetaData.java` is executed)
    in LibFM format will be saved in the `formatted_data` directory having the following
    LibFM (similar to LibSVM) format:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/36100945-4ad5-4e4b-b091-e80013f3884c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, the directory (that is, `formatted_data`) will have the following
    files in it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/11798569-110f-47d7-80ab-8e97f2a8aa58.png)'
  prefs: []
  type: TYPE_IMG
- en: Fantastic! Now that our dataset is ready, we can now start making the movie
    rating prediction using the FM algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Movie rating prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that all of the datasets required for training, validating, and evaluating
    are ready, we can start training the FM model. We first start by showing the filename
    for the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we set the testing data file path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we set the testing metadata file path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the filename for the final prediction output file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we set up the path for writing the logs, metrics, time, and so on for
    each iteration to a file (but don''t worry, we will see them in graph form, too):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we set up the dimension of k0, k1, and k2 so that k0 is use bias, k1
    is the use of one-way interactions, and k2 is the dim of two-way interactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We will iterate the training for 100 times the number of iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We then set the learning rate for SGD—the rate at which the optimizer tries
    to minimize the error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Now that the optimizer knows the learning rate, the next important parameter
    is setting up the regularization parameters to regularize the training against
    overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Java-based FM library needs three-way regularization: bias, one-way, and
    two-way regularization. Therefore, the format accepted by the FM library is r0,
    r1, r2\. Here, r0 is bias regularization, r1 is one-way regularization, and r2
    is two-way regularization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we initialize the standard deviations for the initialization of two-way
    factors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we use the ;`LibSVMDataProvider()` class for loading both training and
    test sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'One the training and test sets are loaded, we start creating the user-item
    table (that is, the main table):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we instantiate the factorization machine before we start the training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the `init()` method is used for initializing the parameters needed for
    instantiating and training the following FM model''s parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The signature of the `init()` method goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we set the number of attributes and standard deviations from the main
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we set the number of dimensions in the factorization. In our case, we
    have 3-way interaction—user, movie, and rating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The preceding values are actually parsed using the `getIntegerValues()` method,
    which accepts the dimension as a string and split using `,`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, it returns only integer values for the dimension to be used by the
    model for making interactions. The following signature is used for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we set up the learning method as **Stochastic Gradient Descent** (**SGD**):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we define the task to be performed. In our case, it is regression. However,
    we are going to use ;`TASK_CLASSIFICATION` for classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we set the regularization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, when it comes to the learning rate, we have to set the learning rates
    (individual, per layer) unlike the DL4J library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding values are actually parsed using the `getDoubleValues()` method,
    which accepts the learning rate as a string and split using `,`. Finally, it returns
    only a single value for the learning rate to be used by the model. The following
    signature is used for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that all the hyperparameters are set, we are ready to start the training.
    For this, unlike DL4J FM, it comes with a ;`learn()` method for learning the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The `learn()` method is an abstract method that takes both train and test sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The concrete implementation of the ;`learn()` method takes both the training
    and test sets. Then, it shuffles the training set to avoid the bias in training.
    Then, it performs the prediction operation using the ;`predict()` method for the
    task type we defined at the beginning (that is, regression in our case).
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, it evaluates the model on the test set and computes the MSE for both
    the training and test set. The actual implementation of this method goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, the FM model performs the prediction operation,
    similar to any other regression algorithm, by considering three-way interaction
    and so on and computing the prediction as a probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Nevertheless, at the end, the training and test MSE per iteration is visualized
    using the `plot()` method from the `PlotUtil_Rating` class. We'll discuss this
    class later on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, we also initialize the logging so that the result and progress
    of the computations are printed on the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we evaluate the model on the test set. Since our task is a regression
    task, we compute the regression metric, such as RMSE, for each iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we save the prediction and all associated metrics in a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code block will generate two files called ;`predict_output.txt`
    and `metrics_logs.txt` for writing predicted results and logs, respectively. For
    example, a sample from the `predicted_output.txt` file shows that the second column
    is the movie ID and the third column is the predicted rating out of 5.0, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, `metrics_logs.txt` shows metrics such as RMSE, MAE, logs,
    as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1133cb50-c9fd-41d2-9223-a7f4e5cd5a08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Nevertheless, since making some sense of the training status and prediction,
    it is difficult just seeing these values, therefore, I decided to plot them. The
    following graph shows the MSE for both the training and testing phase for each
    iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7f56c119-7126-4ba2-8020-792ced3044aa.png)'
  prefs: []
  type: TYPE_IMG
- en: Training and test MSE per iteration (for 100 iterations)
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding graph shows that both training and test errors are consistent,
    which means the FM model was not overfitted. This graph also shows that the error
    count is still very high. Then, I iterated the training 1,000 times and found
    that errors had been reduced slightly, which is reported in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c151fd9e-375d-4f6d-8405-c803b312bbb5.png)'
  prefs: []
  type: TYPE_IMG
- en: Training and test MSE per iteration for up to 1,000 iterations
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, to plot the preceding graph, I wrote a ;`plot()` method in the `PlotUtil_Rating.java`
    class that uses the ;`JFreeChart` library for plotting the training and test error/iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Whereas the `addSeries()` method from the `XYSeries` class adds the series
    for the plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Which one makes more sense ;– ranking or rating?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Is a rating or ranking prediction more logical while developing a movie recommendation
    system? If the amount of ratings per user is high enough, factorizing the user-product
    matrix is the best thing, in my opinion. However, if the dataset is too sparse,
    the prediction can be extremely inaccurate.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing this fact, I was exploring the RankSys library and found that one of
    the contributors is arguing that ranking is more logical. He did not provide any
    explanation, though. Later on, I talked to some recommender system developers
    and researchers and got to know that he probably meant ranking is less sensitive
    to the prediction error due to the gap between a number of ratings and items.
    The reason is that ranking preserves the hierarchy, independent of the absolute
    rating.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on this understanding, later on, I decided to go one step further toward
    ranking prediction. For this, I wrote a spate class called `RankingPrediction.java`
    for predicting movie ranking by each user in the test set, which has the following
    structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/31a53fdf-8eae-44d1-845a-c9ffd79f05f8.png)'
  prefs: []
  type: TYPE_IMG
- en: Movie ranking prediction subproject structure
  prefs: []
  type: TYPE_NORMAL
- en: 'This has three methods, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`createIndexFromFile()`: This method is used for the creation of indexes from
    files that are passing as an argument in the method parameters itself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generateTrainAndTestDataSet()`: This is used for separating data into training
    and testing sets, which is an important part of evaluating data mining models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`main()`: This is used for the creation of indexes, both for items and users,
    and is used for the following operations:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Index for a set of users
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Index for a set of items
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Stores the preferences/rating for users and items provided by `FastUserIndex`
    and `FastItemIndex`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Creates a recommender interface that will be used by `FMRecommender`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Uses a factorization machine that uses `RMSE-like loss` with a balanced sampling
    of negative instances
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'First, we set the path of the input data files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we set the path for the user and movie indexes stated previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we set the path for the resultant file, where the training and test set
    will be generated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create the user index for all the users in the `users.dat` file. Here,
    the users are internally represented with numerical indices from 0 (inclusive)
    to the number of indexed users (exclusive):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding line of code, we used the `SimpleFastUserIndex` class from
    the RankSys library that helped in creating a simple implementation of `FastUserIndex`
    backed by a bi-map called ;`IdxIndex`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we create the item index for all of the items in the `movies.dat` file.
    This creates the index for a set of items. Here, the items are internally represented
    with numerical indices from 0 (inclusive) to the number of indexed items (exclusive):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding line of code, we used the `SimpleFastItemIndex` class from
    the RankSys library, which helps us create a simple implementation of `FastItemIndex`
    backed by a bi-map called ;`IdxIndex`. Then, we store the preferences/rating for
    users and items provided by `FastUserIndex` and `FastItemIndex`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we invoke these two methods for creating user and item indexes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding if statements, we generated indexes from file using the `createIndexFromFile()`
    method that goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the index files are generated, we then start generating the training and
    test sets as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'In this code block, we used the ;`generateTrainAndTestDataSet()` method for
    generating both training and test sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding method divides up 2/3 as the training set and 1/3 as the test
    set. Finally, the file pointers are closed to release the resources. If the preceding
    three if statements executed successfully, you should see that two index files
    and two other files for the training and test sets have been generated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f570978c-1cf1-4616-a08b-e0e0228224a3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, we create a recommender interface, which will be used by the `FMRecommender`
    class, which generates recommendations without any restriction on the items being
    recommended:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, wrap up the preference factorization machine to work with RankSys
    user-preference pairs. Then, we train the model by setting the learning rate,
    regularization, and standard deviation, and iterate the training up to 100 times
    using `PointWiseGradientDescent`. FM then uses RMSE-like loss with a balanced
    sampling of negative instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, the FM model is trained using the `learn()` method,
    which is pretty similar to the `learn()` method used for predicting rating in
    the previous section. Then, to evaluate the model, first, we set the target user
    and `SimpleRecommendationFormat`, which is in tab-separated, user-item score triplets
    (that is, present in the original dataset):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we invoke the `RecommenderRunner` interface to generate recommendations
    and print it based on the format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code block will perform the evaluation on the test set and write
    the recommendation in the text file we specified previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: The prediction has been saved at outFolder/Ranking_RMSE.txt
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at the output file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: This snapshot from the output file shows the predicted ranking by user 944 for
    different movies. Now that we can see that our FM model has predicted the user's
    ranking for movies, inspecting model performance in terms of accuracy and execution
    time would make sense.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this, I wrote a class called `PlotUtil_Rank.java`. This class takes the
    metrics type and a number of iterations and generates the plot using the `plot()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'This method is further called from the `PointWiseGradientDescent.java` class.
    First, we create two `ArrayList` of `Double` to hold the execution time and MSE:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, for each iteration, the ;`learn()` method generates both the MSE error
    and time for each iteration and puts them in the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the `plot()` method is called as follows to plot the graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'By the way, `convertobjectArraytoDouble()`, which is shown in the following
    code, is used to convert the object array into doubles to act as data points for
    the plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding invocation should generate two graphs. First, we see the MSE
    per iteration, and the following graph reports the same for 100 iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/07ab7d7b-9aca-4220-9d58-84f427c6cee1.png)'
  prefs: []
  type: TYPE_IMG
- en: MSE per iteration (up to 100^(th))
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we see the time per iteration, and the following graph reports the same
    for the 100th iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dfe6c1de-3150-473f-9461-dce817101237.png)'
  prefs: []
  type: TYPE_IMG
- en: Time per iteration (up to 100^(th))
  prefs: []
  type: TYPE_NORMAL
- en: Finally, from the second graph, we cannot make important insights except that
    the execution time per iteration fluctuated a lot. However, on the 90^(th) iteration,
    the time needed for each iteration was saturated.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the MSE drastically decreased after the 20th iteration from
    0.16 to 0.13, but was saturated after the 25^(th) iteration. This means increasing
    only a number of iterations, will not help us further reduce the MSE. Therefore,
    I would suggest that you try this after changing not only the number of iterations
    but also other hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: Frequently asked questions (FAQs)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have seen how to develop a movie recommendation that predicts both
    the rating and ranking of movies by users, there are some issues that require
    our attention, too. Also, we couldn't cover/discuss the library in this chapter,
    so I suggest that you read the documentation more carefully.
  prefs: []
  type: TYPE_NORMAL
- en: However, we will still see some frequently asked questions that might already
    be on your mind in this section. Answers to these questions can be found in the
    Appendix.
  prefs: []
  type: TYPE_NORMAL
- en: How can I save a trained FM model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can I restore a saved FM model from disk?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can I use the FM algorithm for solving a classification task?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Give me a few example use cases where FM algorithms have been used.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can I use the FM algorithm for making top-N recommendations?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw how to develop a movie recommendation system using FMs,
    which are a set of algorithms that enhance the performance of linear models by
    incorporating second-order feature interactions that are absent in matrix factorization
    algorithms in a supervised way.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, we have seen some theoretical background of recommendation systems
    using matrix factorization and collaborative filtering before diving into the
    project's implementation using RankSys library-based FMs. Due to page limitation,
    I didn't discuss the library more extensively. However, readers are suggested
    to take a look athe API documentation on GitHub at [https://github.com/RankSys/RankSys](https://github.com/RankSys/RankSys).
  prefs: []
  type: TYPE_NORMAL
- en: This project not only covers movie rating prediction by individual users but
    also discusses ranking prediction, too. Consequently, we also used FMs for predicting
    the ranking of movies.
  prefs: []
  type: TYPE_NORMAL
- en: This is more or less the end of our journey toward developing an end-to-end
    project with Java. However, we are not done yet! In the next chapter, we will
    discuss some recent trends of deep learning. Then, we will see some emerging use
    cases that can be implemented using DL4J library or least we'll see some pointers.
  prefs: []
  type: TYPE_NORMAL
- en: Answers to questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Answer** **to question 1**: For this, you can invoke the `saveModel()` method
    by providing the input model filename:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'The `saveModel()` method goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: Then, the method will save all the metadata (including dimension, rank, weight,
    and attribute information) of the trained model onto disk.
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question 2**: For this, you can invoke the ;`therestoreModel()`
    method by providing the input model filename:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: The invocation of this method will restore the saved model, including all the
    metadata (for example, dimension, rank, weight, and attribute information) of
    the trained model from the disk.
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question 3**: Yes, of course. This algorithm is very effective
    for very sparse datasets, too. All you need is to have the predicted labels in
    the integer and the task type classification, that is, `task == TaskType.TASK_CLASSIFICATION`.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer to question 4**: There are several use cases where FM-based approaches
    have been applied. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: Predicting whether the user is going to buy an item in a session from a given
    sequence of click events performed by users. Also, if he/she is buying, what would
    be the items he/she is going to buy? This problem is called the RecSys Challenge
    2015 (see more at [http://2015.recsyschallenge.com/challenge.html](http://2015.recsyschallenge.com/challenge.html)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To see a sample solution, interested readers can take a look at the following
    book titled *Deep Learning with TensorFlow - Second Edition* by Karim et al Packt
    Publishing, March 2018 (see more at [https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-tensorflow-second-edition](https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-tensorflow-second-edition)).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Using Factorization Machines for Hybrid Recommendation Systems Based on Behavioral,
    Product, and Customer Data* (see more at [https://dl.acm.org/citation.cfm?id=2796542](https://dl.acm.org/citation.cfm?id=2796542)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Answer to question 5**: Yes, you can extract it from implicit feedback (from
    reviews, events, transactions, and so on), since converting the rating prediction
    results to top-N lists is a trivial job. However, I don''t think there''s any
    open source implementations available, but you can of course try by modifying
    LibFM significantly to use pairwise ranking.'
  prefs: []
  type: TYPE_NORMAL
