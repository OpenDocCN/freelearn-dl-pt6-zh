- en: Chapter 2.  Distributed Deep Learning for Large-Scale Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '|   | *"In God we trust, all others must bring data"* |   |'
  prefs: []
  type: TYPE_TB
- en: '|   | --*W. Edwards Deming* |'
  prefs: []
  type: TYPE_TB
- en: In this exponentially growing digital world, big data and deep learning are
    the two hottest technical trends. Deep learning and big data are two interrelated
    topics in the world of data science, and in terms of technological growth, both
    are critically interconnected and equally significant.
  prefs: []
  type: TYPE_NORMAL
- en: Digital data and cloud storage follow a generic law, termed as Moore's law [50],
    which roughly states that the world's data are doubling every two years; however,
    the cost of storing that data decreases at approximately the same rate. This profusion
    of data generates more features and verities, hence, to extract all the valuable
    information out of it, better deep learning models should be built.
  prefs: []
  type: TYPE_NORMAL
- en: This voluminous availability of data helps to bring huge opportunities for multiple
    sectors. Moreover, big data, with its analytic part, has produced lots of challenges
    in the field of data mining, harnessing the data, and retrieving the hidden information
    out of it. In the field of Artificial Intelligence, deep learning algorithms provide
    their best output with large-scale data during the learning process. Therefore,
    as data are growing faster than ever before, deep learning also plays a crucial
    part in delivering all the big data analytic solutions.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will give an insight into how deep learning models behave with
    big data, and reveal the associated challenges. The later part of the chapter
    will introduce Deeplearning4j, an open source distributed framework, with a provision
    for integration with Hadoop and Spark, used to deploy deep learning for large-scale
    data. The chapter will provide examples to show how basic deep neural networks
    can be implemented with Deeplearning4j, and its integration to Apache Spark and
    Hadoop YARN.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the important topics that will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning for massive amounts of data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Challenges of deep learning for big data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed deep learning and Hadoop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deeplearning4j: An open source distributed framework for deep learning'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up Deeplearning4j on Hadoop YARN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning for massive amounts of data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this Exa-Byte scale era, the data are increasing at an exponential rate.
    This growth of data are analyzed by many organizations and researchers in various
    ways, and also for so many different purposes. According to the survey of **International
    Data Corporation** (**IDC**), the Internet is processing approximately 2 Petabytes
    of data every day [51]. In 2006, the size of digital data was around 0.18 ZB,
    whereas this volume has increased to 1.8 ZB in 2011\. Up to 2015, it was expected
    to reach up to 10 ZB in size, and by 2020, its volume in the world will reach
    up to approximately 30 ZB to 35 ZB. The timeline of this data mountain is shown
    in *Figure 2.1*. These immense amounts of data in the digital world are formally
    termed as big data.
  prefs: []
  type: TYPE_NORMAL
- en: '|   | *"The world of Big Data is on fire"* |   |'
  prefs: []
  type: TYPE_TB
- en: '|   | --*The Economist, Sept 2011* |'
  prefs: []
  type: TYPE_TB
- en: '![Deep learning for massive amounts of data](img/image_02_001-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: Figure shows the increasing trend of data for a time span of around
    20 years'
  prefs: []
  type: TYPE_NORMAL
- en: Facebook has almost 21 PB in 200M objects [52], whereas Jaguar ORNL has more
    than 5 PB data. These stored data are growing so rapidly that Exa-Byte scale storage
    systems are likely to be used by 2018 to 2020.
  prefs: []
  type: TYPE_NORMAL
- en: This explosion of data certainly poses an immediate threat to the traditional
    data-intensive computations, and points towards the need for some distributed
    and scalable storage architecture for querying and analysis of the large-scale
    data. A generic line of thought for big data is that raw data is extremely complex,
    sundry, and increasingly growing. An ideal Big dataset consists of a vast amount
    of unsupervised raw data, and with some negligible amount of structured/categorized
    data. Therefore, while processing these amounts of non-stationary structured data,
    the conventional data-intensive computations often fail. As a result, big data,
    having unrestricted diversity, requires sophisticated methods and tools, which
    could be implemented to extract patterns and analyze the large-scale data. The
    growth of big data has mostly been caused by an increasing computational processing
    power and the capability of the modern systems to store data at lower cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering all these features of big data, it can be broken into four distinct
    dimensions, often referred to as the four Vs: **Volume**, **Variety**, **Velocity**,
    and **Veracity**. Following *figure 2.2* shows the different characteristics of
    big data by providing all the 4Vs of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deep learning for massive amounts of data](img/B05883_02_02-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: Figure depicts the visual representation of 4Vs of big data'
  prefs: []
  type: TYPE_NORMAL
- en: In this current data-intensive technology era, the velocity of the data, the
    escalating rate at which the data are collected and obtained is as significant
    as the other parameters of the big data, that is, **Volume** and **Variety**.
    With the given pace, at which this data is getting generated, if it is not collected
    and analyzed sensibly, there is a huge risk of important data loss. Although,
    there is an option to retain this rapid-moving data into bulk storage for batch
    processing at a later period, the genuine importance in tackling this high velocity
    data lies in how quickly an organization can convert the raw data to a structured
    and usable format. Specifically, time-sensitive information such as flight fare,
    hotel fare, or some e-commerce product's price, and so on would become obsolete
    if the data is not immediately retained and processed in a systemic manner. The
    parameter veracity in big data is concerned with the accuracy of the results obtained
    after the data analysis. As data turns more complex each day, sustaining trust
    in the hidden information of big data throws a significant challenge.
  prefs: []
  type: TYPE_NORMAL
- en: To extract and analyze such critically complex data, a better, well-planned
    model is desired. In ideal cases, a model should perform better dealing with big
    data compared to data with small sizes. However, this is not always the case.
    Here, we will show one example to discuss more on this point.
  prefs: []
  type: TYPE_NORMAL
- en: As illustrated in *Figure 2.3*, with a small size dataset, the performance of
    the best algorithm is *n%* better than the worst one. However, as the size of
    the dataset increases (big data), the performance also enhances exponentially
    to some *k % >> n %*. Such kind of traces can well be found from [53], which clearly
    shows the effect of a large-scale training dataset in the performance of the model.
    However, it would be completely misleading that with any of the simplest models,
    one can achieve the best performance only using Big dataset.
  prefs: []
  type: TYPE_NORMAL
- en: From [53] we can see that algorithm 1 is basically a Naive Bayes model, algorithm
    2 belongs to a memory-based model, and algorithm 3 corresponds to Winnow. The
    following graph shows, with a small dataset, that the performance of Winnow is
    less that the memory-based one. Whereas when dealing with Big dataset, both the
    Naive Bayes and Winnow show better performance than the memory-based model. So,
    looking at the *Figure 2.3*, it would be really difficult to infer on what basis
    any one of these simple models work better in an environment of large dataset.
    An intuitive explanation for the relatively poor performance of the memory-based
    method with large datasets is that the algorithm suffered due to the latency of
    loading a huge amount of data to its memory. Hence, it is purely a memory related
    issue, and only using big data would not resolve that. Therefore, a primary reason
    for the performance should be how sophisticated the models are. Hence, the importance
    of deep learning model comes into play.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Big data. Small Minds. No Progress! Big data. Big Brains. Breakthrough! [54]
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning stands in contrast to big data. Deep learning has triumphantly
    been implemented in various industry products and widely practiced by various
    researchers by taking advantage of this large-scale digital data. Famous technological
    companies such as Facebook, Apple, and Google collect and analyze this voluminous
    amount of data on a daily basis, and have been bellicosely going forward with
    various deep learning related projects over the last few years.
  prefs: []
  type: TYPE_NORMAL
- en: Google deploys deep learning algorithms on the massive unstructured data collected
    from various sources including Google's Street view, image search engine, Google's
    translator, and Android's voice recognition.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deep learning for massive amounts of data](img/image_02_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Variation of percentage of accuracy of different types of algorithms
    with increasing size of datasets'
  prefs: []
  type: TYPE_NORMAL
- en: Apple's Siri, a virtual personal assistant for iPhones, provides a bulk of different
    services, such as sport news, weather reports, answers to users' questions, and
    so on. The entire application of Siri is based on deep learning, which collects
    data from different Apple services and obtains its intelligence. Other industries,
    mainly Microsoft and IBM, are also using deep learning as their major domain to
    deal with this massive amount of unstructured data. IBM's brain-like computer,
    Watson, and Microsoft's Bing search engine primarily use deep learning techniques
    to leverage the big data.
  prefs: []
  type: TYPE_NORMAL
- en: Current deep learning architectures comprise of millions or even billions of
    data points. Moreover, the scale at which the data is growing prevents the model
    from the risk of overfitting. The rapid increase in computation power too has
    made the training of advanced models much easier.
  prefs: []
  type: TYPE_NORMAL
- en: '*Table 2.1* shows how big data is practiced with popular deep learning models
    in recent research to get maximum information out of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Models** | **Computing power** | **Datasets** | **Average running time**
    |'
  prefs: []
  type: TYPE_TB
- en: '| Convolutional Neural Network[55] | Two NVIDIA GTX 580 3 GB GPUs. | Roughly
    90 cycles through the training set of 1.2 million high resolution images. | Five
    to six days. |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Belief Network [41] | NVIDIA GTX 280 1 GB GPU. | 1 million images. |
    Approximately one day. |'
  prefs: []
  type: TYPE_TB
- en: '| Sparse autoencoder[ 66] | 1000 CPU having 16000 cores each. | 10 million
    200*200 pixel images. | Approximately three days. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2.1: Recent research progress of large-scale deep learning models. Partial
    information taken from [55]'
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning algorithms, with the help of a hierarchical learning approach,
    are basically used to extract meaningful generic representations from the input
    raw data. Basically, at a higher level, more complex and abstract representations
    of the data are learnt from the previous layers and the less abstracted data of
    the multi-level learning model. Although deep learning can also learn from massive
    amounts of labelled (categorized) data, the models generally look attractive when
    they can learn from unlabeled/uncategorized data [56], and hence, help in generating
    some meaningful patterns and representation of the big unstructured data.
  prefs: []
  type: TYPE_NORMAL
- en: 'While dealing with large-scale unsupervised data, deep learning algorithms
    can extract the generic patterns and relationships among the data points in a
    much better way than the shallow learning architectures. The following are a few
    of the major characteristics of deep learning algorithms, when trained with large-scale
    unlabeled data:'
  prefs: []
  type: TYPE_NORMAL
- en: From the higher level of abstractions and representation, semantics and relational
    knowledge of the big data can be obtained from the deep learning models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even a simple linear model can perform effectively with the knowledge obtained
    from excessively complex and more abstract representations of the huge dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This huge variety of data representation from the unsupervised data opens its
    door for learning other data types such as textual, audio, video, image, and the
    like
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, it can be surely concluded that deep learning will become an essential
    ingredient for providing big data sentiment analysis, predictive analysis, and
    so on, particularly with the enhanced processing power and advancement in the
    **graphics processing unit** (**GPU**) capacity. The aim of this chapter is not
    to extensively cover big data, but to represent the relationship between big data
    and deep learning. The subsequent sections will introduce the key concepts, applications,
    and challenges of deep learning while working with large-scale uncategorized data.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges of deep learning for big data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The potential of big data is certainly noteworthy. However, to fully extract
    valuable information at this scale, we would require new innovations and promising
    algorithms to address many of these related technical problems. For example, to
    train the models, most of the traditional machine learning algorithms load the
    data in memory. But with a massive amount of data, this approach will surely not
    be feasible, as the system might run out of memory. To overcome all these gritty
    problems, and get the most out of the big data with the deep learning techniques,
    we will require brain storming.
  prefs: []
  type: TYPE_NORMAL
- en: Although, as discussed in the earlier section, large-scale deep learning has
    achieved many accomplishments in the past decade, this field is still in a growing
    phase. Big data is constantly raising limitations with its 4Vs. Therefore, to
    tackle all of those, many more advancements in the models need to take place.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges of deep learning due to massive volumes of data (first V)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The volume of large-scale data imposes a great challenge to deep learning. With
    very high dimensionality (attributes), a large number of examples (input) and
    large varieties of classifications (outputs), big data often increases the complexity
    of the model, as well as the running-time complexity of the algorithm. The mountain
    of data makes the training of deep learning algorithms almost impossible using
    centralized storage and its limited processing ability. To provide a cushion to
    this challenge, pushed by the huge volume of data, distributed frameworks with
    parallelized servers should be used. The upgraded deep network models have started
    to use clusters of CPUs and GPUs to enhance the training speed, without compromising
    the algorithm's accuracy. Various new strategies have been evolved for model parallelism
    and data parallelism.
  prefs: []
  type: TYPE_NORMAL
- en: In these types, the models or data are split into blocks, which can fit with
    the in-memory data, and then be distributed to various nodes with forward and
    backward propagations [57]. Deeplearning4j, a Java-based distributed tool for
    deep learning, uses data parallelism for this purpose, and will be explained in
    the next section.
  prefs: []
  type: TYPE_NORMAL
- en: High volumes of data are always associated with noisy labels and data incompleteness.
    This poses a major challenge during the training of large-scale deep learning.
    A huge proportion of the big data is contained by the unlabeled or unstructured
    data, where the noisy labels predominantly exist. To overcome this issue, some
    manual curation of the datasets is required to a significant extent. For example,
    all the search engines are used to collect the data over the last one year span.
    For this data, we need some sort of filtering, particularly to remove redundancy
    and the low-value data. Advanced deep learning methods are essential to handle
    such noisy, redundant data. Also, the associated algorithms should be able to
    tolerate these disarray datasets. One can also implement some more efficient cost
    function and updated training strategy to fully overcome the effect of noisy labels.
    Moreover, the use of semi-supervised learning [58] [59] could help to enhance
    the solution associated with this noisy data.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges of deep learning from a high variety of data (second V)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is the second dimension of big data, which represents all types of formats,
    with different distributions and from numerous sources. The exponentially growing
    data come from heterogeneous sources, which include a mammoth collection of audio
    streams, images, videos, animations, graphics, and unstructured texts from various
    log files. These varieties of data possess different characteristics and behavior.
    Data integration could be the only way to deal with such situations. As stated
    in [Chapter 1](ch01.html "Chapter 1. Introduction to Deep Learning") , *Introduction
    to Deep Learning*, deep learning has the ability to represent learning from structured/unstructured
    data. Deep learning can carry out unsupervised learning in a hierarchical fashion,
    which is training performed one level at a time, and the higher level features
    are defined by the immediate lower levels. This property of deep learning can
    be used to address the data integration problem. The natural solution of this
    could be to learn the data representation from each individual data sources, and
    then integrate the learned features at the subsequent levels.
  prefs: []
  type: TYPE_NORMAL
- en: There have already been a few experiments [60] [61], which have successfully
    demonstrated that deep learning can easily be used for the heterogeneous data
    sources for its significant gains in system performance. However, there are still
    many unanswered questions which deep learning has to address in the upcoming years.
    Currently, most of the deep learning models are mainly tested on bi-modalities
    (data from only two sources), but will the system performance be enhanced while
    dealing with multiple modalities? It might happen that multiple sources of data
    will offer conflicting information; in those cases, how will the model be able
    to nullify such conflicts and integrate the data in a constructive and fruitful
    way? Deep learning seems perfectly appropriate for the integration of various
    sources of data with multiple modalities, on account of its capability of learning
    intermediate representations and the underlying factors associated with a variety
    of data.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges of deep learning from a high velocity of data (third V)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The extreme velocity at which data is growing poses an enormous challenge to
    the deep learning technique. For data analytics, data created at this speed should
    also be processed in a timely manner. Online learning is one of the solutions
    to learning from this high velocity data [62-65]. However, online learning uses
    a sequential learning strategy, where the entire dataset should be kept in-memory,
    which becomes extremely difficult for traditional machines. Although the conventional
    neural network has been modified for online learning [67-71], there is still so
    much scope for progress in this field for deep learning. As an alternate approach
    to online learning, the stochastic gradient descent approach [72], [73] is also
    applied for deep learning. In this type, one training example with the known label
    is fed to the next label to update the model parameters. Further, to speed up
    learning, the updates can also be performed on a small batch basis [74]. This
    mini batch can provide a good balance between running time and the computer memory.
    In the next section, we will explain why mini batch data is most important for
    distributed deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: One more big challenge related to this high velocity of data is that this data
    is extremely changeable in nature. The distribution of data happens too frequently
    over time. Ideally, the data that changes over time is split into chunks taken
    from small time durations. The basic idea is that the data remains stationary
    for some time, and also possesses some major degree of correlation [75] [76].
    Therefore, the deep learning algorithms of big data should have the feature of
    learning the data as a stream. Algorithms which can learn from those non-stationary
    data are really crucial for deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges of deep learning to maintain the veracity of data (fourth V)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data veracity, imprecise, or uncertain data, is sometime overlooked, though
    it is equally consequential as the other 3Vs of big data. With the immense variety
    and velocity of big data, an organization can no longer rely on the traditional
    models to measure the accuracy of data. Unstructured data, by definition, contains
    a huge amount of imprecise and uncertain data. For example, social media data
    is excessively uncertain in nature. Although there are tools that can automate
    the normalization and cleansing of data, they are mostly in the pre-industrial
    stage.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed deep learning and Hadoop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From the earlier sections of this chapter, we already have enough insights
    on why and how the relationship of deep learning and big data can bring major
    changes to the research community. Also, a centralized system is not going to
    help this relationship substantially with the course of time. Hence, distribution
    of the deep learning network across multiple servers has become the primary goal
    of the current deep learning practitioners. However, dealing with big data in
    a distributed environment is always associated with several challenges. Most of
    those are explained in-depth in the previous section. These include dealing with
    higher dimensional data, data with too many features, amount of memory available
    to store, processing the massive Big datasets, and so on. Moreover, Big datasets
    have a high computational resource demand on CPU and memory time. So, the reduction
    of processing time has become an extremely significant criterion. The following
    are the central and primary challenges in distributed deep learning:'
  prefs: []
  type: TYPE_NORMAL
- en: How can we keep chunks of dataset in the primary memory of the nodes?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we maintain coordination among the chunks of data, so that later they
    can be moved together to result in the final outcome?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we make distributed and parallel processing extremely scheduled and
    coordinated?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we achieve an orchestral search process across the dataset to achieve
    high performance?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are multiple ways of using distributed deep learning with big datasets.
    However, when we talk about big data, the framework that is performing tremendously
    well in defending most of the challenges from the past half decade is the Hadoop
    framework [77-80]. Hadoop allows for parallel and distributed processing. It is
    undoubtedly the most popular and widely used framework, and it can store and process
    the data mountain more efficiently compared to the other traditional frameworks.
    Almost all the major technology companies, such as Google, Facebook, and so on
    use Hadoop to deploy and process their data in a sophisticated fashion. Most of
    the software designed at Google, which requires the use of an ocean of data, uses
    Hadoop. The primary advantage of Hadoop is the way it stores and processes enormous
    amount of data across thousands of commodity servers, bringing some well-organized
    results [81]. From our general understanding of deep learning, we can relate that
    deep learning surely needs that sort of distributed computing power to produce
    some wondrous outcomes from the input data. The Big dataset can be split into
    chunks and distributed across multiple commodity hardware for parallel training.
    Further more, the complete stage of a deep neural network can be split into subtasks,
    and then those subtasks can be processed in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Hadoop has turned out to be the point of convergence for all the data lakes.
    The need to shif deep learning to the data, which is already residing in Hadoop,
    has become quintessential.
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop operates on the concept that *moving computation is cheaper than moving
    data* [86] [87]. Hadoop allows for the distributed processing of large-scale datasets
    across clusters of commodity servers. It also provides efficient load balancing,
    has a very high degree of fault tolerance, and is highly horizontally scalable
    with minimal effort. It can detect and tolerate failures in the application layers,
    and hence, is suitable for running on commodity hardware. To achieve the high
    availability of data, Hadoop, by default, keeps a replication factor of three,
    with a copy of each block placed on two other separate machines. So, if a node
    fails, the recovery can be done instantly from the other two nodes. The replication
    factor of Hadoop can be easily increased based on how valuable the data is and
    other associated requirements on the data.
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop was initially built mainly for processing the batch tasks, so it is mostly
    suitable for deep learning networks, where the main task is to find the classification
    of large-scale data. The selection of features to learn how to classify the data
    is mainly done on a large batch of datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop is extremely configurable, and can easily be optimized as per the user's
    requirements. For example, if a user wants to keep more replicas of the data for
    better reliability, he can increase the replication factor. However, an increase
    in the number of replicas will eventually increase the storage requirements. Here
    we will not be explaining more about the features and configuration of data, rather
    we will mostly discuss the part of Hadoop which will be used extensively in distributed
    deep neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: In the new version of Hadoop, the parts which we will mainly use in this book
    are HDFS, Map-Reduce, and **Yet Another Resource Negotiator** (**YARN**). YARN
    has already dominated Hadoop's Map-Reduce (explained in the next part) in a large
    manner. YARN currently has the responsibility to assign the works to the Data
    nodes (data server) of Hadoop. **Hadoop Distributed File System** (**HDFS**),
    on the other hand, is a distributed file system, which is distributed across all
    the Data nodes under a centralized meta-data server called NameNode. To achieve
    high-availability, in the later version, a secondary NameNode was integrated to
    Hadoop framework, the purpose of which is to have a copy of the metadata from
    primary NameNode after certain checkpoints.
  prefs: []
  type: TYPE_NORMAL
- en: Map-Reduce
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Map-Reduce paradigm [83] is a distributed programming model developed by
    Google in 2004, and is associated with processing huge datasets with a parallel
    and distributed algorithm on a cluster of machines. The entire Map-Reduce application
    is useful with large-scale datasets. Basically, it has two primary components,
    one is called Map and the other is called Reduce, along with a few intermediate
    stages like shuffling, sorting and partitioning. In the map phase, the large input
    job is broken down into smaller ones, and each of the jobs is distributed to different
    cores. The operation(s) are then carried out on every small job placed on those
    machines. The Reduce phase accommodates all the scattered and transformed output
    into one single dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Explaining the concept of Map-Reduce in detail is beyond the scope of this
    chapter; interested readers can go through *"Map-Reduce: Simplified data processing
    on large clusters*" [83] to get an in-depth knowledge of this.'
  prefs: []
  type: TYPE_NORMAL
- en: Iterative Map-Reduce
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The deep learning algorithms are iterative in nature - the models learn from
    the optimization algorithms, which go through multiple steps so that it leads
    to a point of minimal error. For these kinds of models the Map-Reduce application
    does not seem to work as efficiently as it does for other use-cases.
  prefs: []
  type: TYPE_NORMAL
- en: Iterative Map-Reduce, a next generation YARN framework (unlike the traditional
    Map-Reduce) does multiple iterations on the data, which passes through only once.
    Although the architecture of Iterative Map-Reduce and Map-Reduce is dissimilar
    in design, the high level of understanding of both the architectures is simple.
    Iterative Map-Reduce is nothing but a sequence of Map-Reduce operations, where
    the output of the first Map-Reduce operation becomes the input to the next operation
    and so on. In the case of deep learning models, the map phase places all the operations
    of a particular iteration on each node of the distributed systems. It then distributes
    that massive input dataset to all the machines in the cluster. The training of
    the models is performed on each node of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Before sending the aggregated new model back to each of the machines, the reduce
    phase takes all the outputs collected from the map phase and calculates the average
    of the parameters. The same operations are iterated over and over again by the
    Iterative Reduce algorithm until the learning process completes and the errors
    minimize to almost zero.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.4* compares the high-level functionalities of the two methods. The
    left image shows the block diagram of Map-Reduce, while on the right, we have
    the close-up of Iterative Map-Reduce. Each ''Processor'' is a working deep network,
    which is learning on small chunks of the larger dataset. In the ''Superstep''
    phase, the averaging of the parameters is done before the entire model is redistributed
    to the whole cluster as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Iterative Map-Reduce](img/B05883_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Difference of functionalities in Map-Reduce and parallel iterative
    reduce'
  prefs: []
  type: TYPE_NORMAL
- en: Yet Another Resource Negotiator (YARN)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The primary idea of YARN is to dissociate job scheduling and resource management
    from the data processing. So the data can continue to process in the system in
    parallel with the Map-Reduce batch jobs. YARN possesses a central resource manager,
    which mostly manages the Hadoop system resources according to the need. The node
    manager (specific to nodes) is responsible for managing and monitoring the processing
    of individual nodes of the cluster. This processing is dedicatedly controlled
    by an ApplicationMaster, which monitors the resources from the central resource
    manager, and works with the node manager to monitor and execute the tasks. The
    following figure gives an overview of the architecture of YARN:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Yet Another Resource Negotiator (YARN)](img/B05883_02_05-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: An overview of the high-level architecture of YARN'
  prefs: []
  type: TYPE_NORMAL
- en: All these components of Hadoop are primarily used in distributed deep learning
    to overcome all the challenges stated earlier. The following subsection shows
    the criteria that need to be satisfied for better performance of distributed deep
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: Important characteristics for distributed deep learning design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'the following are the important characteristics of distributed deep learning
    design:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Small batch processing**: In distributed deep learning, the network must
    intake and process data quickly in parallel. To process and provide results more
    accurately, every node of the cluster should receive small chunks of data of approximately
    10 elements at a time.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For example, say the master node of YARN is coordinating 20 worker nodes for
    a Big dataset of 200 GB. The master node will split the dataset into 10 GB of
    20 small batches of data, allocating one small batch to each worker. The workers
    will process the data in parallel, and send the results back to the master as
    soon as it finishes the computing. All these outcomes will be aggregated by the
    master node, and the average of the results will be finally redistributed to the
    individual workers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Deep learning networks perform well with small batches of nearly 10, rather
    than working with 100 or 200 large batches of data. Small batches of data empower
    the networks to learn from different orientations of the data in-depth, which
    later on recompiles to give a broader knowledge to the model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On the other hand, if the batch size is too large, the network tries to learn
    quickly, which maximizes the errors. Conversly, smaller batch size slows down
    the speed of learning, and results in the possibility of divergence as the network
    approaches towards the minimum error rate.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Parameter Averaging**: Parameter averaging is a crucial operation for the
    training of distributed deep network. In a network, parameters are generally the
    weight and biases of the node layers. As mentioned in the small batch processing
    section, once training is completed for several workers, they will pass different
    sets of parameters back to the master. With every iteration, the parameters are
    averaged, updated, and sent back to the master for further operations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The sequential process of parameter averaging can be outlined as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The master configures the initial network and sets the different hyperparameters
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on the configuration of the training master, the Big dataset is split
    into chunks of several smaller datasets
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For each split of the training dataset, until the error rate approaches towards
    zero, perform the following:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The master distributes the parameter from the master to each individual worker
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Each worker starts the training of the model with its dedicated chunk of dataset
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The average of the parameters is calculated and returned back to the master.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The training completes, and the master will have one copy of the training network
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Parameter averaging offers the following two important advantages in case of
    distributed training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It enables parallelism by generating simultaneous results.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It helps to prevent over-fitting by distributing the given dataset into multiple
    datasets of smaller sizes. The network then learns the average result, rather
    than just aggregating the results from different smaller batches.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 2.6* shows a combined diagrammatic overview of the small batch processing
    and parameter averaging operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Important characteristics for distributed deep learning design](img/B05883_02_06-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: Figure shows the high level architecture of a distributed deep
    learning architecture'
  prefs: []
  type: TYPE_NORMAL
- en: Deeplearning4j - an open source distributed framework for deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Deeplearning4j** (**DL4J**) [82] is an open source deep learning framework
    which is written for JVM, and mainly used for commercial grade. The framework
    is written entirely in Java, and thus, the name ''4j'' is included. Because of
    its use with Java, Deeplearning4j has started to earn popularity with a much wider
    audience and range of practitioners.'
  prefs: []
  type: TYPE_NORMAL
- en: This framework is basically composed of a distributed deep learning library
    that is integrated with Hadoop and Spark. With the help of Hadoop and Spark, we
    can very easily distribute the model and Big datasets, and run multiple GPUs and
    CPUs to perform parallel operations. Deeplearning4j has primarily shown substantial
    success in performing pattern recognition in images, sound, text, time series
    data, and so on. Apart from that, it can also be applied for various customer
    use cases such as facial recognition, fraud detection, business analytics, recommendation
    engines, image and voice search, and predictive maintenance with the sensor data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following *Figure 2.7* shows a generic high-level architectural block diagram
    of Deeplearning4j:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deeplearning4j - an open source distributed framework for deep learning](img/B05883_02_07-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.7: High level architectural block diagram of Deeplearning4j [82]'
  prefs: []
  type: TYPE_NORMAL
- en: Major features of Deeplearning4j
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deeplearning4j comes with various attractive features, which completely distinguishes
    it from other existing deep learning tools like Theano, Torch, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '**Distributed architecture**: Training in Deeplearning4j can be performed in
    two ways - with distributed, multi-threaded deep-learning, or with traditional,
    normal single-threaded deep-learning techniques. The training is carried out in
    clusters of commodity nodes. Therefore, Deeplearning4j is able to process any
    amount of data quickly. The neural networks are trained in parallel using the
    iterative reduce method, which works on Hadoop YARN and Spark. It also integrates
    with Cuda kernels to conduct pure GPU operations, and works with distributed GPUs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deeplearning4j operations can be run on Hadoop YARN or Spark as a job. In Hadoop,
    Iterative Reduce workers work on every block of HDFS, and synchronously process
    the data in parallel. As the processing completes, they push the transformed parameters
    back to their master, where the average of the parameters are taken and the model
    of each worker's node is updated.
  prefs: []
  type: TYPE_NORMAL
- en: In Deeplearning4j, the distributed runtimes are interchangeable, where they
    act like a directory in a huge modular architecture, which can be swapped in or
    out.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data parallelism**: There are two ways in which the neural networks can be
    trained in a distributed manner: one is data parallelism, and the other is model
    parallelism. Deeplearning4j follows data parallelism for training. In data parallelism,
    we can split the large dataset into chunks of smaller datasets, and distribute
    those to parallel models running on different servers to train in parallel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scientific computing capability for the JVM**: For scientific computing in
    Java and Scala, Deeplearning4j includes an N-dimensional array class using **N-Dimensional
    Arrays for Java** (**ND4J**). The functionality of ND4J is much faster than what
    Numpy provides to Python, and its mostly written in C++. It''s effectively based
    on a library for matrix manipulation and linear algebra in a production environment.
    Most of the routines of ND4J are designed to run fast with minimum RAM requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Vectorization tool for machine learning**: For vectorization of various file
    formats and data types, Canova has been merged with Deeplearning4j. Canova performs
    vectorization using an input/output system similar to how Hadoop uses Map-Reduce.
    Canova is primarily designed to vectorize text, CSVs, images, sounds, videos,
    and so on from the **command line interface** (**CLI**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary of functionalities of Deeplearning4j
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following are summary of functionalities of Deeplearning4j:'
  prefs: []
  type: TYPE_NORMAL
- en: Deeplearning4j can be claimed as the most complete, production-ready, open source
    deep learning library ever built
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compared to Theano-based tools, it has many more features specially designed
    for deep networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deeplearning4j is very easy to use; even non-specialists can apply its conventions
    to solve computationally intensive problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tools provide a wide range of applicability, hence, the networks work equally
    well with image, sound, text, and time-series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is completely distributed and can run multiple GPUs in parallel, unlike Theano
    [84], which is not distributed, and Torch7 [85], which has not automated its distribution
    like DL4J
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up Deeplearning4j on Hadoop YARN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deeplearning4j primarily works on networks having multiple layers. To get started
    working with Deeplearning4j, one needs to get accustomed with the prerequisites,
    and how to install all the dependent software. Most of the documentation can be
    easily found on the official website of Deeplearning4j at [https://deeplearning4j.org/](https://deeplearning4j.org/) [88].
  prefs: []
  type: TYPE_NORMAL
- en: In this section of the chapter, we will help you to get familiar with the code
    of Deeplearning4j. Initially, we will show the implementation of a simple operation
    of a multilayer neural network with Deeplearning4j. The later part of the section
    will discuss distributed deep learning with Deeplearning4j library. Deeplearning4j
    trains distributed deep neural network on multiple distributed GPUs using Apache
    Spark. The later part of this section will also introduce the setup of Apache
    Spark for Deeplearning4j.
  prefs: []
  type: TYPE_NORMAL
- en: Getting familiar with Deeplearning4j
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This part will mainly introduce the 'Hello World' programs of deep learning
    with deeplearning4j. We will explain the basic functions of the library with the
    help of two simple deep learning problems.
  prefs: []
  type: TYPE_NORMAL
- en: In Deeplearning4j, `MultiLayerConfiguration`, a class of the library can be
    considered as the base of the building block, which is responsible for organizing
    the layers and the corresponding hyperparameters of a neural network. This class
    can be considered as the core building block of Deeplearning4j for neural networks.
    Throughout the book, we will use this class to configure different multilayer
    neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Hyperparameters are the main backbone to determine the learning process of a
    neural network. They mostly include how to initialize the weights of the models,
    how many times they should be updated, the learning rate of the model, which optimization
    algorithms to use, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: In the first example, we will show how to classify data patterns for the multilayer
    perceptron classifier with the help of Deeplearning4j.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the sample training dataset that will be used in this program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Initially, we need to initialize the various hyperparameters of the networks.
    The following piece of code will set the ND4J environment for the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Number of epochs is set to `30`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following piece of code will load the training data to the network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As the training data is loaded next we load the test data into the model with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Organization of all the layers of the network model as well as setting up the
    hyperparameters can be done with the following piece of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have loaded the training and test dataset, the initialization of the
    model can be done by calling the `init()` method. This will also start the training
    of the model from the given inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'To check the output after a certain internal, let''s print the scores every
    `5` parameter updates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the network is trained by calling the `.fit()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'So the training of the model is done. In the next part, the data points will
    be plotted and the corresponding accuracy of the data will be calculated as shown
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code will store all the training data in an array before plotting
    those in the graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the test data through the network and generating the prediction can
    be done with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: When the preceding code is executed, it will run for approximately 5-10 seconds,
    depending upon your system configuration. During that time, you can check the
    console, which will display the updated score of training for your model.
  prefs: []
  type: TYPE_NORMAL
- en: 'A piece of evaluation is displayed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the program will output the different statistics of the training for
    the model using Deeplearning4j as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In the background, we can visualize the plotting of the data, which will give
    an impression of what the planet Saturn looks like. In the next part, we will
    show how to integrate Hadoop YARN and Spark with Deeplearning4j. The following
    *Figure 2.8* shows the output of the program in graphical representation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting familiar with Deeplearning4j](img/image_02_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.8: The scattered data points are plotted when the preceding program
    is executed. The data points give an impression of the planet Saturn'
  prefs: []
  type: TYPE_NORMAL
- en: Integration of Hadoop YARN and Spark for distributed deep learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To use Deeplearning4j on Hadoop, we need to include the `deeplearning-hadoop`
    dependency as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, for Spark, we have to include the `deeplearning-spark` dependency
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Explaining the detailed functionalities of Apache Spark is beyond the scope
    of this book. Interested readers can catch up on the same at [http://spark.apache.org/](http://spark.apache.org/)
    .
  prefs: []
  type: TYPE_NORMAL
- en: Rules to configure memory allocation for Spark on Hadoop YARN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As already stated in the previous section, Apache Hadoop YARN is a cluster
    resource manager. When Deeplearning4j submits a training job to a YARN cluster
    via Spark, it is the responsibility of YARN to manage the allocation of resources
    such as CPU cores, amount of memory consumed by each executor, and so on. However,
    to extract the best performance from Deeplearning4j on YARN, some careful memory
    configuration is desired. This is done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The executer JVM memory amount needs to be specified using `spark.executor.memory`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The YARN container memory overhead needs to be specified using `spark.yarn.executor.memoryOverhead`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sum of `spark.executor.memory` and `spark.yarn.executor.memoryOverhead`
    must always be less than the amount of memory allocated to a container by the
    YARN.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ND4j and JavaCPP should know the allotment of the off-heap memory; this can
    be done using the `org.bytedeco.javacpp.maxbytes` system property.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`org.bytedeco.javacpp.maxbytes` must be less than `spark.yarn.executor.memoryOverhead`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The current version of Deeplearning4j uses parameter averaging to perform distributed
    training of the neural network. The following operation is performed exactly the
    way it is described in the parameter averaging part of the earlier section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'To list all the files from HDFS so as to run the code on different nodes, run
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: A complete code for how to set up Spark with YARN and HDFS will be provided
    along with the code bundle. For simplicity, only part of the code is shown here
    for the purpose of understanding.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will show an example to demonstrate how to use Spark and load the data
    into memory with Deeplearning4j. We will use a basic DataVec example to show some
    pre-processing operation on some CSV data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The sample dataset will look as like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The problem statement of the program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Remove some unnecessary columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filter out data, and keep only examples with values `USA` and `MX` for the `MerchantCountryCode`
    column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace the invalid entries in the `TransactionAmountUSD` column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parse the data string, and collect the hour of day from it to create a new `HourOfDay`
    column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The following part will define the operations that we want to perform on the
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In unstructured data, the datasets are generally noisy, and so we need to take
    care of some of the invalid data. In case of negative dollar value, the program
    will replace those to `0.0`. We will keep the positive dollar amounts intact.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to format the `DateTime` format as per the problem statement, the following
    piece of code is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'A different schema is created after execution of the all these operations as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The following piece of code will set Spark to perform all the operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'To take the data directly from HDFS, one has to pass `hdfs://{the filepath
    name}`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The input data are parsed using `CSVRecordReader()` method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The pre-defined transformation of Spark is performed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'As mentioned, to save the data back to HDFS, just putting the file path after
    `hdfs://` will do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'When the program is executed with Spark using Deeplearning4j, we will get the
    following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Similar to this example, lots of other datasets can be processed in a customized
    way in Spark. From the next chapter, we will show the Deeplearning4j codes for
    specific deep neural networks. The implementation of Apache Spark and Hadoop YARN
    is a generic procedure, and will not change according to neural network. Readers
    can use that code to deploy the deep network code in cluster or locally, based
    on their requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In contrast to the traditional machine learning algorithms, deep learning models
    have the capability to address the challenges imposed by a massive amount of input
    data. Deep learning networks are designed to automatically extract complex representation
    of data from the unstructured data. This property makes deep learning a precious
    tool to learn the hidden information from the big data. However, due to the velocity
    at which the volume and varieties of data are increasing day by day, deep learning
    networks need to be stored and processed in a distributed manner. Hadoop, being
    the most widely used big data framework for such requirements, is extremely convenient
    in this situation. We explained the primary components of Hadoop that are essential
    for distributed deep learning architecture. The crucial characteristics of distributed
    deep learning networks were also explained in depth. Deeplearning4j, an open source
    distributed deep learning framework, integrates with Hadoop to achieve the mentioned
    indispensable requirement. Deeplearning4j is entirely written in Java, can process
    data faster in a distributed manner with iterative Map-Reduce, and can address
    many problems imposed by the large-scale data. We have provided two sample examples
    to let you know about basic Deeplearning4j codes and syntax. We have also provided
    some code snippets for Spark configuration with integration with Hadoop YARN and
    Hadoop Distributed File System.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter of this book will introduce convolutional neural network, a
    popular deep learning network. The chapter will discuss the method convolution
    and how it can be used to build an advanced neural network mainly for image processing
    and image recognition. The chapter will then provide information on how a convolutional
    neural network can be implemented using Deeplearning4j.
  prefs: []
  type: TYPE_NORMAL
