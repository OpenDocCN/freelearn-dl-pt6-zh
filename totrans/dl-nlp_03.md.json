["```py\n    jupyter notebook\n    ```", "```py\n    import pandas as pd\n    df = pd.read_csv('train_comment_small_50.csv', sep=',')\n    ```", "```py\n    import re\n    ```", "```py\n    def clean_comment(text):\n        # Strip HTML tags\n        text = re.sub('<[^<]+?>', ' ', text)\n\n        # Strip escaped quotes\n        text = text.replace('\\\\\"', '')\n\n        # Strip quotes\n        text = text.replace('\"', '')\n\n        return text\n    ```", "```py\n    df['cleaned_comment'] = df['comment_text'].apply(clean_comment)\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(df['cleaned_comment'], df['toxic'], test_size=0.2)\n    ```", "```py\n    import nltk\n    nltk.download('stopwords')\n    ```", "```py\n    from sklearn.feature_extraction.text import CountVectorizer\n    from nltk.corpus import stopwords\n\n    vectorizer = CountVectorizer(binary=True, stop_words = stopwords.words('english'), lowercase=True, min_df=3, max_df=0.9, max_features=5000)\n    X_train_onehot = vectorizer.fit_transform(X_train)\n    ```", "```py\n    from keras.models import Sequential\n    from keras.layers import Dense\n    ```", "```py\n    nn = Sequential()\n    ```", "```py\n    nn.add(Dense(units=500, activation='relu', input_dim=len(vectorizer.get_feature_names())))\n    ```", "```py\n    nn.add(Dense(units=1, activation='sigmoid'))\n    ```", "```py\n    nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    ```", "```py\n    nn.summary()\n    ```", "```py\n    nn.fit(X_train_onehot[:-20], y_train[:-20], \n              epochs=5, batch_size=128, verbose=1, \n              validation_data=(X_train_onehot[-100:], y_train[-20:]))\n    ```", "```py\n    scores = nn.evaluate(vectorizer.transform(X_test), y_test, verbose=1)\n    print(\"Accuracy:\", scores[1])\n    ```", "```py\n    model.save('nn.hd5')\n    ```"]