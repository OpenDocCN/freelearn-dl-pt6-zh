<html><head></head><body>
<div id="page" style="height:0pt"/><div class="book" title="Chapter&#xA0;12.&#xA0;Learning Features with Unsupervised Generative Networks"><div class="book" id="3APV02-ccdadb29edc54339afcb9bdf9350ba6b"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12" class="calibre1"/>Chapter 12. Learning Features with Unsupervised Generative Networks</h1></div></div></div><p class="calibre8">This chapter focuses on a new type of model, the generative models, which include <span class="strong"><strong class="calibre2">Restricted Boltzmann Machines</strong></span>, <span class="strong"><strong class="calibre2">Deep Belief Networks</strong></span>, <span class="strong"><strong class="calibre2">Variational Auto Encoders</strong></span>, <span class="strong"><strong class="calibre2">Autoregressive models, and Generative Adversarial</strong></span> Networks. For the first nets, we've limited the presentation to the theory, while the last is explained in detail with practical code and advice.</p><p class="calibre8">These <a id="id439" class="calibre1"/>nets do not require any labels to be trained, which is called <span class="strong"><em class="calibre12">unsupervised learning</em></span>. Unsupervised learning helps compute features <a id="id440" class="calibre1"/>from the data, without the bias of the labels. These <a id="id441" class="calibre1"/>models are generative in the sense that they are trained <a id="id442" class="calibre1"/>to generate new data that sounds real.</p><p class="calibre8">The <a id="id443" class="calibre1"/>following points will be covered:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Generative models</li><li class="listitem">Unsupervised learning</li><li class="listitem">Restricted Boltzmann Machines</li><li class="listitem">Deep belief networks</li><li class="listitem">Generative adversarial models</li><li class="listitem">Semi-supervised learning</li></ul></div></div>

<div class="book" title="Chapter&#xA0;12.&#xA0;Learning Features with Unsupervised Generative Networks">
<div class="book" title="Generative models"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch12lvl1sec104" class="calibre1"/>Generative models</h1></div></div></div><p class="calibre8">A generative <a id="id444" class="calibre1"/>model in neural processing is a model that generates data given a noise vector <span class="strong"><em class="calibre12">z</em></span> as input:</p><div class="mediaobject"><img src="../images/00233.jpeg" alt="Generative models" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">The purpose of the training is to find the parameters to generate data as close as possible to the real data.</p><p class="calibre8">Applications <a id="id445" class="calibre1"/>of generative networks include data dimensionality reduction, synthetic data generation, unsupervised feature learning, and pre-training / training efficiency. Pre-training helps generalization because pre-training focuses on the patterns in the data, and less on the data-label relation.</p></div></div>

<div class="book" title="Chapter&#xA0;12.&#xA0;Learning Features with Unsupervised Generative Networks">
<div class="book" title="Generative models">
<div class="book" title="Restricted Boltzmann Machines"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch12lvl2sec28" class="calibre1"/>Restricted Boltzmann Machines</h2></div></div></div><p class="calibre8">A Restricted <a id="id446" class="calibre1"/>Boltzmann Machine <a id="id447" class="calibre1"/>is the simplest generative net, composed of one fully connected hidden layer, as shown in the picture:</p><div class="mediaobject"><img src="../images/00234.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">The full Boltzmann Machines have also hidden-to-hidden and visible-to-visible loop connections, while the <span class="strong"><em class="calibre12">Restricted</em></span> version does not have any.</p><p class="calibre8">In the general case, RBM are defined as <span class="strong"><em class="calibre12">energy-based models</em></span>, which means that they define a probability distribution through an energy function:</p><div class="mediaobject"><img src="../images/00235.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p><div class="mediaobject"><img src="../images/00236.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">
<span class="strong"><em class="calibre12">Z </em></span>is the <span class="strong"><strong class="calibre2">partition function</strong></span>, and <span class="strong"><em class="calibre12">E(v)</em></span> is the <span class="strong"><strong class="calibre2">free energy</strong></span> function (does not depend on the hidden state).</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note06" class="calibre1"/>Note</h3><p class="calibre8">Minimizing the negative log likelihood is equivalent to minimizing the energy function.</p></div><p class="calibre8">The <a id="id448" class="calibre1"/>RBM defines the energy function <a id="id449" class="calibre1"/>as a linearity in the parameters of the model:</p><div class="mediaobject"><img src="../images/00237.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p><div class="mediaobject"><img src="../images/00238.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">The relation between the energy and the free energy is given by:</p><div class="mediaobject"><img src="../images/00239.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">In the case of the RBM:</p><div class="mediaobject"><img src="../images/00240.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">Here <span class="strong"><img src="../images/00241.jpeg" alt="Restricted Boltzmann Machines" class="calibre23"/></span> denotes the sum over possible values of the i-th hidden neuron.</p><p class="calibre8">The RBM are usually considered in the particular case where <code class="email">v</code> and <code class="email">h</code> are binomial values in <span class="strong"><em class="calibre12">{0,1}</em></span>, so:</p><div class="mediaobject"><img src="../images/00242.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">The <a id="id450" class="calibre1"/>model is symmetric, following the symmetry in the <a id="id451" class="calibre1"/>model: hidden and visible have the same place in the energy function:</p><div class="mediaobject"><img src="../images/00243.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">RBM works as a simple stochastic fully connected layer in both directions (from input to hidden, and from hidden to input).</p><p class="calibre8">The <a id="id452" class="calibre1"/>gradient or derivative of the negative log-likelihood for the RBM has two terms, defined as <span class="strong"><strong class="calibre2">positive and negative phases</strong></span>, where the first term increases the probability of data, and the second term decreases the probability of generated samples:</p><div class="mediaobject"><img src="../images/00244.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">Here, the sum is over all possible inputs <span class="strong"><img src="../images/00245.jpeg" alt="Restricted Boltzmann Machines" class="calibre23"/></span> weighted by its probability (the expectation). At the minima, any increase in the free energy of our data sample will decrease the expectation of the total data.</p><p class="calibre8">Empirically, such a sum in the negative phase can be transformed into a sum over <span class="strong"><em class="calibre12">N</em></span> observed (<span class="strong"><em class="calibre12">v,h</em></span>):</p><div class="mediaobject"><img src="../images/00246.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">To <a id="id453" class="calibre1"/>compute such a sum in practice, the probability of observing the sample (<span class="strong"><em class="calibre12">v,h</em></span>) has to satisfy <span class="strong"><em class="calibre12">p(v | h)</em></span> given by the above formula as well as <span class="strong"><em class="calibre12">p(h | v)</em></span>.</p><p class="calibre8">Sampling <a id="id454" class="calibre1"/>is performed via the contrastive divergence algorithm, in practice: <span class="strong"><em class="calibre12">v</em></span> is sampled from the dataset, while <span class="strong"><em class="calibre12">h</em></span> is drawn following its above distribution given <span class="strong"><em class="calibre12">v</em></span>. This operation is repeated, to produce a new <span class="strong"><em class="calibre12">v</em></span> given <span class="strong"><em class="calibre12">h</em></span>, then a new <span class="strong"><em class="calibre12">h</em></span> given <span class="strong"><em class="calibre12">v</em></span>. In practice, this is sufficient to achieve samples closely distributed <a id="id455" class="calibre1"/>to the real distribution. These observed samples for <span class="strong"><em class="calibre12">v</em></span> and <span class="strong"><em class="calibre12">h</em></span> are referred to as <span class="strong"><strong class="calibre2">negative particles</strong></span>, and the second term in the cost function decreases the probability of these generated samples, while the first term increases the probability of the data.</p><p class="calibre8">Here is what the computation of the partition function with the negative particules would look like:</p><div class="informalexample"><pre class="programlisting">W = shared_glorot_uniform((n_visible, n_hidden), <span class="strong"><strong class="calibre2">name</strong></span>='<span class="strong"><strong class="calibre2">W</strong></span>')
hbias = shared_zeros(n_hidden, <span class="strong"><strong class="calibre2">name</strong></span>='<span class="strong"><strong class="calibre2">hbias'</strong></span>)
vbias = shared_zeros(n_visible, <span class="strong"><strong class="calibre2">name</strong></span>=<span class="strong"><strong class="calibre2">'vbias'</strong></span>)
params = [W, hbias, vbias]

<span class="strong"><strong class="calibre2">def</strong></span> sample_h_given_v(v0_sample):
    pre_sigmoid_h1 = T.dot(v0_sample, W) + hbias
    h1_mean = T.nnet.sigmoid(pre_sigmoid_h1)
    h1_sample = theano_rng.binomial(<span class="strong"><strong class="calibre2">size</strong></span>=h1_mean.shape, <span class="strong"><strong class="calibre2">n</strong></span>=1, <span class="strong"><strong class="calibre2">p</strong></span>=h1_mean, <span class="strong"><strong class="calibre2">dtype</strong></span>=theano.config.floatX)
    <span class="strong"><strong class="calibre2">return</strong></span> [pre_sigmoid_h1, h1_mean, h1_sample]

<span class="strong"><strong class="calibre2">def</strong></span> sample_v_given_h(h0_sample):
    pre_sigmoid_v1 = T.dot(h0_sample, W.T) + vbias
    v1_mean = T.nnet.sigmoid(pre_sigmoid_v1)
    v1_sample = theano_rng.binomial(<span class="strong"><strong class="calibre2">size</strong></span>=<span class="strong"><strong class="calibre2">v1_mean.shape</strong></span>, <span class="strong"><strong class="calibre2">n</strong></span>=<span class="strong"><strong class="calibre2">1</strong></span>, <span class="strong"><strong class="calibre2">p=</strong></span>v1_mean, <span class="strong"><strong class="calibre2">dtype</strong></span>=<span class="strong"><strong class="calibre2">theano.config.floatX</strong></span>)
    <span class="strong"><strong class="calibre2">return</strong></span> [pre_sigmoid_v1, v1_mean, v1_sample]

<span class="strong"><strong class="calibre2">def</strong></span> gibbs_hvh(h0_sample):
    pre_sigmoid_v1, v1_mean, <span class="strong"><strong class="calibre2">v1_sample</strong></span> = sample_v_given_h(h0_sample)
    pre_sigmoid_h1, h1_mean, <span class="strong"><strong class="calibre2">h1_sample</strong></span> = sample_h_given_v(v1_sample)
    <span class="strong"><strong class="calibre2">return</strong></span> [pre_sigmoid_v1, v1_mean, v1_sample,
            pre_sigmoid_h1, h1_mean, h1_sample]

chain_start = persistent_chain
(
    [
        pre_sigmoid_nvs,
        nv_means,
        nv_samples,
        pre_sigmoid_nhs,
        nh_means,
        nh_samples
    ],
    updates
) = theano.scan(
    gibbs_hvh,
    <span class="strong"><strong class="calibre2">outputs_info</strong></span>=[None, None, None, None, None, chain_start],
    <span class="strong"><strong class="calibre2">n_steps</strong></span>=k,
    <span class="strong"><strong class="calibre2">name</strong></span>="<span class="strong"><strong class="calibre2">gibbs_hvh</strong></span>"
)

chain_end = nv_samples[-1]

<span class="strong"><strong class="calibre2">def</strong></span> free_energy(v_sample):
    wx_b = T.dot(v_sample, W) + hbias
    vbias_term = T.dot(v_sample, vbias)
    hidden_term = T.sum(T.log(1 + T.exp(wx_b)), <span class="strong"><strong class="calibre2">axis</strong></span>=1)
    <span class="strong"><strong class="calibre2">return</strong></span> -hidden_term - vbias_term

cost = T.mean(free_energy(x)) - T.mean(free_energy(chain_end))</pre></div><p class="calibre8">The <a id="id456" class="calibre1"/>pictures of the filters trained <a id="id457" class="calibre1"/>on MNIST dataset after 15 epochs:</p><div class="mediaobject"><img src="../images/00247.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">And a <a id="id458" class="calibre1"/>mini-batch <a id="id459" class="calibre1"/>of negative particles (1,000 steps of sampling between each row):</p><div class="mediaobject"><img src="../images/00248.jpeg" alt="Restricted Boltzmann Machines" class="calibre9"/></div><p class="calibre10"> </p></div></div></div>

<div class="book" title="Chapter&#xA0;12.&#xA0;Learning Features with Unsupervised Generative Networks">
<div class="book" title="Generative models">
<div class="book" title="Deep belief bets"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch12lvl2sec29" class="calibre1"/>Deep belief bets</h2></div></div></div><p class="calibre8">A <span class="strong"><strong class="calibre2">deep belief network</strong></span> (<span class="strong"><strong class="calibre2">DBN</strong></span>) is <a id="id460" class="calibre1"/>a stack of multiple RBMs to increase their representative power and better capture patterns in the data.</p><p class="calibre8">The <a id="id461" class="calibre1"/>training occurs layer by layer, first considering there is only one RBM with the hidden state <span class="strong"><img src="../images/00249.jpeg" alt="Deep belief bets" class="calibre23"/></span>. Once the weights of the RBM have been trained, these <a id="id462" class="calibre1"/>weights are kept fixed and the hidden layer of the first RBM <span class="strong"><img src="../images/00249.jpeg" alt="Deep belief bets" class="calibre23"/></span> is considered as the visible layer for a second RBM, with one hidden state <span class="strong"><img src="../images/00250.jpeg" alt="Deep belief bets" class="calibre23"/></span>. Each new RBM will capture patterns that have not been captured by the previous RBM as in the following diagram:</p><div class="mediaobject"><img src="../images/00251.jpeg" alt="Deep belief bets" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">It can be shown that each add-on of a new RBM on top of the stack decreases the negative log likelihood.</p><p class="calibre8">As last step, it is possible to use these weights in a classification network, by simply adding a linear layer and a softmax layer on top of the final hidden state, and fine-tuning all the weights via gradient descent training, as usual.</p><p class="calibre8">The application to data dimensionality remains the same, with the unrolling of all layers to produce a decoder network, with weights equal to the transpose of the weights in the encoder network (initial multi-layer RBM):</p><div class="mediaobject"><img src="../images/00252.jpeg" alt="Deep belief bets" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">Such <a id="id463" class="calibre1"/>an unrolled network is called an <span class="strong"><strong class="calibre2">auto encoder</strong></span>.</p><p class="calibre8">In <a id="id464" class="calibre1"/>practice, training directly via a gradient descent without the greedy <a id="id465" class="calibre1"/>layer by layer training would require finding the right initialization, which could be a lot trickier, as the weight initialization has to be close enough to the solution. That is why the commonly used approach for auto encoders is to train each RBM separately.</p></div></div></div>

<div class="book" title="Chapter&#xA0;12.&#xA0;Learning Features with Unsupervised Generative Networks">
<div class="book" title="Generative models">
<div class="book" title="Generative adversarial networks"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch12lvl2sec30" class="calibre1"/>Generative adversarial networks</h2></div></div></div><p class="calibre8">Since the <a id="id466" class="calibre1"/>partition function <a id="id467" class="calibre1"/>in the previous models is untractable and requires contrastive divergence algorithm with Gibbs sampling, game theory has recently delivered a new class of methods for learning generative models, the <span class="strong"><strong class="calibre2">Generative adversarial networks</strong></span> (<span class="strong"><strong class="calibre2">GANs</strong></span>), which enjoys great success today.</p><p class="calibre8">Generative adversarial networks are composed of two models that are alternatively trained to compete with each other. The generator network <span class="strong"><strong class="calibre2">G</strong></span> is optimized to reproduce the true data distribution, by generating data that is difficult for the discriminator <span class="strong"><strong class="calibre2">D</strong></span> to differentiate from real data. Meanwhile, the second network D is optimized to distinguish real data and synthetic data generated by G. Overall, the training procedure is similar to a two-player min-max game with the following objective function:</p><div class="mediaobject"><img src="../images/00253.jpeg" alt="Generative adversarial networks" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">Here, <span class="strong"><em class="calibre12">x</em></span> is real data sampled from real data distribution, and <span class="strong"><em class="calibre12">z</em></span> the noise vector of the generative <a id="id468" class="calibre1"/>model. In some <a id="id469" class="calibre1"/>ways, the discriminator and the generator can be seen as the police and the thief: to be sure the training works correctly, the police is trained twice as much as the thief.</p><p class="calibre8">Let's illustrate GANs with the case of images as data. In particular, let's again take our example from <a class="calibre1" title="Chapter 2. Classifying Handwritten Digits with a Feedforward Network" href="part0026_split_000.html#OPEK1-ccdadb29edc54339afcb9bdf9350ba6b">Chapter 2</a>, <span class="strong"><em class="calibre12">Classifying Handwritten Digits with a Feedforward Network</em></span> about MNIST digits, and consider training a generative adversarial network, to generate images, conditionally on the digit we want.</p><p class="calibre8">The GAN method consists of training the generative model using a second model, the discriminative network, to discriminate input data between real and fake. In this case, we can simply reuse our MNIST image classification model as discriminator, with two classes, <code class="email">real</code> or <code class="email">fake</code>, for the prediction output, and also condition it on the label of the digit that is supposed to be generated. To condition the net on the label, the digit label is concatenated with the inputs:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">def</strong></span> conv_cond_concat(x, y):
    <span class="strong"><strong class="calibre2">return</strong></span> T.concatenate([x, y*T.ones((x.shape[0], y.shape[1], x.shape[2], x.shape[3]))], <span class="strong"><strong class="calibre2">axis</strong></span>=1)

<span class="strong"><strong class="calibre2">def</strong></span> discrim(X, Y, w, w2, w3, wy):
    yb = Y.dimshuffle(0, 1, <span class="strong"><strong class="calibre2">'x'</strong></span>, <span class="strong"><strong class="calibre2">'x'</strong></span>)
    X = conv_cond_concat(X, yb)
    h = T.nnet.relu(dnn_conv(X, w, <span class="strong"><strong class="calibre2">subsample</strong></span>=(2, 2), <span class="strong"><strong class="calibre2">border_mode</strong></span>=(2, 2)), <span class="strong"><strong class="calibre2">alpha</strong></span>=0.2 )
    h = conv_cond_concat(h, yb)
    h2 =  T.nnet.relu(batchnorm(dnn_conv(h, w2, <span class="strong"><strong class="calibre2">subsample</strong></span>=(2, 2), <span class="strong"><strong class="calibre2">border_mode</strong></span>=(2, 2))), <span class="strong"><strong class="calibre2">alpha</strong></span>=0.2)
    h2 = T.flatten(h2, 2)
    h2 = T.concatenate([h2, Y], <span class="strong"><strong class="calibre2">axis</strong></span>=1)
    h3 = T.nnet.relu(batchnorm(T.dot(h2, w3)))
    h3 = T.concatenate([h3, Y], <span class="strong"><strong class="calibre2">axis</strong></span>=1)
    y = T.nnet.sigmoid(T.dot(h3, wy))
    <span class="strong"><strong class="calibre2">return</strong></span> y</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="tip02" class="calibre1"/>Tip</h3><p class="calibre8">Note the use of two leaky rectified linear units, with a leak of 0.2, as activation for the first two convolutions.</p></div><p class="calibre8">To <a id="id470" class="calibre1"/>generate an image given <a id="id471" class="calibre1"/>noise and label, the generator network consists of a stack of deconvolutions, using an input noise vector z that consists of 100 real numbers ranging from 0 to 1:</p><div class="mediaobject"><img src="../images/00254.jpeg" alt="Generative adversarial networks" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">To create a deconvolution in Theano, a dummy convolutional forward pass is created, which gradient is used as deconvolution:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">def</strong></span> deconv(X, w, <span class="strong"><strong class="calibre2">subsample</strong></span>=(1, 1), <span class="strong"><strong class="calibre2">border_mode</strong></span>=(0, 0), <span class="strong"><strong class="calibre2">conv_mode</strong></span>='conv'):
    img = gpu_contiguous(T.cast(X, <span class="strong"><strong class="calibre2">'float32'</strong></span>))
    kerns = gpu_contiguous(T.cast(w, <span class="strong"><strong class="calibre2">'float32'</strong></span>))
    desc = GpuDnnConvDesc(<span class="strong"><strong class="calibre2">border_mode</strong></span>=border_mode, <span class="strong"><strong class="calibre2">subsample</strong></span>=subsample,
<span class="strong"><strong class="calibre2">conv_mode</strong></span>=conv_mode)(gpu_alloc_empty(img.shape[0], kerns.shape[1], img.shape[2]*subsample[0], img.shape[3]*subsample[1]).shape, kerns.shape)
    out = gpu_alloc_empty(img.shape[0], kerns.shape[1], img.shape[2]*subsample[0], img.shape[3]*subsample[1])
    d_img = GpuDnnConvGradI()(kerns, img, out, desc)
    <span class="strong"><strong class="calibre2">return</strong></span> d_img

<span class="strong"><strong class="calibre2">def</strong></span> gen(Z, Y, w, w2, w3, wx):
    yb = Y.dimshuffle(0, 1, 'x', 'x')
    Z = T.concatenate([Z, Y], <span class="strong"><strong class="calibre2">axis</strong></span>=1)
    h = T.nnet.relu(batchnorm(T.dot(Z, w)))
    h = T.concatenate([h, Y], <span class="strong"><strong class="calibre2">axis</strong></span>=1)
    h2 = T.nnet.relu(batchnorm(T.dot(h, w2)))
    h2 = h2.reshape((h2.shape[0], ngf*2, 7, 7))
    h2 = conv_cond_concat(h2, yb)
    h3 = T.nnet.relu(batchnorm(deconv(h2, w3, <span class="strong"><strong class="calibre2">subsample</strong></span>=(<span class="strong"><strong class="calibre2">2</strong></span>, <span class="strong"><strong class="calibre2">2</strong></span>), <span class="strong"><strong class="calibre2">border_mode</strong></span>=(<span class="strong"><strong class="calibre2">2</strong></span>, <span class="strong"><strong class="calibre2">2</strong></span>))))
    h3 = conv_cond_concat(h3, yb)
    x = T.nnet.sigmoid(deconv(h3, wx, <span class="strong"><strong class="calibre2">subsample</strong></span>=(<span class="strong"><strong class="calibre2">2</strong></span>, <span class="strong"><strong class="calibre2">2</strong></span>), <span class="strong"><strong class="calibre2">border_mode</strong></span>=(<span class="strong"><strong class="calibre2">2</strong></span>, <span class="strong"><strong class="calibre2">2</strong></span>)))
    <span class="strong"><strong class="calibre2">return</strong></span> x</pre></div><p class="calibre8">Real <a id="id472" class="calibre1"/>data is given by the tuple (X,Y), while generated data is built from noise and label (Z,Y):</p><div class="informalexample"><pre class="programlisting">X = T.tensor4()
Z = T.matrix()
Y = T.matrix()

gX = gen(Z, Y, *gen_params)
p_real = discrim(X, Y, *discrim_params)
p_gen = discrim(gX, Y, *discrim_params)</pre></div><p class="calibre8">Generator <a id="id473" class="calibre1"/>and discriminator models compete during adversarial learning:</p><div class="book"><ul class="itemizedlist"><li class="listitem">The discriminator is trained to label real data as real (<code class="email">1</code>) and label generated data as generated (<code class="email">0</code>), hence minimizing the following cost function:<div class="informalexample"><pre class="programlisting">d_cost = T.nnet.binary_crossentropy(p_real, 								T.ones(p_real.shape)).mean() \
	+ T.nnet.binary_crossentropy(p_gen, T.zeros(p_gen.shape)).mean()</pre></div></li><li class="listitem">The generator is trained to deceive the discriminator as much as possible. The training signal for the generator is provided by the discriminator network (p_gen) to the generator:<div class="informalexample"><pre class="programlisting">g_cost = T.nnet.binary_crossentropy(p_gen,T.ones(p_gen.shape)).mean()</pre></div></li></ul></div><p class="calibre8">The same as usual follows. Cost with respect to the parameters for each model is computed and training optimizes the weights of each model alternatively, with two times more the discriminator. In the case of GANs, competition between discriminator and generator does not lead to decreases in each loss.</p><p class="calibre8">From the first epoch:</p><div class="mediaobject"><img src="../images/00255.jpeg" alt="Generative adversarial networks" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">To <a id="id474" class="calibre1"/>the 45th epoch:</p><div class="mediaobject"><img src="../images/00256.jpeg" alt="Generative adversarial networks" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">Generated <a id="id475" class="calibre1"/>examples look closer to real ones:</p><div class="mediaobject"><img src="../images/00257.jpeg" alt="Generative adversarial networks" class="calibre9"/></div><p class="calibre10"> </p><div class="book" title="Improve GANs"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch12lvl3sec01" class="calibre1"/>Improve GANs</h3></div></div></div><p class="calibre8">GANs are <a id="id476" class="calibre1"/>recent and very promising but still undergoing heavy research today. Yet, there are ways to improve the previous results.</p><p class="calibre8">First, as for RBM and other networks, GANs can be stacked in order to increase their generative power. As an example, the StackGan model proposes to use two stacked GANs for high quality image generation: the first GAN generates a coarse and low resolution image, while the second uses this generated sample as the input to generate an image of higher definition and realism, in which details of the objects are precised.</p><p class="calibre8">One of <a id="id477" class="calibre1"/>the main issues with GAN is the <span class="strong"><strong class="calibre2">model collapse</strong></span>, which makes them difficult to train. Model collapse occurs when the generator begins to ignore the input noise and learns to generate only one sample, always the same. Diversity in the generation has collapsed. One very nice way to deal with this comes from the S-GAN model, and consists of adding a third net to train with the generator. The purpose of this net is to predict back the noise given the input:</p><div class="mediaobject"><img src="../images/00258.jpeg" alt="Improve GANs" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">To <a id="id478" class="calibre1"/>optimize this third net with the generator, an entropy loss is added to the generator loss, to encourage the generated images <span class="strong"><em class="calibre12">x</em></span> to be sufficiently dependent on the noise <span class="strong"><em class="calibre12">z</em></span>. In other words, the conditional entropy <span class="strong"><em class="calibre12">H(x | z)</em></span> has to be as low as possible:</p><div class="mediaobject"><img src="../images/00259.jpeg" alt="Improve GANs" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">This third net predicts an auxiliary distribution Q to approximate the true posterior <span class="strong"><em class="calibre12">P(z | x)</em></span> and can be proved to be a variational higher bound for <span class="strong"><em class="calibre12">H(x | z)</em></span>. Such a loss function helps the generator not to ignore the input noise.</p></div></div></div></div>
<div class="book" title="Semi-supervised learning" id="3BOFI1-ccdadb29edc54339afcb9bdf9350ba6b"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec105" class="calibre1"/>Semi-supervised learning</h1></div></div></div><p class="calibre8">Last <a id="id479" class="calibre1"/>but not least, such generative adversarial networks can be used to enhance supervised learning itself.</p><p class="calibre8">Suppose the objective is to classify <span class="strong"><em class="calibre12">K</em></span> classes, for which an amount of labeled data is available. It is possible to add some generated samples to the dataset, which come from a generative model, and consider them as belonging to a <span class="strong"><em class="calibre12">(K+1)th</em></span> class, the fake data class.</p><p class="calibre8">Decomposing the training cross-entropy loss of the new classifier between the two sets (real data and fake data) leads to the following formula:</p><div class="mediaobject"><img src="../images/00260.jpeg" alt="Semi-supervised learning" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">Here, <span class="strong"><img src="../images/00261.jpeg" alt="Semi-supervised learning" class="calibre23"/></span> is the probability predicted by the model:</p><div class="mediaobject"><img src="../images/00262.jpeg" alt="Semi-supervised learning" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">Note <a id="id480" class="calibre1"/>that if we know that the data is real:</p><div class="mediaobject"><img src="../images/00263.jpeg" alt="Semi-supervised learning" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">And training on real data (K classes) would have led to the loss:</p><div class="mediaobject"><img src="../images/00264.jpeg" alt="Semi-supervised learning" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">Hence the loss of the global classifier can be rewritten:</p><div class="mediaobject"><img src="../images/00265.jpeg" alt="Semi-supervised learning" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">The second term of the loss corresponds to the standard unsupervised loss for GAN:</p><div class="mediaobject"><img src="../images/00266.jpeg" alt="Semi-supervised learning" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">The <a id="id481" class="calibre1"/>interaction introduced between the supervised and the unsupervised loss is still not well understood but, when the classification is not trivial, an unsupervised loss helps.</p></div>
<div class="book" title="Further reading" id="3CN041-ccdadb29edc54339afcb9bdf9350ba6b"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec106" class="calibre1"/>Further reading</h1></div></div></div><p class="calibre8">You can refer to the following topics for more insights:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><em class="calibre12">Deeplearning.net tutorial on RBM</em></span>: <a class="calibre1" href="http://deeplearning.net/tutorial/rbm.html">http://deeplearning.net/tutorial/rbm.html</a></li><li class="listitem"><span class="strong"><em class="calibre12">Deeplearning.net tutorial on Deep Belief Nets</em></span>: <a class="calibre1" href="http://deeplearning.net/tutorial/DBN.html">http://deeplearning.net/tutorial/DBN.html</a></li><li class="listitem"><span class="strong"><em class="calibre12">Deeplearning.net tutorial on generating with RBM-RNN</em></span>: <a class="calibre1" href="http://deeplearning.net/tutorial/rnnrbm.html">http://deeplearning.net/tutorial/rnnrbm.html</a></li><li class="listitem"><span class="strong"><em class="calibre12">Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription</em></span>, Nicolas Boulanger-Lewandowski, Yoshua Bengio, Pascal Vincent, 2012</li><li class="listitem">Generative Adversarial Networks, Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, 2014</li><li class="listitem"><span class="strong"><em class="calibre12">Gans will</em></span><span class="strong"><em class="calibre12"> change the world</em></span>, Nikolai Yakovenko, 2016 <a class="calibre1" href="https://medium.com/@Moscow25/">https://medium.com/@Moscow25/</a></li><li class="listitem"><span class="strong"><em class="calibre12">Pixel Recurrent Neural Networks</em></span>, Aaron van den Oord, Nal Kalchbrenner, Koray Kavukcuoglu, 2016</li><li class="listitem"><span class="strong"><em class="calibre12">InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets,</em></span> Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel, 2016</li><li class="listitem"><span class="strong"><em class="calibre12">StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks</em></span>, Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaolei Huang, Xiaogang Wang, Dimitris Metaxas, 2016</li><li class="listitem"><span class="strong"><em class="calibre12">Stacked Generative Advanced Networks</em></span>, Xun Huang, Yixuan Li, Omid Poursaeed, John Hopcroft, Serge Belongie, 2016</li><li class="listitem"><span class="strong"><em class="calibre12">Adversarial Learning for Neural Dialogue Generation</em></span>, Jiwei Li, Will Monroe, Tianlin Shi, Sébastien Jean, Alan Ritter, Dan Jurafsky, 2017</li><li class="listitem"><span class="strong"><em class="calibre12">Improved Techniques for Training GANs</em></span>, Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen, 2016</li><li class="listitem"><span class="strong"><em class="calibre12">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</em></span>, Alec Radford, Luke Metz, Soumith Chintala, 2015</li></ul></div></div>
<div class="book" title="Summary" id="3DLGM1-ccdadb29edc54339afcb9bdf9350ba6b"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec107" class="calibre1"/>Summary</h1></div></div></div><p class="calibre8">Generative adversarial networks are a very active area of research today. They belong to the family of generative models, which includes RBM and deep belief networks.</p><p class="calibre8">Generative models aim at generating more data, or learning better features for supervised and other tasks in an unsupervised way.</p><p class="calibre8">Generative models can be conditioned on some environmental input, and try to find the hidden variables behind the real data.</p><p class="calibre8">These models, the most advanced, complete the overview of deep learning nets with Theano. The next chapter will look at some advanced concepts to extend Theano and the future of deep learning.</p></div></body></html>