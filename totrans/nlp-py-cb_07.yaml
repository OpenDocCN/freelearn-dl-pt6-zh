- en: Information Extraction and Text Classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Using inbuilt NERs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating, inversing, and using dictionaries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating your own NEs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing the feature set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Segmenting sentences using classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classifying documents
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing a POS tagger with context
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Information retrieval is a vast area and has many challenges. In previous chapters,
    we understood regular expressions, grammars, **Parts-of-Speech** (**POS**) tagging,
    and chunking. The natural step after this process is to identify the Interested
    Entities in a given piece of text. To be clear, when we are processing large amounts
    of data, we are really interested in finding out whether any famous personalities,
    places, products, and so on are mentioned. These things are called **named entitie****s**
    in NLP. We will understand more about these with examples in the following recipes.
    Also, we will see how we can leverage the clues that are present in the input
    text to categorize large amounts of text, and many more examples will be explained.
    Stay tuned!
  prefs: []
  type: TYPE_NORMAL
- en: Understanding named entities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have seen how to parse the text, identify parts of speech, and extract
    chunks from the text. The next thing that we need to look into is finding **proper
    nouns**, which are also called named entities.
  prefs: []
  type: TYPE_NORMAL
- en: Named entities help us understand more about what is being referred to in a
    given text so that we can further classify the data. Since named entities comprise
    more than one word, it is sometimes difficult to find these from the text.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take up the following examples to understand what named entities are:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Sentence** | **Named entities** |'
  prefs: []
  type: TYPE_TB
- en: '| Hampi is on the South Bank of Tungabhadra river | Hampi, Tungabhadra River
    |'
  prefs: []
  type: TYPE_TB
- en: '| Paris is famous for Fashion | Paris |'
  prefs: []
  type: TYPE_TB
- en: '| Burj Khalifa is one of the Skyscrapers in Dubai | Burj Khalifa , Dubai |'
  prefs: []
  type: TYPE_TB
- en: '| Jeff Weiner is the CEO of LinkedIn | Jeff Weiner, LinkedIn |'
  prefs: []
  type: TYPE_TB
- en: 'Let''s take a closer look at these and try to understand:'
  prefs: []
  type: TYPE_NORMAL
- en: Even though *South Bank* refers to a direction, it does not qualify as a named
    entity because we cannot uniquely identify the object from that.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Even though *Fashion* is a noun, we cannot completely qualify it as named entity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Skyscraper* is a noun, but there can be many possibilities for Skyscrapers.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*CEO* is a role here; there are many possible persons who can hold this title.
    So, this also cannot be a named entity.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To further understand, let''s just look at these NEs from a categories perspective:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Category** | **Examples of named entities** |'
  prefs: []
  type: TYPE_TB
- en: '| `TIMEZONE` | Asia/Kolkata, IST, UTC |'
  prefs: []
  type: TYPE_TB
- en: '| `LOCATION` | Mumbai, Kolkata, Egypt |'
  prefs: []
  type: TYPE_TB
- en: '| `RIVERS` | Ganga, Yamuna, Nile |'
  prefs: []
  type: TYPE_TB
- en: '| `COSMETICS` | Maybelline Deep Coral Lipstick, LOreal Excellence Creme Hair
    Color |'
  prefs: []
  type: TYPE_TB
- en: '| `CURRENCY` | 100 bitcoins, 1.25 INR |'
  prefs: []
  type: TYPE_TB
- en: '| `DATE` | 17-Aug-2017, 19-Feb-2016 |'
  prefs: []
  type: TYPE_TB
- en: '| `TIME` | 10:10 AM |'
  prefs: []
  type: TYPE_TB
- en: '| `PERSON` | Satya Nadella, Jeff Weiner, Bill Gates |'
  prefs: []
  type: TYPE_TB
- en: Using inbuilt NERs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Python NLTK has built-in support for **Named Entity Recognition** (**NER**).
    In order to use this feature, first we need to recollect what we have done so
    far:'
  prefs: []
  type: TYPE_NORMAL
- en: Break a large document into sentences.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Break the sentence into words (or tokens).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identify the parts of speech in the sentence.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract chunks of consecutive words (non-overlapping) from the sentence.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign IOB tags to these words based on the chunking patterns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The next logical step would be to further extend the algorithms to find out
    the named entities as a sixth step. So, we will basically be using data that is
    preprocessed until step 5 as part of this example.
  prefs: []
  type: TYPE_NORMAL
- en: We will be using `treebank` data to understand the NER process. Remember, the
    data is already pre-tagged in IOB format. Without the training process, none of
    the algorithms that we are seeing here are going to work. (So, there is no magic!)
  prefs: []
  type: TYPE_NORMAL
- en: In order to understand the importance of the training process, let's take up
    an example. Say, there is a need for the Archaeological department to figure out
    which of the famous places in India are being tweeted and mentioned in social
    networking websites in the Kannada Language.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming that they have already got the data somewhere and it is in terabytes 
    or even in petabytes, how do they find out all these names? This is where we need
    to take a sample dataset from the original input and do the  training process
    to further use this trained data set to extract the named entities in Kannada.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have Python installed, along with the `nltk` library.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open Atom editor (or you favorite programming editor).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new file called `NER.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0abb176a-d572-4e81-aa7d-8c8dd2d9fa5d.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the program using the Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6018fa18-cf7f-452b-8d0a-e3612aa361cd.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code looks so simple, right? However, all the algorithms are implemented
    in the `nltk` library. So, let''s dig into how this simple program gives what
    we are looking for. This instruction imports the `nltk` library into the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'These three instructions define a new function called `sampleNE()`. We are
    importing the first tagged sentence from the `treebank` corpus and then passing
    it to the `nltk.ne_chunk()` function to extract the named entities. The output
    from this program includes all the named entities with their proper category:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'These three instructions define a new function called `sampleNE2()`. We are
    importing the first tagged sentence from the `treebank` corpus and then passing
    it to the `nltk.ne_chunk()` function to extract the named entities. The output
    from this program includes all the named entities without any proper category.
    This is helpful if the training dataset is not accurate enough to tag the named
    entities with the proper category such as person, organization, location, and
    so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: These three instructions will call the two sample functions that we have defined
    before and print the results on the screen.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Creating, inversing, and using dictionaries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python, as a general-purpose programming language, has support for many built-in
    data structures. Of those, one of the most powerful data structures are dictionaries.
    Before we jump into what dictionaries are, let's try to understand what these
    data structures are used for. Data structures, in short, help programmers to store,
    retrieve, and traverse through data that is stored in these structures. Each data
    structure has its own sets of behaviors and performance benefits that programmers
    should understand before selecting them for a given task at hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s get back to dictionaries. The basic use case of dictionaries can be
    explained with a simple example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use POS identification on the preceding sentence. But if someone were
    to ask what POS `flights` is in this sentence, we should have an efficient way
    to look for this word. This is where dictionaries come into play. They can be
    thought of as **one-to-one** mappings between data of interest. Again this one-to-one
    is at the highest level of abstraction of the data unit that we are talking about.
    If you are an expert programmer in Python, you know how to do **many-to-many**
    also. In this simple example, we need something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now let's answer a different question. Is it possible to print the list of all
    the words in the sentence that are nouns? Yes, for this too, we will learn how
    to use a Python dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have Python installed, along with the `nltk` library, in order to
    run this example.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open Atom editor (or your favorite programming editor).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new file called `Dictionary.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/48346cdf-5656-4b23-bacc-c095c5296b82.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the program using the Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8633a272-e323-4220-ae47-b90ccb3e4f2a.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s understand more about dictionaries by going through the instructions
    we have written so far. We are importing the `nltk` library into the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We are defining a new class called `LearningDictionary`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We are creating a constructor for `LearningDictionary` that takes `sentence` text
    as an argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction breaks the sentence into words using the `nltk.word_tokenize()` function
    and saves the result in the class member `words`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction identifies the POS for `words` and saves the result in the
    class member tagged:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction invokes the `buildDictionary()` function that is defined in
    the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction invokes the `buildReverseDictionary()` function that is defined
    in the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This instruction defines a new class member function called `buildDictionary()`*:*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction initializes a empty `dictionary` variable in the class. These
    two instructions iterate over all the tagged `pos` list elements and then assign
    each `word` to the `dictionary` as key and the POS as value of the key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction defines another class member function called `buildReverseDictionary()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction initializes an empty `dictionary` to a class member, `rdictionary`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction iterates over all the `dictionary` keys and puts the key of `dictionary` into
    a local variable called `key`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction extracts the `value` (POS) of the given `key` (word) and stores
    it in a local variable called `value`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'These four instructions check whether a given `key` (word) is already in the
    reverse dictionary variable (`rdictionary`). If it is, then we append the currently
    found word to the list. If the word is not found, then we create a new list of
    size one with the current word as the member:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This function returns `Yes` or `No` depending on whether a given word is found
    in the `dictionary`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This function returns the POS for the given word by looking into `dictionary`.
    If the value is not found, a special value of `None` is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'These two instructions define a function that returns all the words in the
    sentence with a given POS by looking into `rdictionary` (reverse dictionary).
    If the POS is not found, a special value of `None` is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We define a variable called `sentence`, which stores the string that we are
    interested in parsing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the `LearningDictionary()` class with `sentence` as a parameter.
    Once the class object is created, it is assigned to the learning variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We create a list of `words` that we are interested in knowing the POS of. If
    you see carefully, we have included a few words that are not in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We create a list of `pos` for which we are interested in seeing the words that
    belong to these POS classifications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'These instructions iterate over all the `words`, take one `word` at a time,
    check whether the `word` is in the dictionary by calling the `isWordPresent()` function
    of the object, and then print its status. If the `word` is present in the dictionary,
    then we print the POS for the word:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: In these instructions, we iterate over all the `pos`. We take one word at a
    time and then print the words that are in this POS using the `getWordsForPOS()` function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Choosing the feature set
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Features are one of the most powerful components of `nltk` library. They represent
    clues within the language for easy tagging of the data that we are dealing with.
    In Python terminology, features are expressed as dictionaries, where the keys
    are the labels and the values are the clues extracted from input data.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say we are dealing with some transport department data and we are interested
    in finding out whether a given vehicle number belongs to the Government of Karnataka
    or not. Right now we have no clue about the data we are dealing with. So how can
    we tag the given numbers accurately?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try to learn how the vehicle numbers give some clues about what they
    mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Vehicle number** | **Clues about the pattern** |'
  prefs: []
  type: TYPE_TB
- en: '| **KA-[0-9]{2} [0-9]{2}** | Normal vechicle number |'
  prefs: []
  type: TYPE_TB
- en: '| **KA-[0-9]{2}-F** | KSRTC, BMTC vehicles |'
  prefs: []
  type: TYPE_TB
- en: '| **KA-[0-9]{2}-G** | Government vehicles |'
  prefs: []
  type: TYPE_TB
- en: Using these clues (features), let's try to come up with a simple program that
    can tell us the classification of a given input number.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have Python installed, along with the `nltk` library.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open Atom editor (or your favorite programming editor).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new file called `Features.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/045dfc44-f4cf-45eb-a7d2-69fc0792a43c.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the program using the Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/cb969140-d0cc-4018-9883-f9a2aaf9c635.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s see what our program does. These two instructions import the `nltk` and `random` libraries
    into the current program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We are defining a list of Python tuples, where the first element in the tuple
    is the vehicle number and the second element is the predefined label that is applied
    to the number.
  prefs: []
  type: TYPE_NORMAL
- en: 'These instructions define that all the numbers are classified into three labels—`rtc`, `gov`,
    and `oth`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction shuffles all of the data in the `sampledata` list to make
    sure that the algorithm is not biased by the order of elements in the input sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'These are the test vehicle numbers for which we are interested in finding the
    category:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction defines a new function called `learnSimpleFeatures`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'These instructions define a new function, `vehicleNumberFeature()`, which takes
    the vehicle number and returns the seventh character in the that number. The return
    type is `dictionary`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction creates a list of feature tuples, where the first member in
    the tuple is feature dictionary and the second member in tuple is the label of
    the data. After this instruction, the input vehicle numbers in `sampledata` are
    no longer visible. This is one of the key things to remember:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction trains `NaiveBayesClassifier` with the feature dictionary
    and the labels that are applied to `featuresets`. The result is available in the
    classifier object, which we will use further:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'These instructions iterate over the test data and then print the label of the
    data from the classification done using `vehicleNumberFeature`. Observe the output
    carefully. You will see that the feature extraction function that we have written
    does not perform well in labeling the numbers correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction defines a new function called `learnFeatures`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'These instructions define a new function called `vehicleNumberFeature` that
    returns the feature dictionary with two keys. One key, `vehicle_class`, returns
    the character at position `6` in the string, and `vehicle_prev` has the character
    at position `5`. These kinds of clues are very important to make sure we eliminate
    bad labeling of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction creates a list of `featuresets` and input labels by iterating
    over of all the input trained data. As before, the original input vehicle numbers
    are no longer present here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction creates a `NaiveBayesClassifier.train()` function on `featuresets` and
    returns the object for future use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'These instructions loop through the `testdata` and print the classification
    of the input vehicle number based on the trained dataset. Here, if you observe
    carefully, the false-positive is not there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Invoke both the functions and print the results on the screen.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: If we observe carefully, we realize that the first function's results have one
    false positive, where it cannot identify the `gov` vehicle. This is where the
    second function performs well, as it has more features that improve accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Segmenting sentences using classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A natural language that supports question marks (?), full stops (.), and exclamations
    (!) poses a challenge to us in identifying whether a statement has ended or it
    still continues after the punctuation characters.
  prefs: []
  type: TYPE_NORMAL
- en: This is one of the classic problems to solve.
  prefs: []
  type: TYPE_NORMAL
- en: In order to solve this problem, let's find out the features (or clues) that
    we can leverage to come up with a classifier and then use the classifier to extract
    sentences in large text.
  prefs: []
  type: TYPE_NORMAL
- en: If we encounter a punctuation mark like `.` then it ends a sentence If we encounter
    a punctuation mark like `.` and the next word's first letter is a capital letter,
    then it ends a sentence.
  prefs: []
  type: TYPE_NORMAL
- en: Let's try to write a simple classifier using these two features to mark sentences.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have Python installed along with `nltk` library.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open Atom editor (or your favorite programming editor).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new File called `Segmentation.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f6c31463-5cf4-4682-8e0f-18aa270db410.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the program using the Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c170092c-1016-4885-bd4f-f386b152bf19.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This instruction imports the `nltk` library into the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'This function defines a modified feature extractor that returns a tuple containing
    the dictionary of the features and `True` or `False` to tell whether this feature
    indicates a sentence boundary or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'This function takes a `sentence` as input and returns a list of `featuresets` that
    is a list of tuples, with the feature dictionary and `True` or `False`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'This function takes the input text, breaks it into words, and then traverses
    through each word in the list. Once it encounters a full stop, it calls `classifier`
    to conclude whether it has encountered a sentence end. If the `classifier` returns
    `True`, then the sentence is found and we move on to the next word in the input.
    The process is repeated for all words in the input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'These instructions define a few variables for training and evaluation of our
    classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract all the features from the `traindata` variable and store it in `traindataset`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Train the `NaiveBayesClassifier` on `traindataset` to get  `classifier` as
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Invoke the function on `testdata` and print all the found sentences as output
    on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Classifying documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to write a classifier that can be used to
    classify documents. In our case, we will classify **rich site summary** (**RSS**) feeds.
    The list of categories is known ahead of time, which is important for the classification
    task.
  prefs: []
  type: TYPE_NORMAL
- en: In this information age, there are vast amounts of text available. Its humanly
    impossible for us to properly categorize all information for further consumption.
    This is where categorization algorithms help us to properly categorize the newer
    sets of documents that are being produced based on the training given on sample
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have Python installed, along with the `nltk` and `feedparser` libraries.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open Atom editor (or your favorite programming editor).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new file called `DocumentClassify.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8df78831-67d3-4c71-bb2e-22278a21cc58.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the program using the Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see this output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1cb21192-bb6d-41d2-be3d-7391822aac2e.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how this document classification works. Importing three libraries
    into the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction defines a new dictionary with two RSS feeds pointing to Yahoo!
    sports. They are pre-categorized. The reason we have selected these RSS feeds
    is that data is readily available and categorized for our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Initializing the empty dictionary variable `feedmap` to keep the list of RSS
    feeds in memory until the program terminates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Getting the list of `stopwords` in English and storing it in the `stopwords` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'This function, `featureExtractor()`, takes list of words and then adds them
    to the dictionary, where each key is the word and the value is `True`. The dictionary
    is returned, which are the features for the given input `words`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Empty list to store all the correctly labeled `sentences`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Iterate over all the `keys()` of the dictionary called `urls` and store the
    key in a variable called `category`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Download one feed and store the result in the `feedmap[category]` variable
    using the `parse()` function from the `feedparser` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Display the `url` that is being downloaded on the screen, using Python''s built-in
    the `print` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Iterate over all the RSS entries and store the current entry in a variable
    called `entry` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Take the `summary` (news text) of the RSS feed item into the `data` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'We brea `summary` into `words` based on space so that we can pass these to
    `nltk` for feature extraction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Store all `words` in the current RSS feed item, along with `category` it belongs
    to, in a tuple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract all the features of  `sentences` and store them in the variable `featuresets`.
    Later, do `shuffle()` on this array so that all the elements in the list are randomized
    for the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Create two datasets, one `trainset` and the other `testset`, for our analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `classifier` using the `trainset` data by using the `NaiveBayesClassifier` module''s `train()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Print the accuracy of  `classifier` using `testset`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Print the informative features about this data using the built-in function
    of `classifier`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Take four sample entries from the `nfl` RSS item. Try to tag the document based
    on `title` (remember, we have classified them based on `summary`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Writing a POS tagger with context
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous recipes, we have written regular-expression-based POS taggers that
    leverage word suffixes such as *ed*, *ing*, and so on to check whether the word
    is of a given POS or not. In the English language, the same word can play a dual
    role depending on the context in which it is used.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the word `address` can be both noun and verb depending on the
    context:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Let's try to write a program that leverages the feature extraction concept to
    find the POS of the words in the sentence.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have Python installed, along with `nltk`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open Atom editor (or your favorite programming editor).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new file called `ContextTagger.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1e05adaf-bf14-4c51-b890-3dfd893cf92f.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the program using the Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8fe4c10f-51e2-4850-8334-c218929e0b99.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how the current program works. This instruction imports the `nltk` libarary
    into the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Some sample strings that indicate the dual behavior of the words, `address`,
    `laugh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'This function takes `sentence` strings and returns a list of lists, where the
    inner lists contain the words along with their POS tags:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to set up a baseline and see how bad the tagging can be, this function
    explains how  `UnigramTagger` can be used to print the POS of the words just by
    looking at the current word. We are feeding the sample text to it as learning.
    This `tagger` performs very badly when compared to the built-in tagger that `nltk`
    comes with. But this is just for our understanding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Defining a new function called `withContextTagger()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'This function does feature extraction on a given set of words and returns a
    dictionary of the last three characters of the current word and previous word
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'We are building a `featuredata` list. It contains tuples of `featurelist` and
    `tag` members, which we will use to classify using `NaiveBayesClassifier`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'We take 50% for training and 50% of the feature extracted data to test our
    classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction creates `classifier` using the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction prints the accuracy of the classifier using `testdata`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: These two functions print the results of two preceding functions' computations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
