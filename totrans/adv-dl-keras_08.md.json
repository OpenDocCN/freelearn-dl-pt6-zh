["```py\n$ python3 vae-mlp-mnist-8.1.1.py --weights=vae_mlp_mnist.h5\n\n```", "```py\n# reparameterization trick\n# instead of sampling from Q(z|X), sample eps = N(0,I)\n# z = z_mean + sqrt(var)*eps\ndef sampling(args):\n    z_mean, z_log_var = args\n    batch = K.shape(z_mean)[0]\n    # K is the keras backend\n    dim = K.int_shape(z_mean)[1]\n    # by default, random_normal has mean=0 and std=1.0\n    epsilon = K.random_normal(shape=(batch, dim))\n    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n\n# MNIST dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nimage_size = x_train.shape[1]\noriginal_dim = image_size * image_size\nx_train = np.reshape(x_train, [-1, original_dim])\nx_test = np.reshape(x_test, [-1, original_dim])\nx_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\n\n# network parameters\ninput_shape = (original_dim, )\nintermediate_dim = 512\nbatch_size = 128\nlatent_dim = 2\nepochs = 50\n\n# VAE model = encoder + decoder\n# build encoder model\ninputs = Input(shape=input_shape, name='encoder_input')\nx = Dense(intermediate_dim, activation='relu')(inputs)\nz_mean = Dense(latent_dim, name='z_mean')(x)\nz_log_var = Dense(latent_dim, name='z_log_var')(x)\n\n# use reparameterization trick to push the sampling out as input\nz = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n# instantiate encoder model\nencoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\nencoder.summary()\nplot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n\n# build decoder model\nlatent_inputs = Input(shape=(latent_dim,), name='z_sampling')\nx = Dense(intermediate_dim, activation='relu')(latent_inputs)\noutputs = Dense(original_dim, activation='sigmoid')(x)\n\n# instantiate decoder model\ndecoder = Model(latent_inputs, outputs, name='decoder')\ndecoder.summary()\nplot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n\n# instantiate vae model\noutputs = decoder(encoder(inputs)[2])\nvae = Model(inputs, outputs, name='vae_mlp')\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    help_ = \"Load h5 model trained weights\"\n    parser.add_argument(\"-w\", \"--weights\", help=help_)\n    help_ = \"Use mse loss instead of binary cross entropy (default)\"\n    parser.add_argument(\"-m\",\n                        \"--mse\",\n                        help=help_, action='store_true')\n    args = parser.parse_args()\n    models = (encoder, decoder)\n    data = (x_test, y_test)\n    # VAE loss = mse_loss or xent_loss + kl_loss\n    if args.mse:\n        reconstruction_loss = mse(inputs, outputs)\n    else:\n        reconstruction_loss = binary_crossentropy(inputs,\n                                                  outputs)\n    reconstruction_loss *= original_dim\n    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n    kl_loss = K.sum(kl_loss, axis=-1)\n    kl_loss *= -0.5\n    vae_loss = K.mean(reconstruction_loss + kl_loss)\n    vae.add_loss(vae_loss)\n    vae.compile(optimizer='adam')\n    vae.summary()\n    plot_model(vae,\n               to_file='vae_mlp.png',\n               show_shapes=True)\n\n    if args.weights:\n        vae = vae.load_weights(args.weights)\n    else:\n        # train the autoencoder\n        vae.fit(x_train,\n                epochs=epochs,\n                batch_size=batch_size,\n                validation_data=(x_test, None))\n        vae.save_weights('vae_mlp_mnist.h5')\n\n    plot_results(models,\n                 data,\n                 batch_size=batch_size,\n                 model_name=\"vae_mlp\")\n```", "```py\n$ python3 vae-cnn-mnist-8.1.2.py --weights=vae_cnn_mnist.h5\n\n```", "```py\n# network parameters\ninput_shape = (image_size, image_size, 1)\nbatch_size = 128\nkernel_size = 3\nfilters = 16\nlatent_dim = 2\nepochs = 30\n\n# VAE mode = encoder + decoder\n# build encoder model\ninputs = Input(shape=input_shape, name='encoder_input')\nx = inputs\nfor i in range(2):\n    filters *= 2\n    x = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               activation='relu',\n               strides=2,\n               padding='same')(x)\n\n# shape info needed to build decoder model\nshape = K.int_shape(x)\n\n# generate latent vector Q(z|X)\nx = Flatten()(x)\nx = Dense(16, activation='relu')(x)\nz_mean = Dense(latent_dim, name='z_mean')(x)\nz_log_var = Dense(latent_dim, name='z_log_var')(x)\n\n# use reparameterization trick to push the sampling out as input\n# note that \"output_shape\" isn't necessary with the TensorFlow backend\nz = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n\n# instantiate encoder model\nencoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\nencoder.summary()\nplot_model(encoder, to_file='vae_cnn_encoder.png', show_shapes=True)\n\n# build decoder model\nlatent_inputs = Input(shape=(latent_dim,), name='z_sampling')\nx = Dense(shape[1]*shape[2]*shape[3], activation='relu')(latent_inputs)\nx = Reshape((shape[1], shape[2], shape[3]))(x)\n\nfor i in range(2): \n    x = Conv2DTranspose(filters=filters,\n                        kernel_size=kernel_size,\n                        activation='relu',\n                        strides=2,\n                        padding='same')(x)\n    filters //= 2\n\noutputs = Conv2DTranspose(filters=1,\n                    kernel_size=kernel_size,\n                    activation='sigmoid',\n                    padding='same',\n                    name='decoder_output')(x)\n\n# instantiate decoder model\ndecoder = Model(latent_inputs, outputs, name='decoder')\ndecoder.summary()\nplot_model(decoder, to_file='vae_cnn_decoder.png', show_shapes=True)\n\n# instantiate vae model\noutputs = decoder(encoder(inputs)[2])\nvae = Model(inputs, outputs, name='vae')\n```", "```py\n# compute the number of labels\nnum_labels = len(np.unique(y_train))\n\n# network parameters\ninput_shape = (image_size, image_size, 1)\nlabel_shape = (num_labels, )\nbatch_size = 128\nkernel_size = 3\nfilters = 16\nlatent_dim = 2\nepochs = 30\n\n# VAE model = encoder + decoder\n# build encoder model\ninputs = Input(shape=input_shape, name='encoder_input')\ny_labels = Input(shape=label_shape, name='class_labels')\nx = Dense(image_size * image_size)(y_labels)\nx = Reshape((image_size, image_size, 1))(x)\nx = keras.layers.concatenate([inputs, x])\nfor i in range(2):\n    filters *= 2\n    x = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               activation='relu',\n               strides=2,\n               padding='same')(x)\n\n# shape info needed to build decoder model\nshape = K.int_shape(x)\n\n# generate latent vector Q(z|X)\nx = Flatten()(x)\nx = Dense(16, activation='relu')(x)\nz_mean = Dense(latent_dim, name='z_mean')(x)\nz_log_var = Dense(latent_dim, name='z_log_var')(x)\n\n# use reparameterization trick to push the sampling out as input\n# note that \"output_shape\" isn't necessary with the TensorFlow backend\nz = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n\n# instantiate encoder model\nencoder = Model([inputs, y_labels], [z_mean, z_log_var, z], name='encoder')\nencoder.summary()\nplot_model(encoder, to_file='cvae_cnn_encoder.png', show_shapes=True)\n\n# build decoder model\nlatent_inputs = Input(shape=(latent_dim,), name='z_sampling')\nx = keras.layers.concatenate([latent_inputs, y_labels])\nx = Dense(shape[1]*shape[2]*shape[3], activation='relu')(x)\nx = Reshape((shape[1], shape[2], shape[3]))(x)\nfor i in range(2):\n    x = Conv2DTranspose(filters=filters,\n                        kernel_size=kernel_size,\n                        activation='relu',\n                        strides=2,\n                        padding='same')(x)\n    filters //= 2\n\noutputs = Conv2DTranspose(filters=1,\n                          kernel_size=kernel_size,\n                          activation='sigmoid',\n                          padding='same',\n                          name='decoder_output')(x)\n\n# instantiate decoder model\ndecoder = Model([latent_inputs, y_labels], outputs, name='decoder')\ndecoder.summary()\nplot_model(decoder, to_file='cvae_cnn_decoder.png', show_shapes=True)\n\n# instantiate vae model\noutputs = decoder([encoder([inputs, y_labels])[2], y_labels])\ncvae = Model([inputs, y_labels], outputs, name='cvae')\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    help_ = \"Load h5 model trained weights\"\n    parser.add_argument(\"-w\", \"--weights\", help=help_)\n    help_ = \"Use mse loss instead of binary cross entropy (default)\"\n    parser.add_argument(\"-m\", \"--mse\", help=help_, action='store_true')\n help_ = \"Specify a specific digit to generate\"\n parser.add_argument(\"-d\", \"--digit\", type=int, help=help_)\n help_ = \"Beta in Beta-CVAE. Beta > 1\\. Default is 1.0 (CVAE)\"\n parser.add_argument(\"-b\", \"--beta\", type=float, help=help_)\n    args = parser.parse_args()\n    models = (encoder, decoder)\n    data = (x_test, y_test)\n\n if args.beta is None or args.beta < 1.0:\n beta = 1.0\n print(\"CVAE\")\n model_name = \"cvae_cnn_mnist\"\n else:\n beta = args.beta\n print(\"Beta-CVAE with beta=\", beta)\n model_name = \"beta-cvae_cnn_mnist\"\n\n    # VAE loss = mse_loss or xent_loss + kl_loss\n    if args.mse:\n        reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n    else:\n        reconstruction_loss = binary_crossentropy(K.flatten(inputs),\n                                                  K.flatten(outputs))\n\n    reconstruction_loss *= image_size * image_size\n    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n    kl_loss = K.sum(kl_loss, axis=-1)\n kl_loss *= -0.5 * beta\n cvae_loss = K.mean(reconstruction_loss + kl_loss)\n cvae.add_loss(cvae_loss)\n cvae.compile(optimizer='rmsprop')\n cvae.summary()\n plot_model(cvae, to_file='cvae_cnn.png', show_shapes=True)\n\n if args.weights:\n cvae = cvae.load_weights(args.weights)\n else:\n # train the autoencoder\n cvae.fit([x_train, to_categorical(y_train)],\n epochs=epochs,\n batch_size=batch_size,\n validation_data=([x_test, to_categorical(y_test)], None))\n cvae.save_weights(model_name + '.h5')\n\n if args.digit in range(0, num_labels):\n digit = np.array([args.digit])\n else:\n digit = np.random.randint(0, num_labels, 1)\n\n print(\"CVAE for digit %d\" % digit)\n y_label = np.eye(num_labels)[digit]\n plot_results(models,\n data,\n y_label=y_label,\n batch_size=batch_size,\n model_name=model_name)\n\n```", "```py\n$ python3 cvae-cnn-mnist-8.2.1.py --weights=cvae_cnn_mnist.h5 --digit=0\n\n```", "```py\n    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n    kl_loss = K.sum(kl_loss, axis=-1)\n    kl_loss *= -0.5 * beta\n\n```", "```py\n$ python3 cvae-cnn-mnist-8.2.1.py --beta=7 --weights=beta-cvae_cnn_mnist.h5 --digit=0\n\n```"]