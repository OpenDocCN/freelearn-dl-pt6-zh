<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Preface</h1>
                </header>
            
            <article>
                
<p class="mce-root">As we enter the 21st century, it is quickly becoming apparent that AI and machine learning technologies will radically change the way we live our lives in the future. We now experience AI daily, from conversational assistants to smart recommendations in a search engine, and the average user/consumer now expects a smarter interface in anything they do. This most certainly includes games, and is likely one of the reasons why you, as a game developer, are considering reading this book.</p>
<p>This book will provide you, with a hands-on approach to building deep learning models for simple encoding for the purpose of building self-driving algorithms, generating music, and creating conversational bots, finishing with an in-depth discovery of deep reinforcement learning (DRL). We will begin with the basics of reinforcement learning (RL) and progress to combining DL and RL in order to create DRL. Then, we will take an in-depth look at ways to optimize reinforcement learning to train agents in order to perform complex tasks, from navigating hallways to playing soccer against zombies. Along the way, we will learn the nuances of tuning hyperparameters through hands-on trial and error, as well as how to use cutting-edge algorithms, including curiosity learning, Curriculum Learning, backplay, and i<span>mitation learning, in order to optimize agent training.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Who this book is for</h1>
                </header>
            
            <article>
                
<p>This book is for any game–or budding–game developer who is interested in using deep learning in an aspect of their next game project. In order to be successful in learning this material, you should have knowledge of the Python programming language and another C-based language, such as C#, C, C++, or Java. In addition, a basic knowledge of calculus, statistics, and probability will aid your digestion of the materials and facilitate your learning, but this is not essential.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What this book covers</h1>
                </header>
            
            <article>
                
<p><a href="108dd4cb-0332-4f3b-963b-fbfb49f2c8f0.xhtml" target="_blank">Chapter 1</a>, <em>Deep Learning for Games</em><span>, covers the background of deep learning in games before moving on to cover the basics by building a basic perceptron. From there, we will learn the concepts of network layers and build a simple autoencoder.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p><a href="391f7c79-537a-4c1d-bb92-e517097cd4d8.xhtml" target="_blank">Chapter 2</a>, <em>Convolutional and Recurrent Networks</em><span>, explores advanced layers, known as convolution and pooling, and how to apply them to building a self-driving deep network. Then, we will look at the concept of learning sequences with recurrent layers in deep networks.</span></p>
<p><a href="cb51d15b-9855-47e2-8e45-f74a115ebfa8.xhtml" target="_blank">Chapter 3</a>, <em>GAN for Games</em><span>, outlines the concept of a GAN, a generative adversarial network or an architectural pattern that pits two competing networks against one another. We will then explore and use various GANs to generate a game texture and original music.</span></p>
<p><a href="a8e699ff-c668-4601-842d-4c6e06c47a61.xhtml" target="_blank">Chapter 4</a>, <em>Building a Deep Learning Gaming Chatbot</em><span>, goes into further detail regarding recurrent networks and develops a few forms of conversational chatbot. We will finish the chapter by allowing the chatbot to be chatted with through Unity.</span></p>
<p><a href="6ca7a117-1a8c-49f9-89c0-ee2f2a1e8baf.xhtml" target="_blank">Chapter 5</a>, <em>Introduction DRL</em><span>, begins with the basics of reinforcement learning before moving on to cover multi-arm bandits and Q-Learning. We will then quickly move on to integrating deep learning and will explore deep reinforcement learning using the Open AI Gym environment.</span></p>
<p><a href="b422aff5-b743-4696-ba80-e0a222ea5b4d.xhtml" target="_blank"/><a href="b422aff5-b743-4696-ba80-e0a222ea5b4d.xhtml" target="_blank">Chapter 6</a>, <em>Unity ML-Agents</em><span>, begins by exploring the ML-Agents toolkit, which is a powerful deep reinforcement learning platform built on top of Unity. We will then learn how to set up and train various demo scenarios provided with the toolkit.</span></p>
<p><a href="9b7b6ff8-8daa-42bd-a80f-a7379c37c011.xhtml" target="_blank">Chapter 7</a>, <em>Agent and the Environment</em><span>, explores how an input state captured from the environment affects training. We will look at ways to improve these issues by building different input state encoders for various visual environments.</span></p>
<p><a href="1393797c-79cd-46c3-8e43-a09a7750fc92.xhtml" target="_blank">Chapter 8</a>, <em>Understanding PPO</em><span>, explains how learning to train agents requires some in-depth background knowledge of the various algorithms used in DRL. In this chapter, we will explore in depth the powerhouse of the ML-Agents toolkit, the proximal policy optimization algorithm.</span></p>
<p><a href="ae184eca-6c9d-456e-a72b-85274ddcc10c.xhtml" target="_blank">Chapter 9</a>, <em>Rewards and Reinforcement Learning</em><span>, explains how rewards are foundational to RL, exploring their importance and how to model their functions. We'll also explore the sparsity of rewards and ways of overcoming these problems in RL with Curriculum Learning and backplay.</span></p>
<p><a href="1525f2f4-b9e1-4b7f-ac40-33e801c668ed.xhtml" target="_blank">Chapter 10</a><span>, </span><em>Imitation and Transfer Learning</em><span>, explores further advanced methods, imitation and transfer learning, as ways of overcoming the sparsity of rewards and other agent training problems. We will then look at others ways of applying transfer learning i.</span></p>
<p><a href="15e7adeb-8b67-4b93-81d4-5f129772cd97.xhtml" target="_blank">Chapter 11</a><span>, </span><em>Building Multi-Agent Environments</em><span>, explores a number of scenarios that incorporate multiple agents competing against or cooperating with each other.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p><a href="323523c2-82f9-48c4-b1b5-35d417f90558.xhtml" target="_blank">Chapter 12</a><span>, </span><em>Debugging/Testing a Game with DRL</em><span>, explains how to build a testing/debugging framework with ML-Agents for use on your next game, which is one new aspect of DRL that is less well covered.</span></p>
<p><a href="144a9c95-e3b8-4e82-9f72-51b1b9a3757f.xhtml" target="_blank">Chapter 13</a><span>, <em>Obstacle Tower Challenge and Beyond</em>,</span><span> explores what is next for you. Are you prepared to take on the Unity Obstacle Tower challenge and build your own game, or perhaps you require further learning?</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">To get the most out of this book</h1>
                </header>
            
            <article>
                
<p>Some knowledge of Python and some exposure to machine learning will be beneficial, as will a k<span>nowledge of a C style language, such as C, C++, C#, or Java. Some u</span><span>nderstanding of calculus, while not essential, will be helpful, as will an understanding </span><span>of probability and statistics.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the example code files</h1>
                </header>
            
            <article>
                
<p>You can download the example code files for this book from your account at <a href="http://www.packt.com" target="_blank">www.packt.com</a>. If you purchased this book elsewhere, you can visit <a href="http://www.packt.com/support" target="_blank">www.packt.com/support</a> and register to have the files emailed directly to you.</p>
<p>You can download the code files by following these steps:</p>
<ol>
<li>Log in or register at <a href="http://www.packt.com" target="_blank">www.packt.com</a>.</li>
<li>Select the <span class="packt_screen">SUPPORT</span> tab.</li>
<li>Click on <span class="packt_screen">Code Downloads &amp; Errata</span>.</li>
<li>Enter the name of the book in the <span class="packt_screen">Search</span> box and follow the onscreen instructions.</li>
</ol>
<p>Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p>
<ul>
<li>WinRAR/7-Zip for Windows</li>
<li>Zipeg/iZip/UnRarX for Mac</li>
<li>7-Zip/PeaZip for Linux</li>
</ul>
<p>The code bundle for the book is also hosted on GitHub at <a href="https://github.com/PacktPublishing/Hands-On-Deep-Learning-for-Games">https://github.com/PacktPublishing/Hands-On-Deep-Learning-for-Games</a><a href="https://github.com/PacktPublishing/Hands-On-Deep-Learning-for-Games">. In case there's an update to the code, it will be updated on the existing GitHub repository.</a></p>
<p><a href="https://github.com/PacktPublishing/Hands-On-Deep-Learning-for-Games"/></p>
<p><span>We also have other code bundles from our rich catalog of books and videos available at</span><span> </span><strong><span class="Object"><a href="https://github.com/PacktPublishing/" target="_blank">https://github.com/PacktPublishing/</a></span></strong><span>. Check them out!</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the color images</h1>
                </header>
            
            <article>
                
<p>We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a href="https://www.packtpub.com/sites/default/files/downloads/9781788994071_ColorImages.pdf">https://www.packtpub.com/sites/default/files/downloads/9781788994071_ColorImages.pdf</a><a href="https://www.packtpub.com/sites/default/files/downloads/9781788994071_ColorImages.pdf">.</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conventions used</h1>
                </header>
            
            <article>
                
<p>There are a number of text conventions used throughout this book.</p>
<p><kbd>CodeInText</kbd>: <span>Indicates c</span>ode words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. <span>Here is an example:</span> "Mount the downloaded <kbd>WebStorm-10*.dmg</kbd> disk image file as another disk in your system."</p>
<p>A block of code is set as follows:</p>
<pre>html, body, #map {<br/> height: 100%; <br/> margin: 0;<br/> padding: 0<br/>}</pre>
<p>When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:</p>
<pre>[default]<br/>exten =&gt; s,1,Dial(Zap/1|30)<br/>exten =&gt; s,2,Voicemail(u100)<br/><strong>exten =&gt; s,102,Voicemail(b100)</strong><br/>exten =&gt; i,1,Voicemail(s0)</pre>
<p>Any command-line input or output is written as follows:</p>
<pre><strong>$ mkdir css</strong><br/><strong>$ cd css</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p><strong>Bold</strong>: Indicates a new term, an important word, or w<span>ords that you see on screen. For example, words in menus or dialog boxes appear in the text like this. Here is an example: "Select <span class="packt_screen">System info</span> from the <span class="packt_screen">Administration</span> panel.</span><span>"</span></p>
<div class="packt_infobox">Warnings or important notes appear like this.</div>
<div class="packt_tip">Tips and tricks appear like this.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Get in touch</h1>
                </header>
            
            <article>
                
<p>Feedback from our readers is always welcome.</p>
<p class="mce-root"><strong>General feedback</strong>: If you have questions about any aspect of this book, <span>mention the book title in the subject of your message and</span> email us at <kbd><span>customercare@packtpub.com</span></kbd>.</p>
<p><strong>Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packt.com/submit-errata" target="_blank">www.packt.com/submit-errata</a>, selecting your book, clicking on the Errata Submission Form link, and entering the details.</p>
<p><strong>Piracy</strong>: If you come across any illegal copies of our works in any form on the internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <kbd>copyright@packt.com</kbd> with a link to the material.</p>
<p class="mce-root"><strong>If you are interested in becoming an author</strong>: If there is a topic that you have expertise in, and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com/" target="_blank">authors.packtpub.com</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reviews</h1>
                </header>
            
            <article>
                
<p>Please leave a review. Once you have read and used this book, why not leave a review on the site that you purchased it from? Potential readers can then see and use your unbiased opinion to make purchase decisions, we at Packt can understand what you think about our products, and our authors can see your feedback on their book. Thank you!</p>
<p>For more information about Packt, please visit <a href="http://www.packt.com/" target="_blank">packt.com</a>.<a href="https://www.packtpub.com/" target="_blank"/></p>


            </article>

            
        </section>
    </body></html>