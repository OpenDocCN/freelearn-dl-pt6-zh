- en: Chapter 5.  Restricted Boltzmann Machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '|   | *"What I cannot create, I do not understand."* |   |'
  prefs: []
  type: TYPE_TB
- en: '|   | --*Richard Feynman* |'
  prefs: []
  type: TYPE_TB
- en: So far in this book, we have only discussed the discriminative models. The use
    of these in deep learning is to model the dependencies of an unobserved variable
    y on an observed variable *x*. Mathematically, it is formulated as *P(y|x)*. In
    this chapter, we will discuss deep generative models to be used in deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Generative models are models, which when given some hidden parameters, can randomly
    generate some observable data values out of them. The model works on a joint probability
    distribution over label sequences and observation.
  prefs: []
  type: TYPE_NORMAL
- en: The generative models are used in machine and deep learning either as an intermediate
    step to generate a conditional probability density function or modeling observations
    directly from a probability density function.
  prefs: []
  type: TYPE_NORMAL
- en: '**Restricted Boltzmann machines** (**RBMs**) are a popular generative model
    that will be discussed in this chapter. RBMs are basically probabilistic graphical
    models that can also be interpreted as stochastic neural networks.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Stochastic neural networks** can be defined as a type of artificial neural
    network that is generated by providing random variations into the network. The
    random variation can be supplied in various ways, such as providing stochastic
    weights or by giving a network''s neurons stochastic transfer functions.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss, a special type of Boltzmann machine called
    RBM, which is the main topic of this chapter. We will discuss how **Energy-Based
    models** (**EBMs**) are related to RBM, and their functionalities. Later in this
    chapter, we will introduce **Deep Belief network** (**DBN**), which is an extension
    of the RBM. The chapter will then discuss the large-scale implementation of these
    in distributed environments. The chapter will conclude by giving examples of RBM
    and DBN with Deeplearning4j.
  prefs: []
  type: TYPE_NORMAL
- en: 'The organization of this chapter is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Energy-based models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boltzmann machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restricted Boltzmann machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convolutional Restricted Boltzmann machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep Belief network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed Deep Belief network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation of RBM and DBN with Deeplearning4j
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Energy-based models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main goal of deep learning and statistical modeling is to encode the dependencies
    between variables. By getting an idea of those dependencies, from the values of
    the known variables, a model can answer questions about the unknown variables.
  prefs: []
  type: TYPE_NORMAL
- en: '**Energy-based models** (**EBMs**) [120] gather and collect the dependencies
    by identifying scaler energy, which generally is a measure of compatibility to
    each configuration of the variable. In EBMs, the predictions are made by setting
    the value of observed variables and finding the value of the unobserved variables,
    which minimize the overall energy. Learning in EBMs consists of formulating an
    energy function, which assigns low energies to the correct values of unobserved
    variables and higher energies to the incorrect ones. Energy-based learning can
    be treated as an alternative to probabilistic estimation for classification, decision-making,
    or prediction tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: To give a clear idea about how EBMs work, let us look at a simple example.
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in F*igure 5.1*, let us consider two sets of variables, observed and
    unobserved, namely, *X* and *Y* respectively. Variable *X*, in the figure, represents
    the collection of pixels from an image. Variable *Y* is discrete, and contains
    the possible categories of the object needed for classification. Variable *Y*
    in this case, consists of six possible values, namely: air-plane, animal, human,
    car, truck, and none of the above. The model is used as an energy function that
    will measure the correctness of the mapping between *X* and *Y*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The model uses a convention that small energy values imply highly related configuration
    of the variables. On the other hand, with the increasing energy values, the incompatibility
    of the variables also increases equally. The function that is related to both
    the *X* and *Y* variable is termed as energy function, denoted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Energy-based models](img/B05883_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the case of energy models, the input *X* is collected from the surroundings
    and the model generates an output Y, which is more likely to answer about the
    observed variable *X*. The model is required to produce the value *Y^/*, chosen
    from a set *Y**, which will make the value of the energy function *E(Y, X)* least.
    Mathematically, this is represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Energy-based models](img/image_05_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following *Figure 5.1* depicts the block diagram of the overall example
    mentioned in the preceding section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Energy-based models](img/image_05_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.1: Figure shows a energy model which computes the compatibility between
    the observed variable X and unobserved variable Y. X in the image is a set of
    pixel and Y is the set of level used for categorization of X. The model finds
    choosing ''Animal'' makes the values of energy function least. Image taken from
    [121]'
  prefs: []
  type: TYPE_NORMAL
- en: 'EBMs in deep learning are related to probability. Probability is proportional
    to *e* to the power of negative energy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Energy-based models](img/image_05_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: EBMs define probabilities indirectly by formulating the function *E(x)*. The
    exponential function makes sure that the probability will always be greater than
    zero. This also implies that in an energy-based model, one is always free to choose
    the energy function based on the observed and unobserved variables. Although the
    probabilities for a classification in an energy-based model can arbitrarily approach
    zero, it will never reach that.
  prefs: []
  type: TYPE_NORMAL
- en: Distribution in the form of the preceding equation is a form of Boltzmann distribution.
    The EBMs are hence often termed as **Boltzmann machines**. We will explain about
    Boltzmann machines and their various forms in the subsequent sections of this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Boltzmann machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Boltzmann machines [122] are a network of symmetrically connected, neuron-like
    units, which are used for stochastic decisions on the given datasets. Initially,
    they were introduced to learn the probability distributions over binary vectors.
    Boltzmann machines possess a simple learning algorithm, which helps them to infer
    and reach interesting conclusions about input datasets containing binary vectors.
    The learning algorithm becomes very slow in networks with many layers of feature
    detectors; however, with one layer of feature detector at a time, learning can
    be much faster.
  prefs: []
  type: TYPE_NORMAL
- en: To solve a learning problem, Boltzmann machines consist of a set of binary data
    vectors, and update the weight on the respective connections so that the data
    vectors turn out to be good solutions for the optimization problem laid by the
    weights. The Boltzmann machine, to solve the learning problem, makes lots of small
    updates to these weights.
  prefs: []
  type: TYPE_NORMAL
- en: "The Boltzmann machine over a d-dimensional binary vector can be defined as\
    \ *x \x88![Boltzmann machines](img/Belongs-t0.jpg) {0, 1} ^d*. As mentioned in\
    \ the earlier section, the Boltzmann machine is a type of energy-based function\
    \ whose joint probability function can be defined using the energy function given\
    \ as follows:"
  prefs: []
  type: TYPE_NORMAL
- en: '![Boltzmann machines](img/image_05_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *E(x)* is the energy function and *Z* is termed as a partition function
    that confirms *Î£[x ]P(x)= 1*. The energy function of the Boltzmann machine is
    given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Boltzmann machines](img/image_05_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *W* is the weight matrix of the model parameters and *b* is the vector
    of the bias parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Boltzmann machines such as EBMs work on observed and unobserved variables. The
    Boltzmann machine works more efficiently when the observed variables are not in
    higher numbers. In those cases, the unobserved or hidden variables behave like
    hidden units of multilayer perceptron and show higher order interactions among
    the visible units.
  prefs: []
  type: TYPE_NORMAL
- en: 'Boltzmann machines have interlayer connections between the hidden layers as
    well as between visible units. *Figure 5.2* shows a pictorial representation of
    the Boltzmann machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Boltzmann machines](img/image_05_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.2: Figure shows a graphical representation of a simple Boltzmann machine.
    The undirected edges in the figure signifies the dependency among nodes and w[i,j]
    represents the weight associated between nodes i and j. Figure shows 3 hidden
    nodes and 4 visible nodes'
  prefs: []
  type: TYPE_NORMAL
- en: An interesting property of the Boltzmann machine is that the learning rule does
    not change with the addition of hidden units. This eventually helps to learn the
    binary features to capture the higher-order structure in the input data.
  prefs: []
  type: TYPE_NORMAL
- en: The Boltzmann machine behaves as a universal approximator of probability mass
    function over discrete variables.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In statistical learning, **Maximize Likelihood Estimation** (**MLE**) is a procedure
    of finding the parameters of a statistical model given observations, by finding
    the value of one or more parameters, which maximizes the likelihood of making
    the observations with the parameters.
  prefs: []
  type: TYPE_NORMAL
- en: How Boltzmann machines learn
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The learning algorithms for Boltzmann machines are generally based on maximum
    likelihood estimation method. When Boltzmann machines are trained with learning
    rules based on maximum likelihood estimation, the update of a particular weight
    connecting two units of the model will depend on only those two units concerned.
    The other units of the network take part in modifying the statistics that get
    generated. Therefore, the weight can be updated without letting the rest of the
    network know. In other words, the rest of the network can only know the final
    statistics, but would not know how the statistics are computed.
  prefs: []
  type: TYPE_NORMAL
- en: Shortfall
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Boltzmann machines, with many hidden layers, the network becomes extremely
    large. This makes the model typically slow. The Boltzmann machine stops learning
    with large scale data, as the machine's size also simultaneously grows exponentially.
    With a large network, the weights are generally very large and also the equilibrium
    distribution becomes very high. This unfortunately creates a significant problem
    for Boltzmann machines, which eventually results in a longer time duration to
    reach to an equilibrium state of distribution.
  prefs: []
  type: TYPE_NORMAL
- en: This limitation can be overcome by restricting the connectivity between two
    layers, and thus simplifying the learning algorithm by learning one latent layer
    at a time.
  prefs: []
  type: TYPE_NORMAL
- en: Restricted Boltzmann machine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Restricted Boltzmann machine** (**RBM**) is a classic example of building
    blocks of deep probabilistic models that are used for deep learning. The RBM itself
    is not a deep model but can be used as a building block to form other deep models.
    In fact, RBMs are undirected probabilistic graphical models that consist of a
    layer of observed variables and a single layer of hidden variables, which may
    be used to learn the representation for the input. In this section, we will explain
    how the RBM can be used to build many deeper models.
  prefs: []
  type: TYPE_NORMAL
- en: Let us consider two examples to see the use case of RBM. RBM primarily operates
    on a binary version of factor analysis. Let us say we have a restaurant, and want
    to ask our customer to rate the food on a scale of 0 to 5\. In the traditional
    approach, we will try to explain each food item and customer in terms of the variable's
    hidden factors. For example, foods such as pasta and lasagne will have a strong
    association with the Italian factors. RBM, on the other hand, works on a different
    approach. Instead of asking each customer to rate the food items on a continuous
    scale, they simply mention whether they like it or not, and then RBM will try
    to infer various latent factors, which can help to explain the activation of food
    choices of each customer.
  prefs: []
  type: TYPE_NORMAL
- en: Another example could be to guess someone's movie choice based on the genre
    the person likes. Say Mr. X has supplied his five binary preferences on the set
    of movies given. The job of the RBM will be to activate his preferences based
    on the hidden units. So, in this case, the five movies will send messages to all
    the hidden units, asking them to update themselves. The RBM will then activate
    the hidden units with high probability based on some preferences given to the
    person earlier.
  prefs: []
  type: TYPE_NORMAL
- en: The basic architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The RBM is a shallow, two-layer neural network used as a building block to create
    deep models. The first layer of the RBM is called the observed or visible layer,
    the second layer is called the latent or hidden layer. It is a bipartite graph,
    with no interconnection allowed between any variables in the observed layer, or
    between any units in the latent layer. As shown in *Figure 5.3*, there is no intra-layer
    communication between the layers. Due to this restriction, the model is termed
    as a **Restricted Boltzmann machine**. Each node is used for computation that
    processed the input, and participated in the output by making stochastic (randomly
    determined) decisions about whether to convey that input or not.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A bipartite graph is a graph wherein the vertices can be split into two disjoint
    sets so that every edge connects a vertex of one set to the other. However, there
    is no connection between the vertices of the same set. The vertex sets are usually
    termed as a part of the graph.
  prefs: []
  type: TYPE_NORMAL
- en: The primary intuition behind the two layers of an RBM is that there are some
    visible random variables (for example, food reviews from different customers)
    and some latent variables (such as cuisines, nationality of the customers or other
    internal factors), and the task of training the RBM is to find the probability
    of how these two sets of variables are interconnected to each other.
  prefs: []
  type: TYPE_NORMAL
- en: To mathematically formulate the energy function of an RBM, let's denote the
    observed layer that consists of a set of *n[v]* binary variables collectively
    with the vector *v*. The hidden or latent layers of *n[h]* binary random variables
    are denoted as *h*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the Boltzmann machine, the RBM is also an energy-based model, where
    the joint probability distribution is determined by its energy function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The basic architecture](img/B05883_05_07.jpg)![The basic architecture](img/image_05_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.3: Figure shows a simple RBM. The model is a symmetric bipartite graph,
    where each hidden node is connected to every visible nodes. Hidden units are represented
    as h[i] and visible units as v[i]'
  prefs: []
  type: TYPE_NORMAL
- en: 'The energy function of an RBM with binary visible and latent units is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The basic architecture](img/B05883_05_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *a*, *b*, and *W* are unconstrained, learnable, real-valued parameters.
    From the preceding *Figure 5.3*, we can see that the model is split into two groups
    of variables, *v* and *h*. The interaction between the units is described by the
    matrix *W*.
  prefs: []
  type: TYPE_NORMAL
- en: How RBMs work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, as we are now aware of the basic architecture of an RBM, in this section,
    we will discuss the basic working procedure for this model. The RBM is fed with
    a dataset from which it should learn. Each visible node of the model receives
    a low-level feature from an item of the dataset. For example, for a gray-scale
    image, the lowest level item would be one pixel value of the image, which the
    visible node would receive. Therefore, if an image dataset has n number of pixels,
    the neural network processing them must also possess n input nodes on the visible
    layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How RBMs work](img/B05883_05_04-300x232.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.4 : Figure shows the computation of an RBM for a one input path'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's propagate one single pixel value, *p* through the two-layer network.
    At the first node of the hidden layer, *p* is multiplied by a weight *w*, and
    added to the bias. The final result is then fed into an activation function that
    generates the output of the node. The operation produces the outcome, which can
    be termed as the strength of the signal passing through that node, given an input
    pixel *p*. *Figure 5.4* shows the visual representation of the computation involved
    for a single input RBM.
  prefs: []
  type: TYPE_NORMAL
- en: '![How RBMs work](img/B05883_05_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Every visible node of the RBM is associated with a separate weight. Inputs
    from various units get combined at one hidden node. Each *p* (pixel) from the
    input is multiplied by a separate weight associated with it. The products are
    summed up and added to a bias. This result is passed through an activation function
    to generate the output of the node. The following *Figure 5.5* shows the visual
    representation of the computation involved for multiple inputs to the visible
    layer of RBMs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How RBMs work](img/B05883_05_05-300x232.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.5: Figure shows the computation of an RBM with multiple inputs and
    one hidden unit'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding *Figure 5.5* shows how the weight associated with every visible
    node is used to compute the final outcome from a hidden node.
  prefs: []
  type: TYPE_NORMAL
- en: '![How RBMs work](img/B05883_05_06-300x203.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.6: Figure shows the computation involved with multiple visible units
    and hidden units for an RBM'
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, RBMs are similar to a bipartitone graph. Further, the
    machine's structure is basically similar to a symmetrical bipartite graph because
    input received from all the visible nodes are being passed to all the latent nodes
    of the RBM.
  prefs: []
  type: TYPE_NORMAL
- en: 'For every hidden node, each input p gets multiplied with its respective weight
    *w*. Therefore, for a single input *p* and *m* number of hidden units, the input
    would have *m* weights associated with it. In *Figure 5.6*, the input *p* would
    have three weights, making a total of 12 weights altogether: four input nodes
    from the visible layer and three hidden nodes in the next layer. All the weights
    associated between the two layers form a matrix, where the rows are equal to the
    visible nodes, and the columns are equal to the hidden units. In the preceding
    figure, each hidden node of the second layer accepts the four inputs multiplied
    by their respective weights. The final sum of the products is then again added
    to a bias. This result is then passed through an activation algorithm to produce
    one output for each hidden layer. *Figure 5.6* represents the overall computations
    that occur in such scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: With a stacked RBM, it will form a deeper layer neural network, where the output
    of the first hidden layer would be passed to the next hidden layer as input. This
    will be propagated through as many hidden layers as one uses to reach the desired
    classifying layer. In the subsequent section, we will explain how to use an RBM
    as deep neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Restricted Boltzmann machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Very high dimensional inputs, such as images or videos, put immense stress on
    the memory, computation, and operational requirements of traditional machine learning
    models. In  [Chapter 3](ch03.html "Chapter 3.  Convolutional Neural Network")
    , *Convolutional Neural Network*, we have shown how replacing the matrix multiplication
    by discrete convolutional operations with small kernel resolves these problems.
    Going forward, Desjardins and Bengio [123] have shown that this approach also
    works fine when applied to RBMs. In this section, we will discuss the functionalities
    of this model.
  prefs: []
  type: TYPE_NORMAL
- en: '![Convolutional Restricted Boltzmann machines](img/B05883_05_07-266x300.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.7 : Figure shows the observed variables or the visible units of an
    RBM can be associated with mini batches of image to a compute the final result.
    The weight connections represents a set of filters'
  prefs: []
  type: TYPE_NORMAL
- en: Further, in normal RBMs, the visible units are directly related to all the hidden
    variables through different parameters and weights. To describe an image in terms
    of spatially local features ideally needs fewer parameters, which can be generalized
    better. This helps in detecting and extracting the identical and local features
    from a high dimensional image. Therefore, using an RBM to retrieve all the global
    features from an image for object detection is not so encouraging, especially
    for high dimensional images. One simple approach is to train the RBM on mini batches
    sampled from the input image, placed in blocks on Hadoop's Datanodes to generate
    the local features. The representation of this approach, termed as patch-based
    RBM is shown in *Figure 5.7*. This, however, has some potential limitations. The
    patch-based RBM, used in the distributed environment on Hadoop, does not follow
    the spatial relationship of mini batches, and sees each image's mini batches as
    independent patches from the nearby patches. This makes the feature extracted
    from the neighboring patches independent and somewhat significantly redundant.
  prefs: []
  type: TYPE_NORMAL
- en: To handle such a situation, a **Convolutional Restricted Boltzmann machine**
    (**CRBM**) is used, which is an extension of the traditional RBM model. The CRBM
    is structurally almost similar to RBM, a two-layer model in which the visible
    and hidden random variables are structured as matrices. Hence, in CRBM, the locality
    and neighborhood can be defined for both visible and hidden units. In CRBM, the
    visible matrix represents the image and the small windows of the matrix define
    the mini batches of the image. The hidden units of CRBM are partitioned into different
    feature maps to locate the presence of multiple features at multiple positions
    of the visible units. Units within a feature map represent the same feature at
    different locations of the visible unit. The hidden-visible connections of CRBM
    are completely local, and weights are generally split across the clusters of hidden
    units.
  prefs: []
  type: TYPE_NORMAL
- en: The CRBM's hidden units are used to extract features from the overlapping mini
    batches of visible units. Moreover, the features of neighboring mini batches complement
    each other and collaborate to model the input image.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5.8* shows a CRBM with a matrix of visible units **V** and a matrix
    of hidden units **H**, which are connected with *K 3*3* filters, namely, **W[1]**,
    **W[2]**, **W[3]**,...**W[K]**. The hidden units in the figure are split into
    **K** submatrices called feature map, **H[1]**, **H[2]**,...**H[K]**. Each hidden
    unit **H[i]** signifies the presence of a particular feature at a *3*3* neighborhood
    of visible units.'
  prefs: []
  type: TYPE_NORMAL
- en: A CRBM, unlike a patch-based RBM, is trained on the whole input image or a large
    region of the image, to learn the local features and exploit the spatial relationship
    of the overlapping mini batches, processed in a distributed manner on Hadoop.
    The hidden units of overlapping mini batches depend and cooperate with each other
    in a CRBM. Therefore, one hidden unit, once explained, does not need to be explained
    again in the neighborhood overlapping mini batch. This in turn helps in reducing
    the redundancy of the features.
  prefs: []
  type: TYPE_NORMAL
- en: '![Convolutional Restricted Boltzmann machines](img/B05883_05_08-267x300.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.8: The computation involved in a CRBM is shown in the figure'
  prefs: []
  type: TYPE_NORMAL
- en: Stacked Convolutional Restricted Boltzmann machines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CRBMs can be stacked together to form deep neural networks. **Stacked Convolutional
    Restricted Boltzmann machines **(**Stacked CRBMs**) can be trained layer wise,
    with a bottom-up approach, similar to the layer wise training of fully connected
    neural networks. After each CRBM filtering layer, in a stacked network, a deterministic
    subsampling method is implemented. For subsampling the features, max-pooling is
    performed in non-overlapping image regions. The pooling layer, as explained in
    [Chapter 3](ch03.html "Chapter 3.  Convolutional Neural Network") , *Convolutional
    Neural Network*, helps to minimize the dimensionality of the features. On top
    of that, it makes the feature robust to small shifts and helps to propagate the
    higher-level feature to grow over regions of the input image.
  prefs: []
  type: TYPE_NORMAL
- en: Deep CRBMs require a pooling operation, so that the spatial size of each successive
    layer decreases. Although, most of the traditional convolutional models work fine
    with inputs of a variety of spatial size, for Boltzmann machines it becomes somewhat
    difficult to change the input sizes, mainly due to a couple of reasons. Firstly,
    the partition function of the energy function changes with the size of input.
    Secondly, convolutional networks attain the size invariance by increasing the
    size of the pooling function proportional to the input size. However, scaling
    the pooling regions for Boltzmann machines is very difficult to achieve.
  prefs: []
  type: TYPE_NORMAL
- en: For CRBMs, the pixels residing at the boundary of the image also impose difficulty,
    which is worsened by the fact that Boltzmann machines are symmetric in nature.
    This can be nullified by implicitly zero-padding the input. Bear in mind that,
    zero-padding the input is often driven by lesser input pixels, which may not be
    activated when needed.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Belief networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Deep Belief networks** (**DBNs**) were one of the most popular, non-convolutional
    models that could be successfully deployed as deep neural networks in the year
    2006-07 [124] [125]. The renaissance of deep learning probably started from the
    invention of DBNs back in 2006\. Before the introduction of DBNs, it was very
    difficult to optimize the deep models. By outperforming the **Support Vector machines**
    (**SVMs**), DBNs had shown that deep models can be really successful; although,
    compared to the other generative or unsupervised learning algorithms, the popularity
    of DBNs has fallen a bit, and is rarely used these days. However, they still play
    a very important role in the history of deep learning.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A DBN with only one hidden layer is just an RBM.
  prefs: []
  type: TYPE_NORMAL
- en: DBNs are generative models composed of more than one layer of hidden variables.
    The hidden variables are generally binary in nature; however the visible units
    might consist of binary or real values. In DBNs, every unit of each layer is connected
    to every other unit of its neighbouring layer, although, there can be a DBN with
    sparsely connected units. There possess no connection between the intermediate
    layers. As shown in *Figure 5.9*, DBNs are basically a multilayer network composed
    of several RBMs. The connections between the top two layers are undirected. However,
    the connections between all other layers are directed, where the arrows point
    toward the layer nearest to the data.
  prefs: []
  type: TYPE_NORMAL
- en: Except for the first and last layer of the stack, each layer of a DBN serves
    two purposes. First, it acts as a hidden layer for its predecessor layer, and
    as a visible layer or input for its next layer. DBNs are mainly used to cluster,
    recognize and generate video sequences and images.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deep Belief networks](img/image_05_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.9: A DBN composed of three RBMs is shown in figure'
  prefs: []
  type: TYPE_NORMAL
- en: Greedy layer-wise training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A greedy layer-wise training algorithm for training DBNs was proposed in 2006
    [126]. This algorithm trains the DBN one layer at a time. In this approach, an
    RBM is first trained, which takes the actual data as input and models it.
  prefs: []
  type: TYPE_NORMAL
- en: A one-level DBN is an RBM. The core philosophy of greedy layer-wise approach
    is that after training the top-level RBM of an m-level DBN, the interpretation
    of the parameters changes while adding them in a (*m+1*) level DBN. In an RBM,
    between layers (*m-1*) and *m*, the probability distribution of layer *m* is defined
    in terms of the parameters of that RBM. However, in the case of a DBN, the probability
    distribution of layer *m* is defined in terms of the upper layer's parameters.
    This procedure can be repeated indefinitely, to connect with as many layers of
    DBNs as one desires.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed Deep Belief network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DBNs have so far achieved a lot in numerous applications such as speech and
    phone recognition [127], information retrieval [128], human motion modelling[129],
    and so on. However, the sequential implementation for both RBM and DBNs come with
    various limitations. With a large-scale dataset, the models show various shortcomings
    in their applications due to the long, time consuming computation involved, memory
    demanding nature of the algorithms, and so on. To work with Big data, RBMs and
    DBNs require distributed computing to provide scalable, coherent and efficient
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: To make DBNs acquiescent to the large-scale dataset stored on a cluster of computers,
    DBNs should acquire a distributed learning approach with Hadoop and Map-Reduce.
    The paper in [130] has shown a key-value pair approach for each level of an RBM,
    where the pre-training is accomplished with layer-wise, in a distributed environment
    in Map-Reduce framework. The learning is performed on Hadoop by an iterative computing
    method for the training RBM. Therefore, the distributed training of DBNs is achieved
    by stacking multiple RBMs.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed training of Restricted Boltzmann machines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As mentioned in the earlier sections, the energy function for an RBM is given
    by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Distributed training of Restricted Boltzmann machines](img/image_05_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let an input dataset *I = {x[i] = i= 1, 2,... N}* be used for the distributed
    learning of a RBM. As discussed in the earlier section, for the learning of a
    DBN, the weights and biases in each level of the RBM are initialized at first
    by using a greedy layer-wise unsupervised training. The purpose of the distributed
    training is to learn the weights and the associated biases *b* and *c*. For a
    distributed RBM using Map-Reduce, the one Map-Reduce job is essential in every
    epoch.
  prefs: []
  type: TYPE_NORMAL
- en: For matrix-matrix multiplication, Gibbs sampling is used, and for training of
    RBMs it takes most of the computation time. Therefore, to truncate the computation
    time for this, Gibbs sampling can be distributed in the map phase among multiple
    datasets running different Datanodes on the Hadoop framework.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Gibbs sampling is a **Markov chain Monte Carlo** (**MCMC**) algorithm for determining
    the sequence of observations that are estimated from a specified multivariate
    probability distribution, when traditional direct sampling becomes difficult.
  prefs: []
  type: TYPE_NORMAL
- en: Initially, different parameters needed for training, such as the number of neurons
    for visible and hidden layers, the input layer bias *a*, the hidden layer bias
    *b*, weight *W*, number of epochs (say *N*), learning rate, and so on, are initialized.
    The number of epochs signify that both the map and reduce phase will iterate for
    *N* number of times. For each epoch, the mapper runs for each block of the Datanodes,
    and performs Gibbs sampling to calculate the approximate gradients of *W*, *a*,
    and *b*. The reducer then updates those parameters with the computed increments
    needed for the next epoch. Hence, from the second epoch, the input value for the
    map phase, the updated values of *W*, *a*, and *b*, are calculated from the output
    of the reducer in the previous epoch.
  prefs: []
  type: TYPE_NORMAL
- en: The input dataset I is split into a number of chunks, and stored in different
    blocks, running on each Datanode. Each mapper running on the blocks will compute
    the approximate gradient of the weights and biases for a particular chunk stored
    on that block. The reducers then calculate the increments of respective parameters
    and update them accordingly. The process treats the resulting parameters and the
    updated values as the final outcome of the Map-Reduce phase of that particular
    epoch. After every epoch, the reducer decides whether to store the learned weight,
    if it is the final epoch or whether to increment the epoch index and propagate
    the key-value pair value to the next mapper.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed training of Deep Belief networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For distributed training of DBNs with *L* number of hidden layers, the learning
    is performed with pre-training *L* RBMs. The bottom level RBM is trained as discussed,
    however, for the rest of the (*L-1*) RBMs, the input dataset is changed for each
    level.
  prefs: []
  type: TYPE_NORMAL
- en: 'The input data for *m[th]* level (*L ![Distributed training of Deep Belief
    networks](img/greater-than-equal.jpg) ¥ m > 1*) RBM will be the conditional probability
    of hidden nodes of (*m-1*)[th] level RBMs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Distributed training of Deep Belief networks](img/Capture-9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Distributed back propagation algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is the second phase of distributed training of back propagation algorithm
    to tune the global network. In this procedure, while computing the gradient of
    weights, the feed-forward and back-propagation methods take up the majority of
    the computation time. Hence, for each epoch, for faster execution, this procedure
    should be run in parallel on each mini-batch of the input dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In the first step of the procedure, the learned weights for a *L* level DBN,
    namely, *W1*, *W2*,*...WL* are loaded into the memory, and other hyper-parameters
    are initialized. In this fine-tuning phase, the primary jobs for map and reduce
    phase are similar to that of the RBMs distributed training. The mapper will determine
    the gradients of the weights and eventually update the weight increment. The reducer
    updates the weight increments from one or more weights and passes the output to
    the mapper to perform the next iteration.
  prefs: []
  type: TYPE_NORMAL
- en: The main purpose of this procedure is to obtain some discriminative power of
    the model by placing the label layer on top of the global network and tuning the
    weights of the entire layers iteratively.
  prefs: []
  type: TYPE_NORMAL
- en: Performance evaluation of RBMs and DBNs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The paper [130] performed an experiment of distributed RBM and DBN on Hadoop
    cluster to provide a comparative study with the traditional sequential approach.
    The experiments were carried out on MNIST datasets for hand-written digits recognition.
    There were 60,000 images for the training set, and 10,000 images for the testing
    set. The block size of HDFS is set to 64 MB with a replication factor of 4\. All
    the nodes are set to run 26 mappers and 4 reducers maximum. Interested readers
    can modify the block size and replication factor to see the final results of the
    experiments with these parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Drastic improvement in training time
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The purpose of this experiment is to the compare the distributed RBMs and DBNs
    with the traditional training policy (sequential) in terms of training time. The
    sequential programs were performed on one CPU, whereas the distributed programs
    were on 16 CPUs of a node. Both the experiments were performed on the MNIST datasets
    mentioned earlier. The results obtained are summarized in *Table 5.1* and *Table
    5.2:*
  prefs: []
  type: TYPE_NORMAL
- en: '![Drastic improvement in training time](img/Capture-7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 5.1:The table represents the time needed to complete the training of distributed
    and sequential RBMs
  prefs: []
  type: TYPE_NORMAL
- en: '![Drastic improvement in training time](img/Capture-8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 5.2:The table represents the time needed to complete the training of distributed
    and sequential DBNs
  prefs: []
  type: TYPE_NORMAL
- en: The data shown in the table clearly depicts the advantages of using distributed
    RBMs and DBNs using Hadoop, over the traditional sequential approach. The training
    time for the distributed approach for the models has shown drastic improvement
    over the sequential one. Also, one crucial advantage of using the Hadoop framework
    for distribution is that it scales exceptionally well with the size of the training
    datasets, as well as the number of machines used to distribute it.
  prefs: []
  type: TYPE_NORMAL
- en: The next section of the chapter will demonstrate the programming approach for
    both the models using Deeplearning4j.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation using Deeplearning4j
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section of the chapter will provide a basic idea of how to write the code
    for RBMs and DBNs using Deeplearning4j. Readers will be able to learn the syntax
    for using the various hyperparameters mentioned in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement RBMs and DBNs using Deeplearning4j, the whole idea is very simple.
    The overall implementation can be split into three core phases: loading data or
    preparation of the data, network configuration, and training and evaluation of
    the model.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will first discuss RBMs on IrisDataSet, and then we will
    come to the implementation of DBNs.
  prefs: []
  type: TYPE_NORMAL
- en: Restricted Boltzmann machines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the building and training of RBMs, first we need to define and initialize
    the hyperparameter needed for the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The batchsize here can be initialized as `150`, which means `150` samples of
    the dataset will be submitted to the Hadoop framework at a time. Rest assured
    all other parameters are initialized just as we did it in the earlier chapters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next phase, the Irisdataset is loaded into the system based on the defined
    `batchsize` and number of samples per batch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the RBM is created as a layer using `NeuralNetConfiguration.Builder()`.
    Similarly, the object of Restricted Boltzmann is used to store properties such
    as the transforms applied to the observed and hidden layer - Gaussian and Rectified
    Linear Transforms, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`ReLU` is used for activation function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`weightInit()` function is used for initialization of the weight, which represents
    the starting value of the coefficients needed to amplify the input signal coming
    into each node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Gaussian Transformation is used for visible units and Rectified Linear Transformation
    is used for hidden layers. This is very simple in Deeplearning4j. We need to pass
    the parameters `VisibleUnit`.`GAUSSIAN` and `HiddenUnit.RECTIFIED` inside the
    `.visibleUnit` and `.hiddenUnit` methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The Backpropagation step size is defined here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'To scale to dataset, `scale()` can be called with the object of the Dataset
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'After the evaluation was done in the earlier process, the model is now completely
    ready to be trained. It can be trained in a similar manner using the `fit()` method,
    as done for the earlier models, and passing `getFeatureMatrix` as the parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Deep Belief networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As explained in this chapter, a DBN is a stacked version of the number of RBMs.
    In this part, we will show how to deploy DBNs programmatically using Deeplearning4j.
    The flow of the program will follow the standard procedure as with other models.
    The implementation of simple DBNs is pretty simple using Deeplearning4j. The example
    will show how to train and traverse the input MNIST data with DBNs.
  prefs: []
  type: TYPE_NORMAL
- en: 'For MNIST dataset, the following line specifies the batchsize and number of
    examples, which one user will specify to load the data in HDFS at one time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next phase, the model will be built by stacking 10 RBMs together. The
    following piece of code will specify the way this should be done using Deeplearning4j:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In the last part, the code will be trained using the loaded MNIST dataset,
    by calling the `fit()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon executing the code, the process will give a following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The RBM is a generative model, which can randomly produce visible data values
    when some latent or hidden parameters are supplied to it. In this chapter, we
    have discussed the concept and mathematical model of the Boltzmann machine, which
    is an energy-based model. The chapter then discusses and gives a visual representation
    of the RBM. Further, this chapter discusses CRBM, which is a combination of Convolution
    and RBMs to extract the features of high dimensional images. We then moved toward
    popular DBNs that are nothing but a stacked implementation of RBMs. The chapter
    further discusses the approach to distribute the training of RBMs as well as DBNs
    in the Hadoop framework.
  prefs: []
  type: TYPE_NORMAL
- en: We conclude the chapter by providing code samples for both the models. The next
    chapter of the book will introduce one more generative model called autoencoder
    and its various forms such as de-noising autoencoder, deep autoencoder, and so
    on.
  prefs: []
  type: TYPE_NORMAL
