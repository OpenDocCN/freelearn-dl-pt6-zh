["```py\n    from google.colab import drive\n    drive.mount('/content/drive')\n    ```", "```py\n    cd /content/drive/My Drive/C13550/Lesson02/Exercise04/\n    ```", "```py\n    import cv2\n    from matplotlib import pyplot as plt\n    ```", "```py\n    img = cv2.imread('subway.jpg',0)\n    plt.imshow(img,cmap='gray')\n    plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\n    _,thresh1 = cv2.threshold(img,107,255,cv2.THRESH_BINARY)\n    _,thresh2 = cv2.threshold(img,107,255,cv2.THRESH_BINARY_INV) \n    _,thresh3 = cv2.threshold(img,107,255,cv2.THRESH_TRUNC) \n    _,thresh4 = cv2.threshold(img,107,255,cv2.THRESH_TOZERO)\n    _,thresh5 = cv2.threshold(img,107,255,cv2.THRESH_TOZERO_INV) \n    titles = ['Original Image','BINARY', 'BINARY_INV', 'TRUNC','TOZERO','TOZERO_INV']\n    images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n    for i in range(6):\n        plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n        plt.title(titles[i])\n        plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\n    th2=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,71,7)\n    th3=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,71,7)\n    titles = ['Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n    images = [th2, th3]\n    for i in range(2):\n        plt.subplot(1,2,i+1),plt.imshow(images[i],'gray')\n        plt.title(titles[i])\n        plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\n    ret2,th=cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    titles = ['Otsu\\'s Thresholding']\n    images = [th]\n    for i in range(1):\n        plt.subplot(1,1,i+1),plt.imshow(images[i],'gray')\n        plt.title(titles[i])\n        plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\n    cd /content/drive/My Drive/C13550/Lesson02/Exercise05/\n    ```", "```py\n    import cv2\n    import numpy as np\n    from matplotlib import pyplot as plt\n    ```", "```py\n    img = cv2.imread('Dataset/three.png',0)\n    plt.imshow(img,cmap='gray')\n    plt.xticks([]),plt.yticks([])\n    plt.savefig('ex2_1.jpg', bbox_inches='tight')\n    plt.show()\n    ```", "```py\n    kernel = np.ones((2,2),np.uint8)\n    erosion = cv2.erode(img,kernel,iterations = 1)\n    plt.imshow(erosion,cmap='gray')\n    plt.xticks([]),plt.yticks([])\n    plt.savefig('ex2_2.jpg', bbox_inches='tight')\n    plt.show()\n    ```", "```py\n    kernel = np.ones((2,2),np.uint8)\n    dilation = cv2.dilate(img,kernel,iterations = 1)\n    plt.imshow(dilation,cmap='gray')\n    plt.xticks([]),plt.yticks([])\n    plt.savefig('ex2_3.jpg', bbox_inches='tight')\n    plt.show()\n    ```", "```py\n    import random\n    random.seed(42)\n    def sp_noise(image,prob):\n        '''\n        Add salt and pepper noise to image\n        prob: Probability of the noise\n        '''\n        output = np.zeros(image.shape,np.uint8)\n        thres = 1 - prob \n        for i in range(image.shape[0]):\n            for j in range(image.shape[1]):\n                rdn = random.random()\n                if rdn < prob:\n                    output[i][j] = 0\n                elif rdn > thres:\n                    output[i][j] = 255\n                else:\n                    output[i][j] = image[i][j]\n        return output\n    def sp_noise_on_figure(image,prob):\n        '''\n        Add salt and pepper noise to image\n        prob: Probability of the noise\n        '''\n        output = np.zeros(image.shape,np.uint8)\n        thres = 1 - prob \n        for i in range(image.shape[0]):\n            for j in range(image.shape[1]):\n                rdn = random.random()\n                if rdn < prob:\n                    if image[i][j] > 100:\n                        output[i][j] = 0\n                else:\n                    output[i][j] = image[i][j]\n        return output\n    kernel = np.ones((2,2),np.uint8) \n    # Create thicker figure to work with\n    dilation = cv2.dilate(img, kernel, iterations = 1)\n    # Create noisy image\n    noise_img = sp_noise(dilation,0.05)\n    # Create image with noise in the figure\n    noise_img_on_image = sp_noise_on_figure(dilation,0.15)\n    # Apply Opening to image with normal noise\n    opening = cv2.morphologyEx(noise_img, cv2.MORPH_OPEN, kernel)\n    # Apply Closing to image with noise in the figure\n    closing = cv2.morphologyEx(noise_img_on_image, cv2.MORPH_CLOSE, kernel)\n    images = [noise_img,opening,noise_img_on_image,closing]\n    for i in range(4):\n        plt.subplot(1,4,i+1),plt.imshow(images[i],'gray')\n        plt.xticks([]),plt.yticks([])\n    plt.savefig('ex2_4.jpg', bbox_inches='tight')\n    plt.show()\n    ```", "```py\n    cd /content/drive/My Drive/C13550/Lesson02/Exercise06/\n    ```", "```py\n    import cv2\n    from matplotlib import pyplot as plt\n    import numpy as np\n    ```", "```py\n    img = cv2.imread('Dataset/subway.jpg')\n    #Method to convert the image to RGB\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.savefig('ex3_1.jpg', bbox_inches='tight')\n    plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\n    blur = cv2.blur(img,(51,51)) # Apply normal Blurring\n    blurG = cv2.GaussianBlur(img,(51,51),0) # Gaussian Blurring\n    median = cv2.medianBlur(img,51) # Median Blurring\n    titles = ['Original Image','Averaging', 'Gaussian Blurring', 'Median Blurring']\n    images = [img, blur, blurG, median]\n    for i in range(4):\n        plt.subplot(2,2,i+1),plt.imshow(images[i])\n        plt.title(titles[i])\n        plt.xticks([]),plt.yticks([])\n    plt.savefig('ex3_2.jpg', bbox_inches='tight')\n    plt.show()\n    ```", "```py\n    cd /content/drive/My Drive/C13550/Lesson02/Exercise07/\n    ```", "```py\n    import numpy as np  #Numpy\n    import cv2          #OpenCV\n    from matplotlib import pyplot as plt #Matplotlib\n    count = 0\n    ```", "```py\n    img = cv2.imread('Dataset/number.jpg',0)\n    plt.imshow(img,cmap='gray')\n    plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\n    _,th1=cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU\n    th1 = (255-th1) \n    # This step changes the black with white and vice versa in order to have white figures\n    plt.imshow(th1,cmap='gray')\n    plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\n    open1 = cv2.morphologyEx(th1, cv2.MORPH_OPEN, np.ones((4, 4),np.uint8))\n    plt.imshow(open1,cmap='gray')\n    plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\n    close1 = cv2.morphologyEx(open1, cv2.MORPH_CLOSE, np.ones((8, 8), np.uint8))\n    plt.imshow(close1,cmap='gray')\n    plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\n    open2 = cv2.morphologyEx(close1, cv2.MORPH_OPEN,np.ones((7,12),np.uint8))\n    plt.imshow(open2,cmap='gray')\n    plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\n    _, contours, _ = cv2.findContours(open2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) #Find contours\n    cntsSorted = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True) #Sort the contours\n    cntsLength = len(cntsSorted)\n    images = []\n    for idx in range(cntsLength): #Iterate over the contours\n    \tx, y, w, h = cv2.boundingRect(contour_no) #Get its position and size\n    \t... # Rest of the code in Github\n    \timages.append([x,sample_no]) #Add the image to the list of images and the X position\n    images = sorted(images, key=lambda x: x[0]) #Sort the list of images using the X position\n    {…}\n    ```", "```py\nfrom sklearn.tree import DecisionTreeClassifier\ndtree=DecisionTreeClassifier()\ndtree.fit(x,y)\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\nrndForest=RandomForestClassifier(n_estimators=10)\nrndForest.fit(x,y)\n```", "```py\nfrom sklearn.ensemble import AdaBoostClassifier\nadaboost=AdaBoostClassifier(n_estimators=100)\nadaboost.fit(x_train, y_train)\n```", "```py\nAdaBoostClassifier(RandomForestClassifier(n_jobs=-1,n_estimators=500,max_features='auto'),n_estimators=100)\n```", "```py\n    import numpy as np\n    import random\n    from sklearn import metrics\n    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n    from sklearn.tree import DecisionTreeClassifier\n    from sklearn.utils import shuffle\n    from matplotlib import pyplot as plt\n    import cv2\n    import os\n    import re\n    random.seed(42)\n    ```", "```py\n    from keras.datasets import mnist\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    ```", "```py\n    for idx in range(5):\n        rnd_index = random.randint(0, 59999)\n        plt.subplot(1,5,idx+1),plt.imshow(x_train[idx],'gray')\n        plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\n    # ---------------------------------------------------------\n    def list_files(directory, ext=None):\n        return [os.path.join(directory, f) for f in os.listdir(directory)\n                if os.path.isfile(os.path.join(directory, f)) and ( ext==None or re.match('([\\w_-]+\\.(?:' + ext + '))', f) )]\n       # -------------------------------------------------------\n    def load_images(path,label):\n        X = []\n        Y = []\n        label = str(label)\n        for fname in list_files( path, ext='jpg' ): \n            img = cv2.imread(fname,0)\n            img = cv2.resize(img, (28, 28))\n            X.append(img)\n            Y.append(label)\n        if maximum != -1 :\n            X = X[:maximum]\n            Y = Y[:maximum]\n        X = np.asarray(X)\n        Y = np.asarray(Y)\n        return X, Y\n    ```", "```py\n    print(x_train.shape)\n    print(x_test.shape)\n    X, Y = load_images('Dataset/%d'%(0),0,9)\n    for digit in range(1,10):\n      X_aux, Y_aux = load_images('Dataset/%d'%(digit),digit,9)\n      print(X_aux.shape)\n      X = np.concatenate((X, X_aux), axis=0)\n      Y = np.concatenate((Y, Y_aux), axis=0)\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    x_tr, x_te, y_tr, y_te = train_test_split(X, Y, test_size=0.2)\n    ```", "```py\n    x_train = np.concatenate((x_train, x_tr), axis=0)\n    y_train = np.concatenate((y_train, y_tr), axis=0)\n    x_test = np.concatenate((x_test, x_te), axis=0)\n    y_test = np.concatenate((y_test, y_te), axis=0)\n    print(x_train.shape)\n    print(x_test.shape)\n    ```", "```py\n    x_train = x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2])\n    x_test = x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2])\n    print(x_train.shape)\n    print(x_test.shape)\n    ```", "```py\n    print (\"Applying Decision Tree...\")\n    dtc = DecisionTreeClassifier()\n    dtc.fit(x_train, y_train)\n    ```", "```py\n    y_pred = dtc.predict(x_test)\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n    print(accuracy*100)\n    ```", "```py\n    print (\"Applying RandomForest...\")\n    rfc = RandomForestClassifier(n_estimators=100)\n    rfc.fit(x_train, y_train)\n    ```", "```py\n    print (\"Applying Adaboost...\")\n    adaboost = AdaBoostClassifier(rfc,n_estimators=10)\n    adaboost.fit(x_train, y_train)\n    ```", "```py\n    for number in range(5):\n        imgLoaded = cv2.imread('number%d.jpg'%(number),0)\n        img = cv2.resize(imgLoaded, (28, 28))\n        img = img.flatten()\n        img = img.reshape(1,-1)\n        plt.subplot(1,5,number+1),\n        plt.imshow(imgLoaded,'gray')\n        plt.title(rfc.predict(img)[0])\n        plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\nx_train = (x_train.astype(np.float32))/255.0 #Converts to float and then normalize\nx_test = (x_test.astype(np.float32))/255.0 #Same for the test set\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n```", "```py\ny_train = np_utils.to_categorical(y_train, 10)\ny_test = np_utils.to_categorical(y_test, 10)\n```", "```py\nmodel = Sequential()\nmodel.add(Dense(16, input_shape=input_shape))\nmodel.add(Activation('relu'))\nmodel.add(Dense(8))\nmodel.add(Activation('relu'))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation=\"softmax\"))\n```", "```py\nmodel.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['accuracy'])\n```", "```py\nckpt = ModelCheckpoint('model.h5', save_best_only=True,monitor='val_loss', mode='min', save_weights_only=False)\n```", "```py\nmodel.fit(x_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(x_test, y_test),callbacks=[ckpt])\n```", "```py\n    from keras.callbacks import ModelCheckpoint\n    from keras.layers import Dense, Flatten, Activation, BatchNormalization, Dropout\n    from keras.models import Sequential\n    from keras.optimizers import Adadelta\n    from keras import utils as np_utils\n    ```", "```py\n    x_train = (x_train.astype(np.float32))/255.0\n    x_test = (x_test.astype(np.float32))/255.0\n    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n    y_train = np_utils.to_categorical(y_train, 10)\n    y_test = np_utils.to_categorical(y_test, 10)\n    input_shape = x_train.shape[1:]\n    print(input_shape)\n    print(x_train.shape)\n    ```", "```py\n    def DenseNN(input_shape):\n        model = Sequential()\n        model.add(Dense(512, input_shape=input_shape))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.2))\n        model.add(Dense(512))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.2))\n        model.add(Dense(256))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.2))\n        model.add(Flatten())\n        model.add(Dense(256))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.2))\n        model.add(Dense(10, activation=\"softmax\"))\n    ```", "```py\n    model.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['accuracy'])\n    ```", "```py\n    ckpt = ModelCheckpoint('Models/model.h5', save_best_only=True,monitor='val_loss', mode='min', save_weights_only=False)\n    ```", "```py\n    model.fit(x_train, y_train, \n              batch_size=64,\n              epochs=10,\n              verbose=1,\n              validation_data=(x_test, y_test),\n              callbacks=[ckpt])\n    ```", "```py\n    for number in range(5):\n        imgLoaded = cv2.imread('number%d.jpg'%(number),0)\n        img = cv2.resize(imgLoaded, (28, 28))\n        img = (img.astype(np.float32))/255.0\n        img = img.reshape(1, 28, 28, 1)\n        plt.subplot(1,5,number+1),plt.imshow(imgLoaded,'gray')\n        plt.title(np.argmax(model.predict(img)[0]))\n        plt.xticks([]),plt.yticks([])\n    plt.show()\n    ```", "```py\n    from keras.datasets import fashion_mnist\n    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n    ```"]