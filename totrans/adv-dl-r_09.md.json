["```py\n# Libraries\nlibrary(keras)\nlibrary(EBImage)\n\n# Fashion-MNIST data\nmnist <- dataset_fashion_mnist() \nstr(mnist)\nList of 2\n $ train:List of 2\n  ..$ x: int [1:60000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ y: int [1:60000(1d)] 9 0 0 3 0 2 7 2 5 5 ...\n $ test :List of 2\n  ..$ x: int [1:10000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ y: int [1:10000(1d)] 9 2 1 1 6 1 4 6 5 7 ...\n```", "```py\n# Train and test data\ntrainx <- mnist$train$x\ntestx <- mnist$test$x\n\n# Plot of 64 images\npar(mfrow = c(8,8), mar = rep(0, 4))\nfor (i in 1:64) plot(as.raster(trainx[i,,], max = 255))\n```", "```py\n# Reshape images\ntrainx <- array_reshape(trainx, c(nrow(trainx), 28, 28, 1))\ntestx <- array_reshape(testx, c(nrow(testx), 28, 28, 1))\ntrainx <- trainx / 255\ntestx <- testx / 255\n```", "```py\n# Encoder\ninput_layer <- \n         layer_input(shape = c(28,28,1)) \nencoder <-  input_layer %>% \n         layer_conv_2d(filters = 8, \n                       kernel_size = c(3,3), \n                       activation = 'relu', \n                       padding = 'same') %>%   \n         layer_max_pooling_2d(pool_size = c(2,2),\n                              padding = 'same') %>% \n         layer_conv_2d(filters = 4, \n                       kernel_size = c(3,3), \n                       activation = 'relu', \n                       padding = 'same') %>%  \n         layer_max_pooling_2d(pool_size = c(2,2), \n                              padding = 'same')  \nsummary(encoder)\nOutput\nTensor(\"max_pooling2d_10/MaxPool:0\", shape=(?, 7, 7, 4), dtype=float32)\n```", "```py\n# Decoder\ndecoder <- encoder %>% \n         layer_conv_2d(filters = 4, \n                       kernel_size = c(3,3), \n                       activation = 'relu',\n                       padding = 'same') %>%   \n         layer_upsampling_2d(c(2,2)) %>% \n         layer_conv_2d(filters = 8, \n                       kernel_size = c(3,3), \n                       activation = 'relu',\n                       padding = 'same') %>%  \n         layer_upsampling_2d(c(2,2)) %>% \n         layer_conv_2d(filters = 1, \n                       kernel_size = c(3,3), \n                       activation = 'sigmoid',\n                       padding = 'same')\nsummary(decoder)\nOutput\nTensor(\"conv2d_25/Sigmoid:0\", shape=(?, 28, 28, 1), dtype=float32)\n```", "```py\n# Autoencoder\nae_model <- keras_model(inputs = input_layer, outputs = decoder)\nsummary(ae_model)\n__________________________________________________________________________\nLayer (type)                      Output Shape               Param #       \n==========================================================================\ninput_5 (InputLayer)              (None, 28, 28, 1)            0             \n__________________________________________________________________________\nconv2d_21 (Conv2D)                (None, 28, 28, 8)            80            \n__________________________________________________________________________\nmax_pooling2d_9 (MaxPooling2D)    (None, 14, 14, 8)             0             \n__________________________________________________________________________\nconv2d_22 (Conv2D)                (None, 14, 14, 4)            292           \n__________________________________________________________________________\nmax_pooling2d_10 (MaxPooling2D)   (None, 7, 7, 4)               0             \n__________________________________________________________________________\nconv2d_23 (Conv2D)                (None, 7, 7, 4)              148           \n___________________________________________________________________________\nup_sampling2d_9 (UpSampling2D)    (None, 14, 14, 4)             0             \n___________________________________________________________________________\nconv2d_24 (Conv2D)                (None, 14, 14, 8)            296           \n___________________________________________________________________________\nup_sampling2d_10 (UpSampling2D)   (None, 28, 28, 8)             0             \n___________________________________________________________________________\nconv2d_25 (Conv2D)                (None, 28, 28, 1)             73           \n===========================================================================\nTotal params: 889\nTrainable params: 889\nNon-trainable params: 0\n____________________________________________________________________________________\n```", "```py\n# Compile model\nae_model %>% compile( loss='mean_squared_error',\n         optimizer='adam')\n\n# Fit model\nmodel_one <- ae_model %>% fit(trainx, \n                         trainx, \n                         epochs = 20, \n                         shuffle=TRUE,\n                         batch_size = 32, \n                         validation_data = list(testx,testx))\n```", "```py\n# Reconstruct and plot images - train data\nrc <-   ae_model %>%    keras::predict_on_batch(x = trainx)\npar(mfrow = c(2,5), mar = rep(0, 4))\nfor (i in 1:5) plot(as.raster(trainx[i,,,]))\nfor (i in 1:5) plot(as.raster(rc[i,,,]))\n```", "```py\n# Reconstruct and plot images - train data\nrc <- ae_model %>% keras::predict_on_batch(x = testx) \npar(mfrow = c(2,5), mar = rep(0, 4)) \nfor (i in 1:5) plot(as.raster(testx[i,,,])) \nfor (i in 1:5) plot(as.raster(rc[i,,,]))\n```", "```py\n# MNIST data\nmnist <- dataset_mnist()\nstr(mnist)\nList of 2\n $ train:List of 2\n  ..$ x: int [1:60000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ y: int [1:60000(1d)] 5 0 4 1 9 2 1 3 1 4 ...\n $ test :List of 2\n  ..$ x: int [1:10000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ y: int [1:10000(1d)] 7 2 1 0 4 1 4 9 5 9 ...\n```", "```py\n# Train and test data\ntrainx <- mnist$train$x\ntestx <- mnist$test$x\n\n# Plot\npar(mfrow = c(8,8), mar = rep(0, 4))\nfor (i in 1:64) plot(as.raster(trainx[i,,], max = 255))\n```", "```py\n# Reshape\ntrainx <- array_reshape(trainx, c(nrow(trainx),28,28,1))\ntestx <- array_reshape(testx, c(nrow(testx),28,28,1))\ntrainx <- trainx / 255\ntestx <- testx / 255\n```", "```py\n# Random numbers from uniform distribution\nn <- runif(60000*28*28,0,1)\nn <- array_reshape(n, c(60000,28,28,1))\n\n# Plot\npar(mfrow = c(8,8), mar = rep(0, 4))\nfor (i in 1:64) plot(as.raster(n[i,,,]))\n```", "```py\n# Adding noise to handwritten images - train data\ntrainn <- (trainx + n)/2\npar(mfrow = c(8,8), mar = rep(0, 4))\nfor (i in 1:64) plot(as.raster(trainn[i,,,]))\n```", "```py\n# Adding noise to handwritten images - test data\nn1 <- runif(10000*28*28,0,1) \nn1 <- array_reshape(n1, c(10000,28,28,1)) \ntestn <- (testx +n1)/2\n```", "```py\n# Encoder\ninput_layer <- \n         layer_input(shape = c(28,28,1)) \nencoder <-  input_layer %>% \n         layer_conv_2d(filters = 32, \n                       kernel_size = c(3,3), \n                       activation = 'relu', \n                       padding = 'same') %>%   \n         layer_max_pooling_2d(pool_size = c(2,2),\n                              padding = 'same') %>% \n         layer_conv_2d(filters = 32, \n                       kernel_size = c(3,3), \n                       activation = 'relu', \n                       padding = 'same') %>%  \n         layer_max_pooling_2d(pool_size = c(2,2), \n                              padding = 'same') \nsummary(encoder)\nOutputTensor(\"max_pooling2d_6/MaxPool:0\", shape=(?, 7, 7, 32), dtype=float32)\n```", "```py\n# Decoder\ndecoder <- encoder %>% \n         layer_conv_2d(filters = 32, \n                       kernel_size = c(3,3), \n                       activation = 'relu',\n                       padding = 'same') %>%   \n         layer_upsampling_2d(c(2,2)) %>% \n         layer_conv_2d(filters = 32, \n                       kernel_size = c(3,3), \n                       activation = 'relu',\n                       padding = 'same') %>%  \n         layer_upsampling_2d(c(2,2)) %>% \n         layer_conv_2d(filters = 1, \n                       kernel_size = c(3,3), \n                       activation = 'sigmoid',\n                       padding = 'same')\nsummary(decoder)\nOutput\nTensor(\"conv2d_15/Sigmoid:0\", shape=(?, 28, 28, 1), dtype=float32)\n```", "```py\n# Autoencoder\nae_model <- keras_model(inputs = input_layer, outputs = decoder)\nsummary(ae_model)\n\n______________________________________________________________________\nLayer (type)                    Output Shape             Param #       \n======================================================================\ninput_3 (InputLayer)           (None, 28, 28, 1)           0             \n______________________________________________________________________\nconv2d_11 (Conv2D)             (None, 28, 28, 32)         320           \n______________________________________________________________________\nmax_pooling2d_5 (MaxPooling2D) (None, 14, 14, 32)          0             \n_______________________________________________________________________\nconv2d_12 (Conv2D)             (None, 14, 14, 32)         9248          \n_______________________________________________________________________\nmax_pooling2d_6 (MaxPooling2D) (None, 7, 7, 32)            0             \n_______________________________________________________________________\nconv2d_13 (Conv2D)             (None, 7, 7, 32)           9248          \n_______________________________________________________________________\nup_sampling2d_5 (UpSampling2D) (None, 14, 14, 32)          0             \n_______________________________________________________________________\nconv2d_14 (Conv2D)             (None, 14, 14, 32)         9248          \n_______________________________________________________________________\nup_sampling2d_6 (UpSampling2D) (None, 28, 28, 32)          0             \n________________________________________________________________________\nconv2d_15 (Conv2D)             (None, 28, 28, 1)           289           \n========================================================================\nTotal params: 28,353\nTrainable params: 28,353\nNon-trainable params: 0\n________________________________________________________________________\n```", "```py\n# Compile model\nae_model %>% compile( loss='binary_crossentropy', optimizer='adam')\n```", "```py\n# Fit model\nmodel_two <- ae_model %>% fit(trainn, \n                         trainx, \n                         epochs = 100, \n                         shuffle = TRUE,\n                         batch_size = 128,  \n                        validation_data = list(testn,testx))\n```", "```py\n# Loss for train data\nae_model %>% evaluate(trainn, trainx)\n      loss \n0.07431865\n\n# Loss for test data\nae_model %>% evaluate(testn, testx)\n      loss \n0.07391542\n```", "```py\n# Reconstructing images - train data\nrc <- ae_model %>%   keras::predict_on_batch(x = trainn)\n\n# Plot\npar(mfrow = c(8,8), mar = rep(0, 4))\nfor (i in 1:64) plot(as.raster(rc[i,,,]))\n```", "```py\n# Reconstructing images - test data\nrc <- ae_model %>% keras::predict_on_batch(x = testn) \npar(mfrow = c(8,8), mar = rep(0, 4)) \nfor (i in 1:64) plot(as.raster(rc[i,,,]))\n```", "```py\n# Reading images and image processing\nsetwd(\"~/Desktop/peoplex\")\ntemp = list.files(pattern=\"*.jpeg\")\nmypic <- list()\nfor (i in 1:length(temp)) {mypic[[i]] <- readImage(temp[i])}\nfor (i in 1:length(temp)) {mypic[[i]] <- resize(mypic[[i]], 128, 128)}\nfor (i in 1:length(temp)) {dim(mypic[[i]]) <- c(128, 128,3)}\n```", "```py\n# Combine and plot images\ntrainx <- combine(mypic)\nstr(trainx)\nFormal class 'Image' [package \"EBImage\"] with 2 slots\n  ..@ .Data    : num [1:128, 1:128, 1:3, 1:16] 0.04435 0 0.00357 0.05779 0.05815 ...\n  ..@ colormode: int 2\ntrainx <- aperm(trainx, c(4,1,2,3)\npar(mfrow = c(4,4), mar = rep(0, 4))\nfor (i in 1:16) plot(as.raster(trainx[i,,,]))\n```", "```py\n# Read image files without black line\nsetwd(\"~/Desktop/people\")\ntemp = list.files(pattern=\"*.jpg\")\nmypic <- list()\nfor (i in 1:length(temp)) {mypic[[i]] <- readImage(temp[i])}\nfor (i in 1:length(temp)) {mypic[[i]] <- resize(mypic[[i]], 128, 128)}\nfor (i in 1:length(temp)) {dim(mypic[[i]]) <- c(128, 128,3)}\ntrainy <- combine(mypic)\ntrainy <- aperm(trainy, c(4,1,2,3))\npar(mfrow = c(4,4), mar = rep(0, 4))\nfor (i in 1:16) plot(as.raster(trainy[i,,,]))\npar(mfrow = c(1,1))\n```", "```py\n# Encoder network\ninput_layer <- layer_input(shape = c(128,128,3)) \nencoder <-  input_layer %>% \n         layer_conv_2d(filters = 512, kernel_size = c(3,3), activation = 'relu', padding = 'same') %>%   \n         layer_max_pooling_2d(pool_size = c(2,2),padding = 'same') %>% \n         layer_conv_2d(filters = 512, kernel_size = c(3,3), activation = 'relu', padding = 'same') %>%   \n         layer_max_pooling_2d(pool_size = c(2,2),padding = 'same') %>% \n         layer_conv_2d(filters = 256, kernel_size = c(3,3), activation = 'relu', padding = 'same') %>%  \n         layer_max_pooling_2d(pool_size = c(2,2), padding = 'same')  \nsummary(encoder)\nOutput\nTensor(\"max_pooling2d_22/MaxPool:0\", shape=(?, 16, 16, 256), dtype=float32)\n```", "```py\n# Decoder network\ndecoder <- encoder %>% \n         layer_conv_2d(filters = 256, kernel_size = c(3,3), activation = 'relu',padding = 'same') %>%   \n         layer_upsampling_2d(c(2,2)) %>% \n         layer_conv_2d(filters = 512, kernel_size = c(3,3), activation = 'relu',padding = 'same') %>%   \n         layer_upsampling_2d(c(2,2)) %>% \n         layer_conv_2d(filters = 512, kernel_size = c(3,3), activation = 'relu',padding = 'same') %>%  \n         layer_upsampling_2d(c(2,2)) %>% \n         layer_conv_2d(filters = 3, kernel_size = c(3,3), activation = 'sigmoid',padding = 'same')\nsummary(decoder)\nOutput\nTensor(\"conv2d_46/Sigmoid:0\", shape=(?, 128, 128, 3), dtype=float32)\n```", "```py\n# Compile and fit model\nae_model <- keras_model(inputs = input_layer, outputs = decoder)\nae_model %>% compile( loss='mse',\n         optimizer='adam')\nmodel_three <- ae_model %>% fit(trainx, \n                         trainy, \n                         epochs = 100, \n                         batch_size = 128, \n                         validation_split = 0.2)\nplot(model_three)\n```", "```py\n# Reconstructing images - training\nrc <- ae_model %>%  keras::predict_on_batch(x = trainx)\npar(mfrow = c(5,5), mar = rep(0, 4))\nfor (i in 1:25) plot(as.raster(rc[i,,,]))\n```", "```py\n# 25 new images\nsetwd(\"~/Desktop/newx\")\ntemp = list.files(pattern=\"*.jpg\")\nmypic <- list()\nfor (i in 1:length(temp)) {mypic[[i]] <- readImage(temp[i])}\nfor (i in 1:length(temp)) {mypic[[i]] <- resize(mypic[[i]], 128, 128)}\nfor (i in 1:length(temp)) {dim(mypic[[i]]) <- c(128, 128,3)}\nnewx <- combine(mypic)\nnewx <- aperm(newx, c(4,1,2,3))\npar(mfrow = c(4,4), mar = rep(0, 4))\nfor (i in 1:16) plot(as.raster(newx[i,,,]))\n```", "```py\n# Reconstructing images - new images\nrc <- ae_model %>% keras::predict_on_batch(x = newx)\npar(mfrow = c(5,5), mar = rep(0, 4))\nfor (i in 1:25) plot(as.raster(rc[i,,,]))\n```"]