<html><head></head><body>
		<div class="Content" id="_idContainer063">
			<h1 id="_idParaDest-78"><em class="italics"><a id="_idTextAnchor081"/>Chapter 3</em></h1>
		</div>
		<div class="Content" id="_idContainer064">
			<h1 id="_idParaDest-79"><a id="_idTextAnchor082"/>Introduction to Neural Networks</h1>
		</div>
		<div class="Content" id="_idContainer065">
			<h2>Learning Objectives</h2>
			<p>By the end of this chapter, you will be able to:</p>
			<ul>
				<li class="bullets">Describe Deep Learning and its applications</li>
				<li class="bullets">Differentiate between Deep Learning and machine learning</li>
				<li class="bullets">Explore neural networks and their applications</li>
				<li class="bullets">Understand the training and functioning of a neural network</li>
				<li class="bullets">Use Keras to create neural networks</li>
			</ul>
			<p>This chapter aims to introduce you to neural networks, their applications in Deep Learning, and their general drawbacks.</p>
		</div>
		<div class="Content" id="_idContainer086">
			<h2 id="_idParaDest-80"><a id="_idTextAnchor083"/>Introduction</h2>
			<p>In the previous two chapters, you learned about the basics of natural language processing, its importance, the steps required to prepare text for processing, and two algorithms that aid a machine in understanding and executing tasks based on natural language. However, to cater to higher, more complicated natural language processing problems, such as creating a personal voice assistant like <em class="italics">Siri</em> and <em class="italics">Alexa</em>, additional techniques are required. Deep learning systems, such as neural networks, are often used in natural language processing, and so we're going to cover them in this chapter. In the following chapters, you learn how to use neural networks for the purpose of natural language processing. </p>
			<p>This chapter begins with an explanation on deep learning and how it is different from machine learning. Then, it discusses neural networks, which make up a large part of deep learning techniques, and their basic functioning along with real-world applications. Additionally, it introduces <strong class="bold">Keras</strong>, a Python deep learning library.</p>
			<h3 id="_idParaDest-81"><a id="_idTextAnchor084"/>Introduction to Deep Learning</h3>
			<p>Artificial Intelligence is the idea of agents possessing the natural intelligence of humans. This natural intelligence includes the ability to plan, understand human language, learn, make decisions, solve problems, and recognize words, images and objects. When building these agents, this intelligence is known as artificial intelligence, since it is human-made. These agents do not refer to physical objects. They are, in fact, a reference to software that demonstrates artificial intelligence.</p>
			<p>There are two types of artificial intelligence—narrow and generalized. Narrow artificial intelligence is the kind of artificial intelligence that we are currently surrounded by; it is any single agent possessing one of the several capabilities of natural intelligence. The application areas of natural language processing that you learned about in the first chapter of this book are examples of narrow Artificial Intelligence, because they are agents capable of carrying out a single task, such as, a machine being able to automatically summarize an article. There do exist Technologies do exist that are capable of more than one task, such as self-driving cars, but these are still considered a combination of several narrow AIs.</p>
			<p>Generalized artificial intelligence is the possession of all human capabilities and more, in a single agent, rather than one or two capabilities in a single agent. AI experts claim that once AI has surpassed this goal of generalized AI and it is smarter and more adept than humans themselves in all fields, it will become super artificial intelligence.</p>
			<p>As mentioned in the previous chapters, natural language processing is an approach to achieving artificial intelligence, by enabling machines to understand and communicate with humans in the natural language of humans. Natural language processing prepares textual data and transforms it into a form that machines are able to process—a numerical form. This is where deep learning comes in.</p>
			<p>Like natural language processing and machine learning, deep learning is also a category of techniques and algorithms. It is a subfield of machine learning because both these approaches share the same primary principle—both machine learning and deep learning algorithms take input and use it to predict output.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer066">
					<img alt="Fig 3.1: Deep Learning as a subfield of Machine Learning&#13;&#10;" src="image/C13783_03_01.jpg"/>
				</div>
			</div>
			<h6>Fig 3.1: Deep learning as a subfield of machine learning</h6>
			<p>When trained on a training dataset, both types of algorithms (machine learning and deep learning) aim to minimize the difference between the actual outcomes and their predicted outcomes. This aids them in forming an association between the input and the output, thus resulting in higher accuracy. </p>
			<h3 id="_idParaDest-82"><a id="_idTextAnchor085"/>Comparing Machine Learning and Deep Learning</h3>
			<p>While both these approaches are based on the same principle—predicting output from input—they achieve this in different ways, which is why deep learning has been categorized as a separate approach. Additionally, one of the main reasons for deep learning coming about was the increased accuracy these models provide in their prediction process.</p>
			<p>While machine learning models are quite self-sufficient, they still need human intervention to determine that a prediction is incorrect, and thus they need to get better at performing that particular task. Deep learning models, on the other hand, are capable of determining whether a prediction is incorrect or not by themselves. Thus, deep learning models are self-sufficient; they can make decisions and improve their efficiency without human interventions.</p>
			<p>To better understand this, let's take the example of an air conditioner whose temperature settings can be controlled by voice commands. Let's say that when the air conditioner hears the word "hot," it decreases the temperature, and when it hears the word "cold," it increases the temperature. If this were a machine learning model, then the air conditioner would learn to recognize these two words in different sentences over time. However, if this were a deep learning model, it could learn to alter the temperature based on words and sentences similar to the words "hot" and "cold," such as "It's a little warm" or "I'm freezing!" and so on.</p>
			<p>This is an example that directly relates to natural language processing since the model understands the natural language of humans and acts on what it has understood. In this book we will be sticking to using deep learning models for the purpose of natural language processing, though in reality they can be used in almost every field. They are currently involved in automating the task of driving, by enabling a vehicle to recognize stop signs, read traffic signals, and halt for pedestrians. The medical field is also utilizing deep learning methods to detect diseases at early stages – cancer cells. But since our focus in this book is on enabling machines to understand the natural language of humans, let's get back to that.</p>
			<p>Deep learning techniques are most often used in the supervised learning way, that is, they are provided with labelled data to learn from. However, the key difference between machine learning methods and deep learning methods is that the latter require insanely large amounts of data which didn't exist before. Thus, deep learning has only recently become advantageous. It also requires quite a bit of computing power since it needs to be trained on such large amounts of data.</p>
			<p>The main difference, however, is in a algorithms themselves. If you've studied machine learning before, then you're aware of the variety of algorithms that exist to solve classification and regression problems, as well as unsupervised learning ones. Deep learning systems differ from these algorithms because they use Artificial Neural Networks.</p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor086"/>Neural Networks</h2>
			<p>Often neural networks and deep learning are terms that are used interchangeably. They do not mean the same thing, however, so let's learn the difference.</p>
			<p>As mentioned before, deep learning is an approach that follows the same principle as machine learning, but does so with more accuracy and efficiency. Deep learning systems make use of artificial neural networks, which are computing models on their own. So, basically, neural networks are a part of the deep learning approach but are not the deep learning approach on their own. They are frameworks that are incorporated by deep learning methods.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer067">
					<img alt="Fig 3.2: Neural Networks as a part of the Deep Learning Approach&#13;&#10;" src="image/C13783_03_02.jpg"/>
				</div>
			</div>
			<h6>Fig 3.2: Neural Networks as a part of the deep learning Approach</h6>
			<p>Artificial neural networks are based on a framework inspired by the biological neural networks found in the human brain. These neural networks are made of nodes that enable the networks to learn from images, text, real-life objects, and other things, to be able to execute tasks and predict things accuracy.</p>
			<p>Neural networks consist of layers, which we will take a look at in the following section. The number of layers that a network has can be anywhere from three to hundreds. Neural networks that are made of only three or four layers are called shallow neural networks, whereas networks that have many more layers than that are referred to as deep neural networks. Thus, the neural networks used by the deep learning approach are deep neural networks and they possess several layers. Due to this, deep learning models are very well suited to complex tasks such as facial recognition translating text, and so on.</p>
			<p>These layers break down the input into several levels of abstraction. As a result, the deep learning model is better able to learn from and understand the input, be it images or text or another form of input, which aids it in making decisions and predicting things the way our human mind does.</p>
			<p>Let's go through an example to understand these layers. Imagine that you're in your bedroom doing some work and you notice you're sweating. That's your input data—the fact that you're feeling hot and so in your head a little voice goes "I'm feeling hot!" Next, you might wonder why you're feeling so hot—"Why am I feeling so hot?" This is a thought. You'll then try to come up with a solution to this problem, maybe by taking a shower—"Let me take a quick shower." This is a decision that you've made. But then you remember that you've got to leave for work soon—"But, I need to leave the house soon." This is a memory. You might try to convince yourself by thinking "Isn't there enough time to squeeze in a quick shower, though?" This is the process of a reasoning. Lastly, you'll probably act on your thoughts by either thinking "I'm going to take a shower," or, "there's no time for a shower, never mind." This is decision making and in the event you do take a shower, it is an action.</p>
			<p>The multiple layers in a deep neural network allow the model to go through these different levels of processing just like the mind does, thus building upon the principles of biological neural networks. These layers are how and why deep learning models are able to perform tasks and predict outputs with such high accuracy.</p>
			<h3 id="_idParaDest-84"><a id="_idTextAnchor087"/>Neural Network Architecture</h3>
			<p>Neural network architecture refers to the elements that are the building blocks of a neural network. While there are several different types of neural networks, the basic architecture and foundation remains constant. The architecture includes:</p>
			<ul>
				<li><strong class="bold">Layers</strong></li>
				<li><strong class="bold">Nodes</strong></li>
				<li><strong class="bold">Edges</strong></li>
				<li><strong class="bold">Biases</strong></li>
				<li><strong class="bold">Activation functions</strong></li>
			</ul>
			<h3 id="_idParaDest-85"><a id="_idTextAnchor088"/>The Layers</h3>
			<p>As mentioned before, neural networks are made up of layers. While the number of these layers varies from model to model and is dependent on the task at hand, there are only three types of layers. Each layer is made up of individual nodes and the number of these nodes depends on the requirement of the layer and the neural network as a whole. A node can be thought of as a neuron.</p>
			<p>The layers present in a neural network are as follows:</p>
			<ul>
				<li><em class="italics">The input layer</em><p>As the name suggests, this is the layer that consists of the input data entering the neural network. It is a mandatory layer as every neural network requires input data to learn from and perform operations on to be able to generate an output. This layer can only occur once in a neural network. Each input node is connected to each node present in the proceeding layer.</p><p>The variables or characteristics of input data are known as features. The target output is dependent on these features. For example, take the<span class="Annotation-reference"> </span>iris dataset. (The Iris dataset is one of the most popular datasets for machine learning beginners. It consists of data of three different types of flowers. Each instance has four features and one target class.) The classification label of a flower is dependent on the four features—petal length and width, and sepal length and width. The features, and thus the input layer, is denoted by <strong class="bold">X</strong>, and each individual featured is denoted by <strong class="bold">X1</strong>, <strong class="bold">X2</strong>, ... , <strong class="bold">Xn</strong>.</p></li>
				<li><em class="italics">The hidden layer</em><p>This is the layer where the actual computation is done. It comes after the input layer, since it acts on the input provided by the input layer, and before the output layer, since it generates the output that is provided by the output layer.</p><p>A hidden layer is made up of nodes known as "activation nodes." Each node possesses an activation function, which is a mathematical function that is performed on the inputs received by an activation node to generate an output. Activation functions will be discussed later on in this chapter.</p><p>This is the only type of layer that can occur multiple times, and thus in deep neural networks, there can be up to hundreds of hidden layers present. The number of hidden layers depends on the task at hand.</p><p>The output generated by the nodes of one hidden layer are fed into the proceeding hidden layer as input. The output generated by each activation node of a hidden layer is sent to each activation node of the next layer.</p></li>
				<li><em class="italics">The output layer</em><p>This is the last layer of the neural network and it consists of nodes that provide the final outcome of all the processing and computing. This is also a mandatory layer since a neural network must produce an output based on input data.</p><p>In the case of the iris dataset, the output for a particular instance of a flower would be the category of that flower—Iris setosa, Iris virginica, or Iris versicolor.</p><p>The output, often known as the target, is denoted as <strong class="bold">y</strong>.</p></li>
			</ul>
			<div>
				<div class="IMG---Figure" id="_idContainer068">
					<img alt="Fig 3.3: A Neural Network with 2 Hidden Layers&#13;&#10;" src="image/C13783_03_03.jpg"/>
				</div>
			</div>
			<h6>Fig 3.3: A Neural Network with 2 Hidden Layers</h6>
			<h3 id="_idParaDest-86"><a id="_idTextAnchor089"/>Nodes</h3>
			<p>Each activation node or neuron possess the following components:</p>
			<ul>
				<li>An activation<p>This is the current state of the node—whether it is active or not.</p></li>
				<li>A threshold value (optional)<p>If present, this determines whether a neuron is activated or not, depending on whether the weighted sum is above or below this threshold value.</p></li>
				<li>An activation function<p>This is what computes a new activation for the activation node based on the inputs and the weighted sum.</p></li>
				<li>An output function <p>This generates the output for the particular activation node based on the activation function.</p><p>Input neurons have no such components as they don't perform computation, nor do they have any preceding neurons. Similarly, output neurons don't have these components, since they don't perform computation, nor do they have proceeding neurons.</p></li>
			</ul>
			<h3 id="_idParaDest-87"><a id="_idTextAnchor090"/>The Edges</h3>
			<div>
				<div class="IMG---Figure" id="_idContainer069">
					<img alt=" Fig 3.4: The Weighted Connections of a Neural Network&#13;&#10;" src="image/C13783_03_04.jpg"/>
				</div>
			</div>
			<h6> Fig 3.4: The Weighted Connections of a Neural Network</h6>
			<p>Each of the arrows in the preceding diagram represents a connection between two nodes from two different layers. A connection is known as an edge. Each edge that leads to an activation node has its own weight, which can be considered as a sort of impact that one node has on the other node. Weights can be either positive or negative.</p>
			<p>Take a look at the earlier diagram. Before the values reach the activation function, their values are multiplied by the weights assigned to their respective connections. These multiplied values are then added together to obtain a weighted sum. This weighted sum is basically a measure of how much impact that node has on the output. Thus if the value is low, that means that it doesn't really affect the output that much and so it's not that important. If the value is high, then it shares a strong correlation with the target output and thus plays a role in determining what the output is.</p>
			<h3 id="_idParaDest-88"><a id="_idTextAnchor091"/>Biases</h3>
			<p>A bias is a node, and each layer of a neural network has its own bias node, except for the output layer. Thus, each layer has its own bias node. The bias node holds a value, known as the bias. This value is incorporated in the process of calculating the weighted sum and so also plays a role in determining the output generated by a node.</p>
			<p>Bias is an important aspect of neural networks because it allows the activation function to shift either to the right or to the left. This helps the model to better fit the data and thus produce accurate outputs.</p>
			<h3 id="_idParaDest-89"><a id="_idTextAnchor092"/>Activation Functions</h3>
			<p>Activation functions are functions that are part of the activation nodes found in the hidden layers of neural networks. They serve the purpose of introducing non-linearity into neural networks, which is really important, as without them neural networks would just have linear functions, leaving no difference between them and linear regression models. This defeats the purpose of neural networks, because then they wouldn't be able to learn complex functional relationships that exist within data. Activation functions also need to be differentiable for backpropagation to occur. This will be discussed in future sections of this chapter.</p>
			<p>Basically, an activation node calculates the weighted sum of the inputs it receives, adds the bias, and then applies an activation function to this value. This generates an output for that particular activation node which is then used as input by the proceeding layer. This output is known as an activation value. Therefore, the proceeding activation node in the next layer will receive multiple activation values from preceding activation nodes and calculate a new weighted sum. It will apply its activation function to this value to generate its own activation value. This is how data flows through a neural network. Thus, an activation function helps convert an input signal into an output signal. </p>
			<p>This process of calculating the weighted sum, applying an activation function, and producing an activation value is known as feedforward.</p>
			<p>There are several activation functions (Logistic, TanH, ReLU, and so on). The Sigmoid function is one of the most popular and simple activation functions out there. When represented mathematically, this function looks like</p>
			<div>
				<div class="IMG---Figure" id="_idContainer070">
					<img alt="Figure 3.5: Expression for sigmoid function&#13;&#10;" src="image/C13783_03_05.jpg"/>
				</div>
			</div>
			<h6>Figure 3.5: Expression for sigmoid function</h6>
			<p>As you can see, this function is non-linear.</p>
			<h2 id="_idParaDest-90"><a id="_idTextAnchor093"/>Training a Neural Network</h2>
			<p>So far, we know that once an input is provided to a neural network, it enters the input layer which is an interface that exists to pass on the input to the next layer. If a hidden layer is present, then the inputs are sent to the activation nodes of the hidden layer via weighted connections. The weighted sum of all the inputs received by the activations nodes is calculated by multiplying the inputs with their respective weights and adding these values up along with the bias. The activation function generates an activation value from the weighted sum and this is passed on to the nodes in the next layer. If the next layer is another hidden layer, then it uses the activation values from the previous hidden layer as inputs and repeats the activation process. However, if the proceeding layer is the output layer, then the output is provided by the neural network.</p>
			<p>From all of this information, we can conclusively say that there are three parts of the deep learning model that have an impact on the output generated by the model—the inputs, the connection weights and biases, and the activation functions.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer071">
					<img alt="Figure 3.6: Aspects of a deep learning model that impact the output&#13;&#10;" src="image/C13783_03_06.jpg"/>
				</div>
			</div>
			<h6>Figure 3.6: Aspects of a deep learning model that impact the output</h6>
			<p>While the inputs are taken from the dataset, the former two are not. Thus, the following two questions arise—who or what decides what the weight is for a connection? How do we know which activation functions to use? Let's tackle these questions one by one.</p>
			<h3 id="_idParaDest-91"><a id="_idTextAnchor094"/>Calculating Weights</h3>
			<p>Weights play a very important role in multilayer neural networks, since altering the weight of a single connection can completely alter the weights assigned to further connections and thus the outputs generated by the proceeding layers. Thus, having the optimal weights is necessary to create an accurate deep learning model. This sounds like a lot of pressure, but lucky for us, deep learning models are capable of finding the optimal weights all on their own. To understand this better, let's take the example of linear regression.</p>
			<p>Linear regression is a supervised machine learning algorithm that, as suggested by the name itself, is suitable to solve regression problems (datasets whose output is in the form of continuous numerical values, such as the selling prices of houses). This algorithm assumes there exists a linear relationship between the input (the features) and the output (the target). Basically, it believes that there exists a line of best fit that accurately describes the relationship between the input and output variables. It uses this to predict future numerical values. In a scenario where there is only one input feature, the equation for this line is:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer072">
					<img alt="Figure 3.7: Expression for linear regression&#13;&#10;" src="image/C13783_03_07.jpg"/>
				</div>
			</div>
			<h6>Figure 3.7: Expression for linear regression</h6>
			<p>Where, </p>
			<p><strong class="bold">y</strong> is the target output</p>
			<p><strong class="bold">c</strong> is the y-intercept </p>
			<p><strong class="bold">m</strong> is the model coefficient </p>
			<p><strong class="bold">x</strong> is the input feature</p>
			<p>Similar to the connections in neural networks, the input features have values attached to them too—they're called model coefficients. In a way, these model coefficients determine the importance a feature has in determining the output, which is similar to what the weights in neural networks do. It is important to ensure these model coefficients are of the correct value so as to get correct predictions.</p>
			<p>Let's say that we want to predict the selling price of a house based on how many bedrooms it has. So, the price of the house is our target output and the number of bedrooms it has is our input feature. Since this is a supervised learning method, our model will be fed a dataset that contains instances of our input feature matched with the correct target output.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer073">
					<img alt="Fig 3.8: Sample Dataset for Linear Regression&#13;&#10;" src="image/C13783_03_08.jpg"/>
				</div>
			</div>
			<h6>Fig 3.8: Sample Dataset for Linear Regression</h6>
			<p>Now, our linear regression model needs to find a model coefficient that describes the impact of the number of bedrooms on the selling price of the house. It does this by making use of two algorithms—the loss function and the gradient descent algorithm.</p>
			<h3 id="_idParaDest-92"><a id="_idTextAnchor095"/>The Loss Function</h3>
			<p>The loss function is also sometimes known as the cost function. </p>
			<p>For classification problems, the loss function calculates the difference between the predicted probability of a particular category and the category itself. For example, let's say you have a binary classification problem that needs to predict whether a house will be sold or not. There are only two outputs—"yes" and "no." A classification model when fitted on this data will predict the probability of an instance of data falling in either the "yes" category or the "no" category. Let's say the "yes" category has a value of 1, and "no" has a value of 0. Thus, if the output probability is closer to 1 it will fall in the "yes" category. The loss function for this model will measure this difference.</p>
			<p>For regression problems, the loss function calculates the error between actual values and predicted values. The house price example from the previous section is a regression problem and so the loss function is calculating the error between the actual price of a house, and the price that our model predicted. Thus, in a way, the loss function helps the model self-evaluate its performance. Obviously, the model's aim is to predict the price that is exactly, if not closest to, the actual price. To do this, it needs to minimize the loss function as much as possible.</p>
			<p>The only factor that is directly affecting the price predicted by the model is the model coefficient. To arrive at the model coefficient that is best suited for the problem at hand, the model needs to keep improving the values for<span class="Annotation-reference"> th</span>e model coefficient. Let's call each different value an update of the model coefficient. So, with each update of the model coefficient, the model must calculate the error between the actual price and the price that the model has predicted using that update of the model coefficient.</p>
			<p>Once the function has reached its minimum value, the model coefficient at this minimum point is chosen as the final model coefficient. This value is stored and used in the linear equation described above by the linear regression algorithm. From that point onwards, whenever the model is fed input data in the form of how many bedrooms a house has without target outputs, it uses the linear equation with the apt model coefficient to calculate and predict the price that that house will be sold at. </p>
			<p>There are many different kinds of loss functions—such as MSE (for regression problems) and<span class="Annotation-reference"> </span>Log Loss (for classification problems). Let's take a look at how they work.</p>
			<p>The Mean Squared Error function calculates the difference between the actual values and the predicted values, squares this difference, and then averages it out across the entire dataset. The function, when expressed mathematically, looks like this: </p>
			<div>
				<div class="IMG---Figure" id="_idContainer074">
					<img alt="Figure 3.9: Expression for mean squared error function&#13;&#10;" src="image/C13783_03_09.jpg"/>
				</div>
			</div>
			<h6>Figure 3.9: Expression for mean squared error function</h6>
			<p>Where, </p>
			<p><strong class="bold">n</strong> is the total number of data points </p>
			<p><strong class="bold">yi</strong> is the ith actual value </p>
			<p><strong class="bold">xi</strong> is the input</p>
			<p><strong class="bold">f()</strong> is the function being carried out on the input to generate the output, therefore</p>
			<p><strong class="bold">f(xi)</strong> is the predicted value</p>
			<p>Log loss is used for classification models whose output is a probability value in the range of 0 and 1. The higher the difference between the predicted probability and the actual category, the higher the log loss. The mathematical representation of the log loss functions is: </p>
			<div>
				<div class="IMG---Figure" id="_idContainer075">
					<img alt="Figure 3.10: Expression for log loss function&#13;&#10;" src="image/C13783_03_10.jpg"/>
				</div>
			</div>
			<h6>Figure 3.10: Expression for log loss function</h6>
			<p>Where, </p>
			<p><strong class="bold">N</strong> is the total number of data points </p>
			<p><strong class="bold">yi</strong> is the ith actual label</p>
			<p><strong class="bold">p</strong> is the predicted probability </p>
			<h3 id="_idParaDest-93"><a id="_idTextAnchor096"/>The Gradient Descent Algorithm</h3>
			<p>The process of evaluating the model's performance via the loss function is one that the model carries out independently, as is the process for updating and ultimately choosing the model coefficients. </p>
			<p>Imagine that you're on a mountain and you want to climb back down and reach the absolute bottom. It's cloudy and there are quite a few peaks so you can't exactly see where the bottom is, or which direction it is in, you just know that you need to get there. You start your journey at 5000 meters above sea level, and you decide to take large steps. You take a step and then you check your phone to see how many meters above sea level you are. Your phone says you are 5003 meters above sea level, which means you've gone in the wrong direction. Now, you take a large step in another direction and your phone says you are 4998 meters above sea level. This means you're getting closer to the bottom, but how do you know that this step was the one with the steepest descent? What if you took a step in another direction that brought you down to 4996 meters above sea level? Thus, you check your position after taking a step in each possible direction, and whichever takes you closest the bottom, is the one you choose. </p>
			<p>You keep repeating this process, and then you reach a point where your phone says you are 100 meters above sea level. When you take another step, your phone's reading remains the same—100 meters above sea level. Finally, you have reached what seems to be the bottom since a step in any direction from this point results in you still being 100 meters above sea level.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer076">
					<img alt="Fig 3.11: Updating Parameters&#13;&#10;" src="image/C13783_03_11.jpg"/>
				</div>
			</div>
			<h6>Fig 3.11: Updating Parameters</h6>
			<p>This is how the gradient descent algorithm works. The algorithm descends a plot of the loss function against possible values for the model coefficient and the y-intercept, like you descended the mountain. It starts off with an assigned value for the model coefficient—this is you standing at a point 5000 meters above sea level. It calculates the gradient of the plot at this point. This gradient tells the model which direction it should move in to update the coefficient in order to get closer to the global minimum, which is the end goal. So, it takes a step and arrives at a new point with a new model coefficient. It repeats the process of calculating the gradient, obtaining a direction to move in, updating the coefficient, and taking another step. It checks to see that this step is the one that provides it with the steepest descent. With each step that it takes, it arrives at a new model coefficient and calculates the gradient at that point. This process is repeated until the value of the gradient doesn't change for a number of trials. This means that the algorithm has reached the global minimum and has converged. The model coefficient at this point is used as the final model coefficient in the linear equations.</p>
			<p>In neural networks, the gradient descent algorithm and loss function work together to find values to be assigned to connections as weights and to biases. These values are updated by minimizing the loss function using the gradient descent algorithm, as is the case in linear regression models. Additionally, with the case of linear regression, there is always only one minimum, due to the fact that the loss function is bowl shaped. This makes it easy for the gradient descent algorithm to find it and be sure that this is the lowest point. In the case of neural networks, however, it is not that simple. The activation functions used by neural networks serve the purpose of introducing non-linearity to the situation. </p>
			<p>As a result, the plot of the loss function of a neural network is not a bowl-shaped curve, and this does not have just one minimum point. Instead, it has several minimums, only one of which is the global minima. The rest are known as local minima. This sounds like a major issue, but it is, in fact, alright for the gradient descent algorithm to reach a local minima and choose the weight values at that point, due to the fact that most local minima are usually quite close to the global minimum. There are modified versions of the gradient descent algorithm that are also used when designing neural networks. Stochastic and batch-sized gradient descent are two of them.</p>
			<p>Let's say our loss function is MSE, and we need the gradient descent algorithm to update one weight (w) and one bias (b). </p>
			<div>
				<div class="IMG---Figure" id="_idContainer077">
					<img alt="Figure 3.12: Expression for gradient of loss function&#13;&#10;" src="image/C13783_03_12.jpg"/>
				</div>
			</div>
			<h6>Figure 3.12: Expression for gradient of loss function</h6>
			<p>The gradient is the partial derivative of the loss function, with respect to the weight and the bias. The mathematical representation of this is: </p>
			<div>
				<div class="IMG---Figure" id="_idContainer078">
					<img alt="Figure 3.13: Expression of gradient with partial derivaive of loss function&#13;&#10;" src="image/C13783_03_13.jpg"/>
				</div>
			</div>
			<h6>Figure 3.13: Expression of gradient with partial derivaive of loss function</h6>
			<p>The result of this is the gradient of the loss function at the current position. This also tells us which direction we should move in to continue updating the weight and the bias. </p>
			<p>The size of the step taken is adjusted by a parameter called the learning rate and is a very sensitive parameter in the gradient descent algorithm. It is called alpha and is denoted by α. If the learning rate is too small, then the algorithm will take too many tiny steps and thus take too long to reach the minimum. However, if the learning rate is too large then the algorithm might miss the minimum altogether. Thus, it is important to tweak and test out the algorithm using different learning rates to ensure the right one is chosen.</p>
			<p>The learning rate is multiplied with the gradient calculated at each step in order to modify the size of the step, thus the step size of each step is not always the same. Mathematically, this looks like: </p>
			<div>
				<div class="IMG---Figure" id="_idContainer079">
					<img alt="Figure 3.14: Expression for learning rate multipled with gradient&#13;&#10;" src="image/C13783_03_14.jpg"/>
				</div>
			</div>
			<h6>Figure 3.14: Expression for learning rate multiplied with gradient</h6>
			<p>And,</p>
			<div>
				<div class="IMG---Figure" id="_idContainer080">
					<img alt="Figure 3.15: Expression for learning rate multipled with gradient at each step&#13; &#10;" src="image/C13783_03_15.jpg"/>
				</div>
			</div>
			<h6>Figure 3.15: Expression for learning rate multiplied with gradient at each step</h6>
			<p>The values are subtracted from the previous values of the weight and bias because the partial derivatives point in the direction of the steepest ascent, but our aim is to descend. </p>
			<div>
				<div class="IMG---Figure" id="_idContainer081">
					<img alt="Fig 3.16: Learning Rate&#13;&#10;" src="image/C13783_03_16.jpg"/>
				</div>
			</div>
			<h6>Fig 3.16: Learning Rate</h6>
			<h3 id="_idParaDest-94"><a id="_idTextAnchor097"/>Backpropagation</h3>
			<p>Linear regression is basically a neural network, but without a hidden layer and with an identity activation function (which is a linear function, therefore linearity). Hence, the learning process remains the same as the one described in the previous sections—the loss function aims to minimize the error by having the gradient descent algorithm constantly update the weights till the global minimum is reached.</p>
			<p>However, when dealing with larger, more complicated neural networks that are not linear in nature, the loss calculated is sent back through the network to each layer, which then begins the process of weight updating again. The loss is propagated backwards, therefore this is known as backpropagation.</p>
			<p>Backpropagation is performed using the partial derivatives of the loss function. It involves calculating the loss of every node in every layer by propagating backwards in the neural network. Knowing the loss of every node allows the network to understand which weights are having a drastic negative impact on the output and the loss. Thus, the gradient descent algorithm is able to reduce the weights of these connections that have high error rates, consequently reducing the impact that that node has on the network's output.</p>
			<p>When dealing with many layers in a neural network, there are many activation functions working on the inputs. This can be represented as follows:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer082">
					<img alt="Figure 3.17: Expression for backpropagation function&#13;&#10;" src="image/C13783_03_17.jpg"/>
				</div>
			</div>
			<h6>Figure 3.17: Expression for backpropagation function</h6>
			<p>Here <strong class="bold">X</strong>, <strong class="bold">Y</strong>, and <strong class="bold">Z</strong> are activation functions. As we can see, <strong class="bold">f(x)</strong> is a composite function, thus, backpropagation can be seen as an application of the chain rule. The chain rule is the formula used to calculate the partial derivatives of a composite function, which is what we're doing through backpropagation. Therefore, by applying the chain rule to the preceding function (known as the forward propagation function since values are moving in the forward direction to generate an output) and calculating the partial derivatives with respect to each weight, we will be able to determine exactly how much of an impact each node has on the final output.</p>
			<p>The loss of the final node present in the output layer is the total loss of the entire neural network, because it is in the output layer and so the loss of all the previous nodes gets accumulated. The input nodes present in the input layer do not have a loss because they don't have an impact on the neural network. The input layer is merely an interface that sends the input to the activation nodes present in the hidden layers.</p>
			<p>Therefore, the process of backpropagation is the process of updating the weights using the gradient descent algorithm and the loss function.</p>
			<h4>Note</h4>
			<p class="callout">For more information on the math of backpropagation, click here: <a href="">https://ml-cheatsheet.readthedocs.io/en/latest/backpropagation.html</a></p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor098"/>Designing a Neural Network and Its Applications</h2>
			<p>Common machine learning techniques are used when training and designing a neural network. Neural networks can be classified as:</p>
			<ul>
				<li>Supervised neural networks</li>
				<li>Unsupervised neural networks</li>
			</ul>
			<h3 id="_idParaDest-96"><a id="_idTextAnchor099"/>Supervised neural networks</h3>
			<p>These are like the example used in the previous section (predicting the price of the house based on how many rooms it has). Supervised neural networks are trained on datasets consisting of sample inputs with their corresponding outputs. These are suitable for noise classification and making predictions. </p>
			<p>There are two types of supervised learning methods:</p>
			<ul>
				<li>Classification <p>This is for problems that have discrete categories or classes as target outputs, for example the Iris dataset. The neural network learns from sample inputs and outputs how to correctly classify new data.</p></li>
				<li>Regression<p>This is for problems that have a range of continuous numerical values as target outputs, like the price of a house example. The neural network describes the causal relationship between the inputs and their outputs.</p></li>
			</ul>
			<h3 id="_idParaDest-97"><a id="_idTextAnchor100"/>Unsupervised neural networks</h3>
			<p>These neural networks are trained on data without any target output, and thus are able to recognize and draw out patterns and inferences from the data. This makes them well-suited for tasks such as identifying category relationships and discovering natural distributions in data.</p>
			<ul>
				<li>Clustering</li>
			</ul>
			<p>A cluster analysis is the grouping together of similar inputs. These neural networks can be used for gene sequence analysis and object recognition, amongst other things.</p>
			<p>Neural networks that are capable of pattern recognition can be trained both by supervised or unsupervised methods. They play a key role in text classification and speech recognition.</p>
			<h3 id="_idParaDest-98"><a id="_idTextAnchor101"/>Exercise 17: Creating a neural network</h3>
			<p>In this exercise, we're going to implement a simple, classic neural network, by following the workflow outlined earlier, to predict whether a review is positive or negative.</p>
			<p>This is a natural language processing problem, since the neural network is going to be fed rows of sentences that are actually reviews. Each review has a label in the training set—either 0 for negative or 1 for positive. This label is dependent on the words present in the review and so, our neural network needs to understand the meaning of the review and accordingly label it. Ultimately, our neural network needs to be able to predict whether a review is positive or negative.</p>
			<h4>Note</h4>
			<p class="callout">Download the dataset from the link:</p>
			<p class="callout"><a href="">https://github.com/TrainingByPackt/Deep-Learning-for-Natural-Language-Processing/tree/master/Lesson%2003</a></p>
			<p>The following steps will help you with the solution.</p>
			<ol>
				<li>Open up a new Jupyter notebook by typing the following command in the directory you'd like to code in: <p class="snippet">jupyter notebook</p></li>
				<li>Next, import <strong class="inline">pandas</strong> so that you can store the data in a dataframe:<p class="snippet">import pandas as pd</p><p class="snippet">df = pd.read_csv('train_comment_small_50.csv', sep=',')</p></li>
				<li>Import the regular expressions package<p class="snippet">import re</p></li>
				<li>Create a function to preprocess the reviews by removing the <strong class="inline">HTML</strong> tags, escaped quotes and normal quotes:<p class="snippet">def clean_comment(text):</p><p class="snippet">    # Strip HTML tags</p><p class="snippet">    text = re.sub('&lt;[^&lt;]+?&gt;', ' ', text)</p><p class="snippet"> </p><p class="snippet">    # Strip escaped quotes</p><p class="snippet">    text = text.replace('\\"', '')</p><p class="snippet"> </p><p class="snippet">    # Strip quotes</p><p class="snippet">    text = text.replace('"', '')</p><p class="snippet"> </p><p class="snippet">    return text</p></li>
				<li>Apply this function to the reviews currently stored in your dataframe:<p class="snippet">df['cleaned_comment'] = df['comment_text'].apply(clean_comment)</p></li>
				<li>Import <strong class="inline">train_test_split</strong> from <strong class="inline">scikit-learn</strong> to divide this data into a training set and a validation set:<p class="snippet">from sklearn.model_selection import train_test_split</p><p class="snippet">X_train, X_test, y_train, y_test = train_test_split(df['cleaned_comment'], df['toxic'], test_size=0.2)</p></li>
				<li>Import <strong class="inline">nltk</strong> and <strong class="inline">stopwords</strong> from <strong class="inline">nltk</strong> library:<p class="snippet">import nltk</p><p class="snippet">nltk.download('stopwords')</p></li>
				<li>Now machine learning and deep learning models require numerical data as input, and currently our data is in the form of text. Thus, we're going to use an algorithm called CountVectorizer to convert the words present in the reviews into word count vectors<p class="snippet">from sklearn.feature_extraction.text import CountVectorizer</p><p class="snippet">from nltk.corpus import stopwords</p><p class="snippet"> </p><p class="snippet">vectorizer = CountVectorizer(binary=True, stop_words = stopwords.words('english'), lowercase=True, min_df=3, max_df=0.9, max_features=5000)</p><p class="snippet">X_train_onehot = vectorizer.fit_transform(X_train)</p><p>Our data is clean and prepped now!</p></li>
				<li>We're going to create a two-layer neural network. When defining a neural network, the number of layers does not include the input layer since it's a given that an input layer exists and because the input layer isn't a part of the computation process. So, a two-layer neural network includes an input layer, one hidden layer and an output layer.</li>
				<li>Import the model and the layers from Keras:<p class="snippet">from keras.models import Sequential</p><p class="snippet">from keras.layers import Dense</p></li>
				<li>Initiate the neural network:<p class="snippet">nn = Sequential()</p></li>
				<li>Add the hidden layer. Specify the number of nodes the layer will have the activation function the nodes possess and what the input for the layer is:<p class="snippet">nn.add(Dense(units=500, activation='relu', input_dim=len(vectorizer.get_feature_names())))</p></li>
				<li>Add the output layer. Once again, specify the number of nodes and the activation function. We're going to use the <strong class="inline">sigmoid</strong> function here because this is a binary classification problem (predicting whether a review is positive or negative). We're going to have only one output node since the output is just one value—either 1 or 0. <p class="snippet">nn.add(Dense(units=1, activation='sigmoid'))</p></li>
				<li>We're going to compile the neural network now, and decide which loss function, optimization algorithm and performance metric we want to use. Since the problem is a binary classification one, we're going to use <strong class="inline">binary_crossentropy</strong> as our <strong class="inline">loss</strong> function. The optimization algorithm is basically the gradient descent algorithm. Different versions and modifications of gradient descent exist. In this case, we're going to use the <strong class="inline">Adam</strong> algorithm, which is an extension of stochastic gradient descent:<p class="snippet">nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])</p></li>
				<li>Now, let's summarize our model and see what's going on:<p class="snippet">nn.summary()</p><p>The output you'll get will look something like this:</p><div class="IMG---Figure" id="_idContainer083"><img alt="Figure 3.18: Model summary " src="image/C13783_03_18.jpg"/></div><h6> </h6><h6>Figure 3.18: Model summary </h6></li>
				<li>Now, it's time to train the model. Fit the neural network on the <strong class="inline">X_train</strong> and <strong class="inline">y_train</strong> data we ha<a id="_idTextAnchor102"/>d divided earlier:<p class="snippet">nn.fit(X_train_onehot[:-20], y_train[:-20], </p><p class="snippet">          epochs=5, batch_size=128, verbose=1, </p><p class="snippet">          validation_data=(X_train_onehot[-100:], y_train[-20:]))</p><p>That's it! Our neural network is now ready for testing. </p></li>
				<li>Transform the input validation data into word count vectors and evaluate the neural network. Print the accuracy score to see how your network is doing:<p class="snippet">scores = nn.evaluate(vectorizer.transform(X_test), y_test, verbose=1)</p><p class="snippet">print("Accuracy:", scores[1])</p><p>Your score might be a little different, but it should be close to 0.875. </p><p>Which is a pretty good score. So, there you have it. You just created your first ever neural network, trained it, and validated it.</p><p><strong class="bold">Expected output:</strong></p><div class="IMG---Figure" id="_idContainer084"><img alt="Figure 3.19: Expected accuracy score&#13;&#10;" src="image/C13783_03_19.jpg"/></div><h6>Figure 3.19: Expected accuracy score</h6></li>
				<li>Save your model:<p class="snippet"><strong class="bold">model.save('nn.hd5')</strong></p></li>
			</ol>
			<h2 id="_idParaDest-99"><a id="_idTextAnchor103"/>Fundamentals of Deploying a Model as a Service</h2>
			<p>The purpose of deploying a model as a service is for other people to view and access it with ease, and in other ways besides just looking at your code on GitHub. There are different types of model deployments, depending on why you've created the model in the first place. You could say there are three types—a streaming model (one that constantly learns as it is constantly fed data and then makes predictions), an analytics as a service model (AaaS—one that is open for anyone to interact with) and an on-line model (one which is only accessible by people working within the same company).</p>
			<p>The most common way of showcasing your work is through a web application. There are multiple deployment platforms that aid and allow you to deploy your models through them, such as Deep Cognition, MLflow, and others.</p>
			<p>Flask is the easiest micro web framework to use to deploy your own model without using an existing platform. It is written in Python. Using this framework, you can build a Python API for your model that will easily generate predictions and display them for you.</p>
			<p>The flow is as follows:</p>
			<ol>
				<li value="1">Create a directory for the API</li>
				<li>Copy your pre-trained neural network model to this directory</li>
				<li>Write a program that loads this model, preprocess the input so that it matches the training input of your model, use the model to make predictions and prepare, send, display this prediction.</li>
			</ol>
			<p>To test and run the API, you simply need to type the applications name along with <strong class="bold">.run()</strong>.</p>
			<p>In the case of the neural network we created in, we would save that model and load it into a new Jupyter notebook. We would convert input data (the cleaned reviews) into word count vectors so that the input data for our API would be the same as the training data. Then, we would use our models to generate predictions and display them.</p>
			<h3 id="_idParaDest-100"><a id="_idTextAnchor104"/>Activity 4: Sentiment Analysis of Reviews</h3>
			<p>In the activity, we are going to review comments from a dataset and categorize them as positive or negat<strong class="bold">ive. </strong>The following steps will help you with the solution.</p>
			<h4>Note</h4>
			<p class="callout">You will find the dataset at the following link:</p>
			<p class="callout"><a href="">https://github.com/TrainingByPackt/Deep-Learning-for-Natural-Language-Processing/tree/master/Lesson%2004</a></p>
			<ol>
				<li value="1">Open a new <strong class="inline">Jupyter</strong> notebook. Import the dataset.</li>
				<li>Import the necessary Python packages and necessary classes. Load the dataset in a dataframe.</li>
				<li>Import the necessary libraries to clean and prepare the data. Create an array for your cleaned text to be stored in. Using a <strong class="inline">for</strong> loop, iterate through every instance (every review).</li>
				<li>Import CountVectorizer and convert the words into word count vectors. Create an array to store each unique word as its own column, hence making them independent variables.</li>
				<li>Import necessary label encoding entities.</li>
				<li>Divide the dataset into training and testing sets.</li>
				<li>Create the neural network model.</li>
				<li>Train the model and validate it.</li>
				<li>Evaluate the neural network and print the accuracy scores to see how it's doing.<p><strong class="bold">Expected output:</strong></p></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer085">
					<img alt="Figure 3.20: Accuracy score&#13;&#10;" src="image/C13783_03_20.jpg"/>
				</div>
			</div>
			<h6>Figure 3.20: Accuracy score</h6>
			<h4>Note</h4>
			<p class="callout">The solution for the activity can be found on page 302.</p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor105"/>Summary</h2>
			<p>In this chapter, we were introduced to a subset of machine learning—deep learning. You learned about the differences and similarities between the two categories of techniques and understood the requirement for deep learning and its applications.</p>
			<p>Neural networks are artificial representations of the biological neural networks that are present in the human brain. Artificial neural networks are frameworks that are incorporated by deep learning models and have proven to be increasingly efficient and accurate. They are used in several fields, from training self-driving cars to detecting cancer cells in very early stages.</p>
			<p>We studied the different components of a neural network and learned a network trains and corrects itself, with the help of the loss function, the gradient descent algorithm and backpropagation. You also learned how to perform sentiment analysis on text inputs! Furthermore, you learned the basics of deploying a model as a service.</p>
			<p>In the coming chapters, you will learn more about neural networks and their different types, along with which neural network to use in what situations.</p>
		</div>
	</body></html>