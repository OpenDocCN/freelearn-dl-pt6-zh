["```py\n###########################################################################\n#############Chapter 3 - Deep Learning with neuralnet###################### ###########################################################################\nlibrary(\"neuralnet\")\nlibrary(ISLR)\n\ndata = College\nView(data)\n\nmax_data <- apply(data[,2:18], 2, max) \nmin_data <- apply(data[,2:18], 2, min)\ndata_scaled <- scale(data[,2:18],center = min_data, scale = max_data - min_data) \n\nPrivate = as.numeric(College$Private)-1\ndata_scaled = cbind(Private,data_scaled)\n\nindex = sample(1:nrow(data),round(0.70*nrow(data)))\ntrain_data <- as.data.frame(data_scaled[index,])\ntest_data <- as.data.frame(data_scaled[-index,])\n\nn = names(train_data)\nf <- as.formula(paste(\"Private ~\", paste(n[!n %in% \"Private\"], collapse = \" + \")))\ndeep_net = neuralnet(f,data=train_data,hidden=c(5,3),linear.output=F)\nplot(deep_net)\n\npredicted_data <- compute(deep_net,test_data[,2:18])\nprint(head(predicted_data$net.result))\npredicted_data$net.result <- sapply(predicted_data$net.result,round,digits=0)\n\ntable(test_data$Private,predicted_data$net.result)\n```", "```py\nlibrary(\"neuralnet\")\nlibrary(ISLR)\n```", "```py\ndata = College\nView(data)\n```", "```py\nmax_data <- apply(data[,2:18], 2, max) \nmin_data <- apply(data[,2:18], 2, min)\ndata_scaled <- scale(data[,2:18],center = min_data, scale = max_data - min_data) \n```", "```py\n> str(data)\n'data.frame': 777 obs. of 18 variables:\n $ Private : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Apps : num 1660 2186 1428 417 193 ...\n $ Accept : num 1232 1924 1097 349 146 ...\n $ Enroll : num 721 512 336 137 55 158 103 489 227 172 ...\n $ Top10perc : num 23 16 22 60 16 38 17 37 30 21 ...\n $ Top25perc : num 52 29 50 89 44 62 45 68 63 44 ...\n $ F.Undergrad: num 2885 2683 1036 510 249 ...\n $ P.Undergrad: num 537 1227 99 63 869 ...\n $ Outstate : num 7440 12280 11250 12960 7560 ...\n $ Room.Board : num 3300 6450 3750 5450 4120 ...\n $ Books : num 450 750 400 450 800 500 500 450 300 660 ...\n $ Personal : num 2200 1500 1165 875 1500 ...\n $ PhD : num 70 29 53 92 76 67 90 89 79 40 ...\n $ Terminal : num 78 30 66 97 72 73 93 100 84 41 ...\n $ S.F.Ratio : num 18.1 12.2 12.9 7.7 11.9 9.4 11.5 13.7 11.3 11.5 ...\n $ perc.alumni: num 12 16 30 37 2 11 26 37 23 15 ...\n $ Expend : num 7041 10527 8735 19016 10922 ...\n $ Grad.Rate : num 60 56 54 59 15 55 63 73 80 52 ...\n```", "```py\nPrivate = as.numeric(College$Private)-1\ndata_scaled = cbind(Private,data_scaled)\n```", "```py\nindex = sample(1:nrow(data),round(0.70*nrow(data)))\ntrain_data <- as.data.frame(data_scaled[index,])\ntest_data <- as.data.frame(data_scaled[-index,])\n```", "```py\nn = names(train_data)\nf <- as.formula(paste(\"Private ~\", paste(n[!n %in% \"Private\"], collapse = \" + \")))\n```", "```py\ndeep_net = neuralnet(f,data=train_data,hidden=c(5,3),linear.output=F)\n```", "```py\nplot(deep_net)\n```", "```py\npredicted_data <- compute(deep_net,test_data[,2:18])\nprint(head(predicted_data$net.result))\n```", "```py\n> print(head(predicted_data$net.result))\n [,1]\nAbilene Christian University 0.1917109322\nAdelphi University           1.0000000000\nAdrian College               1.0000000000\nAgnes Scott College          1.0000000000\nAlbertus Magnus College      1.0000000000\nAlbion College               1.0000000000\n```", "```py\npredicted_data$net.result <- sapply(predicted_data$net.result,round,digits=0)\n```", "```py\ntable(test_data$Private,predicted_data$net.result)\n```", "```py\n> table(test_data$Private,predicted_data$net.result)\n\n 0   1\n 0 49   8\n 1  9 167\n```", "```py\n> table(test_data$Private)\n 0   1 \n 57 176\n```", "```py\n> 49 + 8\n[1] 57\n> 9 + 167\n[1] 176\n```", "```py\n> table(predicted_data$net.result)\n 0   1 \n 58 175\n```", "```py\n> 49 + 9\n[1] 58\n> 8 + 167\n[1] 175\n```", "```py\n> Acc = (49 + 167) / (49 + 167 + 9 + 8) \n> Acc\n[1] 0.9270386266\n```", "```py\ninstall.packages(\"h2o\")\n```", "```py\n> install.packages(\"h2o\")\nInstalling package into ‘C:/Users/Giuseppe/Documents/R/win-library/3.4’\n(as ‘lib’ is unspecified)\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/h2o_3.10.5.3.zip'\nContent type 'application/zip' length 73400625 bytes (70.0 MB)\ndownloaded 70.0 MB\npackage ‘h2o’ successfully unpacked and MD5 sums checked\nThe downloaded binary packages are in\n C:\\Users\\Giuseppe\\AppData\\Local\\Temp\\RtmpGEc5iI\\downloaded_packages\n```", "```py\n##########################################################################\n#################Chapter 3 - Deep Learning with H2O and R################# ##########################################################################\n\nlibrary(h2o)\n\nc1=h2o.init(max_mem_size = \"2G\", \n nthreads = 2, \n ip = \"localhost\", \n port = 54321)\n\ndata(iris)\nsummary(iris)\n\niris_d1 <- h2o.deeplearning(1:4,5,\n as.h2o(iris),hidden=c(5,5),\n export_weights_and_biases=T)\niris_d1\nplot(iris_d1)\n\nh2o.weights(iris_d1, matrix_id=1)\nh2o.weights(iris_d1, matrix_id=2)\nh2o.weights(iris_d1, matrix_id=3)\nh2o.biases(iris_d1, vector_id=1)\nh2o.biases(iris_d1, vector_id=2)\nh2o.biases(iris_d1, vector_id=3)\n\n#plot weights connecting `Sepal.Length` to first hidden neurons\nplot(as.data.frame(h2o.weights(iris_d1, matrix_id=1))[,1])\n\n##########################################################################\n```", "```py\nlibrary(h2o)\n```", "```py\nYour next step is to start H2O:\n > h2o.init()\nFor H2O package documentation, ask for help:\n > ??h2o\nAfter starting H2O, you can use the Web UI at http://localhost:54321\nFor more information visit http://docs.h2o.ai\nc1=h2o.init(max_mem_size = \"2G\", \n nthreads = 2, \n ip = \"localhost\", \n port = 54321)\n```", "```py\nc1=h2o.init(max_mem_size = \"2G\", \n nthreads = 2, \n ip = \"localhost\", \n port = 54321)\n```", "```py\n> c1=h2o.init(max_mem_size = \"2G\", nthreads = 2)\nH2O is not running yet, starting it now...\n\nNote: In case of errors look at the following log files:\n C:\\Users\\Giuseppe\\AppData\\Local\\Temp\\RtmpU3xPvT/h2o_Giuseppe_started_from_r.out\n C:\\Users\\Giuseppe\\AppData\\Local\\Temp\\RtmpU3xPvT/h2o_Giuseppe_started_from_r.err\n\njava version \"1.8.0_144\"\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n\nStarting H2O JVM and connecting: . Connection successful!\n\nR is connected to the H2O cluster: \n H2O cluster uptime: 6 seconds 912 milliseconds \n H2O cluster version: 3.10.5.3 \n H2O cluster version age: 2 months and 9 days \n H2O cluster name: H2O_started_from_R_Giuseppe_woc815 \n H2O cluster total nodes: 1 \n H2O cluster total memory: 1.78 GB \n H2O cluster total cores: 4 \n H2O cluster allowed cores: 2 \n H2O cluster healthy: TRUE \n H2O Connection ip: localhost \n H2O Connection port: 54321 \n H2O Connection proxy: NA \n H2O Internal Security: FALSE \n R Version: R version 3.4.1 (2017-06-30)\n```", "```py\ndata(iris)\nsummary(iris)\n```", "```py\n> summary(iris)\n Sepal.Length    Sepal.Width     Petal.Length    Petal.Width \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100 \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300\n Median :5.800   Median :3.000   Median :4.350   Median :1.300 \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199 \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800 \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500      Species\nsetosa    :50 \nversicolor:50 \nvirginica :50 \n```", "```py\niris_d1 <- h2o.deeplearning(1:4,5,\n as.h2o(iris),hidden=c(5,5),\n export_weights_and_biases=T)\n```", "```py\niris_d1\n```", "```py\nplot(iris_d1)\n```", "```py\nh2o.weights(iris_d1, matrix_id=1)\nh2o.weights(iris_d1, matrix_id=2)\nh2o.weights(iris_d1, matrix_id=3)\nh2o.biases(iris_d1, vector_id=1)\nh2o.biases(iris_d1, vector_id=2)\nh2o.biases(iris_d1, vector_id=3)\n```", "```py\n> h2o.weights(iris_d1, matrix_id=1) \n Sepal.Length Sepal.Width Petal.Length  Petal.Width\n1 -0.013207575 -0.06818321  -0.02756812  0.092810206\n2  0.036195096  0.02568028   0.05634377  0.035429616\n3 -0.002411760 -0.11541270   0.08219513  0.001957144\n4  0.091338813 -0.03271343  -0.25603485 -0.205898494\n6 -0.151234403  0.01785624  -0.11815275 -0.110585481 \n[200 rows x 4 columns] \n\n> h2o.biases(iris_d1, vector_id=1) \nC11 0.48224932 0.47699773 0.48994124 0.49552965 0.48991496 0.4739439 \n[200 rows x 1 column] \n```", "```py\nplot(as.data.frame(h2o.weights(iris_d1, matrix_id=1))[,1])\n```", "```py\n> h2o.confusionMatrix(iris_d1)\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class \n setosa versicolor virginica  Error      Rate\nsetosa         50          0         0 0.0000 =  0 / 50\nversicolor      0         48         2 0.0400 =  2 / 50\nvirginica       0          2        48 0.0400 =  2 / 50\nTotals         50         50        50 0.0267 = 4 / 150\n```", "```py\n> pairs(iris[1:4], main = \"Scatterplot matrices of Iris Data\", pch = 21, bg = c(\"red\", \"green3\", \"blue\")[unclass(iris$Species)])\n```", "```py\n> h2o.hit_ratio_table(iris_d1)\nTop-3 Hit Ratios: \n k hit_ratio\n1 1 0.973333\n2 2 1.000000\n3 3 1.000000\n```", "```py\n> h2o.r2(iris_d1)\n[1] 0.9596034\n```", "```py\nm=iris.lm <- h2o.glm(x=2:5,y=1,training_frame=as.h2o(iris))\n```", "```py\n> h2o.r2(m)\n[1] 0.8667852\n```", "```py\nanomaly_model <- h2o.deeplearning(1:4,\n training_frame = as.h2o(iris),\n activation = \"Tanh\",\n autoencoder = TRUE,\n hidden = c(50,20,50),\n sparse = TRUE,\n l1 = 1e-4,\n epochs = 100)\n```"]