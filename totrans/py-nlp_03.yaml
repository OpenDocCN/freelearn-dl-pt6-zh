- en: Understanding the Structure of a Sentences
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we'll explore the basic concepts of NLP. This chapter is the
    most important chapter, as it helps to make your foundation strong.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to cover the following topics to improve your understanding of
    the basic NLP concepts, which will help understand the next chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the components of NLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is context-free grammar?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Morphological analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lexical analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Syntactic analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semantic analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling ambiguity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discourse integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pragmatic analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding components of NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two major components of NLP. We are going to understand both of them.
  prefs: []
  type: TYPE_NORMAL
- en: Natural language understanding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s learn about natural language understanding:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Natural language understanding** (**NLU**) is considered the first component
    of NLP'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NLU is considered an **Artificial Intelligence**-**Hard** (**AI**-**Hard**)
    problem or **Artificial Intelligence**-**Complete** (**AI-Complete**) problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NLU is considered an AI-Hard problem because we are trying to make a computer
    as intelligent as a human
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NLU is hard, but nowadays, tech giants and research communities are improvising
    traditional Machine Learning algorithms and applying various types of deep neural
    network that will help to achieve the goal (computers can also have the intelligence
    to process **natural language** (**NL**))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NLU is defined as the process of converting NL input into useful a representation
    by using computational linguistics tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'NLU requires the following analysis to convert NL into a useful representation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Morphological analysis
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Lexical analysis
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Syntactic analysis
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Semantic analysis
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling ambiguity
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Discourse integration
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Pragmatic analysis
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In this book, we will focus on NLU and develop an NLP-based system that uses
    NLU representation.
  prefs: []
  type: TYPE_NORMAL
- en: Natural language generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s learn about **natural language generation** (**NLG**):'
  prefs: []
  type: TYPE_NORMAL
- en: NLG is considered the second component of NLP.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NLG is defined as the process of generating NL by a machine as output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output of the machine should be in a logical manner, meaning, whatever NL
    is generated by the machine should be logical.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to generate logical output, many NLG systems use basic facts or knowledge-based
    representation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take an example. You have a system that writes an essay on a particular
    topic. If I am instructing my machine to generate 100 words on the topic of **The
    Cows**, and my machine generates 100 words on the topic of cows, then the output
    (here, 100 words about cows) generated by the machine should be in form of valid
    sentences, all sentences should be logically correct, and the context should also
    make sense.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Differences between NLU and NLG
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we are looking at the differences between NLU and NLG:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **NLU** | **NLG** |'
  prefs: []
  type: TYPE_TB
- en: '| This component helps to explain the meaning behind the NL, whether it is
    written text or in speech format. We can analyze English, French, Spanish, Hindi,
    or any other human language. | This component helps to generate the NL using machines.
    |'
  prefs: []
  type: TYPE_TB
- en: '| NLU generates facts from NL by using various tools and techniques, such as
    POS tagger, parsers, and so on, in order to develop NLP applications. | NLG start
    from facts like POS tags, parsing results, and so on to generate the NL. |'
  prefs: []
  type: TYPE_TB
- en: '| It is the process of reading and interpreting language. | It is the process
    of writing or generating language. |'
  prefs: []
  type: TYPE_TB
- en: Branches of NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NLP involves two major branches that help us to develop NLP applications. One
    is computational, the **Computer Science** branch, and the other one is the **Linguistics**
    branch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Refer to *Figure 3.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/680b98f4-c97e-4137-8e26-0dec9c2e7bb2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.1: Branches of NLP'
  prefs: []
  type: TYPE_NORMAL
- en: The **Linguistics** branch focuses on how NL can be analyzed using various scientific
    techniques. So, the **Linguistics** branch does scientific analysis of the form,
    meaning, and context.
  prefs: []
  type: TYPE_NORMAL
- en: All linguistics analysis can be implemented with the help of computer science
    techniques. We can use the analysis and feed elements of analysis in a machine
    learning algorithm to build an NLP application. Here, the machine learning algorithm
    is a part of **Computer Science**, and the analysis of language is **Linguistics**.
  prefs: []
  type: TYPE_NORMAL
- en: Computational linguistics is a field that helps you to understand both computer
    science and linguistics approaches together.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a list of tools that are linguistics concepts and are implemented with
    the help of computer science techniques. These tools are often used for developing
    NLP applications:'
  prefs: []
  type: TYPE_NORMAL
- en: For POS tagging, POS taggers are used. Famous libraries are `nltk` and `pycorenlp`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Morph analyzers are used to generate word-level stemming. For this, the `nltk`
    and `polyglot` libraries are used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parsers are used to identify the structure of the sentences. For this, we are
    using Stanford CoreNLP and `nltk` to generate a parsing tree. You can use Python
    package called `spaCy`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining context-free grammar
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let's focus on NLU, and to understand it, first we need to understand **context-free
    grammar** (**CFG**) and how it is used in NLU.
  prefs: []
  type: TYPE_NORMAL
- en: 'Context-free grammar is defined by its four main components. Those four components
    are shown in this symbolic representation of CFG:'
  prefs: []
  type: TYPE_NORMAL
- en: A set of non-terminal symbols, **N**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of terminal symbols, **T**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A start symbol, **S**, which is a non-terminal symbol
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of rules called **production** **rules P**, for generating sentences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take an example to get better understanding of the context-free grammar
    terminology:'
  prefs: []
  type: TYPE_NORMAL
- en: '***X ->** ![](img/30e1e2bf-4fe0-4b65-90cb-66985a0bd284.png)*'
  prefs: []
  type: TYPE_NORMAL
- en: Here, ***X->** ![](img/30e1e2bf-4fe0-4b65-90cb-66985a0bd284.png)* is called
    the **phrase structure rule** or **production rule**, **P**. *X* ε *N* means *X*
    belongs to non-terminal symbol; ![](img/30e1e2bf-4fe0-4b65-90cb-66985a0bd284.png)
    ε {**N** or **T**} means ![](img/30e1e2bf-4fe0-4b65-90cb-66985a0bd284.png) belongs
    to either terminal symbols or non-terminal symbols. *X* can be rewritten in the
    form of ![](img/30e1e2bf-4fe0-4b65-90cb-66985a0bd284.png). The rule tells you
    which element can be rewritten to generate a sentence, and what the order of the
    elements will be as well.
  prefs: []
  type: TYPE_NORMAL
- en: Now I will take a real NLP example. I'm going to generate a sentence using CFG
    rules. We are dealing with simple sentence structure to understand the concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Let's think. What are the basic elements required to generate grammatically
    correct sentences in English? Can you remember them? Think!
  prefs: []
  type: TYPE_NORMAL
- en: 'I hope you remember that noun phrases and verb phrases are important elements
    of the sentences. So, start from there. I want to generate the following sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: He likes cricket.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to generate the preceding sentence, I''m proposing the following production
    rules:'
  prefs: []
  type: TYPE_NORMAL
- en: 'R1: S -> NP VP'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'R2: NP -> N'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'R3: NP -> Det N'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'R4: VP -> V NP'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'R5: VP -> V'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'R6: N -> Person Name | He | She | Boy | Girl | It | cricket | song | book'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'R7: V -> likes | reads | sings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'See the parse tree of the sentence: **He likes cricket**, in *Figure 3.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/be2ec958-8f06-4f77-a7ff-a40df50df1ec.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.2: Parse tree for the sentence using the production rule'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s know how we have generated a parse tree:'
  prefs: []
  type: TYPE_NORMAL
- en: According to the production rules, we can see **S** can be rewritten as a combination
    of a **noun phrase** (**NP**) and a **verb phrase** (**VP**); see rule *R1*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NP** can be further rewritten as either a **noun** (**NN**) or as a **determiner**
    (**Det**) followed by a noun; see rules *R2* and *R3*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now you can rewrite the **VP** in form of a **verb** (**V**) followed by a **NP**,
    or a **VP** can be rewritten as just **V**; see rules *R4* and *R5*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, **N** can be rewritten in the form of **Person Name**, **He**, **She**,
    and so on. **N** is a terminal symbol; see the rule *R6*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**V** can be rewritten by using any of the options on the right-hand side in
    rule *R7*. **V** is also terminal symbol.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By using all the rules, we have generated the parse tree in *Figure 3.2*.
  prefs: []
  type: TYPE_NORMAL
- en: Don't worry if you cannot generate a parse tree. We will see the concept and
    implementation details in the Chapter 5, *Feature Engineering and NLP Algorithms*.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we have seen a very basic and simple example of CFG. Context-free grammar
    is also called **phrase structure grammar**.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Generate a parse tree by using the rule given previously in this section and
    generate the parse tree for the following sentence:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: She sings a song.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Generate production rules and make a parse tree for the following sentence:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That boy is reading a book.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Morphological analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here, we are going to explore the basic terminology used in field of morphological
    analysis. The terminology and concepts will help you when you are solving real-life
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: What is morphology?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Morphology is branch of linguistics that studies how words can be structured
    and formed.
  prefs: []
  type: TYPE_NORMAL
- en: What are morphemes?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In linguistics, a morpheme is the smallest meaningful unit of a given language.
    The important part of morphology is morphemes, which are the basic unit of morphology.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take an example. The word *boy* consists of single morpheme whereas *boys*
    consists of two morphemes; one is *boy* and the other morpheme -*s*
  prefs: []
  type: TYPE_NORMAL
- en: What is a stem?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The part of a word that an affix is attached to is called as **stem**. The word
    *tie* is **root** whereas *Untie* is **stem.**
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's understand morphological analysis.
  prefs: []
  type: TYPE_NORMAL
- en: What is morphological analysis?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Morphological analysis is defined as grammatical analysis of how words are formed
    by using morphemes, which are the minimum unit of meaning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, morphemes are affixes. Those affixes can be divided into four types:'
  prefs: []
  type: TYPE_NORMAL
- en: Prefixes, which appear before a stem, such as **un**happy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suffixes, which appear after a stem, such as happi**ness**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Infixes, which appear inside a stem, such as b**um**ili (this means buy in Tagalog,
    a language from the Philippines)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Circumfixes surround a word. It is attached to the beginning and end of the
    stem. For example, **ka**baddang**an** (this means help in Tuwali Ifugao, another
    language from the Philippines)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Morphological analysis is used in word segmentation, and **Part Of Speech**
    (**POS**) tagging uses this analysis. I will explain about POS in the *Lexical
    analysis* section, so bear with me until we will connect the dots.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take an example to practically explain the concepts that I have proposed.
    I would like to take the word **Unexpected**. Refer to *Figure 3.3*, which gives
    you an idea about the morphemes and how morphological analysis has taken place:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de0833b8-b0e7-454d-8bda-3565ffeea8bf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.3: Morphemes and morphological analysis'
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 3.3*, we have expressed **Unexpected** as morphemes and performed
    morphological analysis the morphemes. Here, **Un** is a **Prefix**, and **ed**
    is a **Suffix**. **Un** and **ed** can be considered as **affixes**, **Unexpect**
    is the **Stem**.
  prefs: []
  type: TYPE_NORMAL
- en: Let's refer to another important concept and try to relate it to the concept
    of morphemes. I'm talking about how you define a word. Let's see.
  prefs: []
  type: TYPE_NORMAL
- en: What is a word?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A word can be isolated from a sentence as the single smallest element of a sentence
    that carries meaning. This smallest single isolated part of a sentence is called
    a **word**.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the morphemes definition again and try to relate it to the definition
    of word. The reason why I have told you to do this is that you may confuse words
    and morphemes, or maybe you are not sure what the difference is between them.
    It is completely fine that you have thought in this way. They are confusing if
    you do not understand them properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The definitions look similar, but there is a very small difference between
    words and morphemes. We can see the differences in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Morpheme** | **Word** |'
  prefs: []
  type: TYPE_TB
- en: '| Morphemes can or cannot stand alone. The word *cat* can stand alone but plural
    marker *-s* cannot stand alone. Here *cat* and *-s* both are morpheme. | A word
    can stand alone. So, words are basically free-standing units in sentences. |'
  prefs: []
  type: TYPE_TB
- en: '| When a morpheme stands alone then that morpheme is called **root** because
    it conveys the meaning of its own, otherwise morpheme mostly takes affixes.The
    analysis of what kind of affixes morpheme will take is covered under morphological
    analysis. | A word can consist of a single morpheme. |'
  prefs: []
  type: TYPE_TB
- en: '| For example, *cat* is a standalone morpheme, but when you consider *cats*,
    then the suffix *-s* is there, which conveys the information that *cat* is one
    morpheme and the suffix *-s* indicates the grammatical information that the given
    morpheme is the plural form of *cat*. | For example: *Cat* is a standalone word.*Cats*
    is also a standalone word. |'
  prefs: []
  type: TYPE_TB
- en: Classification of morphemes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The classification of morphemes gives us lots of information about how the
    whole concept of morphological analysis works. Refer to *Figure 3.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d590d981-f6ca-4c07-8a15-6645631423c7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.4: Classification of morphemes'
  prefs: []
  type: TYPE_NORMAL
- en: There two major part of morphemes.
  prefs: []
  type: TYPE_NORMAL
- en: Free morphemes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Free morphemes can be explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Free morphemes can stand alone and act as a word. They are also called **unbound
    morphemes** or **free-standing morphemes**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s see some of examples:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dog, cats, town, and house.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All the preceding words can be used with other words as well. Free morphemes
    can appear with other words as well. These kinds of words convey meaning that
    is different if you see the words individually.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s see examples of that:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Doghouse, town hall.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, the meaning of doghouse is different from the individual meanings of dog
    and house. The same applies to town hall.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Bound morphemes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bound morphemes usually take affixes. They are further divided into two classes.
  prefs: []
  type: TYPE_NORMAL
- en: Derivational morphemes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Derivational morphemes are identified when infixes combine with the root and
    changes either the semantic meaning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: Take the word **unkind**. In this word, **un** is a prefix and **kind** is the
    root. The prefix **un** acts as a derivational morpheme that changes the meaning
    of the word **kind** to its opposite meaning, unkind.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Take the word **happiness**. In this word, -**ness** is a derivational morpheme
    and **happy** is the root word. So, -**ness** changes happy to happiness. Check
    the POS tag, **happy** is an adjective and **happiness** is a noun. Here, tags
    that indicate the class of word, such as adjective and noun, are called POS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inflectional morphemes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inflection morphemes are suffixes that are added to a word to assign particular
    grammatical property to that word. Inflectional morphemes are considered to be
    grammatical markers that indicate tense, number, POS, and so on. So, in more simple
    language, we can say that inflectional morphemes are identified as types of morpheme
    that modify the verb tense, aspect, mood, person, number (singular and plural),
    gender, or case, without affecting the words meaning or POS.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: In the word **dogs**, -**s** changes the number of **dog**. -**s** converts
    **dog** from singular to plural form of it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The word **expected** contains -**ed**, which is an inflectional morpheme that
    modifies the verb tense
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is the code for generating the stem from morphemes. We are using the `nltk`
    and `polyglot` libraries. You can find the code on this link: [https://github.com/jalajthanaki/NLPython/blob/master/ch3/3_1_wordsteam.py](https://github.com/jalajthanaki/NLPython/blob/master/ch3/3_1_wordsteam.py)'
  prefs: []
  type: TYPE_NORMAL
- en: 'See the code snippets in *Figure 3.5* and *Figure 3.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9df95dda-917e-4113-a25b-fbc5ca229541.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.5: Generating stems from morphemes using NLTK'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's see how the `polyglot` library has been used refer to *Figure 3.6****:***
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f6c740ed-1658-40d5-aa19-c79e9fd09b1a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.6: Generating stems from morphemes using the polyglot library'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the code snippet is displayed in *Figure 3.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a02b5e5f-475c-45a3-bc33-7e3edd1c0da8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.7: Output of code snippets in Figure 3.5 and Figure 3.6'
  prefs: []
  type: TYPE_NORMAL
- en: What is the difference between a stem and a root?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This could be explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Stem** | **Root** |'
  prefs: []
  type: TYPE_TB
- en: '| In order to generate a stem, we need to remove affixes from the word | A
    root cannot be further divided into smaller morphemes |'
  prefs: []
  type: TYPE_TB
- en: '| From the stem, we can generate the root by further dividing it | A stem is
    generated by using a root plus derivational morphemes |'
  prefs: []
  type: TYPE_TB
- en: '| The word **Untie** is stem | The word **tie** is root |'
  prefs: []
  type: TYPE_TB
- en: Exercise
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Do a morphological analysis like we did in *Figure 3.3* for the morphemes in
    redness, quickly, teacher, unhappy, and disagreement. Define prefixes, suffixes,
    verbs, and stems.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate the stems of the words redness, quickly, teacher, disagreement, reduce,
    construction, deconstruction, and deduce using the `nltk` and `polyglot` libraries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate the stems and roots of disagree, disagreement, historical.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lexical analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lexical analysis is defined as the process of breaking down a text into words,
    phrases, and other meaningful elements. Lexical analysis is based on word-level
    analysis. In this kind of analysis, we also focus on the meaning of the words,
    phrases, and other elements, such as symbols.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, lexical analysis is also loosely described as the **tokenization
    process**. So, before discussing tokenization, let's understand what a token is
    and what a POS tag is.
  prefs: []
  type: TYPE_NORMAL
- en: What is a token?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tokens are defined as the meaningful elements that are generated by using techniques
    of lexical analysis.
  prefs: []
  type: TYPE_NORMAL
- en: What are part of speech tags?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A part of speech is a category of words or lexical items that have similar grammatical
    properties. Words belonging to the same **part of speech** (**POS**) category
    have similar behavior within the grammatical structure of sentences.
  prefs: []
  type: TYPE_NORMAL
- en: In English, POS categories are verb, noun, adjective, adverb, pronoun, preposition,
    conjunction, interjection, and sometimes numeral, article, or determiner.
  prefs: []
  type: TYPE_NORMAL
- en: Process of deriving tokens
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Sentences are formed by stream of words and from a sentence we need to derive
    individual meaningful chunks which are called the **tokens** and process of deriving
    token is called **tokenization**:'
  prefs: []
  type: TYPE_NORMAL
- en: The process of deriving tokens from a stream of text has two stages. If you
    have a lot of paragraphs, then first you need to do sentence tokenization, then
    word tokenization, and generate the meaning of the tokens.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tokenization and lemmatization are processes that are helpful for lexical analysis.
    Using the `nltk` library, we can perform tokenization and lemmatization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tokenization can be defined as identifying the boundary of sentences or words.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lemmatization can be defined as a process that identifies the correct intended
    POS and meaning of words that are present in sentences.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lemmatization also includes POS tagging to disambiguate the meaning of the tokens.
    In this process, the context window is either phrase level or sentence level.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can find the code at the GitHub link: [https://github.com/jalajthanaki/NLPython/tree/master/ch3](https://github.com/jalajthanaki/NLPython/tree/master/ch3)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code snippet is shown in *Figure 3.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e5cecd2f-49b4-48f6-954d-40b1a7c80a5f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.8: Code snippet for tokenization'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the code in *Figure 3.8* is shown in *Figure 3.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/07ee541e-7b12-45f4-8f91-e4e3317a0c5d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.9: Output of tokenization and lemmatization'
  prefs: []
  type: TYPE_NORMAL
- en: Difference between stemming and lemmatization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Stemming and lemmatization both of these concepts are used to normalized the
    given word by removing infixes and consider its meaning. The major difference
    between these is as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Stemming** | **Lemmatization** |'
  prefs: []
  type: TYPE_TB
- en: '| Stemming usually operates on single word without knowledge of the context
    | Lemmatization usually considers words and the context of the word in the sentence
    |'
  prefs: []
  type: TYPE_TB
- en: '| In stemming, we do not consider POS tags | In lemmatization, we consider
    POS tags |'
  prefs: []
  type: TYPE_TB
- en: '| Stemming is used to group words with a similar basic meaning together | Lemmatization
    concept is used to make dictionary or WordNet kind of dictionary. |'
  prefs: []
  type: TYPE_TB
- en: Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You must think how this lexical analysis has been used for developing NLP applications.
    So, here we have listed some of the NLP applications which uses lexical analysis
    concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: Lexical analysis such as sentence tokenization and stop word identification
    is often used in preprocessing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lexical analysis also used to develop a POS tagger. A POS tagger is a tool that
    generates POS tags for a stream of text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Syntactic analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have seen word-level analysis in lexical analysis. In this section, we will
    look at things from a higher level. We are going to focus on the grammar and structure
    of sentences by considering the phrases in the sentences.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's define syntactic analysis and see how it will be used in NLP applications.
  prefs: []
  type: TYPE_NORMAL
- en: What is syntactic analysis?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Syntactic analysis is defined as analysis that tells us the logical meaning
    of certain given sentences or parts of those sentences. We also need to consider
    rules of grammar in order to define the logical meaning as well as correctness
    of the sentences.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take an example: If I''m considering English and I have a sentence such
    as **School go a boy**, this sentence does not logically convey its meaning, and
    its grammatical structure is not correct. So, syntactic analysis tells us whether
    the given sentence conveys its logical meaning and whether its grammatical structure
    is correct.'
  prefs: []
  type: TYPE_NORMAL
- en: Syntactic analysis is a well-developed area of NLP that deals with the syntax
    of NL. In syntactic analysis, grammar rules have been used to determine which
    sentences are legitimate. The grammar has been applied in order to develop a parsing
    algorithm to produce a structure representation or a parse tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, I will generate the parse tree by using the `nltk` and Python wrapper
    libraries for Stanford CoreNLP called `pycorenlp`. Refer the following code snippet
    in *Figure 3.10* and in *Figure 3.11*. The output is given in *Figure 3.12*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5bc03edc-cbce-4e6b-bb40-936eeb90494c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.10: Code snippet for syntactic analysis'
  prefs: []
  type: TYPE_NORMAL
- en: 'How you can use Stanford parser for syntactic analysis is demonstrated in next
    *Figure 3.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c5b21b59-4943-49ca-b967-4f0be1c22dee.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.11: Code snippet for syntactic analysis'
  prefs: []
  type: TYPE_NORMAL
- en: You can see the output of the preceding two code snippet as follows. Refer to
    *Figure 3.12:*
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/38d8d6f5-bf1f-42cd-9ef0-40418093d385.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.12: Output of parsing as part of syntactic analysis'
  prefs: []
  type: TYPE_NORMAL
- en: We will see the parsing tools and its development cycle related details in Chapter
    5, *Feature Engineering and NLP Algorithms*.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Semantic analysis is basically focused on the meaning of the NL. Its definition,
    various elements of it, and its application are explored in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's begin our semantic journey, which is quite interesting if you want
    to do some cool research in this branch.
  prefs: []
  type: TYPE_NORMAL
- en: What is semantic analysis?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Semantic analysis is generating representation for meaning of the NL. You might
    think, if lexical analysis also focuses on the meaning of the words given in stream
    of text, then what is the difference between semantic analysis and lexical analysis?
    The answer is that lexical analysis is based on smaller tokens; its focus is on
    meaning of the words, but semantic analysis focuses on larger chunks. Semantic
    analysis can be performed at the phrase level, sentence level, paragraph level,
    and sometimes at the document level as well. Semantic analysis can be divided
    into two parts, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The study of the meaning of the individual word is called **lexical semantics**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The study of how individual words combine to provide meaning in sentences or
    paragraphs in the context of dealing with a larger unit of NL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I want to give an example. If you have a sentence such as the **white house
    is great**, this can mean the statement is in context of the White House in the
    USA, whereas it is also possible the statement is literally talking about a house
    nearby, whose color is white is great. So, getting the proper meaning of the sentence
    is the task of semantic analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Lexical semantics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lexical semantics includes words, sub-words, or sub-units such as affixes, and
    even compound words, and phrases. Here words, sub-words and so on called **lexical
    items**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The study of lexical semantics includes the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: Classification of lexical items
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decomposition of lexical items
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Differences and similarities between various lexical semantic structures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lexical semantics is the relationship among lexical items, meaning of the sentences
    and syntax of the sentence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's see the various elements that are part of semantic analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Hyponymy and hyponyms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hyponymy describes the relationship between a generic term and instances of
    the specified generic term. Here, a generic term is called a **hypernym**, and
    instances of the generic term are called **hyponyms**.
  prefs: []
  type: TYPE_NORMAL
- en: So, color is a hypernym; red, green, yellow, and so on are hyponyms.
  prefs: []
  type: TYPE_NORMAL
- en: Homonymy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Homonyms are words that have a same syntax or same spelling or same form but
    their meaning are different and unrelated to each other.
  prefs: []
  type: TYPE_NORMAL
- en: The word bank is a classic example. It can mean a financial institution or a
    river bank, among other things.
  prefs: []
  type: TYPE_NORMAL
- en: Polysemy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to understand polysemy, we are focused on words of the sentences. Polysemy
    is a word or phrase which have different, but related senses. These kinds of words
    are also referred as lexically ambiguous words.
  prefs: []
  type: TYPE_NORMAL
- en: Take the word bank. There are several senses or meaning you can consider.
  prefs: []
  type: TYPE_NORMAL
- en: Bank is financial institution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bank can be interpreted as river bank
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the difference between polysemy and homonymy?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A word is called **polysemous** if it is used to express different meanings.
    The difference between the meanings of the word can be obvious.
  prefs: []
  type: TYPE_NORMAL
- en: Two or more words are called **homonyms** if they either have the same sound
    or have the same spelling but do not have related meanings.
  prefs: []
  type: TYPE_NORMAL
- en: Application of semantic analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Semantic analysis is one of the open research area so its basic concepts can
    be used by following applications:'
  prefs: []
  type: TYPE_NORMAL
- en: Word sense disambiguation is one of the major tasks in NLP where semantic analysis
    has been heavily used, and it's still an open research area for Indian languages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will see **word** **sense** **disambiguation** (**WSD**) usage in [Chapter
    7](0dc5bd44-3b7d-47ac-8b0d-51134007b483.xhtml), *Rule-Based System for NLP*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The word2vec concept has emerged to handle semantic similarity. We will see
    this in Chapter 6, *Advance Feature Engineering and NLP Algorithms*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling ambiguity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we jump into semantic analysis, we may find there are many cases that are
    too ambiguous for an NLP system to handle. In these cases, we need to know what
    kinds of ambiguity exist and how we can handle them.
  prefs: []
  type: TYPE_NORMAL
- en: Ambiguity is one of the areas of NLP and cognitive sciences that doesn't have
    a well-defined solution. Sometimes, sentences are so complex and ambiguous that
    only the speaker can define the original or definite meaning of the sentence.
  prefs: []
  type: TYPE_NORMAL
- en: A word, phrase, or sentence is ambiguous if it has more than one meaning. If
    we consider word **light**,than it can mean not very heavy or not very dark. This
    is word level ambiguity. The phrase **porcelain egg container** is structure level
    ambiguity. So, here we will see different types of ambiguities in NLP .
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s see the types of ambiguity, and then see how to handle them by
    using the means that are available. Refer to *Figure 3.13* for the different types
    of ambiguity:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5b0d5e96-c201-42a1-87cc-587c06bd1498.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.13: Types of ambiguity'
  prefs: []
  type: TYPE_NORMAL
- en: Lexical ambiguity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Lexical ambiguity is word-level ambiguity. A single word can have ambiguous
    meaning in terms of its internal structure and its syntactic class. Let''s look
    at some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sentence 1: Look at the stars. Here, *look* is a verb.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sentence 2: The person gave him a warm look. Here, *look* is a noun.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sentence 3: She won three silver medals. Here, *silver* is a noun.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sentence 4: She made silver speech. Here, *silver* is a adjective.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sentence 5: His stress had silvered his hair. Here, *silvered* is a verb.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the preceding examples, specific words change their POS tags according to
    their usage in sentence structure. This kind of ambiguity can been resolved by
    using two approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: By using accurate POS tagger tools, this kind of ambiguity can be resolved
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WordNet sense has various scenes available for a word when the words take specific
    POS tag. This also helps to handle ambiguity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many Indian languages have the same issue of lexical ambiguity.
  prefs: []
  type: TYPE_NORMAL
- en: Syntactic ambiguity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have seen, in syntactic analysis, sequences of words are grammatically structured.
    There are different ways of interpreting sequences of words, and each structure
    has a different interpretation. In syntactic ambiguity, syntax is unclear, not
    the word-level meaning. Here is an example of structural ambiguity:'
  prefs: []
  type: TYPE_NORMAL
- en: The man saw the girl with the telescope. Here, the ambiguity is because it is
    not clear whether the man sees the girl, who has a telescope, or the man sees
    the girl by using telescope. This ambiguity is called **prepositional phrase**
    (**PP**) ambiguity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approach to handle syntactic ambiguity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To handle this ambiguity, we need to use statistical approaches and get the
    most likelihood ratio. We need to take co-occurrences between the verb and the
    preposition in one hand, and preposition and the noun on other hand, and then
    calculate the log-likelihood ratio by using following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e4a2a65e-f919-4a43-b179-c151e067fac0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.14: Log-likelihood ratio'
  prefs: []
  type: TYPE_NORMAL
- en: Here, *p(p/v)* is the probability of seeing a PP with preposition *p* and after
    verb *v*.
  prefs: []
  type: TYPE_NORMAL
- en: And *p(p/n)* is the probability of seeing a PP with preposition *p* after noun
    *n*.
  prefs: []
  type: TYPE_NORMAL
- en: If *F(v,p,n) < 0*, then we need to attach the preposition to the noun, and if
    *F(v,p,n)* >0, then we need to attach preposition to the verb. We will see the
    implementation in [Chapter 5](07f71ca1-6c8a-492d-beb3-a47996e93f04.xhtml), *Feature
    Engineering and NLP Algorithms*.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic ambiguity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Semantic ambiguity occurs when the meaning of the words themselves can be misinterpreted.
    Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: ABC head seeks arms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, the word head either means chief or body part, and in the same way, arms
    can be interpreted as weapons or as body parts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This kind of ambiguity is considered in semantic ambiguity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling semantic ambiguity with high accuracy is an open research area. Nowadays,
    the word2vec representation technique is very useful for handling semantic ambiguity.
  prefs: []
  type: TYPE_NORMAL
- en: Pragmatic ambiguity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Pragmatics ambiguity occurs when the context of a phrase gives it multiple
    different interpretations. Let''s take an example:'
  prefs: []
  type: TYPE_NORMAL
- en: Give it to that girl. This could mean any number of things.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now let''s take a large context:'
  prefs: []
  type: TYPE_NORMAL
- en: I have chocolate and a packet of biscuits. Give it to that girl. Here, it is
    not clear whether it refers to chocolate or the packet of biscuits.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling this kind of ambiguity is still an open area of research.
  prefs: []
  type: TYPE_NORMAL
- en: Discourse integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Discourse integration is closely related to pragmatics. Discourse integration
    is considered as the larger context for any smaller part of NL structure. NL is
    so complex and, most of the time, sequences of text are dependent on prior discourse.
  prefs: []
  type: TYPE_NORMAL
- en: This concept occurs often in pragmatic ambiguity. This analysis deals with how
    the immediately preceding sentence can affect the meaning and interpretation of
    the next sentence. Here, context can be analyzed in a bigger context, such as
    paragraph level, document level, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Concepts of discourse integration have been used by following NLP applications:'
  prefs: []
  type: TYPE_NORMAL
- en: This concept often used in NLG applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chatbots, which are developed to deliver generalized AI. In this kind of application,
    deep learning has been used. We will see the NLG with deep learning in [Chapter
    9](f414d38e-b88e-4239-88bd-2d90e5ce67ab.xhtml), *Deep Learning for NLP and NLG
    Problems*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pragmatic analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pragmatic analysis deals with outside word knowledge, which means knowledge
    that is external to the documents and/or queries. Pragmatics analysis that focuses
    on what was described is reinterpreted by what it actually meant, deriving the
    various aspects of language that require real world knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example:'
  prefs: []
  type: TYPE_NORMAL
- en: Pruning a tree is a long process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, pruning a tree is one of the concepts of computer science algorithm techniques.
    So, the word **pruning** is not related to cutting the actual physical tree, we
    are talking about computer science algorithm. This is an ambiguous situation;
    how to deal with these kinds of ambiguous situations is also an open area of research.
    Big tech giants use deep learning techniques to do pragmatics analysis and try
    to generate the accurate context of the sentence in order to develop highly accurate
    NLP applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter explored the basics of linguistics, which are often used to develop
    NLP applications. We have seen all kinds of analysis related to NL. We have seen
    word level analysis and larger context analysis. We have seen difference between
    some of the key concepts to resolve any confusion. After this chapter, you can
    identify which concepts of linguistics or tool is more interesting for you to
    use. Researchers can find the potential research area if they want to pursue research
    either in linguistics, computer linguistics or computer science with major in
    NLP.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will focus on practical and coding aspects and begin
    our journey to develop NLP applications. The next chapter is all about **preprocessing**
    the data, one of the basic but important steps in developing NLP applications.
    Preprocessing includes some of the concepts which we have described here. We will
    use them along with the standard ways of preprocessing.
  prefs: []
  type: TYPE_NORMAL
