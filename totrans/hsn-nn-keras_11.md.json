["```py\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\nfrom keras.datasets import fashion_mnist\n```", "```py\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\nx_train.shape,  x_test.shape, type(x_train)\n((60000, 28, 28), (10000, 28, 28), numpy.ndarray)\nplt.imshow(x_train[1], cmap='binary')\n```", "```py\n# Normalize pixel values\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n# Flatten images to 2D arrays\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\n# Print out the shape\nprint(x_train.shape)\nprint(x_test.shape)\n-----------------------------------------------------------------------\n(60000, 784)\n(10000, 784)\n```", "```py\n# Size of encoded representation\n# 32 floats denotes a compression factor of 24.5 assuming input is 784 float\n# we have 32*32 or 1024 floats\nencoding_dim = 32\n#Input placeholder\ninput_img = Input(shape=(784,))\n#Encoded representation of input image\nencoded = Dense(encoding_dim, activation='relu',  activity_regularizer=regularizers.l1(10e-5))(input_img)                               \n# Decode is lossy reconstruction of input              \ndecoded = Dense(784, activation='sigmoid')(encoded)\n# This autoencoder will map input to reconstructed output\nautoencoder = Model(input_img, decoded)\n```", "```py\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\nautoencoder.summary()\n```", "```py\n''' The seperate encoder network '''\n\n# Define a model which maps input images to the latent space\nencoder_network = Model(input_img, encoded)\n\n# Visualize network\nencoder_network.summary()\n\n```", "```py\n''' The seperate decoder network ''' \n\n# Placeholder to recieve the encoded (32-dimensional) representation as input\nencoded_input = Input(shape=(encoding_dim,))\n\n# Decoder layer, retrieved from the aucoencoder model\ndecoder_layer = autoencoder.layers[-1]\n\n# Define the decoder model, mapping the latent space to the output layer\ndecoder_network = Model(encoded_input, decoder_layer(encoded_input))\n\n# Visualize network\ndecoder_network.summary()\n```", "```py\n# Time to encode some images\nencoded_imgs = encoder_network.predict(x_test)\n# Then decode them \ndecoded_imgs = decoder_network.predict(encoded_imgs)\n```", "```py\n# use Matplotlib (don't ask)\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(22, 6))\nnum_imgs = 9\nfor i in range(n):                        \n    # display original\n    ax = plt.subplot(2, num_imgs, i + 1)\n    true_img = x_test[i].reshape(28, 28)\n    plt.imshow(true_img)\n\n    # display reconstruction\n    ax = plt.subplot(2, num_imgs, i + 1 + num_imgs)\n    reconstructed_img = decoded_imgs[i].reshape(28,28)\n    plt.imshow(reconstructed_img)\nplt.show()\n\n```", "```py\nimport cv2\nimport datetime as dt\nimport matplotlib.pylab as plt\nimport numpy as np\nimport pandas as pd\nfrom keras import models, layers, optimizers\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\nfrom pathlib import Path\nfrom vis.utils import utils\n```", "```py\nimport os\nall_monkeys = []\nfor image in os.listdir(train_dir):\n    try:\n        monkey = utils.load_img(('C:/Users/npurk/Desktop/VAE/training/' + image), target_size=(64,64))\n        all_monkeys.append(monkey)\n    except Exception as e:\n        pass\n    print('Recovered data format:', type(all_monkeys))    \nprint('Number of monkey images:', len(all_monkeys))\n-----------------------------------------------------------------------\nRecovered data format: <class 'list'> \nNumber of monkey images: 1094\n\n```", "```py\n# Make into array\nall_monkeys = np.asarray(all_monkeys)\nprint('Shape of array:', all_monkeys.shape)\n\n# Normalize pixel values\nall_monkeys = all_monkeys.astype('float32') / 255.\n\n# Flatten array\nall_monkeys = all_monkeys.reshape((len(all_monkeys), np.prod(all_monkeys.shape[1:])))\nprint('Shape after flattened:', all_monkeys.shape)\n\nShape of array: (1094, 64, 64, 3)\nShape after flattened: (1094, 12288)\n```", "```py\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\n\n##Input dimension\ninput_dim=12288\n\n##Encoding dimension for the latent space\nencoding_dim=256\n```", "```py\n# Input layer placeholder\ninput_layer = Input(shape=(input_dim,))\n\n# Encoding layers funnel the images into lower dimensional representations\nencoded = Dense(encoding_dim * 4, activation='relu')(input_layer)\nencoded = Dense(encoding_dim * 2, activation='relu')(encoded)\n\n# Latent space\nencoded = Dense(encoding_dim, activation='relu')(encoded)\n\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = Dense(encoding_dim * 2, activation='relu')(encoded)\ndecoded = Dense(encoding_dim * 4, activation='relu')(decoded)\ndecoded = Dense(input_dim, activation='sigmoid')(decoded)\n\n# this model maps an input to its reconstruction\nautoencoder = Model(input_layer, decoded)\n\nautoencoder.summary()\n_______________________________________________________________\nLayer (type)                 Output Shape              Param #   =================================================================\ninput_1 (InputLayer)         (None, 12288)             0         _______________________________________________________________\ndense_1 (Dense)              (None, 1024)              12583936  _______________________________________________________________\ndense_2 (Dense)              (None, 512)               524800    _______________________________________________________________\ndense_3 (Dense)              (None, 256)               131328    _______________________________________________________________\ndense_4 (Dense)              (None, 512)               131584    _______________________________________________________________\ndense_5 (Dense)              (None, 1024)              525312    _______________________________________________________________\ndense_6 (Dense)              (None, 12288)             12595200  =================================================================\nTotal params: 26,492,160\nTrainable params: 26,492,160\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nautoencoder.compile(optimizer='adam', loss='mse')\n\nautoencoder.fit(x_train, x_train, epochs=100, batch_size=20, verbose=1)\n\nEpoch 1/100\n875/875 [==============================] - 15s 17ms/step - loss: 0.0061\nEpoch 2/100\n875/875 [==============================] - 13s 15ms/step - loss: 0.0030\nEpoch 3/100\n875/875 [==============================] - 13s 15ms/step - loss: 0.0025\nEpoch 4/100\n875/875 [==============================] - 14s 16ms/step - loss: 0.0024\nEpoch 5/100\n875/875 [==============================] - 13s 15ms/step - loss: 0.0024\n```", "```py\ndecoded_imgs = autoencoder.predict(x_test)\n# use Matplotlib (don't ask)\nimport matplotlib.pyplot as plt\n\nn = 6  # how many digits we will display\nplt.figure(figsize=(22, 6))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test[i].reshape(64, 64, 3))    #x_test\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(64, 64, 3))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()\n```", "```py\nfrom keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n\n# Input Placeholder\ninput_img = Input(shape=(64, 64, 3))  # adapt this if using `channels_first` image data format\n\n# Encoder part\nl1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\nl2 = MaxPooling2D((2, 2), padding='same')(l1)\nl3 = Conv2D(16, (3, 3), activation='relu', padding='same')(l2)\n\n# Latent Space, with dimension (None, 32, 32, 16)\nencoded = MaxPooling2D((1,1), padding='same')(l3) \n\n# Decoder Part\nl8 = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\nl9 = UpSampling2D((2, 2))(l8)\ndecoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(l9)\n\nautoencoder = Model(input_img, decoded)\n\nautoencoder.summary()\n_______________________________________________________________\nLayer (type)                 Output Shape              Param #   =================================================================\ninput_2 (InputLayer)         (None, 64, 64, 3)         0         _______________________________________________________________\nconv2d_5 (Conv2D)            (None, 64, 64, 32)        896       _______________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 32, 32, 32)        0         _______________________________________________________________\nconv2d_6 (Conv2D)            (None, 32, 32, 16)        4624      _______________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 32, 32, 16)        0         _______________________________________________________________\nconv2d_7 (Conv2D)            (None, 32, 32, 16)        2320      _______________________________________________________________\nup_sampling2d_2 (UpSampling2 (None, 64, 64, 16)        0         _______________________________________________________________\nconv2d_8 (Conv2D)            (None, 64, 64, 3)         435       =================================================================\nTotal params: 8,275\nTrainable params: 8,275\nNon-trainable params: _________________________________________________________________\n```", "```py\n# Check shape of a layer\nimport keras\nkeras.backend.int_shape(encoded)\n\n(None, 32, 32, 16)\n\n```", "```py\nautoencoder.compile(optimizer='adam', loss='mse')\nautoencoder.fit(x_train, x_train, epochs=50, batch_size=20,\n                shuffle=True, verbose=1)\nEpoch 1/50\n875/875 [==============================] - 7s 8ms/step - loss: 0.0462\nEpoch 2/50\n875/875 [==============================] - 6s 7ms/step - loss: 0.0173\nEpoch 3/50\n875/875 [==============================] - 7s 9ms/step - loss: 0.0133\nEpoch 4/50\n875/875 [==============================] - 8s 9ms/step - loss: 0.0116\n```", "```py\ndef compare_outputs(x_test, decoded_imgs=None, n=10):\n    plt.figure(figsize=(22, 5))\n    for i in range(n):\n        ax = plt.subplot(2, n, i+1)\n        plt.imshow(x_test[i].reshape(64,64,3))\n\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        if decoded_imgs is not None:\n            ax = plt.subplot(2, n, i+ 1 +n)\n            plt.imshow(decoded_imgs[i].reshape(64,64,3))\n\n            ax.get_xaxis().set_visible(False)\n            ax.get_yaxis().set_visible(False)\n    plt.show()\n\ndecoded_imgs = autoencoder.predict(x_test)\nprint('Upper row: Input image provided \\nBottom row: Decoded output \n       generated')\ncompare_outputs(x_test, decoded_imgs)\nUpper row: Input image provided \nBottom row: Decoded output generated\n```", "```py\nnoise_factor = 0.35\n\n# Define noisy versions\nx_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n\n# CLip values between 0 and 1\nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\n```", "```py\n# Effect of adding noise factor\nf = plt.figure()\nf.add_subplot(1,2, 1)\nplt.imshow(x_test[1])\n\nf.add_subplot(1,2, 2)\nplt.imshow(x_test_noisy[1])\n\nplt.show(block=True)\n```", "```py\nautoencoder.compile(optimizer='adam', loss='mse')\nautoencoder.fit(x_train_noisy, x_train, epochs=50, batch_size=20,\n                shuffle=True, verbose=1)\n\nEpoch 1/50875/875 [==============================] - 7s 8ms/step - loss: 0.0449\nEpoch 2/50\n875/875 [==============================] - 6s 7ms/step - loss: 0.0212\nEpoch 3/50\n875/875 [==============================] - 6s 7ms/step - loss: 0.0185\nEpoch 4/50\n875/875 [==============================] - 6s 7ms/step - loss: 0.0169\n```", "```py\ndef compare_outputs(x_test, decoded_imgs=None, n=10):\n    plt.figure(figsize=(22, 5))\n\n    for i in range(n):\n        ax = plt.subplot(2, n, i+1)\n        plt.imshow(x_test_noisy[i].reshape(64,64,3))\n        plt.gray()\n\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        if decoded_imgs is not None:\n            ax = plt.subplot(2, n, i+ 1 +n)\n            plt.imshow(decoded_imgs[i].reshape(64,64,3))\n\n            ax.get_xaxis().set_visible(False)\n            ax.get_yaxis().set_visible(False)\n\n    plt.show()\ndecoded_imgs = autoencoder.predict(x_test_noisy)\nprint('Upper row: Input image provided \\nBottom row: Decoded output generated')\ncompare_outputs(x_test, decoded_imgs)\nUpper row: Input image provided \nBottom row: Decoded output generated\n```"]