<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Transfer Learning</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, we learned that a CNN consists of several layers. We also studied different CNN architectures, tuned different hyperparameters, and identified values for stride, window size, and padding. Then we chose a correct loss function and optimized it. We trained this architecture with a large volume of images. So, the question here is, how do we make use of this knowledge with a different dataset? Instead of building a CNN architecture and training it from scratch, it is possible to take an existing pre-trained network and adapt it to a new and different dataset through a technique called <strong>transfer learning</strong>. <span>We can do so through feature extraction and fine tuning.</span></p>
<div class="packt_tip">Transfer learning is the process of copying knowledge from an already trained network to a new network to solve similar problems. </div>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Feature extraction approach</li>
<li>Transfer learning example</li>
<li>Multi-task learning</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Feature extraction approach</h1>
                </header>
            
            <article>
                
<p><span>In a feature extraction approach, we train only the top level of the network; the rest of the network remains fixed. </span>Consider a feature extraction approach when the new dataset is relatively small and similar to the original dataset. In such cases, the higher-level features learned from the original dataset should transfer well to the new dataset.</p>
<p>Consider a fine-tuning approach when the new dataset is large and similar to the original dataset. Altering the original weights should be safe because the network is unlikely to overfit the new, large dataset.</p>
<p>Let us consider a pre-trained convolutional neural network, as shown in the following diagram. Using this we can study how the transfer of knowledge can be used in different situations:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="253" src="assets/688a6ad3-849b-42f7-b371-4523211bfcbc.png" width="338"/></div>
<p>When should we use transfer learning? Transfer learning can be applied in the following situations, depending on:</p>
<ul>
<li>The size of the new (target) dataset</li>
<li>Similarity between the original and target datasets</li>
</ul>
<p>There are four main use cases:</p>
<ul>
<li><strong>Case 1</strong>: New (target) dataset is small and is similar to the original training dataset</li>
<li><strong>Case 2</strong><span>: </span><span>New (target) dataset is small but is different from the original training dataset</span></li>
<li><strong>Case 3</strong><span>: New (target) dataset is large and is similar to the original training dataset</span></li>
<li><span><strong>Case 4</strong>:<strong> </strong>New (target) dataset is large and is different from the original training dataset</span></li>
</ul>
<p>Let us now walk through each case in detail in the following sections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Target dataset is small and is similar to the original training dataset</h1>
                </header>
            
            <article>
                
<p>If the target dataset is small and similar to the original dataset:</p>
<ul>
<li>In this case, replace the last fully connected layer with a new fully connected layer that matches with the number of classes of the target dataset</li>
<li>Initialize old weights with randomized weights</li>
<li>Train the network to update the weights of the new, fully connected layer:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img height="472" src="assets/daa1d1de-8117-4897-9afd-94588783b1d9.png" width="515"/></div>
<div class="packt_tip">Transfer learning can be used as a strategy to avoid overfitting, especially when there is a small dataset.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Target dataset is small but different from the original training dataset</h1>
                </header>
            
            <article>
                
<p>If the target dataset is small but of a different type to the original – for example, the original dataset is dog images and the new (target) dataset is flower images – then do the following:</p>
<ul>
<li>Slice most of the initial layers of the network</li>
<li>Add to the remaining pre-trained layers a new fully connected layer that matches the number of classes of the target dataset</li>
<li>Randomize the weights of the new fully connected layer and freeze all the weights from the pre-trained network</li>
<li>Train the network to update the weights of the new fully connected layer  </li>
</ul>
<p>Since the dataset is small, overfitting is still a concern here as well. To overcome this, we will keep the weights of the original pre-trained network the same and update only the weights of the new fully connected layer:</p>
<div class="CDPAlignCenter CDPAlign"><img height="450" src="assets/f7a1081a-47f5-4e46-937c-c84bf035dc03.png" width="490"/></div>
<div class="packt_tip">Only fine tune the higher level portion of the network. This is because the beginning layers are designed to extract more generic features. In general, the first layer of a convolutional neural network is not specific to a dataset. </div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Target dataset is large and similar to the original training dataset</h1>
                </header>
            
            <article>
                
<p>Here we do not have an overfitting concern, as the dataset is large. So, in this case, we can retrain the entire network:</p>
<ul>
<li>Remove the last fully connected layer and replace it with a fully connected layer that matches the number of classes in the target dataset</li>
<li>Randomly initialize the weights of this newly added, fully connected layer</li>
<li>Initialize the rest of the weights with pre-trained weights</li>
<li>Train the entire network:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img height="385" src="assets/2df8e25a-0f59-43c8-85f6-4a9486cf6aa7.png" style="font-size: 1em" width="460"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Target dataset is large and different from the original training dataset</h1>
                </header>
            
            <article>
                
<p>If the target dataset is large and different from the original:</p>
<ul>
<li>Remove the last fully connected layer and replace it with a fully connected layer that matches the number of classes in the target dataset</li>
<li><span>Train the entire network from scratch with randomly initialized weights:</span></li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img height="405" src="assets/76604751-43f7-4ae8-875d-66e44fa19053.png" width="471"/></div>
<div class="packt_tip">The <kbd>Caffe</kbd> library has ModelZoo, where one can share network weights.</div>
<p>Consider training from scratch when the dataset is large and completely different from the original dataset. In this case, we have enough data to train from scratch without the fear of overfitting. However, even in this case, it might be beneficial to initialize the entire network with pre-trained weights and fine tune it on the new dataset.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Transfer learning example</h1>
                </header>
            
            <article>
                
<p>In this example, we will take a pre-trained VGGNet and use transfer learning to train a CNN classifier that predicts dog breeds, given a dog image. Keras contains many pre-trained models, along with the code that loads and visualizes them. Another is a flower dataset that can be downloaded here. The Dog breed dataset has 133 dog breed categories and 8,351 dog images. Download the Dog breed dataset here and copy it to your folder. VGGNet has 16 convolutional with pooling layers from beginning to end and three fully connected layers followed by a <kbd>softmax</kbd> function. Its main objective was to show how the depth of the network gives the best performance. It came from <strong>Visual Geometric Group</strong> (<strong>VGG</strong>) at Oxford. Their best performing network is VGG16. The Dog breed dataset is relatively small and has a little overlap with the <kbd>imageNet</kbd> dataset. So, we can remove the last fully connected layer after the convolutional layer and replace it with our own. The weights of the convolutional layer are kept constant. An input image is passed through the convolutional layer and stops at the 16th layer:</p>
<div class="CDPAlignCenter CDPAlign"><img height="244" src="assets/c6d97faf-9d6c-49ee-b829-2de1dd1da654.png" width="527"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">VGGNet Architecture</div>
<p>We will use the bottleneck features of a pre-trained VGG16 network – such a network has already learned features from the <kbd>imageNet</kbd> dataset. Because the <kbd>imageNet</kbd> dataset already contains a few images of dogs, the VGG16 network model has already learned key features for classification. Similarly, other pre-trained CNN architectures can also be considered as an exercise to solve other image classification tasks.</p>
<p>Download the <kbd>bottleneck_features</kbd> of VGG16 here, copy it to your own folder, and load it:</p>
<pre>bottleneck_features = np.load('bottleneck_features/DogVGG16Data.npz')<br/>train_vgg16 = bottleneck_features['train']<br/>valid_vgg16 = bottleneck_features['valid']<br/>test_vgg16 = bottleneck_features['test']</pre>
<p>Now define the model architecture:</p>
<pre>from keras.layers import GlobalAveragePooling2D<br/><br/>model = Sequential()<br/>model.add(GlobalAveragePooling2D(input_shape=(7, 7, 512)))<br/>model.add(Dense(133, activation='softmax'))<br/>model.summary()</pre>
<pre>Layer (type)                     Output Shape          Param #     Connected to                     
=================================================================================================
globalaveragepooling2d_1 (Global (None, 512)           0           globalaveragepooling2d_input_1[0]
_________________________________________________________________________________________________
dense_2 (Dense)                  (None, 133)           68229       globalaveragepooling2d_1[0][0]   
=================================================================================================
Total params: 68,229
Trainable params: 68,229
Non-trainable params: 0
_________________________________________________________________________________________________</pre>
<p>Compile the model and train it:</p>
<pre>model.compile(loss='categorical_crossentropy', optimizer='rmsprop', <br/>                  metrics=['accuracy'])<br/>from keras.callbacks import ModelCheckpoint <br/><br/># train the model<br/>checkpointer = ModelCheckpoint(filepath='dogvgg16.weights.best.hdf5', verbose=1, <br/>                               save_best_only=True)<br/>model.fit(train_vgg16, train_targets, nb_epoch=20, validation_data=(valid_vgg16, valid_targets), <br/>          callbacks=[checkpointer], verbose=1, shuffle=True)</pre>
<p>Load the model and calculate the classification accuracy on the test set:</p>
<pre># load the weights that yielded the best validation accuracy<br/>model.load_weights('dogvgg16.weights.best.hdf5')<br/># get index of predicted dog breed for each image in test set<br/>vgg16_predictions = [np.argmax(model.predict(np.expand_dims(feature, axis=0))) <br/>                     for feature in test_vgg16]<br/><br/># report test accuracy<br/>test_accuracy = 100*np.sum(np.array(vgg16_predictions)==<br/>                           np.argmax(test_targets, axis=1))/len(vgg16_predictions)<br/>print('\nTest accuracy: %.4f%%' % test_accuracy)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Multi-task learning</h1>
                </header>
            
            <article>
                
<p>In multi-task learning, transfer learning happens to be from one pre-trained model to many tasks simultaneously. For example, in self-driving cars, the deep neural network detects traffic signs, pedestrians, and other cars in front at the same time. Speech recognition also benefits from multi-task learning.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In a few specific cases, convolutional neural network architectures trained on images allow us to reuse learned features in a new network. The performance benefits of transferring features decrease the more dissimilar the base task and target task are. It is surprising to know that initializing a convolutional neural network with transferred features from almost any number of layers can produce a boost to generalization performance after fine-tuning to a new dataset.</p>
<p> </p>
<p> </p>


            </article>

            
        </section>
    </body></html>