<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Training Neural Networks with Spark</h1>
                </header>
            
            <article>
                
<p class="mce-root">In the previous two chapters, we have learned how to programmatically configure and build <strong>convolutional neural networks</strong> (<strong>CNNs</strong>) and <strong>recurrent neural networks</strong> (<strong>RNNs</strong>) using the <strong>DeepLearning4j</strong> (<strong>DL4J</strong>) API in Scala. There, implementing the training of these networks was mentioned, but very little explanation has been provided. This chapter finally goes into details of how to implement the training strategies for both kinds of network. The chapter also explains why Spark is important in the training process and what the fundamental role of DL4J is from a performance perspective.</p>
<p class="mce-root">The second and third sections focus on specific training strategies for CNNs and RNNs respectively. The fourth section of this chapter also provides suggestions, tips, and tricks for a proper Spark environment configuration. The final section describes how to use the DL4J Arbiter component for hyperparameter optimization.</p>
<p>Here is a summary of what we will cover in this chapter:</p>
<ul>
<li>CNN distributed training with Spark and DL4J</li>
<li>RNN distributed training with Spark and DL4J</li>
<li>Performance considerations</li>
<li>Hyperparameter optimization</li>
</ul>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Distributed network training with Spark and DeepLearning4j</h1>
                </header>
            
            <article>
                
<p>The training of <strong>Multilayer Neural Networks</strong> (<strong>MNNs</strong>) is computationally expensive—it involves huge datasets, and there is also the need to complete the training process in the fastest way possible. In <a href="ad6da519-0705-4db6-aa38-2b98b85892cc.xhtml" target="_blank">Chapter 1</a>, <em>The Apache Spark Ecosystem</em>, we have learned about how Apache Spark can achieve high performances when undertaking large-scale data processing. This makes it a perfect candidate to perform training, by taking advantage of its parallelism features. But Spark alone isn't enough—its performances are excellent, in particular for ETL or streaming, but in terms of computation, in an MNN training context, some data transformation or aggregation need to be moved down using a low-level language (such as C++).</p>
<p>Here's where the ND4J (<a href="https://nd4j.org/index.html">https://nd4j.org/index.html</a>) module of DL4J comes into play. There's no need to learn and program in C++, as ND4J provides the Scala APIs, and those are what we need to use. The underlying C++ library is transparent to Scala or Java developers using ND4J. Here is a simple example of how a Scala application that uses the ND4J API appears (the inline comments explain what the code does):</p>
<pre>object Nd4JScalaSample {<br/>  def main (args: Array[String]) {<br/> <br/>      // Create arrays using the numpy syntax<br/>      var arr1 = Nd4j.create(4)<br/>      val arr2 = Nd4j.linspace(1, 10, 10)<br/>     <br/>      // Fill an array with the value 5 (equivalent to fill method in numpy)<br/>      println(arr1.assign(5) + "Assigned value of 5 to the array")<br/>     <br/>      // Basic stats methods<br/>      println(Nd4j.mean(arr1) + "Calculate mean of array")<br/>      println(Nd4j.std(arr2) + "Calculate standard deviation of array")<br/>      println(Nd4j.`var`(arr2), "Calculate variance")<br/>  <br/>     ...</pre>
<p>ND4J brings to the JVM an open source, distributed, GPU-enabled, intuitive scientific library, filling the gap between JVM languages and Python programmers in terms of availability of powerful data analysis tools. DL4J relies on Spark for training models in parallel. Large datasets are partitioned, with each partition available to separate neural networks, each one in its own core—DL4J iteratively averages the parameters they produce in a central model.</p>
<p>Just for completeness of information, whether training would be demanded to DL4J only, running multiple models in the same server, <kbd>ParallelWrapper</kbd> (<a href="https://deeplearning4j.org/api/v1.0.0-beta2/org/deeplearning4j/parallelism/ParallelWrapper.html">https://deeplearning4j.org/api/v1.0.0-beta2/org/deeplearning4j/parallelism/ParallelWrapper.html</a>) should be used. But please consider that this process is particularly expensive and the server has to be equipped with a large number of CPUs (at least 64) or multiple GPUs.</p>
<p>DL4J provides the following two classes for training neural networks on top of Spark:</p>
<ul>
<li><kbd>SparkDl4jMultiLayer</kbd> (<a href="https://deeplearning4j.org/api/v1.0.0-beta2/org/deeplearning4j/spark/impl/multilayer/SparkDl4jMultiLayer.html">https://deeplearning4j.org/api/v1.0.0-beta2/org/deeplearning4j/spark/impl/multilayer/SparkDl4jMultiLayer.html</a>), a wrapper around <kbd>MultiLayerNetwork</kbd> (this is the class that has been used in some examples presented in the previous chapters).</li>
<li><kbd>SparkComputationGraph</kbd> (<a href="https://deeplearning4j.org/api/v1.0.0-beta2/org/deeplearning4j/spark/impl/graph/SparkComputationGraph.html">https://deeplearning4j.org/api/v1.0.0-beta2/org/deeplearning4j/spark/impl/graph/SparkComputationGraph.html</a>), a wrapper around <kbd>ComputationGraph</kbd> (<a href="https://deeplearning4j.org/api/v1.0.0-beta2/org/deeplearning4j/nn/graph/ComputationGraph.html">https://deeplearning4j.org/api/v1.0.0-beta2/org/deeplearning4j/nn/graph/ComputationGraph.html</a>), a neural network with arbitrary connection structure (DAG) that can also have an arbitrary number of inputs and outputs.</li>
</ul>
<p>These two classes are wrappers around the standard single-machine classes, so the network configuration process is identical in both standard and distributed training.</p>
<p>In order to train a network through DL4J on a Spark cluster you have to follow this standard workflow:</p>
<ol>
<li> Specify the network configuration through the <kbd>MultiLayerConfiguration</kbd> (<a href="https://static.javadoc.io/org.deeplearning4j/deeplearning4j-nn/0.9.1/org/deeplearning4j/nn/conf/MultiLayerConfiguration.html">https://static.javadoc.io/org.deeplearning4j/deeplearning4j-nn/0.9.1/org/deeplearning4j/nn/conf/MultiLayerConfiguration.html</a>) <span>class </span>or the <kbd>ComputationGraphConfiguration</kbd> (<a href="https://static.javadoc.io/org.deeplearning4j/deeplearning4j-nn/0.9.1/org/deeplearning4j/nn/conf/ComputationGraphConfiguration.html">https://static.javadoc.io/org.deeplearning4j/deeplearning4j-nn/0.9.1/org/deeplearning4j/nn/conf/ComputationGraphConfiguration.html</a>) class</li>
<li>Create an instance of <kbd>TrainingMaster</kbd> (<a href="https://static.javadoc.io/org.deeplearning4j/dl4j-spark_2.11/0.9.1_spark_2/org/deeplearning4j/spark/api/TrainingMaster.html">https://static.javadoc.io/org.deeplearning4j/dl4j-spark_2.11/0.9.1_spark_2/org/deeplearning4j/spark/api/TrainingMaster.html</a>) to control how distributed training is executed in practice</li>
<li> Create the <kbd>SparkDl4jMultiLayer</kbd> or <kbd>SparkComputationGraph</kbd> instance using the network configuration and the <kbd>TrainingMaster</kbd> object previously created</li>
</ol>
<ol start="4">
<li>Load the training data</li>
<li>Call the appropriate fit method on the <kbd>SparkDl4jMultiLayer</kbd> (or <kbd>SparkComputationGraph</kbd>) instance</li>
<li>Save the trained network</li>
<li>Build the JAR file for the Spark job</li>
<li>Submit the JAR for execution</li>
</ol>
<p>The code examples presented in <a href="fbec1d8a-a92f-4899-af0f-11f3d545e0eb.xhtml" target="_blank">Chapter 5</a>, <em>Convolutional Neural Networks</em>, and <a href="f7a89101-15be-49e3-8bf5-8c74c655f6d7.xhtml" target="_blank">Chapter 6</a>, <em>Recurrent Neural Networks</em>, have given you an idea of how to configure and build an MNN; those in <a href="44fab060-12c9-4eec-9e15-103da589a510.xhtml" target="_blank">Chapter 3</a>, <em>Extract, Transform, Load</em>, and <a href="198c1dc7-bc2a-47e8-9f97-8dbe37b7a2e3.xhtml" target="_blank">Chapter 4</a>, <em>Streaming</em>, have presented insights about different ways to load the training data and, from <a href="ad6da519-0705-4db6-aa38-2b98b85892cc.xhtml" target="_blank">Chapter 1</a>, <em>The Apache Spark Ecosystem</em>, you have learned how to execute a Spark job. Let's now focus in the next sections on understanding how to implement the missing part: the network training.</p>
<p>At the present time, to train a network, DL4J provides a single approach—parameter averaging (<a href="https://arxiv.org/abs/1410.7455">https://arxiv.org/abs/1410.7455</a>). Here's how this process conceptually happens:</p>
<ul>
<li>The Spark master starts using the network configuration and parameters</li>
<li>Depending on the configuration of the <kbd>TrainingMaster</kbd>, data is partitioned into subsets</li>
<li>For each subset:
<ul>
<li>Configuration and the parameters are distributed from the master across each worker</li>
<li>Each worker executes the fit on its own partition</li>
<li>The average of the parameters is calculated and then the results are returned back to the master</li>
</ul>
</li>
<li>The training completes and a copy of the trained network is available in the master</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CNN distributed training with Spark and DL4J</h1>
                </header>
            
            <article>
                
<p>Let's get back to the example that has been presented in <a href="fbec1d8a-a92f-4899-af0f-11f3d545e0eb.xhtml" target="_blank">Chapter 5</a>, <em>Convolutional Neural Networks</em>, <em>Hands-on CNN with Spark</em>, about handwritten digits image classification on the <kbd>MNIST</kbd> dataset. For convenience, here's a reminder of the network configuration used there:</p>
<pre>val channels = 1<br/> val outputNum = 10<br/> val conf = new NeuralNetConfiguration.Builder()<br/>     .seed(seed)<br/>     .iterations(iterations)<br/>     .regularization(true)<br/>     .l2(0.0005)<br/>     .learningRate(.01)<br/>     .weightInit(WeightInit.XAVIER)<br/>     .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)<br/>     .updater(Updater.NESTEROVS)<br/>     .momentum(0.9)<br/>     .list<br/>     .layer(0, new ConvolutionLayer.Builder(5, 5)<br/>         .nIn(channels)<br/>         .stride(1, 1)<br/>         .nOut(20)<br/>         .activation(Activation.IDENTITY)<br/>         .build)<br/>     .layer(1, new<br/>     SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)<br/>         .kernelSize(2, 2)<br/>         .stride(2, 2)<br/>         .build)<br/>     .layer(2, new ConvolutionLayer.Builder(5, 5)<br/>         .stride(1, 1)<br/>         .nOut(50)<br/>         .activation(Activation.IDENTITY)<br/>         .build)<br/>     .layer(3, new<br/>     SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)<br/>         .kernelSize(2, 2)<br/>         .stride(2, 2)<br/>         .build)<br/>     .layer(4, new DenseLayer.Builder()<br/>         .activation(Activation.RELU)<br/>         .nOut(500)<br/>         .build)<br/>     .layer(5, new<br/>     OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)<br/>         .nOut(outputNum)<br/>         .activation(Activation.SOFTMAX).build)<br/>         .setInputType(InputType.convolutionalFlat(28, 28, 1))<br/>         .backprop(true).pretrain(false).build</pre>
<p>We used that <kbd>MultiLayerConfiguration</kbd> object to initialize the model. Having the model and the training data, the training can be set. As explained in the previous section, the training happens with Spark. Therefore, the next steps would be creating a Spark context, as follows:</p>
<pre>val sparkConf = new SparkConf<br/> sparkConf.setMaster(master)<br/>     .setAppName("DL4J Spark MNIST Example")<br/> val sc = new JavaSparkContext(sparkConf)</pre>
<p>We then parallelize the training data after loading it in memory<span>, as follows</span>:</p>
<pre>val trainDataList = mutable.ArrayBuffer.empty[DataSet]<br/> while (trainIter.hasNext) {<br/>     trainDataList += trainIter.next<br/> }<br/>  <br/> val paralleltrainData = sc.parallelize(trainDataList)</pre>
<p>Now it is time to create the <kbd>TrainingMaster</kbd> instance<span>, as follows</span>:</p>
<pre>var batchSizePerWorker: Int = 16<br/> val tm = new ParameterAveragingTrainingMaster.Builder(batchSizePerWorker)<br/>     .averagingFrequency(5)<br/>     .workerPrefetchNumBatches(2)      <br/>     .batchSizePerWorker(batchSizePerWorker)<br/>     .build</pre>
<p>We can use the only currently available implementation for the <kbd>TrainingMaster</kbd> interface, the <kbd>ParameterAveragingTrainingMaster</kbd> (<a href="https://static.javadoc.io/org.deeplearning4j/dl4j-spark_2.11/0.9.1_spark_2/org/deeplearning4j/spark/impl/paramavg/ParameterAveragingTrainingMaster.html">https://static.javadoc.io/org.deeplearning4j/dl4j-spark_2.11/0.9.1_spark_2/org/deeplearning4j/spark/impl/paramavg/ParameterAveragingTrainingMaster.html</a>). In the preceding example we have used only three configuration options available for this <kbd>TrainingMaster</kbd> implementation, but there are more:</p>
<ul>
<li><kbd>dataSetObjectSize</kbd>: Specifies how many examples are in each <kbd>DataSet</kbd>.</li>
<li><kbd>workerPrefetchNumBatches</kbd>: The Spark workers are capable of asynchronously prefetching a number of <kbd>DataSet</kbd> objects, in order to avoid waiting for data to be loaded. It is possible to disable prefetching by setting this property to zero. Setting it to two (such as in our example) is a good compromise (a sensible default with a non-excessive use of memory).</li>
<li><kbd><em>rddTrainingApproach</em></kbd>: DL4J provides two approaches when training from an RDD—<kbd>RDDTrainingApproach.Export</kbd> and <kbd>RDDTrainingApproach.Direct</kbd> (<a href="https://static.javadoc.io/org.deeplearning4j/dl4j-spark_2.11/0.9.1_spark_2/org/deeplearning4j/spark/api/RDDTrainingApproach.html">https://static.javadoc.io/org.deeplearning4j/dl4j-spark_2.11/0.9.1_spark_2/org/deeplearning4j/spark/api/RDDTrainingApproach.html</a>). <kbd>Export</kbd> is the default approach; it first saves an <kbd>RDD&lt;DataSet&gt;</kbd> to disk in batched and serialized form. Then, the executors load asynchronously all the <kbd>DataSet</kbd> objects. The choice between the <kbd>Export</kbd> and the <kbd>Direct</kbd> method depends on the size of the datasets. For large datasets that don't fit into memory and multiple epochs, the <kbd>Export</kbd> approach is preferable—in those cases the split and repartition operations overhead typical of the <kbd>Direct</kbd> approach doesn't apply and the memory consumption is smaller.</li>
<li><kbd>exportDirectory</kbd>: The location where the temporary data files are stored (<kbd>Export</kbd> method only).</li>
<li><kbd>storageLevel</kbd>: Applies only when using a <kbd>Direct</kbd> approach and training from a <kbd>RDD&lt;DataSet&gt;</kbd> or <kbd>RDD&lt;MultiDataSet&gt;</kbd>. The default storage level that DL4J persists the <em>RDDs</em> at is <kbd>StorageLevel.MEMORY_ONLY_SER</kbd>.</li>
<li><kbd>storageLevelStreams</kbd>: Applies only when using the <kbd>fitPaths(RDD&lt;String&gt;)</kbd> method. The default storage level that DL4J persists the <kbd>RDD&lt;String&gt;</kbd> at is <kbd>StorageLevel.MEMORY_ONLY</kbd><em>.</em></li>
<li><kbd>repartitionStrategy</kbd>: Specifies the strategy by which repartitioning should be done. Possible values are <kbd>Balanced</kbd> (default, custom repartitioning strategy defined by DL4J) and <kbd>SparkDefault</kbd> (standard repartitioning strategy used by Spark).</li>
</ul>
<p>Here you can find the full list and their meaning:</p>
<p><a href="https://deeplearning4j.org/docs/latest/deeplearning4j-spark-training">https://deeplearning4j.org/docs/latest/deeplearning4j-spark-training</a></p>
<p>Once the <kbd>TrainingMaster</kbd> configuration and strategy have been defined, an instance of <kbd>SparkDl4jMultiLayer</kbd> can be created<span>, as follows</span>:</p>
<pre>val sparkNet = new SparkDl4jMultiLayer(sc, conf, tm)</pre>
<p>Then the training can happen, choosing the appropriate <kbd>fit</kbd> method<span>, as follows</span>:</p>
<pre>var numEpochs: Int = 15<br/> var i: Int = 0<br/>     for (i &lt;- 0 until numEpochs) {<br/>     sparkNet.fit(paralleltrainData)<br/>     println("Completed Epoch {}", i)<br/> }</pre>
<p><a href="b30120ea-bd42-4cb7-95d9-5ecaa2b7c181.xhtml" target="_blank">Chapter 8</a>, <em>Monitoring and Debugging Neural Network Training</em>, and <a href="869a9495-e759-4810-8623-d8b76ba61398.xhtml" target="_blank">Chapter 9</a>, <em>Interpreting Neural Network Output</em>, will explain how to monitor, debug, and evaluate the results of network training.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">RNN distributed training with Spark and DL4J</h1>
                </header>
            
            <article>
                
<p>Let's reconsider the example that has been presented in <a href="f7a89101-15be-49e3-8bf5-8c74c655f6d7.xhtml" target="_blank"/><a href="f7a89101-15be-49e3-8bf5-8c74c655f6d7.xhtml" target="_blank">Chapter 6</a>, <em>Recurrent Neural Networks</em>, section <em>RNNs with DL4J and Spark</em>, about an LSTM that would be trained to generate text, one character at a time. For convenience, let's remind ourselves of the network configuration used there (an LSTM RNN implementation of the model proposed by Alex Graves):</p>
<pre>val rng = new Random(12345)<br/> val lstmLayerSize: Int = 200<br/> val tbpttLength: Int = 50<br/> val nSamplesToGenerate: Int = 4<br/> val nCharactersToSample: Int = 300<br/> val generationInitialization: String = null<br/> val conf = new NeuralNetConfiguration.Builder()<br/>     .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)<br/>     .iterations(1)<br/>     .learningRate(0.1)<br/>     .rmsDecay(0.95)<br/>     .seed(12345)<br/>     .regularization(true)<br/>     .l2(0.001)<br/>     .weightInit(WeightInit.XAVIER)<br/>     .updater(Updater.RMSPROP)<br/>     .list<br/>     .layer(0, new GravesLSTM.Builder().nIn(SparkLSTMCharacterExample.CHAR_TO_INT.size).nOut(lstmLayerSize).activation(Activation.TANH).build())<br/>     .layer(1, new GravesLSTM.Builder().nIn(lstmLayerSize).nOut(lstmLayerSize).activation(Activation.TANH).build())<br/>     .layer(2, new RnnOutputLayer.Builder(LossFunction.MCXENT).activation(Activation.SOFTMAX)<br/>       .nIn(lstmLayerSize).nOut(SparkLSTMCharacterExample.nOut).build) //MCXENT + softmax for classification<br/>     .backpropType(BackpropType.TruncatedBPTT).tBPTTForwardLength(tbpttLength).tBPTTBackwardLength(tbpttLength)<br/>     .pretrain(false).backprop(true)<br/>     .build</pre>
<p>All of the considerations made in <em>CNN distributed training with Spark and DeepLearning4j</em>, about the creation and configuration of a <kbd>TrainingMaster</kbd> instance, <span>apply the same way for </span><span>the creation and configuration of a</span> <kbd>SparkDl4jMultiLayer</kbd> <span>instance, so they are not repeated. What is different for the</span> <kbd>SparkDl4jMultiLayer</kbd> <span>is that, in this case, we have to specify the</span> <kbd>IteratorListeners</kbd> <span>(</span><a href="https://static.javadoc.io/org.deeplearning4j/deeplearning4j-nn/0.9.1/org/deeplearning4j/optimize/api/IterationListener.html">https://static.javadoc.io/org.deeplearning4j/deeplearning4j-nn/0.9.1/org/deeplearning4j/optimize/api/IterationListener.html</a><span>) for the model (which would be useful in particular for monitoring and debugging purposes, as will be explained in next chapter). Specify the iterator listeners as follows:</span></p>
<pre>val sparkNetwork: SparkDl4jMultiLayer = new SparkDl4jMultiLayer(sc, conf, tm)<br/> sparkNetwork.setListeners(Collections.singletonList[IterationListener](new ScoreIterationListener(1)))</pre>
<p>And here's one way the training could happen in this case. Define the number of epochs<span>, as follows</span>:</p>
<pre>val numEpochs: Int = 10</pre>
<p>Then for each one, apply the appropriate fit method through the <kbd>sparkNetwork</kbd> and sample some characters<span>, as follows</span>:</p>
<pre>(0 until numEpochs).foreach { i =&gt;<br/>     //Perform one epoch of training. At the end of each epoch, we are returned a copy of the trained network<br/>     val net = sparkNetwork.fit(trainingData)<br/> <br/>     //Sample some characters from the network (done locally)<br/>     println("Sampling characters from network given initialization \"" +<br/>       (if (generationInitialization == null) "" else generationInitialization) + "\"")<br/>     val samples = ... // Implement your own sampling method<br/>     <br/>     samples.indices.foreach { j =&gt;<br/>       println("----- Sample " + j + " -----")<br/>       println(samples(j))<br/>     }<br/> }</pre>
<p>Finally, because we decided on an <kbd>Export</kbd> trained approach, we need to delete the temporary files when done<span>, as follows</span>:</p>
<pre>tm.deleteTempFiles(sc)</pre>
<p><a href="b30120ea-bd42-4cb7-95d9-5ecaa2b7c181.xhtml" target="_blank">Chapter 8</a>, <em>Monitoring and Debugging Neural Network Training</em>, and <a href="869a9495-e759-4810-8623-d8b76ba61398.xhtml" target="_blank">Chapter 9</a>, <em>Interpreting Neural Network Output</em>, will explain how to monitor, debug, and evaluate the results of this network training.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Performance considerations</h1>
                </header>
            
            <article>
                
<p>This section presents some recommendations to get the most from DL4J when training on Spark. Let's start with some considerations about memory configuration. It is important to understand how DL4J manages memory first. This framework is built upon the ND4J scientific library (written in C++). ND4J utilizes off-heap memory management—this means that the memory allocated for <kbd>INDArrays</kbd> isn't on the JVM heap, as happens for Java objects, but it is allocated outside the JVM. This kind of memory management allows for the efficient use of high-performance native code for numerical operations and it is also necessary for efficient operations with CUDA (<a href="https://developer.nvidia.com/cuda-zone">https://developer.nvidia.com/cuda-zone</a>) when running on GPUs.</p>
<p>This way, the outcome in terms of extra memory and time overhead is evident—allocating memory on the JVM heap requires that any time there is the need to preliminary copy the data from there, perform then the calculations, and finally copy the result back. ND4J simply passes pointers around for numerical calculations. Heap (JVM) and off-heap (ND4J through JavaCPP (<a href="https://github.com/bytedeco/javacpp">https://github.com/bytedeco/javacpp</a>)) are two separate memory pools. In DL4J, the memory limits of both are controlled via Java command-line arguments through the following system properties:</p>
<ul>
<li><kbd>Xms</kbd>: The memory the JVM heap can use at application start</li>
<li><kbd>Xmx</kbd>: The maximum memory limit the JVM heap could use</li>
<li><kbd>org.bytedeco.javacpp.maxbytes</kbd>: The off-heap maximum memory limit</li>
<li><kbd>org.bytedeco.javacpp.maxphysicalbytes</kbd>: To be set typically with the same value as for the <kbd>maxbytes</kbd> property</li>
</ul>
<p><a href="1066b0d4-c2f3-44f9-9cc4-d38469d72c3f.xhtml" target="_blank">Chapter 10</a>, <em>Deploying on a Distributed System</em>, (which focuses on the deployment of a distributed system to train or run a neural network) will present more details about memory management.</p>
<p>Another good practice to improve performance is to configure Spark locality settings. This is an optional configuration, but can bring benefits on this front. Locality refers to where data is, relative to where it can be processed. At execution time, any time data has to be copied across the network to be processed by a free executor; Spark has to decide between waiting for an executor that has local access to the data to become free or executing the network transfer. The default behavior for Spark is to wait a bit before transferring data across the network to a free executor.</p>
<p>Training neural networks with DL4J is computationally intensive, so the amount of computation per input <kbd>DataSet</kbd> is relatively high. For this reason, the Spark default behavior isn’t an ideal fit for maximizing cluster utilization. During Spark training, DL4J ensures there is exactly one task per executor—so it is always better to immediately transfer data to a free executor, rather than waiting for another one to become free. The computation time will become more important than any network transfer time. The way to tell Spark that it hasn't to wait, but start transferring data immediately is simple—when submitting the configuration we have to set the value of the <kbd>spark.locality.wait</kbd> property to <kbd>0</kbd>.</p>
<p>Spark has problems handling Java objects with large off-heap components (this could be the case with <kbd>DataSet</kbd> and <kbd>INDArray</kbd> objects in DL4J), in particular in caching or persisting them. From <a href="ad6da519-0705-4db6-aa38-2b98b85892cc.xhtml" target="_blank">Chapter 1</a>, <em>The Apache Spark Ecosystem</em>, you know that Spark provides different storage levels. Among those, <kbd>MEMORY_ONLY</kbd> and <kbd>MEMORY_AND_DISK</kbd> persistence can cause problems with off-heap memory, because Spark can't properly estimate the size of objects in an RDD, leading to out of memory issues. It is then good practice using <kbd>MEMORY_ONLY_SER</kbd> or <kbd>MEMORY_AND_DISK_SER</kbd> when persisting an <kbd>RDD&lt;DataSet&gt;</kbd> or an <kbd>RDD&lt;INDArray&gt;</kbd>.</p>
<p>Let's go into detail on this. Spark drops part of an RDD based on the estimated size of that block. It estimates the size of a block depending on the selected persistence level. In the case of <kbd>MEMORY_ONLY</kbd> or <kbd>MEMORY_AND_DISK</kbd>, the estimate is done by walking the Java object graph. The problem is that this process doesn't take into account the off-heap memory used by DL4J and ND4J, so Spark underestimates the true size of objects, such as <kbd>DataSets</kbd> or <kbd>INDArrays</kbd>.</p>
<p>Furthermore, when deciding whether to keep or drop blocks, Spark also only considers the amount of heap memory used. <kbd>DataSet</kbd> and <kbd>INDArray</kbd> objects have a very small on-heap size, then Spark will keep too many of them, causing out of memory issues because off-heap memory becomes exhausted. In cases of <kbd>MEMORY_ONLY_SER</kbd> or <kbd>MEMORY_AND_DISK_SER</kbd>, Spark stores blocks on the JVM heap in serialized form. Because there is no off-heap memory for the serialized objects, their size can be estimated accurately by Spark—it drops blocks when required, avoiding out of memory issues.</p>
<p>Spark provides two serialization libraries—Java (default serialization) and Kryo (<a href="https://github.com/EsotericSoftware/kryo">https://github.com/EsotericSoftware/kryo</a>). By default, it serializes objects using Java’s <kbd>ObjectOutputStream</kbd> (<a href="https://docs.oracle.com/javase/8/docs/api/java/io/ObjectOutputStream.html">https://docs.oracle.com/javase/8/docs/api/java/io/ObjectOutputStream.html</a>), and can work with any class that implements the serializable interface (<a href="https://docs.oracle.com/javase/8/docs/api/java/io/Serializable.html">https://docs.oracle.com/javase/8/docs/api/java/io/Serializable.html</a>). However, it can also use the Kryo library, which is significantly faster and more compact than the Java serialization.</p>
<p>The cons are that Kryo doesn't support all of the serializable types and it doesn't work well with the off-heap data structures by ND4J. So if you want to use Kryo serialization with ND4J on Spark, it is necessary to set some extra configuration, in order to skip potential <kbd>NullPointerExceptions</kbd> due to incorrect serialization on some of the <kbd>INDArray</kbd> fields. To use Kryo you need to add the dependency to your project (the following example is for Maven, but you can import the same dependency with Gradle or sbt using the specific syntax for those build tools), as follows:</p>
<pre>&lt;dependency&gt;<br/>   &lt;groupId&gt;org.nd4j&lt;/groupId&gt;<br/>   &lt;artifactId&gt;nd4j-kryo_2.11&lt;/artifactId&gt;<br/>   &lt;version&gt;0.9.1&lt;/version&gt;<br/> &lt;/dependency&gt;</pre>
<p>Then configure Spark to use the Nd4J Kryo registrator<span>, as follows</span>:</p>
<pre>val sparkConf = new SparkConf<br/> sparkConf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")<br/> sparkConf.set("spark.kryo.registrator", "org.nd4j.Nd4jRegistrator")</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hyperparameter optimization</h1>
                </header>
            
            <article>
                
<p>Before any training can begin, ML techniques in general, and so DL techniques, have a set of parameters that have to be chosen. They are referred to as hyperparameters. Keeping focus on DL, we can say that some of these (the number of layers and their size) define the architecture of a neural network, while others define the learning process (learning rate, regularization, and so on). Hyperparameter optimization is an attempt to automate this process (that has a significant impact on the results achieved by training a neural network) using a dedicated software that applies some search strategies. DL4J provides a tool, Arbiter, for hyperparameter optimization of neural nets. This tool doesn't fully automate the process—a manual intervention from data scientists or developers is needed in order to specify the search spaces (the ranges of valid values for hyperparameters). Please be aware that the current Arbiter implementation doesn't prevent failures on finding good models in those cases where the search spaces haven't been manually defined in a good way. The rest of this section covers the details of how Arbiter can be used programmatically.</p>
<p>The Arbiter dependency needs to be added to the DL4J Scala project for which hyperparameter optimization need to be done<span>, as follows</span>:</p>
<pre>groupId: org.deeplearning4j<br/> artifactId: arbiter-deeplearning4j<br/> version: 0.9.1</pre>
<p>The sequence of steps to follow to set up and execute a hyperparameter optimization through Arbiter is always the same, <span>as follows</span>:</p>
<ul>
<li>Define a hyperparameter search space</li>
<li>Define a candidate generator for that hyperparameter search space</li>
<li>Define a data source</li>
<li>Define a model saver</li>
<li>Choose a score function</li>
<li>Choose a termination condition</li>
<li>Use the previously defined data source, model saver, score function, and termination condition to construct an optimization configuration</li>
<li>Execute the process using the optimization runner</li>
</ul>
<p>Let's now see the details on how to programmatically implement these steps. The setup of the hyperparameter configuration space is very similar to the configuration of an MNN in DL4J. It happens through the <kbd>MultiLayerSpace</kbd> class (<a href="https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/MultiLayerSpace.html">https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/MultiLayerSpace.html</a>). <kbd>ParameterSpace&lt;P&gt;</kbd> (<a href="https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/optimize/api/ParameterSpace.html">https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/optimize/api/ParameterSpace.html</a>) is the arbiter class through which it is possible to define acceptable ranges of values for a given hyperparameter. Here are some examples:</p>
<pre>val learningRateHyperparam = new ContinuousParameterSpace(0.0001, 0.1)  <br/>val layerSizeHyperparam = new IntegerParameterSpace(16, 256)</pre>
<p>The lower and upper bound values specified in the <kbd>ParameterSpace</kbd> constructors are included in the interval. Interval values are generated uniformly at random between the given boundary. The hyperparameters space can then be built, such as in the following example:</p>
<pre>val hyperparameterSpace = new MultiLayerSpace.Builder<br/>    .weightInit(WeightInit.XAVIER)<br/>    .l2(0.0001)<br/>    .updater(new SgdSpace(learningRateHyperparam))<br/>    .addLayer(new DenseLayerSpace.Builder<br/>        .nIn(784)<br/>        .activation(Activation.LEAKYRELU)<br/>        .nOut(layerSizeHyperparam)<br/>        .build())<br/>    .addLayer(new OutputLayerSpace.Builder<br/>        .nOut(10)<br/>        .activation(Activation.SOFTMAX)<br/>        .lossFunction(LossFunctions.LossFunction.MCXENT)<br/>        .build)<br/>    .numEpochs(2)<br/>    .build</pre>
<p>In DL4J, two classes, <kbd>MultiLayerSpace</kbd> and <kbd>ComputationGraphSpace</kbd> (<a href="https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/ComputationGraphSpace.html">https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/ComputationGraphSpace.html</a>), are available for the hyperparameters search space setup (they represent what <kbd>MultiLayerConfiguration</kbd> and <kbd>ComputationGraphConfiguration</kbd> are for MNNs configuration.)</p>
<p>The next step is the definition of candidate generator. It could be a random search, such as in the following line of code:</p>
<pre>val candidateGenerator:CandidateGenerator = new RandomSearchGenerator(hyperparameterSpace, null)</pre>
<p>Alternatively, it could be a grid search.</p>
<p>In order to define the data source (the origin of the data to be used to train and test the different candidates), the <kbd>DataSource</kbd> interface (<a href="https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/optimize/api/data/DataSource.html">https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/optimize/api/data/DataSource.html</a>) is available in Arbiter and needs to be implemented (it requires a no-argument constructor) for a given origin.</p>
<p>At this point we need to define where to save the model that would be generated and tested. Arbiter supports saving models to disk or storing results in-memory. Here is an example of usage of the <kbd>FileModelSaver</kbd> class (<a href="https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/saver/local/FileModelSaver.html">https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/saver/local/FileModelSaver.html</a>) to save to disk:</p>
<pre>val baseSaveDirectory = "arbiterOutput/"<br/>val file = new File(baseSaveDirectory)<br/>if (file.exists) file.delete<br/>file.mkdir<br/>val modelSaver: ResultSaver = new FileModelSaver(baseSaveDirectory)</pre>
<p>We have to choose a score function. Arbiter provides three different choices—<kbd>EvaluationScoreFunction</kbd> (<a href="https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/scoring/impl/EvaluationScoreFunction.html">https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/scoring/impl/EvaluationScoreFunction.html</a>), <kbd>ROCScoreFunction</kbd> (<a href="https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/scoring/impl/ROCScoreFunction.html">https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/scoring/impl/ROCScoreFunction.html</a>), and <kbd>RegressionScoreFunction</kbd> (<a href="https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/scoring/impl/RegressionScoreFunction.html">https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/scoring/impl/RegressionScoreFunction.html</a>).</p>
<p>More details on evaluation, ROC, and regression will be discussed in <a href="869a9495-e759-4810-8623-d8b76ba61398.xhtml" target="_blank">Chapter 9</a>, <em>Interpreting Neural Network Output</em>. Here's an example with <kbd>EvaluationScoreFunction</kbd>:</p>
<pre>val scoreFunction:ScoreFunction = new EvaluationScoreFunction(Evaluation.Metric.ACCURACY)</pre>
<p>Finally we specify a list of termination conditions. The current implementation of Arbiter provides only two termination conditions, <kbd>MaxTimeCondition</kbd> (<a href="https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/optimize/api/termination/MaxTimeCondition.html">https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/optimize/api/termination/MaxTimeCondition.html</a>) and <kbd>MaxCandidatesCondition</kbd> (<a href="https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/optimize/api/termination/MaxCandidatesCondition.html">https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/optimize/api/termination/MaxCandidatesCondition.html</a>). Searching stops when one of the specified termination conditions is satisfied for a hyperparameters space. In the following example, the search stops after 15 minutes or after 20 candidates (depending on the one that<br/>
happens first):</p>
<pre><span class="pl-k">val</span> <span class="pl-smi">terminationConditions</span> <span class="pl-k">=</span> <span class="pl-en">Array</span>(<span class="pl-k">new</span> <span class="pl-en">MaxTimeCondition</span>(<span class="pl-c1">15</span>, <span class="pl-en">TimeUnit</span>.<span class="pl-en">MINUTES</span>), <span class="pl-k">new</span> <span class="pl-en">MaxCandidatesCondition</span>(<span class="pl-c1">20</span>))</pre>
<p>Now that all of the options have been set, it is possible to build the <kbd>OptimizationConfiguration</kbd> (<a href="https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/optimize/config/OptimizationConfiguration.html">https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/optimize/config/OptimizationConfiguration.html</a>)<span>, as follows</span>:</p>
<pre>val configuration: OptimizationConfiguration = new OptimizationConfiguration.Builder<br/>    .candidateGenerator(candidateGenerator)<br/>    .dataSource(dataSourceClass,dataSourceProperties)<br/>    .modelSaver(modelSaver)<br/>    .scoreFunction(scoreFunction)<br/>    .terminationConditions(terminationConditions)<br/>    .build</pre>
<p>Then run it through an <kbd>IOptimizationRunner</kbd> (<a href="https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/optimize/runner/IOptimizationRunner.html">https://deeplearning4j.org/api/latest/org/deeplearning4j/arbiter/optimize/runner/IOptimizationRunner.html</a>), such as in the following example:</p>
<pre>val runner = new LocalOptimizationRunner(configuration, new MultiLayerNetworkTaskCreator())<br/>runner.execute</pre>
<p>At the end of the execution, the application stores the generated candidate in separate directories inside the base save directory preliminary specified for the model saver. Each subdirectory is named with a progressive number.</p>
<p>With reference to this section's examples, it would be <kbd>./arbiterOutput/0/</kbd> for the first candidate, <kbd>./arbiterOutput/1/</kbd> for the second, and so on. A JSON representation of the model is also generated (as shown in following screenshot) and it could be stored as well for further re-use:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c2142391-9ad0-454e-a76c-acba8691848b.png" style="width:31.58em;height:43.42em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.1: Candidate JSON serialization in Arbiter</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Arbiter UI</h1>
                </header>
            
            <article>
                
<p>To get the results of a hyperparameter optimization, you have to wait for the process execution to end and finally retrieve them using the Arbiter API, such as in the following example:</p>
<pre>val indexOfBestResult: Int = runner.bestScoreCandidateIndex<br/>val allResults = runner.getResults<br/><br/>val bestResult = allResults.get(indexOfBestResult).getResult<br/>val bestModel = bestResult.getResult<br/><br/>println("Configuration of the best model:\n")<br/>println(bestModel.getLayerWiseConfigurations.toJson)</pre>
<p>But, depending on the specific case, this process could be long and take hours before it ends and the results become available. Luckily, Arbiter provides a web UI to monitor it at runtime and get insights of potential issues and hints about tuning the optimization configuration, with no need to wait in vain until it completes. In order to begin using this web UI, a further dependency should be added to the project<span>, as follows</span>:</p>
<pre class="mce-root">groupId: org.deeplearning4j<br/> artifactId: arbiter-ui_2.11<br/> version: 1.0.0-beta3</pre>
<p>The server that manages the web UI needs to be configured before the <kbd>IOptimizationRunner</kbd> starts<span>, as follows</span>:</p>
<pre>val ss: StatsStorage = new FileStatsStorage(new File("arbiterUiStats.dl4j"))<br/>runner.addListeners(new ArbiterStatusListener(ss))<br/>UIServer.getInstance.attach(ss)</pre>
<p>In the preceding example we are persisting the Arbiter stats to file. Once the optimization process has started, the web UI can be accessed at the following URL<span>, as follows</span>:</p>
<pre>http://:9000/arbiter</pre>
<p class="mce-root"/>
<p>It has a single view, which, at the top, shows a summary of the ongoing optimization process, as seen in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/2c93b853-c30a-4dce-8101-19146b24c07d.png"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.2: Live summary of a hyperparameters optimization process</div>
<p>In its central area, it shows a summary of the optimization settings, <span>as seen in the following screenshot:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/bf0a277d-9b06-47f7-96aa-23ff2719d7cb.png"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.3: Summary of a hyperparameter optimization settings</div>
<p>And, at the bottom, it shows a list of the results, <span>as seen in the following screenshot:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/6e624d3c-e872-4596-9f77-cbf615288a10.png"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.4: Live summary of the results of a hyperparameter optimization process</div>
<p>By clicking on a result id, extra details about that particular candidate, extra charts, and the model configuration are shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/b772b489-4bae-4388-ab84-741b23a8e246.png"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.5: Candidate details in the Arbiter web UI</div>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The Arbiter UI uses the same implementation and persistence strategy of the DL4J UI to monitor the training process. These details will be covered in the next chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, you have learned how training happens for CNNs and RNNs with DL4J, ND4J, and Apache Spark. You now also have insights into memory management, a number of tips to improve performance for the training process, and details of how to use Arbiter for hyperparameter optimization.</p>
<p>The next chapter will focus on how to monitor and debug CNNs and RNNs during their training phases.</p>


            </article>

            
        </section>
    </body></html>