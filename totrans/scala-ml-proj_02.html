<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Analyzing and Predicting Telecommunication Churn</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will develop a <strong>machine learning</strong> (<strong>ML</strong>) project to analyze and predict whether a customer is likely to cancel the subscription to his telecommunication contract or not. In addition, we'll do some preliminary analysis of the data and take a closer look at what types of customer features are typically responsible for such a churn.</p>
<p>Widely used classification algorithms, such as decision trees, random forest, logistic regression, and <strong>Support Vector Machines</strong> (<strong>SVMs</strong>) will be used for analyzing and making the prediction. By the end, readers will be able to choose the best model to use for a production-ready environment.</p>
<p>In a nutshell, we will learn the following topics throughout this end-to-end project:</p>
<ul>
<li>Why, and how, do we do churn prediction?</li>
<li>Logistic regression-based churn prediction</li>
<li>SVM-based churn prediction</li>
<li>Decision tree-based churn prediction</li>
<li>Random forest-based churn prediction</li>
<li>Selecting the best model for deployment</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Why do we perform churn analysis, and how do we do it?</h1>
                </header>
            
            <article>
                
<p><strong>Customer churn</strong> is the loss of clients or customers (also known as <strong>customer attrition</strong><span class="st">,</span> customer <span class="st">turnover, or</span> customer <span class="st">defection).</span> This concept was initially used within the telecommunications industry when many subscribers switched to other service providers. However, it has become a very important issue in other areas of business, such as banks, internet service providers, insurance companies, and so on. Well, two of the primary reasons for churn are customer <span class="st">dissatisfaction and cheaper and/or better offers from the competition</span>.</p>
<p>As you can see in <em>Figure 1</em>, there are four possible contracts with the customer in a business industry: contractual, non-contractual, voluntary, and involuntary. The full cost of customer churn includes both the lost revenue and the (tele-) marketing costs involved with replacing those customers with new ones. However, this type of loss can cause a huge loss to a business. Think back to a decade ago, when Nokia was the dominator of the cell phone market. All of a sudden, Apple announced iPhone 3G, and that was a revolution in the smartphone era. Then, around 10 to 12% of customers stopped using Nokia and switched to iPhone. Although later on, Nokia also tried to release a smartphone, eventually, they could not compete with Apple:</p>
<div class="CDPAlignCenter CDPAlign"><img height="319" width="865" src="assets/cc26a83d-61b4-4cf0-b673-1e91438ec329.png"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 1: Four types of possible contracts with the customers</div>
<p>Churn prediction <span class="st">is fundamental to businesses, as it allows them to detect customers who are likely to cancel a subscription, product, or service.</span> It can also minimize customer defection. It does so by predicting which customers are likely to cancel a subscription to a service. Then, the respective business can have a special offer or plan for those customers (who might cancel the subscription). This way, a business can reduce the churn ratio. This should be a key business goal of every online business.</p>
<p>When it comes to employee churn prediction, the typical task is to determine what factors predict an employee leaving his/her job. These types of prediction processes are heavily data-driven and are often required to utilize advanced ML techniques. In this chapter, however, we will mainly focus on customer churn prediction and analysis. For this, a number of factors should be analyzed in order to understand the customer's behavior, including but not limited to:</p>
<ul>
<li>Customer's demographic data, such as age, marital status, and so on</li>
<li>Customer's sentiment analysis of social media</li>
<li>Browsing behavior from clickstream logs</li>
<li>Historical data that shows patterns of behavior that suggest churn</li>
<li>Customer's usage patterns and geographical usage trends</li>
<li>Calling-circle data and support call center statistics</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Developing a churn analytics pipeline</h1>
                </header>
            
            <article>
                
<p>In ML, we observe an algorithm's performance in two stages: learning and inference. The ultimate target of the learning stage is to prepare and describe the available data, also called the <strong>feature vector</strong>, which is used to train the model.</p>
<p>The learning stage is one of the most important stages, but it is also truly time-consuming. It involves preparing a list of vectors, also called <strong>feature vectors</strong> (vectors of numbers representing the value of each feature), from the training data after transformation so that we can feed them to the learning algorithms. On the other hand, training data also sometimes contains impure information that needs some pre-processing, such as cleaning.</p>
<p>Once we have the feature vectors, the next step in this stage is preparing (or writing/reusing) the learning algorithm. The next important step is training the algorithm to prepare the predictive model. Typically, (and of course based on data size), running an algorithm may take hours (or even days) so that the features converge into a useful model, as shown in the following figure:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f458d39c-885d-4161-b766-251ea56c1efb.png"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 2: Learning and training a predictive model - it shows how to generate the feature vectors from the training data to train the learning algorithm that produces a predictive model</div>
<p>The second most important stage is the inference that is used for making an intelligent use of the model, such as predicting from the never-before-seen data, making recommendations, deducing future rules, and so on. Typically, it takes less time compared to the learning stage, and is sometimes even in real time. Thus, inferencing is all about testing the model against new (that is, unobserved) data and evaluating the performance of the model itself, as shown in the following figure:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7e917a27-ffcf-43d6-8794-a16d48bd0fed.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 3: Inferencing from an existing model towards predictive analytics (feature vectors are generated from unknown data for making predictions)</div>
<p>However, during the whole process and for making the predictive model a successful one, data acts as the first-class citizen in all ML tasks. Keeping all this in mind, the following figure shows an analytics pipeline that can be used by telecommunication companies:</p>
<div class="CDPAlignCenter CDPAlign"><img height="262" width="512" src="assets/9abacbdc-9ed4-4ab4-938f-54ee24efcc24.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 4: Churn analytics pipeline</div>
<p>With this kind of analysis, telecom companies can discern how to predict and enhance the customer experience, which can, in turn, prevent churn and tailor marketing campaigns. In practice, often these business assessments are used in order to retain the customers most likely to leave, as opposed to those who are likely to stay.</p>
<p>Thus, we need to develop a predictive model so that it ensures that our model is sensitive to the <kbd>Churn = True</kbd> samples—that is, a binary classification problem. We will see more details in upcoming sections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Description of the dataset</h1>
                </header>
            
            <article>
                
<p>The <strong>Orange Telecom's Churn Dataset</strong>, which consists of cleaned customer activity data (features), along with a churn label specifying whether a customer canceled the subscription, will be used to develop our predictive model. The churn-80 and churn-20 datasets can be downloaded from the following links, respectively:</p>
<ul>
<li><a href="https://bml-data.s3.amazonaws.com/churn-bigml-80.csv">https://bml-data.s3.amazonaws.com/churn-bigml-80.csv</a></li>
<li><a href="https://bml-data.s3.amazonaws.com/churn-bigml-20.csv">https://bml-data.s3.amazonaws.com/churn-bigml-20.csv</a></li>
</ul>
<p>However, as more data is often desirable for developing ML models, let's use the larger set (that is, churn-80) for training and cross-validation purposes, and the smaller set (that is, churn-20) for final testing and model performance evaluation.</p>
<p>Note that the latter set is only used to evaluate the model (that is for demonstration purposes). For a production ready environment, telecommunication companies can use their own dataset with necessary preprocessing and feature engineering. The dataset has the following schema:</p>
<ul>
<li><strong>State</strong>: <kbd>String</kbd></li>
<li><strong>Account length</strong>: <kbd>Integer</kbd></li>
<li><strong>Area code</strong>: <kbd>Integer</kbd></li>
<li><strong>International plan</strong>: <kbd>String</kbd></li>
<li><strong>Voicemail plan</strong>: <kbd>String</kbd></li>
<li><strong>Number email messages</strong>: <kbd>Integer</kbd></li>
<li><strong>Total day minutes</strong>: <kbd>Double</kbd></li>
<li><strong>Total day calls</strong>: <kbd>Integer</kbd></li>
<li><strong>Total day charge</strong>: <kbd>Double</kbd></li>
<li><strong>Total eve minutes</strong>: <kbd>Double</kbd></li>
<li><strong>Total eve calls</strong>: <kbd>Integer</kbd></li>
<li><strong>Total eve charge</strong>: <kbd>Double</kbd></li>
<li><strong>Total night minutes</strong>: <kbd>Double</kbd></li>
<li><strong>Total night calls</strong>: <kbd>Integer</kbd></li>
<li><strong>Total night charge</strong>: <kbd>Double</kbd></li>
<li><strong>Total intl minutes</strong>: <kbd>Double</kbd></li>
<li><strong>Total intl calls</strong>: <kbd>Integer</kbd></li>
<li><strong>Total intl charge</strong>: <kbd>Double</kbd></li>
<li><strong>Customer service calls</strong>: <kbd>Integer</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploratory analysis and feature engineering</h1>
                </header>
            
            <article>
                
<p>In this sub-section, we will see some EDA of the dataset before we start preprocessing and feature engineering. Only then creation of an analytics pipeline makes sense. At first, let's import necessary packages and libraries as follows:</p>
<pre><strong>import</strong> org.apache.spark._<br/><strong>import</strong> org.apache.spark.sql.functions._<br/><strong>import</strong> org.apache.spark.sql.types._<br/><strong>import</strong> org.apache.spark.sql._<br/><strong>import</strong> org.apache.spark.sql.Dataset</pre>
<p>Then, let's specify the data source and schema for the dataset to be processed. When loading the data into a DataFrame, we can specify the schema. This specification provides optimized performance compared to the pre-Spark 2.x schema inference.</p>
<p>At first, let's create a Scala case class with all the fields specified. The variable names are self-explanatory:</p>
<pre><strong>case </strong><strong>class</strong> CustomerAccount(state_code: String, <br/>    account_length: Integer, <br/>    area_code: String, <br/>    international_plan: String, <br/>    voice_mail_plan: String, <br/>    num_voice_mail: Double, <br/>    total_day_mins: Double, <br/>    total_day_calls: Double, <br/>    total_day_charge: Double,<br/>    total_evening_mins: Double, <br/>    total_evening_calls: Double, <br/>    total_evening_charge: Double,<br/>    total_night_mins: Double, <br/>    total_night_calls: Double, <br/>    total_night_charge: Double,<br/>    total_international_mins: Double, <br/>    total_international_calls: Double, <br/>    total_international_charge: Double,<br/>    total_international_num_calls: Double, <br/>    churn: String)</pre>
<p>Now, let's create a custom schema having a structure similar to our already created data source, as follows:</p>
<pre><strong>val</strong> schema = StructType(Array(<br/>    StructField("state_code", StringType, <strong>true</strong>),<br/>    StructField("account_length", IntegerType, <strong>true</strong>),<br/>    StructField("area_code", StringType, <strong>true</strong><span>),<br/></span>    StructField("international_plan", StringType, <strong>true</strong>),<br/>    StructField("voice_mail_plan", StringType, <strong>true</strong>),<br/>    StructField("num_voice_mail", DoubleType, <strong>true</strong>),<br/>    StructField("total_day_mins", DoubleType, <strong>true</strong>),<br/>    StructField("total_day_calls", DoubleType, <strong>true</strong>),<br/>    StructField("total_day_charge", DoubleType, <strong>true</strong>),<br/>    StructField("total_evening_mins", DoubleType, <strong>true</strong>),<br/>    StructField("total_evening_calls", DoubleType, <strong>true</strong>),<br/>    StructField("total_evening_charge", DoubleType, <strong>true</strong>),<br/>    StructField("total_night_mins", DoubleType, <strong>true</strong>),<br/>    StructField("total_night_calls", DoubleType, <strong>true</strong>),<br/>    StructField("total_night_charge", DoubleType, <strong>true</strong>),<br/>    StructField("total_international_mins", DoubleType, <strong>true</strong>),<br/>    StructField("total_international_calls", DoubleType, <strong>true</strong>),<br/>    StructField("total_international_charge", DoubleType, <strong>true</strong>),<br/>    StructField("total_international_num_calls", DoubleType, <strong>true</strong>),<br/>    StructField("churn", StringType, <strong>true</strong>)<br/>))</pre>
<p>Let's create a Spark session and import the <kbd>implicit._</kbd> that enables us to specify a DataFrame operation, as follows:</p>
<pre><strong>val</strong> spark: SparkSession = SparkSessionCreate.createSession("preprocessing")<br/><strong>import</strong> spark.implicits._</pre>
<p>Now let's create the training set. We read the CSV file with Spark's recommended format, <kbd>com.databricks.spark.csv</kbd>. We don't need any explicit schema inference, making the infer Schema false, but instead, we need our own schema we just created previously. Then, we load the data file from our desired location, and finally, specify our data source so that our DataFrame looks exactly the same as we specified:</p>
<pre><strong>val</strong> trainSet: Dataset[CustomerAccount] = spark.read.<br/>        option("inferSchema", "false")<br/>        .format("com.databricks.spark.csv")<br/>        .schema(schema)<br/>        .load("data/churn-bigml-80.csv")<br/>        .as[CustomerAccount]</pre>
<p>Now, let's see what the schema looks like:</p>
<pre>trainSet.printSchema()<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="228" width="313" src="assets/489ed265-308b-4a22-82c2-127c473bd023.png"/></div>
<p>Excellent! It looks exactly the same as the data structure. Now let's see some sample data using the <kbd>show()</kbd> method, as follows:</p>
<pre>trainSet.show()<br/>&gt;&gt;&gt;</pre>
<p><span class="NormalPACKTCarattere">In the following figure, column names are made shorter for visibility on the picture</span>:</p>
<div class="CDPAlignCenter CDPAlign"><img height="224" width="639" src="assets/601a7523-4f1b-45d2-9481-d0f868bca26d.png"/></div>
<p>We can also see related statistics of the training set using the <kbd>describe()</kbd> method from Spark:</p>
<div class="packt_tip">The <kbd>describe()</kbd> method is a Spark DataFrame's built-in method for statistical processing. It applies summary statistics calculations on all numeric columns. Finally, it returns the computed values as a single DataFrame.</div>
<pre><strong>val</strong> statsDF = trainSet.describe()<br/>statsDF.show()<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="118" width="597" src="assets/fe307ce5-7904-41fd-b30b-63a24fee94e5.png"/></div>
<p>If this dataset can be fit into RAM, we can cache it for quick and repeated access using the <kbd>cache()</kbd> method from Spark:</p>
<pre>trainSet.cache()</pre>
<p>Let's see some useful properties, such as variable correlation with churn. For example, let's see how the churn is related to the total number of international calls:</p>
<pre>trainSet.groupBy("churn").sum("total_international_num_calls").show()<br/>&gt;&gt;&gt;<br/>+-----+----------------------------------+<br/>churn|sum(total_international_num_calls)|<br/>+-----+----------------------------------+<br/>|False| 3310.0|<br/>| True| 856.0|<br/>+-----+----------------------------------+</pre>
<p>Let's see how the churn is related to the total international call charges:</p>
<pre>trainSet.groupBy("churn").sum("total_international_charge").show()<br/> &gt;&gt;&gt;<br/>+-----+-------------------------------+<br/>|churn|sum(total_international_charge)|<br/>+-----+-------------------------------+<br/>|False| 6236.499999999996|<br/>| True| 1133.63|<br/>+-----+-------------------------------+</pre>
<p>Now that we also need to have the test set prepared to evaluate the model, let's prepare the same set, similar to the train set, as follows:</p>
<pre><strong>val</strong> testSet: Dataset[CustomerAccount] = <br/>    spark.read.<br/>    option("inferSchema", "false")<br/>    .format("com.databricks.spark.csv")<br/>    .schema(schema)<br/>    .load("data/churn-bigml-20.csv")<br/>    .as[CustomerAccount]</pre>
<p>Now let's cache them for faster access for further manipulation:</p>
<pre>testSet.cache()</pre>
<p>Now, let's see some related properties of the training set to understand its suitableness for our purposes. At first, let's create a temp view for persistence for this session. We can create a catalog as an interface that can be used to create, drop, alter, or query underlying databases, tables, functions, and many more:</p>
<pre>trainSet.createOrReplaceTempView("UserAccount")<br/>spark.catalog.cacheTable("UserAccount")</pre>
<p>Grouping the data by the churn label and calculating the number of instances in each group demonstrates that there are around six times more false churn samples as true churn samples. Let's verify this statement with the following line of code:</p>
<pre>trainSet.groupBy("churn").count.show()<br/>&gt;&gt;&gt;<br/>+-----+-----+<br/>|churn|count|<br/>+-----+-----+<br/>|False| 2278|<br/>| True| 388 |<br/>+-----+-----+</pre>
<p>We can also see the previous statement, verified using Apache Zeppelin (see more details on how to configure and getting started in <a href="3e09dbd3-a9bb-4451-97f1-1a961d28b4a0.xhtml" target="_blank">Chapter 8</a>, <em>Using Deep Belief Networks in Bank Marketing</em>), as follows:</p>
<pre>spark.sqlContext.sql("SELECT churn,SUM(international_num_calls) as Total_intl_call FROM UserAccount GROUP BY churn").show()<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="178" width="534" src="assets/b933288d-c96b-4772-888f-b1930c1c0593.png"/></div>
<p>As we have already stated, in most cases the target is to retain the customers who are most likely to leave, as opposed to those who are likely to stay or are staying. This also signifies that we should prepare our training set such that it ensures that our ML model is sensitive to the true churn samples—that is, having churn label true.</p>
<p>We can also observe that the preceding training set is highly unbalanced. Therefore, it would be feasible to put two sample types on the same footing using stratified sampling. The <kbd>sampleBy()</kbd> method can be used to do so when provided with fractions of each sample type to be returned.</p>
<p>Here, we're keeping all instances of the <kbd>True</kbd> churn class, but downsampling the <kbd>False</kbd> churn class to a fraction of <em>388/2278</em>, which is about <kbd>0.1675</kbd>:</p>
<pre><strong>val</strong> fractions = Map("False" -&gt; 0.1675, "True" -&gt; 1.0)</pre>
<p>This way, we are also mapping only <kbd>True</kbd> churn samples. Now, let's create a new DataFrame for the training set containing only downsampled ones:</p>
<pre><strong>val</strong> churnDF = trainSet.stat.sampleBy("churn", fractions, 12345L)</pre>
<p>The third parameter is the seed used for the reproducibility purpose. Now let's see:</p>
<pre>churnDF.groupBy("churn").count.show()<br/>&gt;&gt;&gt;<br/>+-----+-----+<br/>|churn|count|<br/>+-----+-----+<br/>|False| 390|<br/>| True| 388|<br/>+-----+-----+</pre>
<p>Now let's see how the variables are related to each other. Let's see how the day, night, evening, and international voice calls contribute to the <kbd>churn</kbd> class. Just execute the following line:</p>
<pre>spark.sqlContext.sql("SELECT churn, SUM(total_day_charge) as TDC, SUM(total_evening_charge) as TEC,    <br/>                      SUM(total_night_charge) as TNC, SUM(total_international_charge) as TIC,  <br/>                      SUM(total_day_charge) + SUM(total_evening_charge) + SUM(total_night_charge) + <br/>                      SUM(total_international_charge) as Total_charge FROM UserAccount GROUP BY churn <br/>                      ORDER BY Total_charge DESC")<br/>.show()<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="78" width="559" src="assets/5a0af826-28e0-463e-b042-50b3498f37b0.png"/></div>
<p>On Apache Zeppelin, the preceding result can be seen as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img height="159" width="435" src="assets/a764a0a5-e3c5-4867-b495-2d5952c8407d.png"/></div>
<p>Now, let's see how many minutes of day, night, evening, and international voice calls have contributed to the preceding total charge to the <kbd>churn</kbd> class. Just execute the following line:</p>
<pre>spark.sqlContext.sql("SELECT churn, SUM(total_day_mins) <br/>                      + SUM(total_evening_mins) + SUM(total_night_mins) <br/>                      + SUM(total_international_mins) as Total_minutes <br/>                    FROM UserAccount GROUP BY churn").show()<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="87" width="182" src="assets/548bee1c-eb4e-40dc-b02c-e58b1729a683.png"/></div>
<p>On Apache Zeppelin, the preceding result can be seen as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img height="183" width="518" src="assets/aa00e9d2-c314-4459-8e51-135748fb243d.png"/></div>
<p>From the preceding two graphs and tables, it is clear that total day minutes and total day charge are a highly correlated feature in this training set, which is not beneficial for our ML model training. Therefore, it would be better to remove them altogether. Moreover, the following graph shows all possible correlations (plotted in PySpark, though):</p>
<div class="CDPAlignCenter CDPAlign"><img height="601" width="607" src="assets/7aea33d2-92d3-4c01-8b74-aba1b5cb883e.jpg"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 5: Correlation matrix, including all the features</div>
<p>Let's drop one column of each pair of correlated fields, along with the <strong>State</strong> and <strong>Area code</strong> columns, too, since those will not be used either:</p>
<pre><strong>val</strong> trainDF = churnDF<br/>    .drop("state_code")<br/>    .drop("area_code")<br/>    .drop("voice_mail_plan")<br/>    .drop("total_day_charge")<br/>    .drop("total_evening_charge")</pre>
<p>Excellent. Finally, we have our training DataFrame that can be used for better predictive modeling. Let's take a look at some columns of the resulting DataFrame:</p>
<pre class="mce-root">trainDF.select("account_length", "international_plan", "num_voice_mail",         <br/>               "total_day_calls","total_international_num_calls", "churn")<br/>.show(10)<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="564" width="1856" class="alignnone size-full wp-image-242 image-border" src="assets/a90814fb-81d6-440c-bc2a-226ee24a1bd0.png"/></div>
<p>However, <span>we are not done yet; the current DataFrame cannot be fed to the model as an estimator</span>. As we described, the Spark ML API needs our data to be converted in a Spark DataFrame format, consisting of a label (in Double) and features (in Vector).</p>
<p>Now, we need to create a pipeline to pass the data through and chain several transformers and estimators. The pipeline then works as a feature extractor. More specifically, we have prepared two <kbd>StringIndexer</kbd> transformers and a <kbd>VectorAssembler</kbd>.</p>
<div class="packt_infobox"><kbd>StringIndexer</kbd> encodes a categorical column of labels to a column of label indices (that is, numerical). If the input column is numeric, we have to cast it into a string and index the string values. Other Spark pipeline components, such as Estimator or Transformer, make use of this string-indexed label. In order to do this, the input column of the component must be set to this string-indexed column name. In many cases, you can set the input column with <kbd>setInputCol</kbd>. Interested readers should refer to this <a href="https://spark.apache.org/docs/latest/ml-features.html">https://spark.apache.org/docs/latest/ml-features.html</a> for more details.</div>
<p>The first <kbd>StringIndexer</kbd> converts the String categorical feature <kbd>international_plan</kbd> and labels into number indices. The second <kbd>StringIndexer</kbd> converts the categorical label (that is, <kbd>churn</kbd>) to numeric. This way, indexing categorical features enables decision trees and random forest-like classifiers to treat categorical features appropriately, hence improving performance.</p>
<p><span>Now, add the following lines of code, index labels, and metadata to the label column.</span> Fit on the whole dataset to include all labels in the index:</p>
<pre><strong>val</strong> ipindexer = <strong>new</strong> StringIndexer()<br/>    .setInputCol("international_plan")<br/>    .setOutputCol("iplanIndex")<br/><br/><strong>val</strong> labelindexer = <strong>new</strong> StringIndexer()<br/>    .setInputCol("churn")<br/>    .setOutputCol("label")</pre>
<p>Now we need to extract the most important features that contribute to the classification. Since we have dropped some columns already, the resulting column set consists of the following fields:</p>
<pre>* Label → churn: True or False<br/>* Features → {("account_length", "iplanIndex", "num_voice_mail", "total_day_mins", "total_day_calls", "total_evening_mins", "total_evening_calls", "total_night_mins", "total_night_calls", "total_international_mins", "total_international_calls", "total_international_num_calls"}</pre>
<p>As we have already converted categorical labels into numeric using <kbd>StringIndexer</kbd>, the next task is to extract the features:</p>
<pre><strong>val</strong> featureCols = Array("account_length", "iplanIndex", <br/>                        "num_voice_mail", "total_day_mins", <br/>                        "total_day_calls", "total_evening_mins", <br/>                        "total_evening_calls", "total_night_mins", <br/>                        "total_night_calls", "total_international_mins", <br/>                        "total_international_calls", "total_international_num_calls")</pre>
<p>Now, let's transform the features into feature vectors, which are vectors of numbers representing the value for each feature. In our case, we will use <kbd>VectorAssembler</kbd>. It takes all the <kbd>featureCols</kbd> and combines/transforms them into a single column called <strong>features</strong>:</p>
<pre><strong>val</strong> assembler = <strong>new</strong> VectorAssembler()<br/>    .setInputCols(featureCols)<br/>    .setOutputCol("features")</pre>
<p>Now that we have the real training set consisting of labels and feature vectors ready, the next task is to create an estimator—the third element of a pipeline. We start with a very simple but powerful Logistic Regression<strong> </strong>classifier.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">LR for churn prediction</h1>
                </header>
            
            <article>
                
<p>LR is one of the most widely used classifiers to predict a binary response. It is a linear ML method, as described in <a href="4b0be2d2-f313-471f-83fe-830931fc8af9.xhtml" target="_blank">Chapter 1</a>, <em>Analyzing Insurance Severity Claim</em>. The <kbd>loss</kbd> function is the formulation given by the logistic loss:</p>
<div class="CDPAlignCenter CDPAlign"><img height="25" width="279" class="fm-editor-equation" src="assets/58d1cdb4-4e46-48ce-8051-bf44e2fbf31c.png"/></div>
<p>For the LR model, the <kbd>loss</kbd> function is the logistic loss. For a binary classification problem, the algorithm outputs a binary LR model such that, for a given new data point, denoted by <em>x</em>, the model makes predictions by applying the logistic function:</p>
<div class="CDPAlignCenter CDPAlign"><img height="42" width="124" class="fm-editor-equation" src="assets/a34028da-b03e-4cb1-a247-c08dd7e7d7ce.png"/></div>
<p>In the preceding equation, <em>z = W<sup>T</sup>X</em> and if <em>f(W<sup>T</sup>X)&gt;0.5</em>, the outcome is positive; otherwise, it is negative.</p>
<div class="packt_infobox">Note that the raw output of the LR model, <em>f(z)</em>, has a probabilistic interpretation.</div>
<p>Note that compared to linear regression, logistic regression provides you with a higher classification accuracy. Moreover, it is a flexible way to regularize a model for custom adjustment, and overall, the model responses are measures of probability.</p>
<p>Most importantly, whereas linear regression can predict only continuous values, <span>linear regression</span> can still be generalized enough to make it predict discrete values:</p>
<pre><strong>import</strong> org.apache.spark._<br/><strong>import</strong> org.apache.spark.sql.SparkSession<br/><strong>import</strong> org.apache.spark.sql.functions._<br/><strong>import</strong> org.apache.spark.ml.classification.{BinaryLogisticRegressionSummary, LogisticRegression, LogisticRegressionModel}<br/><strong>import</strong> org.apache.spark.ml.Pipeline<br/><strong>import</strong> org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}<br/><strong>import</strong> org.apache.spark.mllib.evaluation.BinaryClassificationMetrics <br/><strong>import</strong> org.apache.spark.ml.evaluation.BinaryClassificationEvaluator</pre>
<p><span>Now that we already know linear regression's working principle, let's start using the Spark-based implementation of linear regression. Let's start by importing the required packages and libraries.</span></p>
<p>Now, let's create a Spark session and import implicit:</p>
<pre><strong>val</strong> spark: SparkSession = SparkSessionCreate.createSession("ChurnPredictionLogisticRegression")<br/><strong>import</strong> spark.implicits._</pre>
<p>We now need to define some hyperparameters to train an <span>linear regression</span>-based pipeline:</p>
<pre><strong>val</strong> numFolds = 10<br/><strong>val</strong> MaxIter: Seq[Int] = Seq(100)<br/><strong>val</strong> RegParam: Seq[Double] = Seq(1.0) // L2 regularization param, set 1.0 with L1 regularization<br/><strong>val</strong> Tol: Seq[Double] = Seq(1e-8)// for convergence tolerance for iterative algorithms<br/><strong>val</strong> ElasticNetParam: Seq[Double] = Seq(0.0001) //Combination of L1 &amp; L2</pre>
<p>The <kbd>RegParam</kbd> is a scalar that helps adjust the strength of the constraints: a small value implies a soft margin, so naturally, a large value implies a hard margin, and being an infinity is the hardest margin.</p>
<div class="packt_tip">By default, LR performs an L2 regularization with the regularization parameter set to 1.0. The same model performs an L1 regularized variant of LR with the regularization parameter (that is, <kbd>RegParam</kbd>) set to 0.10. Elastic Net is a combination of L1 and L2 regularization.</div>
<p>On the other hand, the <kbd>Tol</kbd> parameter is used for the convergence tolerance for iterative algorithms such as logistic regression or linear SVM. Now, once we have the hyperparameters defined and initialized, the next task is to instantiate an <span>linear regression</span> estimator, as follows:</p>
<pre><strong>val</strong> lr = <strong>new</strong> LogisticRegression()<br/>    .setLabelCol("label")<br/>    .setFeaturesCol("features")</pre>
<p>Now that we have three transformers and an estimator ready, the next task is to chain in a single pipeline—that is, each of them acts as a stage:</p>
<pre><strong>val</strong> pipeline = <strong>new</strong> Pipeline()<br/>    .setStages(Array(PipelineConstruction.ipindexer,<br/>    PipelineConstruction.labelindexer,<br/>    PipelineConstruction.assembler, lr))</pre>
<p>In order to perform such a grid search over the hyperparameter space, we need to define it first. Here, the functional programming properties of Scala are quite handy, because we just add function pointers and the respective parameters to be evaluated to the parameter grid, where you set up the parameters to test, and a cross-validation evaluator, to construct a model selection workflow. This searches through <span>linear regression</span>'s max iteration, regularization param, tolerance, and Elastic Net for the best model:</p>
<pre><strong>val</strong> paramGrid = <strong>new</strong> ParamGridBuilder()<br/>    .addGrid(lr.maxIter, MaxIter)<br/>    .addGrid(lr.regParam, RegParam)<br/>    .addGrid(lr.tol, Tol)<br/>    .addGrid(lr.elasticNetParam, ElasticNetParam)<br/>    .build()</pre>
<div class="packt_infobox">Note that the hyperparameters form an n-dimensional space where <em>n</em> is the number of hyperparameters. Every point in this space is one particular hyperparameter configuration, which is a hyperparameter vector. Of course, we can't explore every point in this space, so what we basically do is a grid search over a (hopefully evenly distributed) subset in that space.</div>
<p>We then need to define a <kbd>BinaryClassificationEvaluator</kbd> evaluator, since this is a binary classification problem. Using this evaluator, the model will be evaluated according to a precision metric by comparing the test label column with the test prediction column. The default metrics are an area under the precision-recall curve and an area under the <strong>receiver operating characteristic</strong> (<strong>ROC</strong>) curve:</p>
<pre><strong>val</strong> evaluator = <strong>new</strong> BinaryClassificationEvaluator()<br/>    .setLabelCol("label")<br/>    .setRawPredictionCol("prediction")</pre>
<p>We use a <kbd>CrossValidator</kbd> for best model selection. The <kbd>CrossValidator</kbd> uses the Estimator Pipeline, the Parameter Grid, and the Classification Evaluator. The <kbd>CrossValidator</kbd> uses the <kbd>ParamGridBuilder</kbd> to iterate through the max iteration, regression param, and tolerance and Elastic Net parameters of <span>linear regression</span>, and then evaluates the models, repeating 10 times per parameter value for reliable results—that is, 10-fold cross-validation:</p>
<pre><strong>val</strong> crossval = <strong>new</strong> CrossValidator()<br/>    .setEstimator(pipeline)<br/>    .setEvaluator(evaluator)<br/>    .setEstimatorParamMaps(paramGrid)<br/>    .setNumFolds(numFolds)</pre>
<p>The preceding code is meant to perform cross-validation. The validator itself uses the <kbd>BinaryClassificationEvaluator</kbd> estimator for evaluating the training in the progressive grid space on each fold and makes sure that there's no overfitting.</p>
<p>Although there is so much stuff going on behind the scenes, the interface to our <kbd>CrossValidator</kbd> object stays slim and well-known, as <kbd>CrossValidator</kbd> also extends from Estimator and supports the fit method. This means that, after calling fit, the complete predefined pipeline, including all feature preprocessing and the LR classifier, is executed multiple times—each time with a different hyperparameter vector:</p>
<pre><strong>val</strong> cvModel = crossval.fit(Preprocessing.trainDF)</pre>
<p>Now it's time to evaluate the predictive power of the LR model we created using the test dataset, which has not been used for any training or cross-validation so far—that is, unseen data to the model. As a first step, we need to transform the test set to the model pipeline, which will map the features according to the same mechanism we described in the preceding feature engineering step:</p>
<pre><strong>val</strong> predictions = cvModel.transform(Preprocessing.testSet)<br/><strong>al</strong> result = predictions.select("label", "prediction", "probability")<br/><strong>val</strong> resutDF = result.withColumnRenamed("prediction", "Predicted_label")<br/>resutDF.show(10)<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="183" width="262" class="alignnone size-full wp-image-243 image-border" src="assets/b2101733-4336-453c-9d7e-2bf2fb7c7f1a.png"/></div>
<p>The prediction probabilities can also be very useful in ranking customers according to their likeliness to imperfection. This way, a limited number of resources can be utilized in a telecommunication business for withholding but can be focused to the most valuable customers.</p>
<p>However, seeing the previous prediction DataFrame, it is really difficult to guess the classification accuracy. In the second step, the evaluator evaluates itself using <kbd>BinaryClassificationEvaluator</kbd>, as follows:</p>
<pre><strong>val</strong> accuracy = evaluator.evaluate(predictions)<br/>println("Classification accuracy: " + accuracy)<br/>&gt;&gt;&gt;<br/>Classification accuracy: 0.7670592565329408</pre>
<p>So, we get about 77% of classification accuracy from our binary classification model. Now using the accuracy for the binary classifier does not make enough sense.</p>
<p>Hence, researchers often recommend other performance metrics, such as area under the precision-recall curve and area under the ROC curve. However, for this we need to construct an RDD containing the raw scores on the test set:</p>
<pre><strong>val</strong> predictionAndLabels = predictions<br/>    .select("prediction", "label")<br/>    .rdd.map(x =&gt; (x(0).asInstanceOf[Double], x(1)<br/>    .asInstanceOf[Double]))</pre>
<p>Now, the preceding RDD can be used to compute the <span>two </span>previously-mentioned performance metrics:</p>
<pre><strong>val</strong> metrics = <strong>new</strong> BinaryClassificationMetrics(predictionAndLabels)<br/>println("Area under the precision-recall curve: " + metrics.areaUnderPR)<br/>println("Area under the receiver operating characteristic (ROC) curve : " + metrics.areaUnderROC)<br/>&gt;&gt;&gt;<br/>Area under the precision-recall curve: 0.5761887477313975<br/>Area under the receiver operating characteristic (ROC) curve: 0.7670592565329408</pre>
<p>In this case, the evaluation returns 77% accuracy, but only 58% precision. In the following, we calculate some more metrics; for example, false and true positive and negative predictions are also useful to evaluate the model's performance:</p>
<ul>
<li><strong>True positive</strong>: How often the model correctly predicted subscription canceling</li>
<li><strong>False positive</strong>: How often the model incorrectly predicted subscription canceling</li>
<li><strong>True negative</strong>: How often the model correctly predicted no canceling at all</li>
<li><strong>False negative</strong>: How often the model incorrectly predicted no canceling</li>
</ul>
<pre><strong>val</strong> lp = predictions.select("label", "prediction")<br/><strong>val</strong> counttotal = predictions.count()<br/><strong>val</strong> correct = lp.filter($"label" === $"prediction").count()<br/><br/><strong>val</strong> wrong = lp.filter(not($"label" === $"prediction")).count()<br/><strong>val</strong> ratioWrong = wrong.toDouble / counttotal.toDouble<br/><strong>val</strong> ratioCorrect = correct.toDouble / counttotal.toDouble<br/><br/><strong>val</strong> truep = lp.filter($"prediction" === 0.0).filter($"label" ===<br/>$"prediction").count() / counttotal.toDouble<br/><br/><strong>val</strong> truen = lp.filter($"prediction" === 1.0).filter($"label" ===<br/>$"prediction").count() / counttotal.toDouble<br/><br/><strong>val</strong> falsep = lp.filter($"prediction" === 1.0).filter(not($"label" ===<br/>$"prediction")).count() / counttotal.toDouble<br/><br/><strong>val</strong> falsen = lp.filter($"prediction" === 0.0).filter(not($"label" ===<br/>$"prediction")).count() / counttotal.toDouble<br/><br/>println("Total Count : " + counttotal)<br/>println("Correct : " + correct)<br/>println("Wrong: " + wrong)<br/>println("Ratio wrong: " + ratioWrong)<br/>println("Ratio correct: " + ratioCorrect)<br/>println("Ratio true positive : " + truep)<br/>println("Ratio false positive : " + falsep)<br/>println("Ratio true negative : " + truen)<br/>println("Ratio false negative : " + falsen)<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="212" width="459" class="alignnone size-full wp-image-244 image-border" src="assets/16371f9d-cf39-4676-98fc-4407d4fba749.png"/></div>
<p>Yet, we have not received good accuracy, so let's continue trying other classifiers, such as SMV. This time, we will use the linear SVM implementation from the Apache Spark ML package.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SVM for churn prediction</h1>
                </header>
            
            <article>
                
<p>SVM is also used widely for large-scale classification (that is, binary as well as multinomial) tasks. Besides, it is also a linear ML method, as described in <a href="4b0be2d2-f313-471f-83fe-830931fc8af9.xhtml" target="_blank">Chapter 1</a>, <em>Analyzing Insurance Severity Claim</em>. The linear SVM algorithm outputs an SVM model, where the loss function used by SVM can be defined using the hinge loss, as follows:</p>
<div class="CDPAlignCenter CDPAlign"><em><span class="mi">L</span><span class="mo">(</span><span class="mi"><strong>w</strong></span><span class="mo">;</span><span class="mi"><strong>x</strong></span><span class="mo">,</span><span class="mi">y</span><span class="mo">):=max{</span><span class="mn">0</span><span class="mo">,</span><span class="mn">1</span><span class="mo">−</span><span class="mi">y</span><span class="mi"><strong>w</strong></span><span class="mi"><sup>T</sup></span><span class="mi"><strong>x</strong></span><span class="mo">}</span></em></div>
<p>The linear SVMs in Spark are trained with an L2 regularization, by default. However, it also supports L1 regularization, by which the problem itself becomes a linear program.</p>
<p>Now, suppose we have a set of new data points <em>x</em>; the model makes predictions based on the value of <em><strong><span class="mi">w</span></strong><span class="mi"><sup>T</sup></span><strong><span class="mi">x</span></strong></em>. By default, if <em><span class="mi"><strong>w</strong></span></em><span class="mi"><em><sup>T</sup></em></span><em><span class="mi"><strong>x</strong></span><span class="mo">≥</span><span class="mn">0</span></em>, then the outcome is positive, and negative otherwise.</p>
<p>Now that we already know the SVMs working principle, let's start using the Spark-based implementation of SVM. Let's start by importing the required packages and libraries:</p>
<pre><strong>import</strong> org.apache.spark._<br/><strong>import</strong> org.apache.spark.sql.SparkSession<br/><strong>import</strong> org.apache.spark.sql.functions._<br/><strong>import</strong> org.apache.spark.ml.classification.{LinearSVC, LinearSVCModel}<br/><strong>import</strong><span> org.apache.spark.sql.SparkSession<br/></span><strong>import</strong> org.apache.spark.sql.functions.max<br/><strong>import</strong> org.apache.spark.ml.Pipeline<br/><strong>import</strong> org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}<br/><strong>import</strong> org.apache.spark.mllib.evaluation.BinaryClassificationMetrics<br/><strong>import</strong> org.apache.spark.ml.evaluation.BinaryClassificationEvaluator</pre>
<p>Now let's create a Spark session and import implicit:</p>
<pre><strong>val</strong> spark: SparkSession = SparkSessionCreate.createSession("ChurnPredictionLogisticRegression")<br/><strong>import</strong> spark.implicits._</pre>
<p>We now need to define some hyperparameters to train an LR-based pipeline:</p>
<pre><strong>val</strong> numFolds = 10<br/><strong>val</strong> MaxIter: Seq[Int] = Seq(100)<br/><strong>val</strong> RegParam: Seq[Double] = Seq(1.0) // L2 regularization param, set 0.10 with L1 reguarization<br/><strong>val</strong> Tol: Seq[Double] = Seq(1e-8)<br/><strong>val</strong> ElasticNetParam: Seq[Double] = Seq(1.0) // Combination of L1 and L2</pre>
<p>Now, once we have the hyperparameters defined and initialized, the next task is to instantiate an LR estimator, as follows:</p>
<pre><strong>val</strong> svm = <strong>new</strong> LinearSVC()</pre>
<p>Now that we have three transformers and an estimator ready, the next task is to chain in a single pipeline—that is, each of them acts as a stage:</p>
<pre><strong>val</strong> pipeline = <strong>new</strong> Pipeline()<br/>     .setStages(Array(PipelineConstruction.ipindexer,<br/>                      PipelineConstruction.labelindexer,<br/>                      PipelineConstruction.assembler,svm)<br/>                      )</pre>
<p>Let's define the <kbd>paramGrid</kbd> to perform such a grid search over the hyperparameter space. This searches through SVM's max iteration, regularization param, tolerance, and Elastic Net for the best model:</p>
<pre><strong>val</strong> paramGrid = <strong>new</strong> ParamGridBuilder()<br/>    .addGrid(svm.maxIter, MaxIter)<br/>    .addGrid(svm.regParam, RegParam)<br/>    .addGrid(svm.tol, Tol)<br/>    .addGrid(svm.elasticNetParam, ElasticNetParam)<br/>    .build()</pre>
<p>Let's define a <kbd>BinaryClassificationEvaluator</kbd> evaluator to evaluate the model:</p>
<pre><strong>val</strong> evaluator = <strong>new</strong> BinaryClassificationEvaluator()<br/>    .setLabelCol("label")<br/>    .setRawPredictionCol("prediction")</pre>
<p>We use a <kbd>CrossValidator</kbd> for performing 10-fold cross-validation for best model selection:</p>
<pre><strong>val</strong> crossval = <strong>new</strong> CrossValidator()<br/>    .setEstimator(pipeline)<br/>    .setEvaluator(evaluator)<br/>    .setEstimatorParamMaps(paramGrid)<br/>    .setNumFolds(numFolds)</pre>
<p>Let's now call the <kbd>fit</kbd> method so that the complete predefined pipeline, including all feature preprocessing and the LR classifier, is executed multiple times—each time with a different hyperparameter vector:</p>
<pre><strong>val</strong> cvModel = crossval.fit(Preprocessing.trainDF)</pre>
<p>Now it's time to evaluate the predictive power of the SVM model on the test dataset. As a first step, we need to transform the test set with the model pipeline, which will map the features according to the same mechanism we described in the preceding feature engineering step:</p>
<pre><strong>val</strong> predictions = cvModel.transform(Preprocessing.testSet)<br/>prediction.show(10)<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="187" width="357" src="assets/ad85dba1-6541-44bf-bf6c-560e0d867804.png"/></div>
<p>However, seeing the previous prediction DataFrame, it is really difficult to guess the classification accuracy. In the second step, the evaluator evaluates itself using <kbd>BinaryClassificationEvaluator</kbd>, as follows:</p>
<pre><strong>val</strong> accuracy = evaluator.evaluate(predictions)<br/>println("Classification accuracy: " + accuracy)<br/>&gt;&gt;&gt;<br/>Classification accuracy: 0.7530180345969819</pre>
<p>So we get about 75% of classification accuracy from our binary classification model. Now, using the accuracy for the binary classifier does not make enough sense.</p>
<p>Hence, researchers often recommend other performance metrics, such as area under the precision-recall curve and area under the ROC curve. However, for this we need to construct an RDD containing the raw scores on the test set:</p>
<pre><strong>val</strong> predictionAndLabels = predictions<br/>    .select("prediction", "label")<br/>    .rdd.map(x =&gt; (x(0).asInstanceOf[Double], x(1)<br/>    .asInstanceOf[Double]))</pre>
<p>Now the preceding RDD can be used to compute the two previously-mentioned performance metrics:</p>
<pre><strong>val</strong> metrics = <strong>new</strong> BinaryClassificationMetrics(predictionAndLabels)<br/>println("Area under the precision-recall curve: " + metrics.areaUnderPR)<br/>println("Area under the receiver operating characteristic (ROC) curve : " + metrics.areaUnderROC)<br/>&gt;&gt;&gt;<br/>Area under the precision-recall curve: 0.5595712265324828<br/>Area under the receiver operating characteristic (ROC) curve: 0.7530180345969819</pre>
<p>In this case, the evaluation returns 75% accuracy but only 55% precision. In the following, we again calculate some more metrics; for example, false and true positive and negative predictions are also useful to evaluate the model's performance:</p>
<pre><strong>val</strong> lp = predictions.select("label", "prediction")<br/><strong>val</strong> counttotal = predictions.count()<br/><br/><strong>val</strong> correct = lp.filter($"label" === $"prediction").count()<br/><br/><strong>val</strong> wrong = lp.filter(not($"label" === $"prediction")).count()<br/><strong>val</strong> ratioWrong = wrong.toDouble / counttotal.toDouble<br/><br/><strong>val</strong> ratioCorrect = correct.toDouble / counttotal.toDouble<br/><br/><strong>val</strong> truep = lp.filter($"prediction" === 0.0).filter($"label" ===<br/>$"prediction").count() / counttotal.toDouble<br/><br/><strong>val</strong> truen = lp.filter($"prediction" === 1.0).filter($"label" ===<br/>$"prediction").count() / counttotal.toDouble<br/><br/><strong>val</strong> falsep = lp.filter($"prediction" === 1.0).filter(not($"label" ===<br/>$"prediction")).count() / counttotal.toDouble<br/><br/><strong>val</strong> falsen = lp.filter($"prediction" === 0.0).filter(not($"label" ===<br/>$"prediction")).count() / counttotal.toDouble<br/><br/>println("Total Count : " + counttotal)<br/>println("Correct : " + correct)<br/>println("Wrong: " + wrong)<br/>println("Ratio wrong: " + ratioWrong)<br/>println("Ratio correct: " + ratioCorrect)<br/>println("Ratio true positive : " + truep)<br/>println("Ratio false positive : " + falsep)<br/>println("Ratio true negative : " + truen)<br/>println("Ratio false negative : " + falsen)<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="183" width="316" src="assets/6d30c141-8fcc-4bda-8273-b5fc3c4f9a3d.png"/></div>
<p>Yet, we have not received good accuracy using SVM. Moreover, there is no option to select the most suitable features, which would help us train our model with the most appropriate features. This time , we will again use a more robust classifier, such as the <strong>decision trees</strong> (<strong>DTs</strong>) implementation from the Apache Spark ML package.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">DTs for churn prediction</h1>
                </header>
            
            <article>
                
<p>DTs are commonly considered a supervised learning technique used for solving classification and regression tasks.</p>
<p>More technically, each branch in a DT represents a possible decision, occurrence, or reaction, in terms of statistical probability. Compared to naive Bayes, DTs are a far more robust classification technique. The reason is that at first, the DT splits the features into training and test sets. Then, it produces a good generalization to infer the predicted labels or classes. Most interestingly, a DT algorithm can handle both binary and multiclass classification problems.</p>
<p>For instance, in the <span>following </span>example figure, DTs learn from the admission data to approximate a sine curve with a set of <strong>if...else</strong> decision rules. The dataset contains the record of each student who applied for admission, say, to an American university. Each record contains the graduate record exam score, CGPA score, and the rank of the column. Now we will have to predict who is competent based on these three features (variables). DTs can be used to solve this kind of problem after training the DT model and pruning unwanted branches of the tree. In general, a deeper tree signifies more complex decision rules and a better-fitted model:</p>
<div class="CDPAlignCenter CDPAlign"><img height="466" width="479" src="assets/fa48fbd9-4b1f-4e97-abd1-fe85ca6be6d4.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 6: Decision tree for university admission data</div>
<p>Therefore, the deeper the tree, the more complex the decision rules and the more fitted the model is. Now let's see some pros and cons of DTs:</p>
<table class="MsoTableGrid">
<tbody>
<tr>
<td/>
<td>
<p><strong>Pros</strong></p>
</td>
<td>
<p><strong>Cons</strong></p>
</td>
<td>
<p><strong>Better at</strong></p>
</td>
</tr>
<tr>
<td>
<p><strong>Decision trees (DTs)</strong></p>
</td>
<td>
<p>-Simple to implement, train, and interpret</p>
<p>-Trees can be visualized</p>
<p>-Requires little data preparation</p>
<p>-Less model building and prediction time</p>
<p>-Can handle both numeric and categorical data</p>
<p>-Possibility of validating the model using the statistical tests</p>
<p>-Robust against noise and missing values</p>
<p>-High accuracy</p>
</td>
<td>
<p>-Interpretation is hard with large and complex trees</p>
<p>-Duplication may occur within the same sub-tree</p>
<p>-Possible issues with diagonal decision boundaries</p>
<p>-Decision tree learners can create over-complex trees that do not generalize the data well</p>
<p>-Sometimes DTs can be unstable because of small variants in the data</p>
<p>-Learning the DT itself is an NP-complete problem</p>
<p>-DT learners create biased trees if some classes dominate</p>
</td>
<td>
<p>-Targeting highly accurate classification</p>
<p>-Medical diagnosis and prognosis</p>
<p>-Credit risk analytics</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Now, that we already know the working principle of DTs, let's start using the Spark-based implementation of DTs. Let's start by importing required packages and libraries:</p>
<pre><strong>import</strong> org.apache.spark._<br/><strong>import</strong> org.apache.spark.sql.SparkSession<br/><strong>import</strong> org.apache.spark.sql.functions._<br/><strong>import</strong> org.apache.spark.sql.types._<br/><strong>import</strong> org.apache.spark.sql._<br/><strong>import</strong> org.apache.spark.ml.Pipeline<br/><strong>import</strong> org.apache.spark.ml.classification.{DecisionTreeClassifier, DecisionTreeClassificationModel}<br/><strong>import</strong> org.apache.spark.mllib.evaluation.BinaryClassificationMetrics<br/><strong>import</strong> org.apache.spark.ml.evaluation.BinaryClassificationEvaluator<br/><strong>import</strong> org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}</pre>
<p>Now let's create a Spark session and import implicit:</p>
<pre><strong>val</strong> spark: SparkSession = SparkSessionCreate.createSession("ChurnPredictionDecisionTrees")<br/><strong>import</strong> spark.implicits._</pre>
<p>Now, once we have the hyperparameters defined and initialized, the next task is to instantiate a <kbd>DecisionTreeClassifier</kbd> estimator, as follows:</p>
<pre><strong>val</strong> dTree = <strong>new</strong> DecisionTreeClassifier()<br/>                .setLabelCol("label")<br/>                .setFeaturesCol("features")<br/>                .setSeed(1234567L)</pre>
<p>Now that we have three transformers and an estimator ready, the next task is to chain in a single pipeline—that is, each of them acts as a stage:</p>
<pre><strong>val</strong> pipeline = <strong>new</strong> Pipeline()<br/>                .setStages(Array(PipelineConstruction.ipindexer,<br/>                PipelineConstruction.labelindexer,<br/>                PipelineConstruction.assembler,dTree))</pre>
<p>Let's define the paramgrid to perform such a grid search over the hyperparameter space. This search is through DT's impurity, max bins, and max depth for the best model. Maximum depth of the tree: depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.</p>
<p>On the other hand, the maximum number of bins is used for separate continuous features and for choosing how to split on features at each node. More bins give higher granularity. In short, we search through decision tree's <kbd>maxDepth</kbd> and <kbd>maxBins</kbd> parameters for the best model:</p>
<pre><strong>var</strong> paramGrid = <strong>new</strong> ParamGridBuilder()<br/>    .addGrid(dTree.impurity, "gini" :: "entropy" :: Nil)<br/>    .addGrid(dTree.maxBins, 2 :: 5 :: 10 :: 15 :: 20 :: 25 :: 30 :: Nil)<br/>    .addGrid(dTree.maxDepth, 5 :: 10 :: 15 :: 20 :: 25 :: 30 :: 30 :: Nil)<br/>    .build()</pre>
<p>In the preceding code segment, we're creating a progressive paramgrid through sequence format. That means we are creating the grid space with different hyperparameter combinations. This will help us provide the best model that consists of the most optimal hyperparameters.</p>
<p>Let's define a <kbd>BinaryClassificationEvaluator</kbd> evaluator to evaluate the model:</p>
<pre><strong>val</strong> evaluator = <strong>new</strong> BinaryClassificationEvaluator()<br/>    .setLabelCol("label")<br/>    .setRawPredictionCol("prediction")</pre>
<p>We use a <kbd>CrossValidator</kbd> for performing 10-fold cross-validation for best model selection:</p>
<pre><strong>val</strong> crossval = <strong>new</strong> CrossValidator()<br/>    .setEstimator(pipeline)<br/>    .setEvaluator(evaluator)<br/>    .setEstimatorParamMaps(paramGrid)<br/>    .setNumFolds(numFolds)</pre>
<p>Let's now call the <kbd>fit</kbd> method so that the complete predefined pipeline, including all feature preprocessing and the DT classifier, is executed multiple times—each time with a different hyperparameter vector:</p>
<pre><strong>val</strong> cvModel = crossval.fit(Preprocessing.trainDF)</pre>
<p>Now it's time to evaluate the predictive power of the DT model on the test dataset. As a first step, we need to transform the test set with the model pipeline, which will map the features according to the same mechanism we described in the previous feature engineering step:</p>
<pre><strong>val</strong> predictions = cvModel.transform(Preprocessing.testSet)<br/>prediction.show(10)<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="192" width="293" src="assets/7ecce996-69f6-4412-b021-7588816d89d6.png"/></div>
<p>However, seeing the preceding prediction DataFrame, it is really difficult to guess the classification accuracy. In the second step, in the evaluation is the evaluate itself using <kbd>BinaryClassificationEvaluator</kbd>, as follows:</p>
<pre><strong>val</strong> accuracy = evaluator.evaluate(predictions)<br/>println("Classification accuracy: " + accuracy)<br/>&gt;&gt;&gt;<br/>Accuracy: 0.870334928229665</pre>
<p>So, we get about 87% of classification accuracy from our binary classification model. Now, similar to SVM and LR, we will observe the area under the precision-recall curve and the area under the ROC curve based on the following RDD containing the raw scores on the test set:</p>
<pre><strong>val</strong> predictionAndLabels = predictions<br/>    .select("prediction", "label")<br/>    .rdd.map(x =&gt; (x(0).asInstanceOf[Double], x(1)<br/>    .asInstanceOf[Double]))</pre>
<p>Now the preceding RDD can be used to compute the two previously-mentioned performance metrics:</p>
<pre><strong>val</strong> metrics = <strong>new</strong> BinaryClassificationMetrics(predictionAndLabels)<br/>println("Area under the precision-recall curve: " + metrics.areaUnderPR)<br/>println("Area under the receiver operating characteristic (ROC) curve : " + metrics.areaUnderROC)<br/>&gt;&gt;&gt;<br/>Area under the precision-recall curve: 0.7293101942399631<br/>Area under the receiver operating characteristic (ROC) curve: 0.870334928229665</pre>
<p>In this case, the evaluation returns 87% accuracy but only 73% precision, which is much better than that of SVM and LR. In the following, we again calculate some more metrics; for example, false and true positive and negative predictions are also useful to evaluate the model's performance:</p>
<pre><strong>val</strong> lp = predictions.select("label", "prediction")<br/><strong>val</strong> counttotal = predictions.count()<br/><br/><strong>val</strong> correct = lp.filter($"label" === $"prediction").count()<br/><br/><strong>val</strong> wrong = lp.filter(not($"label" === $"prediction")).count()<br/><br/><strong>val</strong> ratioWrong = wrong.toDouble / counttotal.toDouble<br/><br/><strong>val</strong> ratioCorrect = correct.toDouble / counttotal.toDouble<br/><br/><strong>val</strong> truep = lp.filter($"prediction" === 0.0).filter($"label" ===<br/>$"prediction").count() / counttotal.toDouble<br/><br/><strong>val</strong> truen = lp.filter($"prediction" === 1.0).filter($"label" ===<br/>$"prediction").count() / counttotal.toDouble<br/><br/><strong>val</strong> falsep = lp.filter($"prediction" === 1.0).filter(not($"label" ===<br/>$"prediction")).count() / counttotal.toDouble<br/><br/><strong>val</strong> falsen = lp.filter($"prediction" === 0.0).filter(not($"label" ===<br/>$"prediction")).count() / counttotal.toDouble<br/><br/>println("Total Count : " + counttotal)<br/>println("Correct : " + correct)<br/>println("Wrong: " + wrong)<br/>println("Ratio wrong: " + ratioWrong)<br/>println("Ratio correct: " + ratioCorrect)<br/>println("Ratio true positive : " + truep)<br/>println("Ratio false positive : " + falsep)<br/>println("Ratio true negative : " + truen)<br/>println("Ratio false negative : " + falsen)<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="276" width="400" src="assets/e919b818-4fc3-4bd9-8bde-c1e4974f3518.png"/></div>
<p>Fantastic; we achieved 87% accuracy, but for what factors? Well, it can be debugged to get the decision tree constructed during the classification. But first, let's see at what level we achieved the best model after the cross-validation:</p>
<pre><strong>val</strong> bestModel = cvModel.bestModel<br/>println("The Best Model and Parameters:n--------------------")<br/>println(bestModel.asInstanceOf[org.apache.spark.ml.PipelineModel].stages(3))<br/>&gt;&gt;&gt;</pre>
<p>The Best Model and Parameters:</p>
<pre>DecisionTreeClassificationModel (uid=dtc_1fb45416b18b) of depth 5 with 53 nodes.</pre>
<p>That means we achieved the best tree model at depth 5 having 53 nodes. Now let's extract those moves (that is, decisions) taken during tree construction by showing the tree. This tree helps us to find the most valuable features in our dataset:</p>
<pre>bestModel.asInstanceOf[org.apache.spark.ml.PipelineModel]<br/>    .stages(3)<br/>    .extractParamMap<br/><br/><strong>val</strong> treeModel = bestModel.asInstanceOf[org.apache.spark.ml.PipelineModel]<br/>    .stages(3)<br/>    .asInstanceOf[DecisionTreeClassificationModel]<br/>println("Learned classification tree model:n" + treeModel.toDebugString)<br/>&gt;&gt;&gt;</pre>
<p>Learned classification tree model:</p>
<pre>If (feature 3 &lt;= 245.2)<br/>    If (feature 11 &lt;= 3.0)<br/>        If (feature 1 in {1.0})<br/>            If (feature 10 &lt;= 2.0)<br/>                Predict: 1.0<br/>            Else (feature 10 &gt; 2.0)<br/>            If (feature 9 &lt;= 12.9)<br/>                Predict: 0.0<br/>            Else (feature 9 &gt; 12.9)<br/>                Predict: 1.0<br/>        ...</pre>
<pre>    Else (feature 7 &gt; 198.0)<br/>        If (feature 2 &lt;= 28.0)<br/>            Predict: 1.0<br/>        Else (feature 2 &gt; 28.0)<br/>            If (feature 0 &lt;= 60.0)<br/>                Predict: 0.0<br/>            Else (feature 0 &gt; 60.0)<br/>                Predict: 1.0</pre>
<p>In the preceding output, the <kbd>toDebugString()</kbd> function prints the tree's decision nodes and the final prediction comes out at the end leaves. It is also clearly seen that features 11 and 3 are used for decision making; they are the two most important reasons why a customer is likely to churn. But what are those two features? Let's see them:</p>
<pre>println("Feature 11:" + Preprocessing.trainDF.filter(PipelineConstruction.featureCols(11)))<br/>println("Feature 3:" + Preprocessing.trainDF.filter(PipelineConstruction.featureCols(3)))<br/>&gt;&gt;&gt;<br/>Feature 11: [total_international_num_calls: double]<br/>Feature 3: [total_day_mins: double]</pre>
<p>So the customer service calls and total day minutes are selected by the decision trees, since it provides an automated mechanism for determining the most important features.</p>
<p>Wait! We are not finished yet. Last but not least, we will use an ensemble technique, RF, which is considered a more robust classifier than DTs. Again, let's use the Random Forest implementation from the Apache Spark ML package.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Random Forest for churn prediction</h1>
                </header>
            
            <article>
                
<p>As described in <a href="4b0be2d2-f313-471f-83fe-830931fc8af9.xhtml" target="_blank">Chapter 1</a>, <em>Analyzing Insurance Severity Claim</em>, Random Forest is an ensemble technique that takes a subset of observations and a subset of variables to build decision trees—that is, an ensemble of DTs. More technically, it builds several decision trees and integrates them together to get a more accurate and stable prediction.</p>
<div class="CDPAlignCenter CDPAlign"><img height="358" width="578" src="assets/5cc25b68-25d8-404b-8419-01ce7bd71ce4.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7: Random forest and its assembling technique explained  </div>
<p>This is a direct consequence, since by maximum voting from a panel of independent juries, we get the final prediction better than the best jury (see the preceding figure). Now that we already know the working principle of RF, let's start using the Spark-based implementation of RF. Let's start by importing the required packages and libraries:</p>
<pre><strong>import</strong> org.apache.spark._<br/><strong>import</strong> org.apache.spark.sql.SparkSession<br/><strong>import</strong> org.apache.spark.sql.functions._<br/><strong>import</strong> org.apache.spark.sql.types._<br/><strong>import</strong> org.apache.spark.sql._<br/><strong>import</strong> org.apache.spark.ml.Pipeline<br/><strong>import</strong> org.apache.spark.ml.classification.{RandomForestClassifier, RandomForestClassificationModel}<br/><strong>import</strong> org.apache.spark.mllib.evaluation.BinaryClassificationMetrics<br/><strong>import</strong> org.apache.spark.ml.evaluation.BinaryClassificationEvaluator<br/><strong>import</strong> org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}</pre>
<p class="mce-root">Now let's create Spark session and import implicit:</p>
<pre><strong>val</strong> spark: SparkSession = SparkSessionCreate.createSession("ChurnPredictionRandomForest")<br/><strong>import</strong> spark.implicits._</pre>
<p>Now, once we have the hyperparameters defined and initialized, the next task is to instantiate a <kbd>DecisionTreeClassifier</kbd> estimator, as follows:</p>
<pre><strong>val</strong> rf = <strong>new</strong> RandomForestClassifier()<br/>    .setLabelCol("label")<br/>    .setFeaturesCol("features")<br/>    .setSeed(1234567L)// for reproducibility</pre>
<p>Now that we have three transformers and an estimator ready, the next task is to chain in a single pipeline—that is, each of them acts as a stage:</p>
<pre><strong>val</strong> pipeline = <strong>new</strong> Pipeline()<br/>    .setStages(Array(PipelineConstruction.ipindexer,<br/>    PipelineConstruction.labelindexer,<br/>    PipelineConstruction.assembler,rf))</pre>
<p>Let's define the paramgrid to perform such a grid search over the hyperparameter space:</p>
<pre><strong>val</strong> paramGrid = <strong>new</strong> ParamGridBuilder()<br/>    .addGrid(rf.maxDepth, 3 :: 5 :: 15 :: 20 :: 50 :: Nil)<br/>    .addGrid(rf.featureSubsetStrategy, "auto" :: "all" :: Nil)<br/>    .addGrid(rf.impurity, "gini" :: "entropy" :: Nil)<br/>    .addGrid(rf.maxBins, 2 :: 5 :: 10 :: Nil)<br/>    .addGrid(rf.numTrees, 10 :: 50 :: 100 :: Nil)<br/>    .build()</pre>
<p>Let's define a <kbd>BinaryClassificationEvaluator</kbd> evaluator to evaluate the model:</p>
<pre><strong>val</strong> evaluator = <strong>new</strong> BinaryClassificationEvaluator()<br/>    .setLabelCol("label")<br/>    .setRawPredictionCol("prediction")</pre>
<p>We use a <kbd>CrossValidator</kbd> for performing 10-fold cross-validation for best model selection:</p>
<pre><strong>val</strong> crossval = <strong>new</strong> CrossValidator()<br/>    .setEstimator(pipeline)<br/>    .setEvaluator(evaluator)<br/>    .setEstimatorParamMaps(paramGrid)<br/>    .setNumFolds(numFolds)</pre>
<p>Let's now call the <kbd>fit</kbd> method so that the complete, predefined pipeline, including all feature preprocessing and the DT classifier, is executed multiple times—each time with a different hyperparameter vector:</p>
<pre><strong>val</strong> cvModel = crossval.fit(Preprocessing.trainDF)</pre>
<p>Now it's time to evaluate the predictive power of the DT model on the test dataset. As a first step, we need to transform the test set to the model pipeline, which will map the features according to the same mechanism we described in the previous feature engineering step:</p>
<pre><strong>val</strong> predictions = cvModel.transform(Preprocessing.testSet)<br/>prediction.show(10)<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="193" width="277" class="alignnone size-full wp-image-248 image-border" src="assets/3c3565fc-44f6-4bf0-a838-72fae88c09e3.png"/></div>
<p>However, seeing the preceding prediction DataFrame, it is really difficult to guess the classification accuracy. In the second step, in the evaluation is the evaluate itself using <kbd>BinaryClassificationEvaluator</kbd>, as follows:</p>
<pre><strong>val</strong> accuracy = evaluator.evaluate(predictions)<br/>println("Classification accuracy: " + accuracy)<br/>&gt;&gt;&gt;<br/>Accuracy: 0.870334928229665</pre>
<p>So, we get about 87% of classification accuracy from our binary classification model. Now, similar to SVM and LR, we will observe the area under the precision-recall curve and the area under the ROC curve based on the following RDD containing the raw scores on the test set:</p>
<pre><strong>val</strong> predictionAndLabels = predictions<br/>    .select("prediction", "label")<br/>    .rdd.map(x =&gt; (x(0).asInstanceOf[Double], x(1)<br/>    .asInstanceOf[Double]))</pre>
<p>Now the preceding RDD can be used to compute the two previously-mentioned performance metrics:</p>
<pre><strong>val</strong> metrics = <strong>new</strong> BinaryClassificationMetrics(predictionAndLabels)<br/><br/>println("Area under the precision-recall curve: " + metrics.areaUnderPR)<br/>println("Area under the receiver operating characteristic (ROC) curve : " + metrics.areaUnderROC)<br/>&gt;&gt;&gt;<br/>Area under the precision-recall curve: 0.7293101942399631<br/>Area under the receiver operating characteristic (ROC) curve: 0.870334928229665</pre>
<p>In this case, the evaluation returns 87% accuracy but only 73% precision, which is much better than that of SVM and LR. In the following, we again calculate some more metrics; for example, false and true positive and negative predictions are also useful to evaluate the model's performance:</p>
<pre><strong>val</strong> lp = predictions.select("label", "prediction")<br/><strong>val</strong> counttotal = predictions.count()<br/><br/><strong>val</strong> correct = lp.filter($"label" === $"prediction").count()<br/><br/><strong>val</strong> wrong = lp.filter(not($"label" === $"prediction")).count()<br/><br/><strong>val</strong> ratioWrong = wrong.toDouble / counttotal.toDouble<br/><br/><strong>val</strong> ratioCorrect = correct.toDouble / counttotal.toDouble<br/><br/><strong>val</strong> truep = lp.filter($"prediction" === 0.0).filter($"label" ===<br/>$"prediction").count() / counttotal.toDouble<br/><br/><strong>val</strong> truen = lp.filter($"prediction" === 1.0).filter($"label" ===<br/>$"prediction").count() / counttotal.toDouble<br/><br/><strong>val</strong> falsep = lp.filter($"prediction" === 1.0).filter(not($"label" ===<br/>$"prediction")).count() / counttotal.toDouble<br/><br/><strong>val</strong> falsen = lp.filter($"prediction" === 0.0).filter(not($"label" ===<br/>$"prediction")).count() / counttotal.toDouble<br/><br/>println("Total Count : " + counttotal)<br/>println("Correct : " + correct)<br/>println("Wrong: " + wrong)<br/>println("Ratio wrong: " + ratioWrong)<br/>println("Ratio correct: " + ratioCorrect)<br/>println("Ratio true positive : " + truep)<br/>println("Ratio false positive : " + falsep)<br/>println("Ratio true negative : " + truen)<br/>println("Ratio false negative : " + falsen)<br/>&gt;&gt;&gt;</pre>
<p>We will get the following result:</p>
<div class="CDPAlignCenter CDPAlign"><img height="284" width="458" src="assets/9c1a146a-2390-4b0e-b71e-af399d8e61b3.png"/></div>
<p>Fantastic; we achieved 91% accuracy, but for what factors? Well, similar to DT, Random Forest can be debugged to get the decision tree that was constructed during the classification. For the tree to be printed and the most important features selected, try the last few lines of code in the DT, and you're done.</p>
<p>Can you now guess how many different models were trained? Well, we have 10-folds on CrossValidation and five-dimensional hyperparameter space cardinalities between 2 and 7. Now let's do some simple math: 10 * 7 * 5 * 2 * 3 * 6 = 12600 models!</p>
<p>Note that we still make the hyperparameter space confined, with <kbd>numTrees</kbd>, <kbd>maxBins</kbd>, and <kbd>maxDepth</kbd> limited to 7. Also, remember that bigger trees will most likely perform better. Therefore, feel free to play around with this code and add features, and also use a bigger hyperparameter space, say, bigger trees.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Selecting the best model for deployment</h1>
                </header>
            
            <article>
                
<p>From the preceding results, it can be seen that LR and SVM models have the same but higher false positive rate compared to Random Forest and DT. So we can say that DT and Random Forest have better accuracy overall in terms of true positive counts. Let's see the validity of the preceding statement with prediction distributions on pie charts for each model:</p>
<div class="CDPAlignCenter CDPAlign"><img height="402" width="640" class="alignnone size-full wp-image-246 image-border" src="assets/e0108be2-f86e-40ab-9f3f-00e341dda8df.png"/></div>
<p>Now, it's worth mentioning that using random forest, we are actually getting high accuracy, but it's a very resource, as well as time-consuming job; the training, especially, takes a considerably longer time as compared to LR and SVM.</p>
<p>Therefore, if you don't have higher memory or computing power, it is recommended to increase the Java heap space prior to running this code to avoid OOM errors.</p>
<p>Finally, if you want to deploy the best model (that is, Random Forest in our case), it is recommended to save the cross-validated model immediately after the <kbd>fit()</kbd> method invocation:</p>
<pre>// Save the workflow<br/>cvModel.write.overwrite().save("model/RF_model_churn")</pre>
<p>Your trained model will be saved to that location. The directory will include:</p>
<ul>
<li>The best model</li>
<li>Estimator</li>
<li>Evaluator</li>
<li>The metadata of the training itself</li>
</ul>
<p>Now the next task will be restoring the same model, as follows:</p>
<pre>// Load the workflow back<br/><strong>val</strong> cvModel = CrossValidatorModel.load("model/ RF_model_churn/")</pre>
<p>Finally, we need to transform the test set to the model pipeline that maps the features according to the same mechanism we described in the preceding feature engineering step:</p>
<pre><strong>val</strong> predictions = cvModel.transform(Preprocessing.testSet)</pre>
<p>Finally, we evaluate the restored model:</p>
<pre><strong>val</strong> evaluator = <strong>new</strong> BinaryClassificationEvaluator()<br/>    .setLabelCol("label")<br/>    .setRawPredictionCol("prediction")<br/><br/><strong>val</strong> accuracy = evaluator.evaluate(predictions)<br/>    println("Accuracy: " + accuracy)<br/>    evaluator.explainParams()<br/><br/><strong>val</strong> predictionAndLabels = predictions<br/>    .select("prediction", "label")<br/>    .rdd.map(x =&gt; (x(0).asInstanceOf[Double], x(1)<br/>    .asInstanceOf[Double]))<br/><br/><strong>val</strong> metrics = <strong>new</strong> BinaryClassificationMetrics(predictionAndLabels)<br/><strong>val</strong> areaUnderPR = metrics.areaUnderPR<br/>println("Area under the precision-recall curve: " + areaUnderPR)</pre>
<pre><strong>val</strong> areaUnderROC = metrics.areaUnderROC<br/>println("Area under the receiver operating characteristic (ROC) curve: " + areaUnderROC)<br/>&gt;&gt;&gt;</pre>
<p>You will receive the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img height="264" width="529" src="assets/5cb2c2c5-1984-4919-a0c1-8d433a22c386.png"/></div>
<p>Well, done! We have managed to reuse the model and do the same prediction. But, probably due to the randomness of data, we observed slightly different predictions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have seen how to develop an ML project to predict whether a customer is likely to cancel their subscription or not, and then used it to develop a real-life predictive model. We have developed predictive models using LR, SVMs, DTs, and Random Forest. We have also analyzed what types of customer data are typically used to do preliminary analysis of the data. Finally, we have seen how to choose which model to use for a production-ready environment.</p>
<p>In the next chapter, we will see how to develop a real-life project that collects historical and live <strong>Bitcoin</strong> data and predicts the price for an upcoming week, month, and so on. In addition to this, we will see how to generate a simple signal for online cryptocurrency trading.</p>


            </article>

            
        </section>
    </body></html>