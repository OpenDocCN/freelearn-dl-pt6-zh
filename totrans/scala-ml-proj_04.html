<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Population-Scale Clustering and Ethnicity Prediction</h1>
                </header>
            
            <article>
                
<p>Understanding variations in genome sequences assists us in identifying people who are predisposed to common diseases, curing rare diseases, and finding the corresponding population group of individuals from a larger population group. Although classical machine learning techniques allow researchers to identify groups (that is, clusters) of related variables, the accuracy and effectiveness of these methods diminish for large and high-dimensional datasets such as the whole human genome.</p>
<p>On the other hand, <strong>Deep Neural Networks</strong> (<strong>DNNs</strong>) form the core of <strong>deep learning</strong> (<strong>DL</strong>) and provide algorithms to model complex, high-level abstractions in data. They can better exploit large-scale datasets to build complex models.</p>
<p>In this chapter, we apply the K-means algorithm to large-scale genomic data from the 1000 Genomes project analysis aimed at clustering genotypic variants at the population scale. Finally, we train an H2O-based DNN model and a Spark-based random forest model for predicting geographic ethnicity. The theme of this chapter is <em>give me your genetic variants data and I will tell your ethnicity</em>.</p>
<p>Nevertheless, we will configure H2O so that the same setting can be used in upcoming chapters too. Concisely, we will learn the following topics throughout this end-to-end project:</p>
<ul>
<li>Population-scale clustering and geographic ethnicity prediction</li>
<li>The 1000 Genomes project, a deep catalog of human genetic variants</li>
<li>Algorithms and tools</li>
<li>Using K-means for population-scale clustering</li>
<li>Using H2O for ethnicity prediction</li>
<li>Using random forest for ethnicity prediction</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Population scale clustering and geographic ethnicity</h1>
                </header>
            
            <article>
                
<p><strong>Next-generation genome sequencing</strong> (<strong>NGS</strong>) reduces overhead and time for genomic sequencing, leading to big data production in an unprecedented way. In contrast, analyzing this large-scale data is computationally expensive and increasingly becomes the key bottleneck. This increase in NGS data in terms of number of samples overall and features per sample demands solutions for massively parallel data processing, which imposes extraordinary challenges on machine learning solutions and bioinformatics approaches. The use of genomic information in medical practice requires efficient analytical methodologies to cope with data from thousands of individuals and millions of their variants.</p>
<p>One of the most important tasks is the analysis of genomic profiles to attribute individuals to specific ethnic populations, or the analysis of nucleotide haplotypes for disease susceptibility. The data from the 1000 Genomes project serves as the prime source to analyze genome-wide <strong>single nucleotide polymorphisms</strong> (<strong>SNPs</strong>) at scale for the prediction of the individual's ancestry with regards to continental and regional origins.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Machine learning for genetic variants</h1>
                </header>
            
            <article>
                
<p>Research has revealed that population groups from Asia, Europe, Africa, and America can be separated based on their genomic data. However, it is more challenging to accurately predict the haplogroup and the continent of origin, that is, geography, ethnicity, and language. Other research shows that the Y chromosome lineage can be geographically localized, forming the evidence for (geographically) clustering the human alleles of the human genotypes.</p>
<p>Thus, the clustering of individuals is correlated with geographic origin and ancestry. Since race depends on ancestry as well, the clusters are also correlated with the more traditional concepts of race, but the correlation is not perfect since genetic variation occurs according to probabilistic principles. Therefore, it does not follow a continuous distribution in different races and rather overlaps across or spills into different populations.</p>
<p>As a result, the identification of ancestry, or even race, may prove to be useful for biomedical reasons, but any direct assessment of disease-related genetic variation will ultimately yield more accurate and beneficial information.</p>
<p>The datasets provided by various genomics projects, such as <strong>The Cancer Genome Atlas</strong> (<strong>TCGA</strong>), <strong>International Cancer Genome Consortium (ICGC)</strong>, <strong>1000 Genomes Projects</strong>, and <strong>Personal Genome Project</strong> (<strong>PGP</strong>), dispose of large-scale data. For fast processing of such data, ADAM and Spark-based solutions have been proposed and are now widely used in genomics data analytics research.</p>
<p>Spark forms the most efficient data-processing framework and, in addition, provides primitives for in-memory cluster computing, for example, for querying the user data repeatedly. This makes Spark an excellent candidate for machine learning algorithms that outperform the Hadoop-based MapReduce framework. By using the genetic variants dataset from the 1000 Genomes project, we will try to answer the following questions:</p>
<ul>
<li>How is human genetic variation distributed geographically among different population groups?</li>
<li>Can we use the genomic profile of individuals to attribute them to specific populations or derive disease susceptibility from their nucleotide haplotype?</li>
<li>Is the individual's genomic data suitable to predict geographic origin (that is, the population group for an individual)?</li>
</ul>
<p>In this project, we addressed the preceding questions in a scalable and more efficient way. Particularly, we examined how we applied Spark and ADAM for large-scale data processing, H2O for K-means clustering of the whole population to determine inter- and intra-population groups, and MLP-based supervised learning by tuning more hyperparameters to more accurately predict the population group for an individual according to the individual's genomic data. Do not worry at this point; we will provide the technical details on working with these technologies in a later section.</p>
<p>However, before getting started, let's take a brief journey to the 1000 Genomes Project dataset to provide you with some justification on why interoperating these technologies is really important.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">1000 Genomes Projects dataset description</h1>
                </header>
            
            <article>
                
<p>The data from the 1000 Genomes project is a very large catalog of human genetic variants. The project aims to determine genetic variants with frequencies higher than 1% in the populations studied. The data has been made openly available and freely accessible through public data repositories to scientists worldwide. Also, the data from the 1000 Genomes project is widely used to screen variants discovered in exome data from individuals with genetic disorders and in cancer genome projects.</p>
<p>The genotype dataset in <strong>Variant Call Format</strong> (<strong>VCF</strong>) provides the data of human individuals (that is, samples) and their genetic variants, and in addition, the global allele frequencies as well as the ones for the super populations. The data denotes the population's region for each sample which is used for the predicted category in our approach. Specific chromosomal data (in VCF format) may have additional information denoting the super-population of the sample or the sequencing platform used. For multiallelic variants, each alternative <strong>allele frequency</strong> (<strong>AF</strong>) is presented in a comma-separated list, shown as follows:</p>
<pre><span class="MsoIntenseEmphasis">1 15211 rs78601809 T G 100 PASS AC=3050;</span><br/> <span class="MsoIntenseEmphasis">AF=0.609026;</span><br/> <span class="MsoIntenseEmphasis">AN=5008;</span><br/> <span class="MsoIntenseEmphasis">NS=2504;</span><br/> <span class="MsoIntenseEmphasis">DP=32245;</span><br/> <span class="MsoIntenseEmphasis">EAS_AF=0.504;</span><br/> <span class="MsoIntenseEmphasis">AMR_AF=0.6772;</span><br/> <span class="MsoIntenseEmphasis">AFR_AF=0.5371;</span><br/> <span class="MsoIntenseEmphasis">EUR_AF=0.7316;</span><br/> <span class="MsoIntenseEmphasis">SAS_AF=0.6401;</span><br/> <span class="MsoIntenseEmphasis">AA=t|||;</span><br/> <span class="MsoIntenseEmphasis">VT=SNP</span></pre>
<p>The AF is calculated as the quotient of <strong>Allele Count</strong> (<strong>AC</strong>) and <strong>Allele Number</strong> (<strong>AN</strong>) and NS is the total number of samples with data, whereas <kbd>_AF</kbd> denotes the AF for a specific region.</p>
<p>The 1000 Genomes Project started in 2008; the consortium consisted of more than 400 life scientists and phase 3 finished in September 2014 covering <kbd>2,504</kbd> individuals from 26 populations (that is, ethnic backgrounds) in total. In total, over 88 million variants (84.7 million <strong>single nucleotide polymorphisms</strong> (<strong>SNPs</strong>), 3.6 million short insertions/deletions (indels), and 60,000 structural variants) have been identified as high-quality haplotypes.</p>
<p>In short, 99.9% of the variants consist of SNPs and short indels. Less important variants—including SNPs, indels, deletions, complex short substitutions, and other structural variant classes—have been removed for quality control. As a result, the third phase release leaves 84.4 million variants.</p>
<p>Each of the 26 populations has about 60-100 individuals from Europe, Africa, America (South and North), and Asia (South and East). The population samples are grouped into super-population groups according to their predominant ancestry: East Asian (<strong>CHB</strong>, <strong>JPT</strong>, <strong>CHS</strong>, <strong>CDX</strong>, and <strong>KHV</strong>), European (<strong>CEU</strong>, <strong>TSI</strong>, <strong>FIN</strong>, <strong>GBR</strong>, and <strong>IBS</strong>), African (<strong>YRI</strong>, <strong>LWK</strong>, <strong>GWD</strong>, <strong>MSL</strong>, <strong>ESN</strong>, <strong>ASW</strong>, and <strong>ACB</strong>), American (<strong>MXL</strong>, <strong>PUR</strong>, <strong>CLM</strong>, and <strong>PEL</strong>), and South Asian (<strong>GIH</strong>, <strong>PJL</strong>, <strong>BEB</strong>, <strong>STU</strong>, and <strong>ITU</strong>). For details, refer to <em>Figure 1</em>:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/6c184827-d03e-4b8d-a33b-7a1084dbf66b.png"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 1: Geographic ethnic groups from 1000 Genomes project's release 3 (source http://www.internationalgenome.org/)</div>
<p>The released datasets provide the data for 2,504 healthy adults (18 years and older, third project phase); only reads with at least 70 <strong>base pairs</strong> (<strong>bp</strong>) have been used until more advanced solutions are available. All genomic data from all samples were combined to attribute all variants to a region. However, note that specific haplotypes may not occur in the genomes of a particular region; that is, the multi-sample approach allows attributing variants to an individual's genotype even if the variants are not covered by sequencing reads from that sample.</p>
<p>In other words, overlapping reads are provided and the single sample genomes have not necessarily been consolidated. All individuals were sequenced using both of these:</p>
<ul>
<li>Whole-genome sequencings (<em>mean depth = 7.4x</em>, where <em>x</em> is the number of reads, on average, that are likely to be aligned at a given reference <em>bp</em>)</li>
<li>Targeted exome sequencing (<em>mean depth = 65.7x</em>)</li>
</ul>
<p>In addition, individuals and their first-degree relatives such as an adult offspring were genotyped using high-density SNP microarrays. Each genotype comprises all 23 chromosomes and a separate panel file denotes the sample and population information. <em>Table 1</em> gives an overview of the different releases of the 1000 Genomes project:</p>
<p class="packt_figref CDPAlignLeft CDPAlign"><strong>Table 1 – Statistics of the 1000 Genomes project's genotype dataset</strong> <strong>(source:</strong> <a href="http://www.internationalgenome.org/data" target="_blank">http://www.internationalgenome.org/data</a><strong>)</strong></p>
<table class="MsoTableGrid">
<tbody>
<tr>
<td>
<p><strong>1000 genome release</strong></p>
</td>
<td>
<p><strong>Variants</strong></p>
</td>
<td>
<p><strong>Individual</strong></p>
</td>
<td>
<p><strong>Populations</strong></p>
</td>
<td>
<p><strong>File format</strong></p>
</td>
</tr>
<tr>
<td>
<p>Phase 3</p>
</td>
<td>
<p>Phase 3</p>
</td>
<td>
<p>2,504</p>
</td>
<td>
<p>26</p>
</td>
<td>
<p>VCF</p>
</td>
</tr>
<tr>
<td>
<p>Phase 1</p>
</td>
<td>
<p>37.9 million</p>
</td>
<td>
<p>1,092</p>
</td>
<td>
<p>14</p>
</td>
<td>
<p>VCF</p>
</td>
</tr>
<tr>
<td>
<p>Pilot</p>
</td>
<td>
<p>14.8 million</p>
</td>
<td>
<p>179</p>
</td>
<td>
<p>4</p>
</td>
<td>
<p>VCF</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>The AF in the five super-population groups, <strong>EAS=East Asian</strong>, <strong>EUR=European</strong>, <strong>AFR=African</strong>, <strong>AMR=American</strong>, <strong>SAS=South Asian</strong> populations are calculated from allele numbers (AN, range= [0, 1]).</p>
<div class="packt_tip"><span>See the details of the panel file at </span><a href="ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel">ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel</a><span>.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Algorithms, tools, and techniques</h1>
                </header>
            
            <article>
                
<p>Large-scale data from release 3 of the 1000 Genomes project contributes to 820 GB of data. Therefore, ADAM and Spark are used to pre-process and prepare the data (that is, training, testing, and validation sets) for the MLP and K-means models in a scalable way. Sparkling water transforms the data between H2O and Spark.</p>
<p>Then, K-means clustering, the MLP (using H2O) are trained. For the clustering and classification analysis, the genotypic information from each sample is required using the sample ID, variation ID, and the count of the alternate alleles where the majority of variants that we used were SNPs and indels.</p>
<p>Now, we should know the minimum info about each tool used such as ADAM, H2O, and some background information on the algorithms such as K-means, MLP for clustering, and classifying the population groups.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">H2O and Sparkling water</h1>
                </header>
            
            <article>
                
<p>H2O is an AI platform for machine learning. It offers a rich set of machine learning algorithms and a web-based data processing UI that comes as both open sources as well as commercial. Using H2O, it's possible to develop machine learning and DL applications with a wide range of languages, such as Java, Scala, Python, and R:</p>
<div class="CDPAlignCenter CDPAlign"><img height="414" width="728" src="assets/96b2598b-a253-48cd-8213-de1386bb9314.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 2: The H2O compute engine and available features (source: https://h20.ai/)</div>
<p>It also has the ability to interface with Spark, HDFS, SQL, and NoSQL databases. In short, H2O works with R, Python, and Scala on Hadoop/Yarn, Spark, or laptop. On the other hand, Sparkling water combines the fast, scalable ML algorithms of H2O with the capabilities of Spark. It drives the computation from Scala/R/Python and utilizes the H2O flow UI. In short, Sparkling <em>water = H2O + Spark</em>.</p>
<p>Throughout the next few chapters, we will explore and the wide rich features of H2O and Sparkling water; however, I believe it would be useful to provide a diagram of all of the functional areas that it covers:</p>
<div class="CDPAlignCenter CDPAlign"><img height="213" width="401" src="assets/dbb845b1-18f8-431e-97d1-195b6b8d84ca.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 3: A glimpse of available algorithms and the supported ETL techniques (source: https://h20.ai/)</div>
<p>This is a list of features and techniques curated from the H2O website. It can be used for wrangling data, modeling using the data, and scoring the resulting models:</p>
<ul>
<li>Process</li>
<li>Model</li>
<li>The scoring tool</li>
<li>Data profiling</li>
<li><strong>Generalized linear models</strong> (<strong>GLM</strong>)</li>
<li>Predict</li>
<li>Summary statistics</li>
<li>Decision trees</li>
<li>Confusion matrix</li>
<li>Aggregate, filter, bin, and derive columns</li>
<li><strong>Gradient boosting machine</strong> (<strong>GBM</strong>)</li>
<li>AUC</li>
<li>Slice, log transform, and anonymize</li>
<li>K-means</li>
<li>Hit ratio</li>
<li>Variable creation</li>
<li>Anomaly detection</li>
<li>PCA/PCA score</li>
<li><span>DL</span></li>
<li>Multimodel scoring</li>
<li>Training and validation sampling plan</li>
<li>Naive Bayes</li>
<li>Grid search</li>
</ul>
<p>The following figure shows how to provide a clear method of describing the way in which H2O Sparkling water can be used to extend the functionality of Apache Spark. Both H2O and Spark are open source systems. Spark MLlib contains a great deal of functionality, while H2O extends this with a wide range of extra functionalities, including <span>DL</span>. It offers tools to transform, model, and score the data, as we can find in Spark ML. It also offers a web-based user interface to interact with:</p>
<div class="CDPAlignCenter CDPAlign"><img height="282" width="501" src="assets/b10c6dbb-b830-491c-9d73-d0b27bdde21c.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 4: Sparkling water extends H2O and interoperates with Spark (source: https://h20.ai/)</div>
<p>The following figure shows how H2O integrates with Spark. As we already know, Spark has master and worker servers; the workers create executors to do the actual work. The following steps occur to run a Sparkling water-based application:</p>
<ul>
<li>Spark's submit command sends the Sparkling water JAR to the Spark master</li>
<li>The Spark master starts the workers and distributes the JAR file</li>
<li>The Spark workers start the executor JVMs to carry out the work</li>
<li>The Spark executor starts an H2O instance</li>
</ul>
<p>The H2O instance is embedded with the Executor JVM, and so it shares the JVM heap space with Spark. When all of the H2O instances have started, H2O forms a cluster, and then the H2O flow web interface is made available:</p>
<div class="CDPAlignCenter CDPAlign"><img height="347" width="577" src="assets/10b221b6-aa8f-4e8f-ab55-a9da2d90afc3.png"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 5: How Sparkling water fits into the Spark architecture (source: http://blog.cloudera.com/blog/2015/10/how-to-build-a-machine-learning-app-using-sparkling-water-and-apache-spark/)</div>
<p>The preceding figure explains how H2O fits into the Spark architecture and how it starts, but what about data sharing? Now the question would be: how does data pass between Spark and H2O? The following diagram explains this:</p>
<div class="CDPAlignCenter CDPAlign"><img height="293" width="556" src="assets/8b0ab4ad-f630-4cc0-aa39-d8253355e303.png"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 6: Data passing mechanism between Spark and H2O</div>
<p>To get a clearer view of the preceding figure, a new H2O RDD data structure has been created for H2O and Sparkling water. It is a layer based at the top of an H2O frame, each column of which represents a data item and is independently compressed to provide the best compression ratio.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">ADAM for large-scale genomics data processing</h1>
                </header>
            
            <article>
                
<p>Analyzing DNA and RNA sequencing data requires large-scale data processing to interpret the data according to its context. Excellent tools and solutions have been developed at academic labs, but often fall short on scalability and interoperability. <span class="col-11 text-gray-dark mr-2">By this means, ADAM is a genomics analysis platform with specialized file formats built using Apache Avro, Apache Spark and Parquet.</span></p>
<p>However, large-scale data processing solutions such as ADAM-Spark can be applied directly to the output data from a sequencing pipeline, that is, after quality control, mapping, read preprocessing, and variant quantification using single sample data. Some examples are DNA variants for DNA sequencing, read counts for RNA sequencing, and so on.</p>
<div class="packt_infobox">See more at <a href="http://bdgenomics.org/">http://bdgenomics.org/</a> and the related publication: Massie, Matt and Nothaft, Frank et al., ADAM: Genomics Formats and Processing Patterns for Cloud Scale Computing, UCB/EECS-2013-207, EECS Department, University of California, Berkeley.</div>
<p class="CDPAlignCenter CDPAlign CDPAlignLeft">In our study, ADAM is used to achieve the scalable genomics data analytics platform with support for the VCF file format so that we can transform genotype-based RDD into a Spark DataFrame.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Unsupervised machine learning</h1>
                </header>
            
            <article>
                
<p>Unsupervised learning is a type of machine learning algorithm used for grouping related data objects and finding hidden patterns by inferencing from unlabeled datasets—that is, training sets consisting of input data without labels.</p>
<p>Let's see a real-life example. Suppose you have a large collection of non-pirated and totally legal MP3 files in a crowded and massive folder on your hard drive. Now, what if you could build a predictive model that helps you automatically group together similar songs and organize them into your favorite categories, such as country, rap, and rock?</p>
<p>This is an act of assigning an item to a group so that an MP3 is added to the respective playlist in an unsupervised way. For classification, we assume that you are given a training dataset of correctly labeled data. Unfortunately, we do not always have that luxury when we collect data in the real world.</p>
<p>For example, suppose we would like to divide a huge collection of music into interesting playlists. How can we possibly group together songs if we do not have direct access to their metadata? One possible approach is a mixture of various ML techniques, but clustering is often at the heart of the solution:</p>
<div class="CDPAlignCenter CDPAlign"><img height="205" width="639" src="assets/dd15ee54-52ae-47a9-8dcf-646723794d3a.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7: Clustering data samples at a glance</div>
<p>In other words, the main objective of unsupervised learning algorithms is to explore unknown/hidden patterns in input data that is unlabeled. Unsupervised learning, however, also comprehends other techniques to explain the key features of the data in an exploratory way to find the hidden patterns. To overcome this challenge, clustering techniques are used widely to group unlabeled data points based on certain similarity measures in an unsupervised way.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Population genomics and clustering</h1>
                </header>
            
            <article>
                
<p>Clustering analysis is about dividing data samples or data points and putting them into corresponding homogeneous classes or clusters. Thus, a simple definition of clustering can be thought of as the process of organizing objects into groups whose members are similar in some way, as shown in.</p>
<p>This way, a cluster is a collection of objects that have some similarity between them and are dissimilar to the objects belonging to other clusters. If collections of genetic variants are given, clustering algorithms put these objects into a group based on similarity—that is, population groups or super-population groups.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How does K-means work?</h1>
                </header>
            
            <article>
                
<p>A clustering algorithm, such as K-means, locates the centroid of the group of data points. However, to make clustering accurate and effective, the algorithm evaluates the distance between each point from the centroid of the cluster.</p>
<p>Eventually, the goal of clustering is to determine intrinsic grouping in a set of unlabeled data. For example, the K-means algorithm tries to cluster related data points within the predefined <strong>three</strong> (that is, <em>k = 3</em>) clusters as shown in <em>Figure 8</em>:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="342" width="419" src="assets/e9b8ab25-2f24-4635-b875-9710eb439de4.png"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Figure 8: The results of a typical clustering algorithm and a representation of the cluster centers</div>
<p>In our case, using a combined approach of Spark, ADAM and H2O are capable of processing large amounts of variant data points. Suppose, we have n data points (x<sub>i</sub>, i=1, 2… n, example, genetic variants) that need to be partitioned into <span class="mi"><em>k</em></span> clusters. Then K-means assigns a cluster to each data point and aiming to find the positions <span class="mi"><em>μ<sub>i</sub></em></span><span class="mo">, </span><em><span class="mi">i</span><span class="mo">=</span><span class="mn">1...</span><span class="mi">k</span></em> of the clusters that minimize the distance from the data points to the cluster. Mathematically, K-means tries to achieve the goal by solving an equation—that is, an optimization problem:</p>
<div class="CDPAlignCenter CDPAlign"><img height="53" width="390" class="fm-editor-equation" src="assets/bb521b9d-0f9d-49ed-b2f7-e642e98ee905.png"/></div>
<p>In the preceding equation, <em>c<sub>i</sub></em> is the set of data points that assigned to cluster <em>i</em> and <em>d(x,μ<sub>i</sub>)=∥x−μ<sub>i</sub>∥<sub>2</sub><sup>2</sup></em> is the Euclidean distance to be calculated. The algorithm computes this distance between data points and the center of the k clusters by minimizing the <strong>Within-Cluster Sum of Squares</strong> (that is, <strong>WCSS</strong>), where <em>c<sub>i</sub></em> is the set of points belonging to cluster <em>i</em>.</p>
<p>Therefore, we can understand that the overall clustering operation using K-means is not a trivial one but an NP-hard optimization problem. Which also means that K-means algorithm not only tries to find the global minima but also often is stuck in different solutions. The K-means algorithm proceeds by alternating between two steps:</p>
<ul>
<li><strong>Cluster assignment step</strong>: Assign each observation to the cluster whose mean yields the least <strong>WCSS</strong>. The sum of squares is the squared Euclidean distance.</li>
<li><strong>Centroid update step</strong>: Calculate the new means to be the centroids of the observations in the new clusters.</li>
</ul>
<p>In a nutshell, the overall approach of K-means training can be described in following figure:</p>
<div class="CDPAlignCenter CDPAlign"><img height="302" width="537" src="assets/aab181a6-0476-41d9-822d-bb2c0feeab04.png"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 9: Overall approach of the K-means algorithm process</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">DNNs for geographic ethnicity prediction</h1>
                </header>
            
            <article>
                
<p><strong>Multilayer Perceptron</strong> (<strong>MLP</strong>) is an example of a DNN that is a feed-forward neural network; that is, there are only connections between the neurons from different layers. There is one (pass through) input layer, one or more layers of <strong>linear threshold units</strong> (<strong>LTUs</strong>) (called <strong>hidden layers</strong>), and one final layer of LTUs (called the <strong>output layer</strong>).</p>
<p>Each layer, excluding the output layer, involves a bias neuron and is fully connected to the next layer, forming a fully connected bipartite graph. The signal flows exclusively from the input to the output, that is, one-directional (<strong>feed-forward</strong>).</p>
<p>Until recently, an MLP was trained using the back-propagation training algorithm, but now the optimized version (that is, Gradient Descent) uses a reverse-mode auto diff; that is, the neural networks are trained with SGD using back-propagation as a gradient computing technique. Two layers of abstraction are used in DNN training for solving classification problems:</p>
<ul>
<li><strong>Gradient computation</strong>: Using back-propagation</li>
<li><strong>Optimization level</strong>: Using SGD, ADAM, RMSPro, and Momentum optimizers to compute the gradient computed earlier</li>
</ul>
<p>In each training cycle, the algorithm feeds the data into the network and computes the state and output for every neuron in the consecutive layers. The approach then measures the output error over the network, that is, the gap between the expected output and the current output, and the contribution from each neuron in the last hidden layer towards the neuron's output error.</p>
<p>Iteratively, the output error is propagated back to the input layer through all hidden layers and the error gradient is calculated across all connection weights during backward propagation:</p>
<div class="CDPAlignCenter CDPAlign"><img height="192" width="336" src="assets/a6998423-d881-4f26-a9e3-c868dc81c503.png"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 10: A modern MLP consisting of input layer, ReLU, and softmax</div>
<p>For a multiclass classification task, the output layer is typically determined by a shared softmax function (see <em>Figure 2</em> for more) in contrast to individual activation functions, and each output neuron provides the estimated probability for the corresponding class.</p>
<p>Additionally, we will be using tree ensembles such as random forest for the classification. At this moment, I believe we can skip the basic introduction of RF since we have covered it in detail in <a href="4b0be2d2-f313-471f-83fe-830931fc8af9.xhtml" target="_blank">Chapter 1</a>, <em>Analyzing Insurance Severity Claims</em>, <a href="4e196881-40c8-4eb9-b2b3-e332a49adc1a.xhtml" target="_blank">Chapter 2</a>, <em>Analyzing and Predicting Telecommunication Churn</em>, and <a href="51e66c26-e12b-4764-bbb7-444986c05870.xhtml" target="_blank">Chapter 3</a>, <em>High-Frequency Bitcoin Price Prediction from Historical Data</em>. Well, it is time for the being stared. Nonetheless, it is always good to have your programming environment ready before getting your hands dirty.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Configuring programming environment</h1>
                </header>
            
            <article>
                
<p>In this section, we describe how to configure our programming environment so that we can interoperate with Spark, H2O, and Adam. Note that using H2O on a laptop or desktop is quite resource intensive. Therefore, make sure that your laptop has at least 16 GB of RAM and enough storage.</p>
<p>Anyway, I am going to make this project a Maven project on Eclipse. However, you can try to define the same dependencies in SBT too. Let us define the properties tag on a <kbd>pom.xml</kbd> file for a Maven-friendly project:</p>
<pre>&lt;properties&gt;<br/>    &lt;spark.version&gt;2.2.1&lt;/spark.version&gt;<br/>    &lt;scala.version&gt;2.11.12&lt;/scala.version&gt;<br/>    &lt;h2o.version&gt;3.16.0.2&lt;/h2o.version&gt;<br/>    &lt;sparklingwater.version&gt;2.2.6&lt;/sparklingwater.version&gt;<br/>    &lt;adam.version&gt;0.23.0&lt;/adam.version&gt;<br/>&lt;/properties&gt;</pre>
<p>Then we can the latest version of the Spark 2.2.1 version (any 2.x version or even higher should work fine):</p>
<pre>&lt;dependency&gt;<br/>    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;<br/>    &lt;artifactId&gt;spark-core_2.11&lt;/artifactId&gt;<br/>    &lt;version&gt;${spark.version}&lt;/version&gt;<br/>&lt;/dependency&gt;</pre>
<p>Then we need to declare the dependencies for H2O and Sparkling water that match the version specified in the properties tag. Later versions might also work, and you can try:</p>
<pre>&lt;dependency&gt;<br/>    &lt;groupId&gt;ai.h2o&lt;/groupId&gt;<br/>    &lt;artifactId&gt;sparkling-water-core_2.11&lt;/artifactId&gt;<br/>    &lt;version&gt;2.2.6&lt;/version&gt;<br/>&lt;/dependency&gt;<br/>&lt;dependency&gt;<br/>    &lt;groupId&gt;ai.h2o&lt;/groupId&gt;<br/>    &lt;artifactId&gt;sparkling-water-examples_2.11&lt;/artifactId&gt;<br/>    &lt;version&gt;2.2.6&lt;/version&gt;<br/>&lt;/dependency&gt;<br/>&lt;dependency&gt;<br/>    &lt;groupId&gt;ai.h2o&lt;/groupId&gt;<br/>    &lt;artifactId&gt;h2o-core&lt;/artifactId&gt;<br/>    &lt;version&gt;${h2o.version}&lt;/version&gt;<br/>&lt;/dependency&gt;<br/>&lt;dependency&gt;<br/>    &lt;groupId&gt;ai.h2o&lt;/groupId&gt;<br/>    &lt;artifactId&gt;h2o-scala_2.11&lt;/artifactId&gt;<br/>    &lt;version&gt;${h2o.version}&lt;/version&gt;<br/>&lt;/dependency&gt;<br/>&lt;dependency&gt;<br/>    &lt;groupId&gt;ai.h2o&lt;/groupId&gt;<br/>    &lt;artifactId&gt;h2o-algos&lt;/artifactId&gt;<br/>    &lt;version&gt;${h2o.version}&lt;/version&gt;<br/>&lt;/dependency&gt;<br/>&lt;dependency&gt;<br/>    &lt;groupId&gt;ai.h2o&lt;/groupId&gt;<br/>    &lt;artifactId&gt;h2o-app&lt;/artifactId&gt;<br/>    &lt;version&gt;${h2o.version}&lt;/version&gt;<br/>&lt;/dependency&gt;<br/>&lt;dependency&gt;<br/>    &lt;groupId&gt;ai.h2o&lt;/groupId&gt;<br/>    &lt;artifactId&gt;h2o-persist-hdfs&lt;/artifactId&gt;<br/>    &lt;version&gt;${h2o.version}&lt;/version&gt;<br/>&lt;/dependency&gt;<br/>&lt;dependency&gt;<br/>    &lt;groupId&gt;ai.h2o&lt;/groupId&gt;<br/>    &lt;artifactId&gt;google-analytics-java&lt;/artifactId&gt;<br/>    &lt;version&gt;1.1.2-H2O-CUSTOM&lt;/version&gt;<br/>&lt;/dependency&gt;</pre>
<p>Finally, let's define ADAM and its dependencies:</p>
<pre>&lt;dependency&gt;<br/>    &lt;groupId&gt;org.bdgenomics.adam&lt;/groupId&gt;<br/>    &lt;artifactId&gt;adam-core_2.11&lt;/artifactId&gt;<br/>    &lt;version&gt;0.23.0&lt;/version&gt;<br/>&lt;/dependency&gt;</pre>
<p>When I tried this on a Windows machine, additionally I had to install <kbd>joda-time</kbd> dependencies. Let us do it (but depending your platform, it might not be needed):</p>
<pre>&lt;dependency&gt;<br/>    &lt;groupId&gt;joda-time&lt;/groupId&gt;<br/>    &lt;artifactId&gt;joda-time&lt;/artifactId&gt;<br/>    &lt;version&gt;2.9.9&lt;/version&gt;<br/>&lt;/dependency&gt;</pre>
<p>Once you create a Maven project in Eclipse (manually from the IDE or using <kbd>$ mvn install)</kbd>, all the required dependencies will be downloaded! We are ready to code now!</p>
<p>Wait! How about seeing the UI of H2O on the browser? For this, we have to manually download the H2O JAR somewhere in our computer and run it as a regular <kbd>.jar</kbd> file. In short, it's a three-way process:</p>
<ul>
<li>Download the <strong>Latest Stable Release</strong> H<sub>2</sub>O from <a href="https://www.h2o.ai/download/" target="_blank">https://www.h2o.ai/download/</a>. Then unzip it; it contains everything you need to get started.</li>
<li>From your terminal/command prompt, run the <kbd>.jar</kbd> using <kbd>java -jar h2o.jar</kbd>.</li>
<li>Point your browser to <kbd>http://localhost:54321</kbd>:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img height="373" width="397" src="assets/bbe1f494-edb7-4737-980a-1d485ebda72a.png"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 11: The UI of H2O FLOW</div>
<p>This shows the available features of the latest version (that is, h2o-3.16.0.4 as of 19 January 2018) of H2O. However, I am not going to explain everything here, so let's stop exploring because I believe for the time being this much knowledge about H2O and Sparking water will be enough.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data pre-processing and feature engineering</h1>
                </header>
            
            <article>
                
<p>I already stated that all the 24 VCF files contribute 820 GB of data. Therefore, I decided to use the genetic variant of chromosome Y only one two make the demonstration clearer. The size is around 160 MB, which is not meant to pose huge computational challenges. You can download all the VCF files as well as the panel file from <a href="ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/">ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/</a>.</p>
<p>Let us get started. We start by creating <kbd>SparkSession</kbd>, the gateway for the Spark application:</p>
<pre><strong>val</strong> spark:SparkSession = SparkSession<br/>    .builder()<br/>    .appName("PopStrat")<br/>    .master("local[*]")<br/>    .config("spark.sql.warehouse.dir", "C:/Exp/")<br/>    .getOrCreate()</pre>
<p>Then let's show Spark the path of both VCF and the panel file:</p>
<pre><strong>val</strong> genotypeFile = "&lt;path&gt;/ALL.chrY.phase3_integrated_v2a.20130502.genotypes.vcf"<br/><strong>val</strong> panelFile = "&lt;path&gt;/integrated_call_samples_v3.20130502.ALL.panel "</pre>
<p>We process the panel file using Spark to access the target population data and identify the population groups. We first create a set of the populations that we want to predict:</p>
<pre><strong>val</strong> populations = Set("FIN", "GBR", "ASW", "CHB", "CLM")</pre>
<p>Then we need to create a map of sample ID → population so that we can filter out the samples we are not interested in:</p>
<pre><strong>def</strong> extract(file: String,<br/>filter: (String, String) =&gt; Boolean): Map[String, String] = {<br/>Source<br/>    .fromFile(file)<br/>    .getLines()<br/>    .map(line =&gt; {<br/><strong>val</strong> tokens = line.split(Array('t', ' ')).toList<br/>tokens(0) -&gt; tokens(1)<br/>}).toMap.filter(tuple =&gt; filter(tuple._1, tuple._2))<br/>}<br/><br/><strong>val</strong> panel: Map[String, String] = extract(<br/>panelFile,<br/>(sampleID: String, pop: String) =&gt; populations.contains(pop))</pre>
<p>Note that the panel file produces the sample ID of all individuals, population groups, ethnicities, super population groups, and the genders shown as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img height="74" width="478" src="assets/ed1be322-c2e8-4982-a8f6-50c9546d37ef.png"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 12: Contents of a sample panel file</div>
<p>Then load the ADAM genotypes and filter the genotypes so that we're left with only those in the populations we're interested in:</p>
<pre><strong>val</strong> allGenotypes: RDD[Genotype] = sc.loadGenotypes(genotypeFile).rdd<br/><strong>val</strong> genotypes: RDD[Genotype] = allGenotypes.filter(genotype =&gt; {<br/>    panel.contains(genotype.getSampleId)<br/>    })</pre>
<p>The next job would be converting the <kbd>Genotype</kbd> objects into our own <kbd>SampleVariant</kbd> objects to try to conserve memory. Then, the <kbd>genotype</kbd> object is converted into a <kbd>SampleVariant</kbd> object that contains only the data we need for further processing: the sample ID, which uniquely identifies a particular sample; a variant ID, which uniquely identifies a particular genetic variant; and a count of alternate alleles (only when the sample differs from the reference genome).</p>
<p>The signature that prepares a sample variant is given here; it takes <kbd>sampleID</kbd>, <kbd>variationId</kbd>, and the <kbd>alternateCount</kbd>:</p>
<pre><strong>case </strong><strong>class</strong> SampleVariant(sampleId: String,<br/>        variantId: Int,<br/>        alternateCount: Int)</pre>
<p>Alright! Let us find <kbd>variantID</kbd> from the <kbd>genotype</kbd> file. A <kbd>varitantId</kbd> is a <kbd>String</kbd> type consisting of the name, start, and the end position in the chromosome:</p>
<pre><strong>def</strong> variantId(genotype: Genotype): String = {<br/><strong>    val</strong> name = genotype.getVariant.getContigName<br/><strong>    val</strong> start = genotype.getVariant.getStart<br/><strong>    val</strong> end = genotype.getVariant.getEnd<br/>s"$name:$start:$end"<br/>}</pre>
<p>Once we have the <kbd>variantID</kbd>, we should hunt for the alternate count. In the <kbd>genotype</kbd> file, the objects that do not have an allele reference are roughly genetic alternates:</p>
<pre><strong>def</strong> alternateCount(genotype: Genotype): Int = {<br/>      genotype.getAlleles.asScala.count(_ != GenotypeAllele.REF)<br/>   }</pre>
<p>Lastly, we construct a simple variant object. For this, we need to intern sample IDs as they will be repeated a lot in a VCF file:</p>
<pre><strong>def</strong> toVariant(genotype: Genotype): SampleVariant = {<br/><strong>    new</strong> SampleVariant(genotype.getSampleId.intern(),<br/>            variantId(genotype).hashCode(),<br/>            alternateCount(genotype))<br/>        }</pre>
<p>Excellent! We have been able to construct simple variants. Now, the next challenging task is to prepare <kbd>variantsRDD</kbd> before we are able to create the <kbd>variantsBySampleId</kbd> RDD:</p>
<pre><strong>val</strong> variantsRDD: RDD[SampleVariant] = genotypes.map(toVariant)</pre>
<p>Then we have to group the variants by sample ID so that we can process the variants sample by sample. After that, we can get the total number of samples to be used to find variants that are missing for some samples. Lastly, we have to group the variants by variant ID and filter out those variants that are missing from some samples:</p>
<pre><strong>val</strong> variantsBySampleId: RDD[(String, Iterable[SampleVariant])] =<br/>variantsRDD.groupBy(_.sampleId)<br/><br/><strong>val</strong> sampleCount: Long = variantsBySampleId.count()<br/>println("Found " + sampleCount + " samples")<br/><br/><strong>val</strong> variantsByVariantId: RDD[(Int, Iterable[SampleVariant])] =<br/>variantsRDD.groupBy(_.variantId).filter {<br/><strong>        case</strong> (_, sampleVariants) =&gt; sampleVariants.size == sampleCount<br/>    }</pre>
<p>Now let's make a map of variant ID → count of samples with an alternate count of greater than zero. Then we filter out those variants that are not in our desired frequency range. The objective here is simply to reduce the number of dimensions in the dataset to make it easier to train the model:</p>
<pre><strong>val</strong> variantFrequencies: collection.Map[Int, Int] = variantsByVariantId<br/>.map {<br/><strong>    case</strong> (variantId, sampleVariants) =&gt;<br/>        (variantId, sampleVariants.count(_.alternateCount &gt; 0))<br/>        }.collectAsMap()</pre>
<p>The total number of samples (or individuals) has been determined before grouping them based on their variant IDs and filtering out variants without support by the samples to simplify the data pre-processing and to better cope with the very large number of variants (in total 84.4 million).</p>
<p><em>Figure 13</em> shows a conceptual view of a genotype variants collection in the 1000 Genomes project and exposes the feature extraction process from the same data to train our K-means and MLP models:</p>
<div class="CDPAlignCenter CDPAlign"><img height="302" width="431" src="assets/5006da23-8d31-45d6-a5a6-dfeb88d14337.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Figure 13: Conceptual view of the genotype variants collection in the 1000 Genomes project</div>
<p>The specified range is arbitrary and was chosen because it includes a reasonable number of variants, but not too many. To be more specific, for each variant, the frequency for alternate alleles have been calculated, and variants with less than 12 alternate alleles have been excluded, leaving about 3 million variants in the analysis (for 23 chromosome files):</p>
<pre><strong>val</strong> permittedRange = inclusive(11, 11)<br/><strong>val</strong> filteredVariantsBySampleId: RDD[(String, Iterable[SampleVariant])] =<br/>    variantsBySampleId.map {<br/><strong>        case</strong> (sampleId, sampleVariants) =&gt;<br/><strong>        val</strong> filteredSampleVariants = sampleVariants.filter(<br/>        variant =&gt;<br/>        permittedRange.contains(<br/>        variantFrequencies.getOrElse(variant.variantId, -1)))<br/>    (sampleId, filteredSampleVariants)<br/>    }</pre>
<p>Once we has <kbd>filteredVariantsBySampleId</kbd>, the next task is to sort the variants for each sample ID. Each sample should now have the same number of sorted variants:</p>
<pre><strong>val</strong> sortedVariantsBySampleId: RDD[(String, Array[SampleVariant])] =<br/>    filteredVariantsBySampleId.map {<br/><strong>        case</strong> (sampleId, variants) =&gt;<br/>        (sampleId, variants.toArray.sortBy(_.variantId))<br/>        }<br/>    println(s"Sorted by Sample ID RDD: " + sortedVariantsBySampleId.first())</pre>
<p>All items in the RDD should now have the same variants in the same order. The final task is to use <kbd>sortedVariantsBySampleId</kbd> to construct an RDD of <kbd>Row</kbd> containing the region and the alternate count:</p>
<pre><strong>val</strong> rowRDD: RDD[Row] = sortedVariantsBySampleId.map {<br/><strong>    case</strong> (sampleId, sortedVariants) =&gt;<br/><strong>        val</strong> region: Array[String] = Array(panel.getOrElse(sampleId, "Unknown"))<br/><strong>        val</strong> alternateCounts: Array[Int] = sortedVariants.map(_.alternateCount)<br/>        Row.fromSeq(region ++ alternateCounts)<br/>        }</pre>
<p>Therefore, we can just use the first one to construct our header for the training data frame:</p>
<pre><strong>val</strong> header = StructType(<br/>        Seq(StructField("Region", StringType)) ++<br/>        sortedVariantsBySampleId<br/>            .first()<br/>            ._2<br/>            .map(variant =&gt; {<br/>                StructField(variant.variantId.toString, IntegerType)<br/>        }))</pre>
<p>Well done! Up to this point, we have our RDD and the header <kbd>StructType</kbd>. So now, we can play with both H2O and the Spark deep/machine learning algorithm with minimal adjustment/conversion. The overall flow of this end-to-end project can be seen in the following figure:</p>
<div class="CDPAlignCenter CDPAlign"><img height="276" width="682" src="assets/47f8c70a-7a52-495c-bbc2-afbab44c1ab1.png"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 14: The pipeline of the overall approach</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model training and hyperparameter tuning</h1>
                </header>
            
            <article>
                
<p>Once we have <kbd>rowRDD</kbd> and the header, the next task is to construct the rows of our Schema DataFrame from the variants using the header and <kbd>rowRDD</kbd>:</p>
<pre><strong>val</strong> sqlContext = spark.sqlContext<br/><strong>val</strong> schemaDF = sqlContext.createDataFrame(rowRDD, header)<br/>schemaDF.printSchema()<br/>schemaDF.show(10)<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="161" width="380" src="assets/9e459b56-504f-4465-a5c5-ebd78266d610.png"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 15: A snapshot of the training dataset containing features and the label (that is, Region) columns</div>
<p>In the preceding DataFrame, only a few columns, including the label, are shown so that it fits on the page.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Spark-based K-means for population-scale clustering</h1>
                </header>
            
            <article>
                
<p>In a previous section, we have seen how the K-means work. So we can directly dive into the implementation. Since the training will be unsupervised, we need to drop the label column (that is, <kbd>Region</kbd>):</p>
<pre><strong>val</strong> sqlContext = sparkSession.sqlContext<br/><strong>val</strong> schemaDF = sqlContext.createDataFrame(rowRDD, header).drop("Region")<br/>schemaDF.printSchema()<br/>schemaDF.show(10)<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img src="assets/34b50280-9728-4f15-8048-2b5e56d2f801.png"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 16: A snapshot of the training dataset for K-means without the label (that is, Region)</div>
<p>Now, we have seen in <a href="4b0be2d2-f313-471f-83fe-830931fc8af9.xhtml" target="_blank">Chapters 1</a>, <em>Analyzing Insurance Severity Claims</em> and <a href="4e196881-40c8-4eb9-b2b3-e332a49adc1a.xhtml" target="_blank">Chapter 2</a>, <em>Analyzing and Predicting Telecommunication Churn</em> that Spark expects two columns (that is, features and label) for supervised training, and for unsupervised training, it <span>expects</span> only a single column containing the features. Since we dropped the label column, we now need to amalgamate the entire variable column into a single <kbd>features</kbd> column. So for this, we will again use the <kbd>VectorAssembler()</kbd> transformer. At first, let's select the columns to be embedded into a vector space:</p>
<pre><strong>val</strong> featureCols = schemaDF.columns</pre>
<p>Then we instantiate the <kbd>VectorAssembler()</kbd> transformer, specifying the input columns and the output column:</p>
<pre><strong>val</strong> assembler = <br/><strong>new</strong> VectorAssembler()<br/>    .setInputCols(featureCols)<br/>    .setOutputCol("features")<br/><strong>val</strong> assembleDF = assembler.transform(schemaDF).select("features")</pre>
<p>Now let's see how it looks:</p>
<pre>assembleDF.show()<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="282" width="120" src="assets/a26cbeac-f5c1-423c-984d-1b5417fda8b5.png"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 17: A snapshot of the feature vectors for the K-means</div>
<p>Since our dataset is very highly dimensional, we can use some dimensionality algorithms such as PCA. So let's do it by instantiating a <kbd>PCA()</kbd> transformer as follows:</p>
<pre><strong>val</strong> pca = <br/><strong>new</strong> PCA()<br/>    .setInputCol("features")<br/>    .setOutputCol("pcaFeatures")<br/>    .setK(50)<br/>    .fit(assembleDF)</pre>
<p>Then we transform the assembled DataFrame (that is, assembled) and the top 50 principle components. You can adjust the number though. Finally, to avoid the ambiguity, we renamed the <kbd>pcaFeatures</kbd> <span>column </span><span>to</span> <kbd>features</kbd><span>:</span></p>
<pre><strong>val</strong> pcaDF = pca.transform(assembleDF)<br/>            .select("pcaFeatures")<br/>            .withColumnRenamed("pcaFeatures", "features")<br/>pcaDF.show()<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="331" width="145" src="assets/6b822396-5778-4322-9013-44a867bc6a2f.png"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 18: A snapshot of the top 50 principal components as the most important features</div>
<p>Excellent! Everything went smoothly. Finally, we are ready to train the K-means algorithm:</p>
<pre><strong>val</strong> kmeans = <br/><strong>new</strong> KMeans().setK(5).setSeed(12345L)<br/><strong>val</strong> model = kmeans.fit(pcaDF)</pre>
<p>So let's evaluate clustering by computing the <strong>Within-Set Sum of Squared Errors</strong> (<strong>WSSSE</strong>):</p>
<pre><strong>val</strong> WSSSE = model.computeCost(pcaDF)<br/>println("Within-Cluster Sum of Squares for k = 5 is" + WSSSE)<br/>&gt;&gt;&gt;</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Determining the number of optimal clusters</h1>
                </header>
            
            <article>
                
<p>The beauty of clustering algorithms such as K-means is that they do the clustering on the data with an unlimited number of features. They are great tools to use when you have raw data and would like to know the patterns in that data. However, deciding on the number of clusters prior doing the experiment might not be successful and may sometimes lead to an overfitting or underfitting problem.</p>
<p>On the other hand, one common thing to all three algorithms (that is, K-means, bisecting K-means, and Gaussian mixture) is that the number of clusters must be determined in advance and supplied to the algorithm as a parameter. Hence, informally, determining the number of clusters is a separate optimization problem to be solved.</p>
<p>Now we will use a heuristic approach based on the Elbow method. We start from K = 2 clusters, then we run the K-means algorithm for the same dataset by increasing K and observing the value of the cost function WCSS:</p>
<pre><strong>val</strong> iterations = 20<br/><strong>for</strong> (i &lt;- 2 to iterations) {<br/><strong>        val</strong> kmeans = <strong>new</strong> KMeans().setK(i).setSeed(12345L)<br/><strong>        val</strong> model = kmeans.fit(pcaDF)<br/><strong>        val</strong> WSSSE = model.computeCost(pcaDF)<br/>        println("Within-Cluster Sum of Squares for k = " + i + " is " +<br/>                WSSSE)<br/>    }</pre>
<p>At some point, a big drop in cost function can be observed, but then the improvement became marginal with the increasing value of <kbd>k</kbd>. As suggested in cluster analysis literature, we can pick the <kbd>k</kbd> after the last big drop of WCSS as an optimal one. Now, let's see the WCSS values for a different number of clusters between 2 and 20 for example:</p>
<pre>Within-Cluster Sum of Squares for k = 2 is 453.161838161838<br/>Within-Cluster Sum of Squares for k = 3 is 438.2392344497606<br/>Within-Cluster Sum of Squares for k = 4 is 390.2278787878787<br/>Within-Cluster Sum of Squares for k = 5 is 397.72112098427874<br/>Within-Cluster Sum of Squares for k = 6 is 367.8890909090908<br/>Within-Cluster Sum of Squares for k = 7 is 362.3360347662672<br/>Within-Cluster Sum of Squares for k = 8 is 347.49306362861336<br/>Within-Cluster Sum of Squares for k = 9 is 327.5002901103624<br/>Within-Cluster Sum of Squares for k = 10 is 327.29376873556436<br/>Within-Cluster Sum of Squares for k = 11 is 315.2954156954155<br/>Within-Cluster Sum of Squares for k = 12 is 320.2478696814693<br/>Within-Cluster Sum of Squares for k = 13 is 308.7674242424241<br/>Within-Cluster Sum of Squares for k = 14 is 314.64784054938576<br/>Within-Cluster Sum of Squares for k = 15 is 297.38523698523704<br/>Within-Cluster Sum of Squares for k = 16 is 294.26114718614707<br/>Within-Cluster Sum of Squares for k = 17 is 284.34890572390555<br/>Within-Cluster Sum of Squares for k = 18 is 280.35662525879917<br/>Within-Cluster Sum of Squares for k = 19 is 272.765762015762<br/>Within-Cluster Sum of Squares for k = 20 is 272.05702362771336</pre>
<p>Now let us discuss how to take advantage of the Elbow method for determining the number of clusters. As shown next, we calculated the cost function, WCSS, as a function of a number of clusters for the K-means algorithm applied to Y chromosome genetic variants from the selected population groups.</p>
<p>It can be observed that a somewhat <strong>big drop</strong> occurs when <kbd>k = 9</kbd> (which is not a drastic drop though). Therefore, we choose the number of clusters to be 10, as shown in <em>Figure 10</em>:</p>
<div class="CDPAlignCenter CDPAlign"><img height="330" width="440" src="assets/4260d5c6-46f4-4302-9948-ab8cbd4190b8.png"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 19: Number of clusters as a function of WCSS</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using H2O for ethnicity prediction</h1>
                </header>
            
            <article>
                
<p>Up to this point, we have seen how to cluster genetic variants. We have also used the Elbow method and found the number of optimal <kbd>k</kbd>, the tentative number cluster. Now we should explore another task that we planned at the beginning—that is, ethnicity prediction.</p>
<p>In the previous K-means section, we prepared a Spark DataFrame named <kbd>schemaDF</kbd>. That one cannot be used with H2O. However, an additional conversion is necessary. We use the <kbd>asH2OFrame()</kbd> method to convert the Spark DataFrame into an H2O frame:</p>
<pre><strong>val</strong> dataFrame = h2oContext.asH2OFrame(schemaDF)</pre>
<p>Now, one important thing you should remember while using H2O is that if you do not convert the label column into categorical, it will treat the classification task as regression. To get rid of this, we can use the <kbd>toCategoricalVec()</kbd> method from H2O. Since H2O frames are resilient, we can further update the same frame:</p>
<pre>dataFrame.replace(dataFrame.find("Region"),<br/>dataFrame.vec("Region").toCategoricalVec()).remove()<br/>dataFrame.update()</pre>
<p>Now our H2O frame is ready to train an H2O-based DL model (which is DNN, or to be more specific, a deep MLP). However, before we start the training, let's randomly split the DataFrame into 60% training, 20% test, and 20% validation data using the H2O built-in <kbd>FrameSplitter()</kbd> method:</p>
<pre><strong>val</strong> frameSplitter = <strong>new</strong> FrameSplitter(<br/>        dataFrame, Array(.8, .1), Array("training", "test", "validation")<br/>        .map(Key.make[Frame]),<strong>null</strong>)<br/><br/>water.H2O.submitTask(frameSplitter)<br/><strong>val</strong> splits = frameSplitter.getResult<br/><strong>val</strong> training = splits(0)<br/><strong>val</strong> test = splits(1)<br/><strong>val</strong> validation = splits(2)</pre>
<p>Fantastic! Our train, test, and validation sets are ready, so let us set the parameters for our <span>DL</span> model:</p>
<pre>// Set the parameters for our deep learning model.<br/><strong>val</strong> deepLearningParameters = <strong>new</strong> DeepLearningParameters()<br/>        deepLearningParameters._train = training<br/>        deepLearningParameters._valid = validation<br/>        deepLearningParameters._response_column = "Region"<br/>        deepLearningParameters._epochs = 200<br/>        deepLearningParameters._l1 = 0.01<br/>        deepLearningParameters._seed = 1234567<br/>        deepLearningParameters._activation = Activation.RectifierWithDropout<br/>        deepLearningParameters._hidden = Array[Int](128, 256, 512)</pre>
<p>In the preceding setting, we have specified an MLP having three hidden layers with 128, 256 and 512 neurons respectively. So altogether, there are five layers including the input and the output layer. The training will iterate up to 200 epoch. Since we have used too many neurons in the hidden layer, we should use the dropout to avoid overfitting. To avoid achieve a better regularization, we used the l1 regularization.</p>
<p>The preceding setting also states that we will train the model using the training set, and additionally the validation set will be used to validate the training. Finally, the response column is <kbd>Region</kbd>. On the other hand, the seed is used to ensure reproducibility.</p>
<p>So all set! Now let's train the <span>DL</span> model:</p>
<pre><strong>val</strong> deepLearning = <strong>new</strong> DeepLearning(deepLearningParameters)<br/><strong>val</strong> deepLearningTrained = deepLearning.trainModel<br/><strong>val</strong> trainedModel = deepLearningTrained.get</pre>
<p>Depending on your hardware configuration, it might take a while. Therefore, it is time to  rest and get some coffee maybe! Once we have the trained model, we can see the training error:</p>
<pre><strong>val</strong> error = trainedModel.classification_error()<br/>println("Training Error: " + error)<br/>&gt;&gt;&gt;<br/>Training Error: 0.5238095238095238</pre>
<p>Unfortunately, the training was not that great! Nevertheless, we should try with different combination of hyperparameters. The error turns out to be high though, but let us not worry too much and evaluate the model, compute some model metrics, and evaluate model quality:</p>
<pre><strong>val</strong> trainMetrics = ModelMetricsSupport.modelMetrics[ModelMetricsMultinomial](trainedModel, test)<br/><strong>val</strong> met = trainMetrics.cm()<br/><br/>println("Accuracy: "+ met.accuracy())<br/>println("MSE: "+ trainMetrics.mse)<br/>println("RMSE: "+ trainMetrics.rmse)<br/>println("R2: " + trainMetrics.r2)<br/>&gt;&gt;&gt;<br/>Accuracy: 0.42105263157894735<br/>MSE: 0.49369297490740655<br/>RMSE: 0.7026328877211816<br/>R2: 0.6091597281983032</pre>
<p>Not so high accuracy! However, you should try with other VCF files and by tuning the hyperparameters too. For example, after reducing the neurons in the hidden layers and with l2 regularization and 100 epochs, I had about 20% improvement:</p>
<pre><strong>val</strong> deepLearningParameters = <strong>new</strong> DeepLearningParameters()<br/>        deepLearningParameters._train = training<br/>        deepLearningParameters._valid = validation<br/>        deepLearningParameters._response_column = "Region"<br/>        deepLearningParameters._epochs = 100<br/>        deepLearningParameters._l2 = 0.01<br/>        deepLearningParameters._seed = 1234567<br/>        deepLearningParameters._activation = Activation.RectifierWithDropout<br/>        deepLearningParameters._hidden = Array[Int](32, 64, 128)<br/>&gt;&gt;&gt;<br/>Training Error: 0.47619047619047616<br/>Accuracy: 0.5263157894736843<br/>MSE: 0.39112548936806274<br/>RMSE: 0.6254002633258662<br/>R2: 0.690358987583617</pre>
<p>Another improvement clue is here. Apart from these hyperparameters, another advantage of using H2O-based <span>DL</span> algorithms is that we can take the relative variable/feature importance. In previous chapters, we have seen that when using a Random Forest algorithm in Spark, it is also possible to compute the variable importance.</p>
<p>Therefore, the idea is that if your model does not perform well, it would be worth dropping less important features and doing the training again. Now, it is possible to find the feature importance during supervised training. I have observed this feature importance:</p>
<div class="CDPAlignCenter CDPAlign"><img height="268" width="466" src="assets/ba65fb17-4d3b-43ad-ae89-0b2780157865.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 20: Relative feature importance using H2O</div>
<p>Now the question would be why don't you drop them and try training again and observe if the accuracy has increased or not? Well, I leave it up to the readers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using random forest for ethnicity prediction</h1>
                </header>
            
            <article>
                
<p>In the previous section, we have seen how to use H2O for ethnicity prediction. However, we could not achieve better prediction accuracy. Therefore, H2O is not mature enough to compute all the necessary performance metrics.</p>
<p>So why don't we try Spark-based tree ensemble techniques such as Random Forest or GBTs? Because we have seen that in most cases, RF shows better predictive accuracy, so let us try with that one.</p>
<p>In the K-means section, we've already prepared the Spark DataFrame named <kbd>schemaDF</kbd>. Therefore, we can simply transform the variables into feature vectors that we described before. Nevertheless, for this, we need to exclude the label column. We can do it using the <kbd>drop()</kbd> method as follows:</p>
<pre><strong>val</strong> featureCols = schemaDF.columns.drop(1)<br/><strong>val</strong> assembler = <br/><strong>new</strong> VectorAssembler()<br/>    .setInputCols(featureCols)<br/>    .setOutputCol("features")<br/><strong>val</strong> assembleDF = assembler.transform(schemaDF).select("features", "Region")<br/>assembleDF.show()</pre>
<p>At this point, you can further reduce the dimensionality and extract the most principal components using PCA or any other feature selector algorithm. However, I will leave it up to you. Since Spark expects the label column to be numeric, we have to convert the ethnic group name into numeric. We can use <kbd>StringIndexer()</kbd> for this. It is straightforward:</p>
<pre><strong>val</strong> indexer = <br/><strong>new</strong> StringIndexer()<br/>    .setInputCol("Region")<br/>    .setOutputCol("label")<br/><br/><strong>val</strong> indexedDF =  indexer.fit(assembleDF)<br/>                .transform(assembleDF)<br/>                .select("features", "label") </pre>
<p>Then we randomly split the dataset for training and testing. In our case, let's use 75% for the training and the rest for the testing:</p>
<pre><strong>val</strong> seed = 12345L<br/><strong>val</strong> splits = indexedDF.randomSplit(Array(0.75, 0.25), seed)<br/><strong>val</strong> (trainDF, testDF) = (splits(0), splits(1))</pre>
<p>Since this this a small dataset, considering this fact, we can <kbd>cache</kbd> both the train and test set for faster access:</p>
<pre>trainDF.cache<br/>testDF.cache<br/><strong>val</strong> rf = <strong>new</strong> RandomForestClassifier()<br/>    .setLabelCol("label")<br/>    .setFeaturesCol("features")<br/>    .setSeed(1234567L)</pre>
<p>Now let's create a <kbd>paramGrid</kbd> for searching through decision tree's <kbd>maxDepth</kbd> parameter for the best model:</p>
<pre><strong>val</strong> paramGrid =<br/><strong>new</strong> ParamGridBuilder()<br/>    .addGrid(rf.maxDepth, 3 :: 5 :: 15 :: 20 :: 25 :: 30 :: Nil)<br/>    .addGrid(rf.featureSubsetStrategy, "auto" :: "all" :: Nil)<br/>    .addGrid(rf.impurity, "gini" :: "entropy" :: Nil)<br/>    .addGrid(rf.maxBins, 3 :: 5 :: 10 :: 15 :: 25 :: 35 :: 45 :: Nil)<br/>    .addGrid(rf.numTrees, 5 :: 10 :: 15 :: 20 :: 30 :: Nil)<br/>    .build()<br/><br/><strong>val</strong> evaluator = <strong>new</strong> MulticlassClassificationEvaluator()<br/>    .setLabelCol("label")<br/>    .setPredictionCol("prediction")</pre>
<p>Then we set up the 10-fold cross validation for an optimized and stable model. This will reduce the chances of overfitting:</p>
<pre><strong>val</strong> numFolds = 10<br/><strong>val</strong> crossval = <br/><strong>new</strong> CrossValidator()<br/>    .setEstimator(rf)<br/>    .setEvaluator(evaluator)<br/>    .setEstimatorParamMaps(paramGrid)<br/>    .setNumFolds(numFolds)</pre>
<p>Well, now we are ready for the training. So let's train the random forest model with the best hyperparameters setting:</p>
<pre><strong>val</strong> cvModel = crossval.fit(trainDF)</pre>
<p>Now that we have the cross-validated and the best model, why don't we evaluate the model using the test set. Why not? First, we compute the prediction DataFrame for each instance. Then we use the <kbd>MulticlassClassificationEvaluator()</kbd> to evaluate the performance since this is a multiclass classification problem.</p>
<p>Additionally, we compute performance metrics such as <kbd>accuracy</kbd>, <kbd>precision</kbd>, <kbd>recall</kbd>, and <kbd>f1</kbd> measure. Note that using RF classifier, we can get <kbd>weightedPrecision</kbd> and the <kbd>weightedRecall</kbd>:</p>
<pre><strong>val</strong> predictions = cvModel.transform(testDF)<br/>predictions.show(10)<br/>&gt;&gt;&gt;</pre>
<div class="CDPAlignCenter CDPAlign"><img height="203" width="489" src="assets/40c0900b-2076-47ed-beb4-0bdc16c67382.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 21: Raw prediction probability, true label, and the predicted label using random forest</div>
<pre><strong>val</strong> metric = <br/><strong>new</strong> MulticlassClassificationEvaluator()<br/>    .setLabelCol("label")<br/>    .setPredictionCol("prediction")<br/><br/><strong>val</strong> evaluator1 = metric.setMetricName("accuracy")<br/><strong>val</strong> evaluator2 = metric.setMetricName("weightedPrecision")<br/><strong>val</strong> evaluator3 = metric.setMetricName("weightedRecall")<br/><strong>val</strong> evaluator4 = metric.setMetricName("f1")</pre>
<p>Now let's compute the classification <kbd>accuracy</kbd>, <kbd>precision</kbd>, <kbd>recall</kbd>, <kbd>f1</kbd> measure and error on test data:</p>
<pre><strong>val</strong> accuracy = evaluator1.evaluate(predictions)<br/><strong>val</strong> precision = evaluator2.evaluate(predictions)<br/><strong>val</strong> recall = evaluator3.evaluate(predictions)<br/><strong>val</strong> f1 = evaluator4.evaluate(predictions)</pre>
<p>Finally, we print the performance metrics:</p>
<pre>println("Accuracy = " + accuracy);<br/>println("Precision = " + precision)<br/>println("Recall = " + recall)<br/>println("F1 = " + f1)<br/>println(s"Test Error = ${1 - accuracy}")<br/>&gt;&gt;&gt;<br/>Accuracy = 0.7196470196470195<br/>Precision = 0.7196470196470195<br/>Recall = 0.7196470196470195<br/>F1 = 0.7196470196470195<br/>Test Error = 0.28035298035298046</pre>
<p>Yes, it turns out to be a better performer. This is bit unexpected since we hoped to have better predictive accuracy from a <span>DL</span> model, but we did not. As I already stated, we can still try with other parameters of H2O. Anyway, we can now see around 25% improvement using random forest. However, probably, it can still be improved.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we saw how to interoperate with a few big data tools such as Spark, H2O, and ADAM for handling a large-scale genomics dataset. We applied the Spark-based K-means algorithm to genetic variants data from the 1000 Genomes project analysis, aiming to cluster genotypic variants at the population scale.</p>
<p>Then we applied an H2O-based <span>DL</span> algorithm and Spark-based Random Forest models to predict geographic ethnicity. Additionally, we learned how to install and configure H2O for <span>DL</span>. This knowledge will be used in later chapters. Finally and importantly, we learned how to use H2O to compute variable importance in order to select the most important features in a training set.</p>
<p>In the next chapter, we will see how effectively we can use the <strong>Latent Dirichlet Allocation</strong> (<strong>LDA</strong>) algorithm for finding useful patterns in data. We will compare other topic modeling algorithms and the scalability power of LDA. In addition, we will utilize <strong>Natural Language Processing</strong> (<strong>NLP</strong>) libraries such as Stanford NLP.</p>


            </article>

            
        </section>
    </body></html>