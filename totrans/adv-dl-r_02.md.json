["```py\n# Information from a Keras R session\nsessionInfo()\n\nR version 3.6.0 (2019-04-26)\nPlatform: x86_64-apple-darwin15.6.0 (64-bit)\nRunning under: macOS 10.15\n\nMatrix products: default\nBLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib\n\nRandom number generation:\n RNG: Mersenne-Twister \n Normal: Inversion \n Sample: Rounding \n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats graphics grDevices utils datasets methods base\n\nother attached packages:\n[1] keras_2.2.4.1\n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.2 lattice_0.20-38 lubridate_1.7.4 zeallot_0.1.0 \n [5] grid_3.6.0 R6_2.4.0 jsonlite_1.6 magrittr_1.5 \n [9] tfruns_1.4 stringi_1.4.3 whisker_0.4 Matrix_1.2-17 \n[13] reticulate_1.13 generics_0.0.2 tools_3.6.0 stringr_1.4.0 \n[17] compiler_3.6.0 base64enc_0.1-3 tensorflow_1.14.0\n```", "```py\n# Model architecture\nmodel <- keras_model_sequential()\n model %>% \n layer_dense(units = 8, activation = 'relu', input_shape = c(21)) %>% \n layer_dense(units = 3, activation = 'softmax')\n```", "```py\n# RELU function and related plot\nx <- rnorm(10000, 2, 10)\ny <- ifelse(x<0, 0, x)\npar(mfrow = c(1,2))\nhist(x)\nplot(x,y)\n```", "```py\n# Softmax function and related plot\nx <- runif(1000, 1, 5)\ny <- exp(x)/sum(exp(x))\npar(mfrow=c(1,2))\nhist(x)\nplot(x,y)\n```", "```py\nmodel %>% \n   compile(loss = 'binary_crossentropy', \n   optimizer = 'adam',\n   metrics = 'accuracy')\n```", "```py\n# Example-1\ny <- c(0, 0, 0, 1, 1, 1)\nyhat <- c(0.2, 0.3, 0.1, 0.8, 0.9, 0.7)\n(loss <- - y*log(yhat) - (1-y)*log(1-yhat))\n\n[1] 0.2231436 0.3566749 0.1053605 0.2231436 0.1053605 0.3566749\n\nmean(loss)\n\n[1] 0.228393\n\n# Example-2\nyhat <- c(0.2, 0.9, 0.1, 0.8, 0.9, 0.2)\n(loss <- - y*log(yhat) - (1-y)*log(1-yhat))\n\n[1] 0.2231436 2.3025851 0.1053605 0.2231436 0.1053605 1.6094379\n\nmean(loss)\n\n[1] 0.761505\n```", "```py\nmodel %>%   \n fit(training, \n   trainLabels, \n   epochs = 200,\n   batch_size = 32, \n   validation_split = 0.2)\n```", "```py\n# Save/reload model\nsave_model_hdf5(model, \n filepath, \n overwrite = TRUE,\n include_optimizer = TRUE)\nmodel_x <- load_model_hdf5(filepath, \n custom_objects = NULL, \n compile = TRUE)\n```"]