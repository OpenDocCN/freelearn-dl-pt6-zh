["```py\n<properties>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n        <java.version>1.8</java.version>\n        <jdk.version>1.8</jdk.version>\n        <nd4j.backend>nd4j-cuda-9.0-platform</nd4j.backend>\n        <nd4j.version>1.0.0-alpha</nd4j.version>\n        <dl4j.version>1.0.0-alpha</dl4j.version>\n        <datavec.version>1.0.0-alpha</datavec.version>\n        <arbiter.version>1.0.0-alpha</arbiter.version>\n        <logback.version>1.2.3</logback.version>\n</properties>\n```", "```py\n<dependency>\n     <groupId>org.nd4j</groupId>\n     <artifactId>nd4j-cuda-9.0-platform</artifactId>\n     <version>${nd4j.version}</version>\n</dependency>\n<dependency>\n      <groupId>org.deeplearning4j</groupId>\n      <artifactId>deeplearning4j-cuda-9.0</artifactId>\n      <version>${dl4j.version}</version>\n</dependency>\n```", "```py\n// ParallelWrapper will take care of load balancing between GPUs. ParallelWrapper wrapper = new ParallelWrapper.Builder(YourExistingModel)\n     .prefetchBuffer(24)\n     .workers(8)\n     .averagingFrequency(1)\n     .reportScoreAfterAveraging(true)\n     .useLegacyAveraging(false)\n     .build();\n```", "```py\nParallelWrapper wrapper = new ParallelWrapper.Builder(net)            \n            .prefetchBuffer(8)// DataSets prefetching options. Set to number of actual devices\n            .workers(8)// set number of workers equal to number of available devices \n            .averagingFrequency(3)// rare averaging improves performance, but reduce accuracy           \n            .reportScoreAfterAveraging(true) // if set TRUE, on every averaging model's score reported\n            .build();\n```", "```py\n<dependency>\n      <groupId>org.deeplearning4j</groupId>\n      <artifactId>deeplearning4j-parallel-wrapper_2.11</artifactId>\n      <version>${dl4j.version}</version>\n</dependency>\n```", "```py\n<dependency>\n       <groupId>org.bytedeco</groupId>\n       <artifactId>javacv-platform</artifactId>\n       <version>1.4.1</version>\n</dependency>\n```", "```py\nimport os\n\nROOT = os.path.dirname(os.path.abspath(__file__))\nDATA = os.path.join(ROOT, 'VideoData')\nUCF_RAW = os.path.join(ROOT, 'VideoData', 'UCF101')\nUCF_MP4 = os.path.join(ROOT, 'VideoData', 'UCF101_MP4')\n\nif not os.path.isdir(UCF_MP4):\n    print(\"Start converting UCF101 dataset to MP4...\")\n    filepaths = []\n\n    for label_dir in os.listdir(os.path.join(UCF_RAW)):\n        for file in os.listdir(os.path.join(UCF_RAW, label_dir)):\n            filepath = (UCF_RAW, label_dir, file)\n            filepaths.append(filepath)\n    files_len = len(filepaths)\n    os.mkdir(UCF_MP4)\n\n    for i, (_, label_dir, file_avi) in enumerate(filepaths):\n        if file_avi.endswith('.avi'):\n            file_mp4 = file_avi.rstrip('.avi') + '.mp4'\n            input_filepath = os.path.join(UCF_RAW, label_dir, file_avi)\n            output_filepath = os.path.join(UCF_MP4, label_dir, file_mp4)\n\n            if not os.path.isfile(output_filepath):\n                output_dir = os.path.join(UCF_MP4, label_dir)\n                if not os.path.isdir(output_dir):\n                    os.mkdir(output_dir)\n                os.system('ffmpeg -v error -i %s -strict -2 %s' % (input_filepath, output_filepath))\n        print(\"%d of %d files converted\" % (i+1, files_len))\nprint(\"Dataset ready\")\n```", "```py\npublic UCF101Reader(String dataDirectory) {\n        this.dataDirectory = dataDirectory.endsWith(\"/\") ? dataDirectory : dataDirectory + \"/\";\n          }\n\npublic DataSetIterator getDataSetIterator(int startIdx, int nExamples, int miniBatchSize) throws Exception {\n    ExistingDataSetIterator iter = new ExistingDataSetIterator(createDataSetIterable(startIdx, \n                                                               nExamples, miniBatchSize));\n        return new AsyncDataSetIterator(iter,1);\n    }\n```", "```py\nprivate UCF101RecordIterable createDataSetIterable(int startIdx, int nExamples, int miniBatchSize) \n                                                   throws IOException {\n        return new UCF101RecordIterable(dataDirectory, labelMap(), V_WIDTH, V_HEIGHT,startIdx, nExamples);\n                  }\n```", "```py\npublic static final int V_WIDTH = 320;\npublic static final int V_HEIGHT = 240;\npublic static final int V_NFRAMES = 100;\nprivate final String dataDirectory;\nprivate volatile Map<Integer, String> _labelMap;\n```", "```py\npublic Map<Integer, String> labelMap() throws IOException {\n        if(_labelMap == null) {\n            synchronized (this) {\n                if(_labelMap == null) {\n                    File root = new File(dataDirectory);\n                    _labelMap = Files.list(root.toPath()).map(f -> f.getFileName().toString())\n                            .sorted().collect(HashMap::new, (h, f) -> h.put(h.size(), f), (h, o) -> {});\n                }\n            }\n        }\n        return _labelMap;\n    }\n```", "```py\n// The @NotNull Annotation ensures iterator() method des not return null.\n@NotNull\n@Override\npublic Iterator<DataSet> iterator() {\n        return rowsStream(dataDirectory).skip(this.skip).limit(this.limit).flatMap(p -> \n               dataSetsStreamFromFile(p.getKey(), p.getValue())).iterator();\n    }\n```", "```py\npublic static Stream<Pair<Path, String>> rowsStream(String dataDirectory) {\n        try {\n            List<Pair<Path, String>> files = Files.list(Paths.get(dataDirectory)).flatMap(dir -> {\n                try {\n                    return Files.list(dir).map(p -> Pair.of(p, dir.getFileName().toString()));\n                } catch (IOException e) {\n                    e.printStackTrace();\n                    return Stream.empty();\n                }\n            }).collect(Collectors.toList());\n            Collections.shuffle(files, new Random(43));\n            return files.stream();\n        } catch (IOException e) {\n            e.printStackTrace();\n            return Stream.empty();\n        }\n    }\n```", "```py\nprivate Stream<DataSet> dataSetsStreamFromFile(Path path, String label) {\n        return StreamSupport.stream(Spliterators.spliteratorUnknownSize(dataSetsIteratorFromFile(path, \n                                    label), Spliterator.ORDERED), false);\n    }\n```", "```py\nprivate Iterator<DataSet> dataSetsIteratorFromFile(Path path, String label) {\n        FileChannelWrapper _in = null;\n        try {\n            _in = NIOUtils.readableChannel(path.toFile());\n            MP4Demuxer d1 = MP4Demuxer.createMP4Demuxer(_in);\n            SeekableDemuxerTrack videoTrack_ = (SeekableDemuxerTrack)d1.getVideoTrack();\n            FrameGrab fg = new FrameGrab(videoTrack_, new AVCMP4Adaptor(videoTrack_.getMeta()));\n\n            final int framesTotal = videoTrack_.getMeta().getTotalFrames();\n            return Collections.singleton(recordReaderMultiDataSetIterator.nextDataSet(_in, framesTotal, \n                  fg, labelMapInversed.get(label), labelMap.size())).iterator();\n        } catch(IOException | JCodecException e) {\n            e.printStackTrace();\n            return Collections.emptyIterator();\n        }\n    }\n```", "```py\nprivate INDArray labelToNdArray(String label) {\n int maxTSLength = 1; // frames per dataset\n int labelVal = labelMapInversed.get(label);\n          INDArray arr = Nd4j.*create*(new int[]{1, classesCount}, 'f');\n          arr.put(0, labelVal, 1f);\n return arr;\n}\n```", "```py\nprivate void testReadFrame(Consumer<Picture> consumer) throws IOException, JCodecException {\n        // Read the clip sequentially one by one\n        next:\n        for(Iterator<Pair<Path, String>> iter = rowsStream().iterator(); iter.hasNext(); ) {\n            Pair<Path, String> pair = iter.next();\n            Path path = pair.getKey();\n            pair.getValue();\n\n            for(int i = 0; i < 100; i++) {\n                try {\n                    // Hold video frames as pictures\n                    Picture picture = FrameGrab.getFrameFromFile(path.toFile(), i);\n                    consumer.accept(picture);\n                } catch (Throwable ex) {\n                    System.out.println(ex.toString() + \" frame \" + i + \" \" + path.toString());\n                    continue next;\n                }\n            }\n            System.out.println(\"OK \" + path.toString());\n        }\n    }\n```", "```py\nprivate Stream<Pair<Path, String>> rowsStream() {\n        try {\n            return Files.list(Paths.get(dataDirectory)).flatMap(dir -> {\n                try {\n                    return Files.list(dir).map(p -> Pair.of(p, dir.getFileName().toString()));\n                } catch (IOException e) {\n                    e.printStackTrace();\n                    return Stream.empty();\n                }\n            });\n        } catch (IOException e) {\n            e.printStackTrace();\n            return Stream.empty();\n        }\n    }\n```", "```py\nprivate String dataDirectory = \"VideoData/UCF101_MP4/\";\npublic static void main(String[] args) throws IOException, JCodecException {\n        JCodecTest test = new JCodecTest();\n        test.testReadFrame(new FxShow());\n}\n```", "```py\nString dataDirectory = \"VideoData/UCF101_MP4/\";// Paths to video dataset\n```", "```py\nprivate static int *miniBatchSize* = 128;\nprivate static int *NUM_EXAMPLE* = 10;\nUCF101Reader reader = new UCF101Reader(dataDirectory);\n```", "```py\nint examplesOffset = 0; // start from N-th file\n```", "```py\nint nExamples = Math.*min*(NUM_*EXAMPLE*, reader.fileCount());\n```", "```py\nint testStartIdx = examplesOffset + Math.*max*(2, (int) (0.8 * nExamples)); //80% in train, 20% in test \nint nTest = nExamples - testStartIdx + examplesOffset;\nSystem.*out*.println(\"Dataset consist of \" + reader.fileCount() + \" video clips, use \" \n                    + nExamples + \" of them\");\n```", "```py\nSystem.*out*.println(\"Starting training...\");\nDataSetIterator trainData = reader.getDataSetIterator(examplesOffset, nExamples - nTest, *miniBatchSize*);\n```", "```py\nSystem.out.println(\"Use \" + String.*valueOf*(nTest) + \" video clips for test\"); \nDataSetIterator testData = reader.getDataSetIterator(testStartIdx, nExamples, *miniBatchSize*);\n```", "```py\nprivate static MultiLayerConfiguration *conf*;\nprivate static MultiLayerNetwork *net*; \nprivate static String *modelPath* = \"bin/ConvLSTM_Model.zip\";\nprivate static int *NUM_CLASSES*;\nprivate static int *nTrainEpochs* = 100;\n```", "```py\n*NUM_CLASSES* = reader.labelMap().size();\n```", "```py\n//Set up network architecture:\n conf = new NeuralNetConfiguration.Builder()\n                .seed(12345)\n                .l2(0.001) //l2 regularization on all layers\n                .updater(new Adam(0.001)) // we use Adam as updater\n                .list()\n                .layer(0, new ConvolutionLayer.Builder(10, 10)\n                        .nIn(3) //3 channels: RGB\n                        .nOut(30)\n                        .stride(4, 4)\n                        .activation(Activation.RELU)\n                        .weightInit(WeightInit.RELU)\n                        .build()) //Output: (130-10+0)/4+1 = 31 -> 31*31*30\n                .layer(1, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)\n                        .kernelSize(3, 3)\n                        .stride(2, 2).build()) //(31-3+0)/2+1 = 15\n                .layer(2, new ConvolutionLayer.Builder(3, 3)\n                        .nIn(30)\n                        .nOut(10)\n                        .stride(2, 2)\n                        .activation(Activation.RELU)\n                        .weightInit(WeightInit.RELU)\n                        .build()) //Output: (15-3+0)/2+1 = 7 -> 7*7*10 = 490\n                .layer(3, new DenseLayer.Builder()\n                        .activation(Activation.RELU)\n                        .nIn(2340) // 13 * 18 * 10 = 2340, see CNN layer width x height\n                        .nOut(50)\n                        .weightInit(WeightInit.RELU)\n                        .gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue)\n                        .gradientNormalizationThreshold(10)\n                        .updater(new AdaGrad(0.01))// for faster convergence\n                        .build())\n                .layer(4, new LSTM.Builder()\n                        .activation(Activation.SOFTSIGN)\n                        .nIn(50)\n                        .nOut(50)\n                        .weightInit(WeightInit.XAVIER)\n                        .updater(new AdaGrad(0.008))\n                        .gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue)\n                        .gradientNormalizationThreshold(10)\n                        .build())\n                .layer(5, new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT)\n                        .activation(Activation.SOFTMAX)\n                        .nIn(50)\n                        .nOut(NUM_CLASSES)    \n                        .weightInit(WeightInit.XAVIER)\n                        .gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue)\n                        .gradientNormalizationThreshold(10)\n                        .build())\n                .inputPreProcessor(0, new RnnToCnnPreProcessor(UCF101Reader.V_HEIGHT, \n                                   UCF101Reader.V_WIDTH, 3))\n                .inputPreProcessor(3, new CnnToFeedForwardPreProcessor(13, 18, 10))\n                .inputPreProcessor(4, new FeedForwardToRnnPreProcessor())\n                .pretrain(false).backprop(true)\n                .backpropType(BackpropType.TruncatedBPTT)\n                .tBPTTForwardLength(UCF101Reader.V_NFRAMES / 5)\n                .tBPTTBackwardLength(UCF101Reader.V_NFRAMES / 5)\n                .build();\n```", "```py\n*net* = new MultiLayerNetwork(*conf*);\n*net*.init();\n*net*.setListeners(new ScoreIterationListener(1));\n```", "```py\nSystem.*out*.println(\"Number of parameters in network: \" + *net*.numParams());\nfor(int i=0; i<*net*.getnLayers(); i++){\n    System.*out*.println(\"Layer \" + i + \" nParams = \" + *net*.getLayer(i).numParams());\n}\n```", "```py\nfor (int i = 0; i < *nTrainEpochs*; i++) {\n         int j = 0;\n         while(trainData.hasNext()) {\n               long start = System.*nanoTime*();\n               DataSet example = trainData.next();\n               *net*.fit(example);\n               System.*out*.println(\" Example \" + j + \" processed in \" \n                                 + ((System.*nanoTime*() - start) / 1000000) + \" ms\");\n               j++;\n              }\n       System.*out*.println(\"Epoch \" + i + \" complete\");\n}\n```", "```py\nprivate static void saveConfigs() throws IOException {\n         Nd4j.*saveBinary*(*net*.params(),new File(\"bin/videomodel.bin\"));\n         FileUtils.*writeStringToFile*(new File(\"bin/videoconf.json\"), *conf*.toJson());\n  }\n```", "```py\nprivates tatic void saveNetwork() throws IOException {\n         File locationToSave = new File(*modelPath*);\n boolean saveUpdater = true;\n         ModelSerializer.*writeModel*(*net*, locationToSave, saveUpdater);\n}\n```", "```py\nprivate static void evaluateClassificationPerformance(MultiLayerNetwork net, int testStartIdx, \n                     int nExamples, DataSetIterator testData) throws Exception {\n          Evaluation evaluation = new Evaluation(*NUM_CLASSES*);\n while(testData.hasNext()) {\n                DataSet dsTest = testData.next();\n                INDArray predicted = net.output(dsTest.getFeatureMatrix(), false);\n                INDArray actual = dsTest.getLabels(); \n                evaluation.evalTimeSeries(actual, predicted);\n                 }\n          System.*out*.println(evaluation.stats());\n}\n>>>\n Predictions labeled as 0 classified by model as 0: 493 times\n Predictions labeled as 0 classified by model as 7: 3 times\n Predictions labeled as 1 classified by model as 6: 287 times\n Predictions labeled as 1 classified by model as 7: 1 times\n Predictions labeled as 2 classified by model as 6: 758 times\n Predictions labeled as 2 classified by model as 7: 3 times\n Predictions labeled as 3 classified by model as 6: 111 times\n Predictions labeled as 3 classified by model as 7: 1 times\n Predictions labeled as 4 classified by model as 6: 214 times\n Predictions labeled as 4 classified by model as 7: 2 times\n Predictions labeled as 5 classified by model as 6: 698 times\n Predictions labeled as 5 classified by model as 7: 3 times\n Predictions labeled as 6 classified by model as 6: 128 times\n Predictions labeled as 6 classified by model as 5: 1 times\n Predictions labeled as 7 classified by model as 7: 335 times\n Predictions labeled as 8 classified by model as 8: 209 times\n Predictions labeled as 8 classified by model as 7: 2 times\n ==========================Scores===================\n # of classes: 9\n Accuracy: 0.4000\n Precision: 0.39754\n Recall: 0.4109\n F1 Score: 0.4037\n Precision, recall & F1: macro-averaged (equally weighted avg. of 9 classes)\n ======================================================\n```", "```py\npublic static void main(String[] args) throws Exception {        \n        String dataDirectory = \"VideoData/UCF101_MP4/\";\n        UCF101Reader reader = new UCF101Reader(dataDirectory); \n        NUM_CLASSES = reader.labelMap().size();        \n\n        int examplesOffset = 0; // start from N-th file\n        int nExamples = Math.min(NUM_EXAMPLE, reader.fileCount()); // use only \"nExamples\" for train/test\n        int testStartIdx = examplesOffset + Math.max(2, (int) (0.9 * nExamples)); //90% train, 10% in test\n        int nTest = nExamples - testStartIdx + examplesOffset;\n        System.out.println(\"Dataset consist of \" + reader.fileCount() + \" images, use \"\n                           + nExamples + \" of them\");        \n\n        //Conduct learning\n        System.out.println(\"Starting training...\");       \n        DataSetIterator trainData = reader.getDataSetIterator(examplesOffset, \n                                    nExamples - nTest, miniBatchSize);        \n        networkTrainer(reader, trainData);\n\n        //Save network and video configuration\n        saveConfigs();\n\n        //Save the trained model\n        saveNetwork();\n\n        //Evaluate classification performance:\n        System.out.println(\"Use \" + String.valueOf(nTest) + \" images for validation\");\n        DataSetIterator testData = reader.getDataSetIterator(testStartIdx, nExamples, miniBatchSize);\n        evaluateClassificationPerformance(net,testStartIdx,nTest, testData);        \n    }\n```", "```py\n$ sudo apt-get install python-software-properties\n$ sudo apt-get update\n$ sudo add-apt-repository ppa:webupd8team/java\n$ sudo apt-get update\n```", "```py\n$ sudo apt-get install oracle-java8-installer\n```", "```py\n$ echo \"export JAVA_HOME=/usr/lib/jvm/java-8-oracle\" >> ~/.bashrc\n$ echo \"export PATH=$PATH:$JAVA_HOME/bin\" >> ~/.bashrc\n$ source ~/.bashrc\n```", "```py\n$ echo $JAVA_HOME\n```", "```py\n/usr/lib/jvm/java-8-oracle\n```", "```py\n$ java -version\n>>>\n java version \"1.8.0_121\"\n Java(TM) SE Runtime Environment (build 1.8.0_121-b15)\n Java HotSpot(TM) 64-Bit Server VM (build 25.121-b15, mixed mode)\n```", "```py\nCudaEnvironment.getInstance().getConfiguration()\n       .allowMultiGPU(true) // key option enabled\n       .setMaximumDeviceCache(2L * 1024L * 1024L * 1024L) // large cache\n       .allowCrossDeviceAccess(true); // cross-device access for faster model averaging over a piece\n```", "```py\n*net* = new MultiLayerNetwork(*conf*);\n*net*.init(); \n\nParallelWrapper wrapper = new ParallelWrapper.Builder(net)\n       .prefetchBuffer(8)// DataSets prefetching options. Set this with respect to number of devices\n       .workers(8)// set number of workers equal to number of available devices -i.e. 8 for p2.8xlarge \n       .averagingFrequency(3)// rare averaging improves performance, but might reduce model accuracy           \n       .reportScoreAfterAveraging(true) // if set TRUE, on every avg. model score will be reported \n       .build();\n```", "```py\nfor (int i = 0; i < nTrainEpochs; i++) {\n     wrapper.fit(trainData);\n     System.out.println(\"Epoch \" + i + \" complete\"); \n    }\n```", "```py\nimport org.nd4j.jita.conf.CudaEnvironment; \nimport org.deeplearning4j.parallelism.ParallelWrapper;\n```", "```py\nprivate static void networkTrainer(UCF101Reader reader, DataSetIterator trainData) throws Exception {        \n    //Set up network architecture:\n    conf = new NeuralNetConfiguration.Builder()\n                .seed(12345)\n                .l2(0.001) //l2 regularization on all layers\n                .updater(new Adam(0.001))\n                .list()\n                .layer(0, new ConvolutionLayer.Builder(10, 10)\n                        .nIn(3) //3 channels: RGB\n                        .nOut(30)\n                        .stride(4, 4)\n                        .activation(Activation.RELU)\n                        .weightInit(WeightInit.RELU)\n                        .build())   //Output: (130-10+0)/4+1 = 31 -> 31*31*30\n                .layer(1, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)\n                        .kernelSize(3, 3)\n                        .stride(2, 2).build())   //(31-3+0)/2+1 = 15\n                .layer(2, new ConvolutionLayer.Builder(3, 3)\n                        .nIn(30)\n                        .nOut(10)\n                        .stride(2, 2)\n                        .activation(Activation.RELU)\n                        .weightInit(WeightInit.RELU)\n                        .build())   //Output: (15-3+0)/2+1 = 7 -> 7*7*10 = 490\n                .layer(3, new DenseLayer.Builder()\n                        .activation(Activation.RELU)\n                        .nIn(2340) // 13 * 18 * 10 = 2340, see CNN layer width x height\n                        .nOut(50)\n                        .weightInit(WeightInit.RELU)\n                        .gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue)\n                        .gradientNormalizationThreshold(10)\n                        .updater(new AdaGrad(0.01))\n                        .build())\n                .layer(4, new LSTM.Builder()\n                        .activation(Activation.SOFTSIGN)\n                        .nIn(50)\n                        .nOut(50)\n                        .weightInit(WeightInit.XAVIER)\n                        .updater(new AdaGrad(0.008))\n                        .gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue)\n                        .gradientNormalizationThreshold(10)\n                        .build())\n                .layer(5, new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT)\n                        .activation(Activation.SOFTMAX)\n                        .nIn(50)\n                        .nOut(NUM_CLASSES)    \n                        .weightInit(WeightInit.XAVIER)\n                        .gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue)\n                        .gradientNormalizationThreshold(10)\n                        .build())\n                .inputPreProcessor(0, new RnnToCnnPreProcessor(UCF101Reader.V_HEIGHT, \n                                   UCF101Reader.V_WIDTH, 3))\n                .inputPreProcessor(3, new CnnToFeedForwardPreProcessor(13, 18, 10))\n                .inputPreProcessor(4, new FeedForwardToRnnPreProcessor())\n                .pretrain(false).backprop(true)\n                .backpropType(BackpropType.TruncatedBPTT)\n                .tBPTTForwardLength(UCF101Reader.V_NFRAMES / 5)\n                .tBPTTBackwardLength(UCF101Reader.V_NFRAMES / 5)\n                .build();\n\n        net = new MultiLayerNetwork(conf);\n        net.init();\n        net.setListeners(new ScoreIterationListener(1));\n\n        System.out.println(\"Number of parameters in network: \" + net.numParams());\n        for( int i=0; i<net.getnLayers(); i++ ){\n            System.out.println(\"Layer \" + i + \" nParams = \" + net.getLayer(i).numParams());\n        }\n\n    // ParallelWrapper will take care of load balancing between GPUs.\n    ParallelWrapper wrapper = new ParallelWrapper.Builder(net)            \n            .prefetchBuffer(8)// DataSets prefetching options. Set value with respect to number of devices\n            .workers(8)// set number of workers equal to number of available devices \n            .averagingFrequency(3)// rare avg improves performance, but might reduce accuracy           \n            .reportScoreAfterAveraging(true) // if set TRUE, on every avg. model score will be reported\n            .build();\n\n   for (int i = 0; i < nTrainEpochs; i++) {\n                wrapper.fit(trainData);\n                System.out.println(\"Epoch \" + i + \" complete\");\n        }\n    }\n```", "```py\npublic static void main(String[] args) throws Exception {  \n        // Workaround for CUDA backend initialization\n        CudaEnvironment.getInstance()\n                .getConfiguration()\n                .allowMultiGPU(true)\n                .setMaximumDeviceCache(2L * 1024L * 1024L * 1024L)\n                .allowCrossDeviceAccess(true);   \n\n        String dataDirectory = \"/home/ubuntu/UCF101_MP4/\";\n        UCF101Reader reader = new UCF101Reader(dataDirectory); \n        NUM_CLASSES = reader.labelMap().size();        \n\n        int examplesOffset = 0; // start from N-th file\n        int nExamples = Math.min(NUM_EXAMPLE, reader.fileCount()); // use only \"nExamples\" for train/test\n        int testStartIdx = examplesOffset + Math.max(2, (int) (0.9 * nExamples)); //90% train, 10% in test\n        int nTest = nExamples - testStartIdx + examplesOffset;\n\n        System.out.println(\"Dataset consist of \" + reader.fileCount() + \" images, use \" \n                          + nExamples + \" of them\");        \n\n        //Conduct learning\n        System.out.println(\"Starting training...\");       \n        DataSetIterator trainData = reader.getDataSetIterator(examplesOffset, \n                                    nExamples - nTest, miniBatchSize);        \n        networkTrainer(reader, trainData);\n\n        //Save network and video configuration\n        saveConfigs();\n\n        //Save the trained model\n        saveNetwork();\n\n        //Evaluate classification performance:\n        System.out.println(\"Use \" + String.valueOf(nTest) + \" images for validation\");\n        DataSetIterator testData = reader.getDataSetIterator(testStartIdx, nExamples, 10);\n        evaluateClassificationPerformance(net,testStartIdx,nTest, testData);        \n    }\n\n```", "```py\n$sudo apt-get install maven\n```", "```py\n$ sudo mvn clean install\n```", "```py\n$ cd target/\n$ java -Xmx30g -jar VideoClassifier-0.0.1-SNAPSHOT-jar-with-dependencies.jar\n```", "```py\nubuntu@ip-172-31-40-27:~/JavaDeepLearningDL4J/target$ java -Xmx30g -jar VideoClassifier-0.0.1-SNAPSHOT-jar-with-dependencies.jar\n```", "```py\nDataset consist of 1112 images, use 20 of them\nStarting training...\n18:57:34.815 [main] INFO org.nd4j.linalg.factory.Nd4jBackend - Loaded [JCublasBackend] backend\n18:57:34.844 [main] WARN org.reflections.Reflections - given scan urls are empty. set urls in the configuration\n18:57:47.447 [main] INFO org.nd4j.nativeblas.NativeOpsHolder - Number of threads used for NativeOps: 32\n18:57:51.433 [main] DEBUG org.nd4j.jita.concurrency.CudaAffinityManager - Manually mapping thread [28] to device [0], out of [8] devices...\n18:57:51.441 [main] INFO org.nd4j.nativeblas.Nd4jBlas - Number of threads used for BLAS: 0\n18:57:51.447 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner - Backend used: [CUDA]; OS: [Linux]\n18:57:51.447 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner - Cores: [32]; Memory: [26.7GB];\n18:57:51.447 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner - Blas vendor: [CUBLAS]\n18:57:51.452 [main] INFO org.nd4j.linalg.jcublas.ops.executioner.CudaExecutioner - Device opName: [Tesla K80]; CC: [3.7]; Total/free memory: [11995578368]\n18:57:51.452 [main] INFO org.nd4j.linalg.jcublas.ops.executioner.CudaExecutioner - Device opName: [Tesla K80]; CC: [3.7]; Total/free memory: [11995578368]\n18:57:51.452 [main] INFO org.nd4j.linalg.jcublas.ops.executioner.CudaExecutioner - Device opName: [Tesla K80]; CC: [3.7]; Total/free memory: [11995578368]\n 18:57:51.452 [main] INFO org.nd4j.linalg.jcublas.ops.executioner.CudaExecutioner - Device opName: [Tesla K80]; CC: [3.7]; Total/free memory: [11995578368]\n18:57:51.452 [main] INFO org.nd4j.linalg.jcublas.ops.executioner.CudaExecutioner - Device opName: [Tesla K80]; CC: [3.7]; Total/free memory: [11995578368]\n18:57:51.452 [main] INFO org.nd4j.linalg.jcublas.ops.executioner.CudaExecutioner - Device opName: [Tesla K80]; CC: [3.7]; Total/free memory: [11995578368]\n18:57:51.452 [main] INFO org.nd4j.linalg.jcublas.ops.executioner.CudaExecutioner - Device opName: [Tesla K80]; CC: [3.7]; Total/free memory: [11995578368]\n18:57:51.452 [main] INFO org.nd4j.linalg.jcublas.ops.executioner.CudaExecutioner - Device opName: [Tesla K80]; CC: [3.7]; Total/free memory: [11995578368]\n18:57:51.697 [main] DEBUG org.nd4j.jita.handler.impl.CudaZeroHandler - Creating bucketID: 1\n18:57:51.706 [main] DEBUG org.nd4j.jita.handler.impl.CudaZeroHandler - Creating bucketID: 2\n18:57:51.711 [main] DEBUG org.reflections.Reflections - going to scan these urls:\njar:file:/home/ubuntu/JavaDeepLearningDL4J/target/VideoClassifier-0.0.1-SNAPSHOT-jar-with-dependencies.jar!/.\n...\n```", "```py\nCudaEnvironment.getInstance().getConfiguration().allowMultiGPU(true);\n```", "```py\nDataTypeUtil.setDTypeForContext(DataBuffer.Type.HALF);\n```"]