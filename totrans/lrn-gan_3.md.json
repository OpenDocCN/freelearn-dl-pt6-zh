["```py\nY = tf.placeholder(tf.float32, shape=(None, num_labels))\n```", "```py\nDhidden = 256  # hidden units of Discriminator's network\nGhidden = 512  # hidden units of Generator's network\nK = 8          # maxout units of Discriminator\n\n# Discriminator Network\n\ndef discriminator(x, y):\n    u = tf.reshape(tf.matmul(x, DW1x) + tf.matmul(y, DW1y) + Db1, [-1, K, Dhidden])\n    Dh1 = tf.nn.dropout(tf.reduce_max(u, reduction_indices=[1]), keep_prob)\n    return tf.nn.sigmoid(tf.matmul(Dh1, DW2) + Db2)\n\n# Generator Network\n\ndef generator(z,y):\n    Gh1 = tf.nn.relu(tf.matmul(Z, GW1z) + tf.matmul(Y, GW1y) + Gb1)\n    G = tf.nn.sigmoid(tf.matmul(Gh1, GW2) + Gb2)\n    return G\n```", "```py\nG_sample = generator(Z, Y)\nDG = discriminator(G_sample, Y)\n\nDloss = -tf.reduce_mean(tf.log(discriminator(X, Y)) + tf.log(1 - DG))\nGloss = tf.reduce_mean(tf.log(1 - DG) - tf.log(DG + 1e-9)) \n```", "```py\nX_mb, y_mb = mnist.train.next_batch(mini_batch_size)\n\nZ_sample = sample_Z(mini_batch_size, noise_dim)\n\n_, D_loss_curr = sess.run([Doptimizer, Dloss], feed_dict={X: X_mb, Z: Z_sample, Y:y_mb, keep_prob:0.5})\n\n_, G_loss_curr = sess.run([Goptimizer, Gloss], feed_dict={Z: Z_sample, Y:y_mb, keep_prob:1.0})\n```", "```py\nnsamples=6\n\n      Z_sample = sample_Z(nsamples, noise_dim)\n        y_sample = np.zeros(shape=[nsamples, num_labels])\n        y_sample[:, 7] = 1 # generating image based on label\n\n        samples = sess.run(G_sample, feed_dict={Z: Z_sample, Y:y_sample})\n```", "```py\npython download.py\n\n```", "```py\npython simple-cgan.py\n\n```", "```py\nself.repeat_num = int(np.log2(height)) â€“ 2.\n\ndef GeneratorCNN(z, hidden_num, output_num, repeat_num, data_format, reuse):\n    with tf.variable_scope(\"G\", reuse=reuse) as vs:\n        num_output = int(np.prod([8, 8, hidden_num]))\n        x = slim.fully_connected(z, num_output, activation_fn=None)\n        x = reshape(x, 8, 8, hidden_num, data_format)\n\n        for idx in range(repeat_num):\n            x = slim.conv2d(x, hidden_num, 3, 1, activation_fn=tf.nn.elu, data_format=data_format)\n            x = slim.conv2d(x, hidden_num, 3, 1, activation_fn=tf.nn.elu, data_format=data_format)\n            if idx < repeat_num - 1:\n                x = upscale(x, 2, data_format)\n\n        out = slim.conv2d(x, 3, 3, 1, activation_fn=None, data_format=data_format)\n\n    variables = tf.contrib.framework.get_variables(vs)\n    return out, variables\n```", "```py\ndef DiscriminatorCNN(x, input_channel, z_num, repeat_num, hidden_num, data_format):\n    with tf.variable_scope(\"D\") as vs:\n        # Encoder\n        x = slim.conv2d(x, hidden_num, 3, 1, activation_fn=tf.nn.elu, data_format=data_format)\n\n        prev_channel_num = hidden_num\n        for idx in range(repeat_num):\n            channel_num = hidden_num * (idx + 1)\n            x = slim.conv2d(x, channel_num, 3, 1, activation_fn=tf.nn.elu, data_format=data_format)\n            x = slim.conv2d(x, channel_num, 3, 1, activation_fn=tf.nn.elu, data_format=data_format)\n            if idx < repeat_num - 1:\n                x = slim.conv2d(x, channel_num, 3, 2, activation_fn=tf.nn.elu, data_format=data_format)\n                #x = tf.contrib.layers.max_pool2d(x, [2, 2], [2, 2], padding='VALID')\n\n        x = tf.reshape(x, [-1, np.prod([8, 8, channel_num])])\n        z = x = slim.fully_connected(x, z_num, activation_fn=None)\n```", "```py\n        num_output = int(np.prod([8, 8, hidden_num]))\n        x = slim.fully_connected(x, num_output, activation_fn=None)\n        x = reshape(x, 8, 8, hidden_num, data_format)\n\n        for idx in range(repeat_num):\n            x = slim.conv2d(x, hidden_num, 3, 1, activation_fn=tf.nn.elu, data_format=data_format)\n            x = slim.conv2d(x, hidden_num, 3, 1, activation_fn=tf.nn.elu, data_format=data_format)\n            if idx < repeat_num - 1:\n                x = upscale(x, 2, data_format)\n\n        out = slim.conv2d(x, input_channel, 3, 1, activation_fn=None, data_format=data_format)\n\n    variables = tf.contrib.framework.get_variables(vs)\n```", "```py\nd_out, self.D_z, self.D_var = DiscriminatorCNN(\n                tf.concat([G, x], 0), self.channel, self.z_num, self.repeat_num,\n                self.conv_hidden_num, self.data_format)\n        AE_G, AE_x = tf.split(d_out, 2)\n\n        self.G = denorm_img(G, self.data_format)\n        self.AE_G, self.AE_x = denorm_img(AE_G, self.data_format), denorm_img(AE_x, self.data_format)\n\nif self.optimizer == 'adam':\n            optimizer = tf.train.AdamOptimizer\n        else:\n            raise Exception(\"[!] Caution! Paper didn't use {} opimizer other than Adam\".format(config.optimizer))\n\n        g_optimizer, d_optimizer = optimizer(self.g_lr), optimizer(self.d_lr)\n\n        self.d_loss_real = tf.reduce_mean(tf.abs(AE_x - x))\n        self.d_loss_fake = tf.reduce_mean(tf.abs(AE_G - G))\n\n        self.d_loss = self.d_loss_real - self.k_t * self.d_loss_fake\n        self.g_loss = tf.reduce_mean(tf.abs(AE_G - G))\n```", "```py\n    git clone https://github.com/carpedm20/BEGAN-tensorflow.git\n    cd BEGAN-tensorflow\n\n    ```", "```py\n    python download.py\n\n    ```", "```py\n    python main.py --dataset=CelebA --use_gpu=True\n\n    ```", "```py\n    git clone https://github.com/xhujoy/CycleGAN-tensorflow\n    cd CycleGAN-tensorflow\n    ```", "```py\n    bash ./download_dataset.sh apple2orange\n\n    ```", "```py\n    python main.py --dataset_dir=apple2orange\n\n    ```", "```py\n    tensorboard --logdir=./logs\n\n    ```", "```py\n    python main.py --dataset_dir=apple2orange --phase=test --which_direction=AtoB\n\n    ```", "```py\n    git clone https://github.com/xhujoy/CycleGAN-tensorflow\n    cd CycleGAN-tensorflow\n\n    ```", "```py\n    bash ./download_dataset.sh horse2zebra\n\n    ```", "```py\n    python main.py --dataset_dir=horse2zebra\n\n    ```", "```py\n    tensorboard --logdir=./logs\n\n    ```", "```py\n    python main.py --dataset_dir=horse2zebra --phase=test --which_direction=AtoB\n\n    ```"]