["```py\nimport nltk\n```", "```py\nsimpleSentence = \"Bangalore is the capital of Karnataka.\"\n```", "```py\nwordsInSentence = nltk.word_tokenize(simpleSentence)\n```", "```py\nprint(wordsInSentence)\n```", "```py\npartsOfSpeechTags = nltk.pos_tag(wordsInSentence)\n```", "```py\nprint(partsOfSpeechTags)\n```", "```py\nimport nltk\n```", "```py\ndef learnDefaultTagger(simpleSentence):\n  wordsInSentence = nltk.word_tokenize(simpleSentence)\n  tagger = nltk.DefaultTagger(\"NN\")\n  posEnabledTags = tagger.tag(wordsInSentence)\n  print(posEnabledTags)\n```", "```py\ndef learnDefaultTagger(simpleSentence):\n```", "```py\nwordsInSentence = nltk.word_tokenize(simpleSentence)\n```", "```py\ntagger = nltk.DefaultTagger(\"NN\")\n```", "```py\nposEnabledTags = tagger.tag(wordsInSentence)\n```", "```py\nprint(posEnabledTags)\n```", "```py\ndef learnRETagger(simpleSentence):\n  customPatterns = [\n    (r'.*ing$', 'ADJECTIVE'),\n    (r'.*ly$', 'ADVERB'),\n    (r'.*ion$', 'NOUN'),\n    (r'(.*ate|.*en|is)$', 'VERB'),\n    (r'^an$', 'INDEFINITE-ARTICLE'),\n    (r'^(with|on|at)$', 'PREPOSITION'),\n    (r'^\\-?[0-9]+(\\.[0-9]+)$', 'NUMBER'),\n    (r'.*$', None),\n  ]\n  tagger = nltk.RegexpTagger(customPatterns)\n  wordsInSentence = nltk.word_tokenize(simpleSentence)\n  posEnabledTags = tagger.tag(wordsInSentence)\n  print(posEnabledTags)\n```", "```py\ndef learnRETagger(simpleSentence):\n```", "```py\ncustomPatterns = [\n  (r'.*ing$', 'ADJECTIVE'),\n  (r'.*ly$', 'ADVERB'),\n  (r'.*ion$', 'NOUN'),\n  (r'(.*ate|.*en|is)$', 'VERB'),\n  (r'^an$', 'INDEFINITE-ARTICLE'),\n  (r'^(with|on|at)$', 'PREPOSITION'),\n  (r'^\\-?[0-9]+(\\.[0-9]+)$', 'NUMBER'),\n  (r'.*$', None),\n]\n```", "```py\ntagger = nltk.RegexpTagger(customPatterns)\n```", "```py\nwordsInSentence = nltk.word_tokenize(simpleSentence)\n```", "```py\nposEnabledTags = tagger.tag(wordsInSentence)\n```", "```py\nprint(posEnabledTags)\n```", "```py\ndef learnLookupTagger(simpleSentence):\n  mapping = {\n    '.': '.', 'place': 'NN', 'on': 'IN',\n    'earth': 'NN', 'Mysore' : 'NNP', 'is': 'VBZ',\n    'an': 'DT', 'amazing': 'JJ'\n  }\n  tagger = nltk.UnigramTagger(model=mapping)\n  wordsInSentence = nltk.word_tokenize(simpleSentence)\n  posEnabledTags = tagger.tag(wordsInSentence)\n  print(posEnabledTags)\n```", "```py\ndef learnLookupTagger(simpleSentence):\n```", "```py\ntagger = nltk.UnigramTagger(model=mapping)\n```", "```py\nwordsInSentence = nltk.word_tokenize(simpleSentence)\n```", "```py\nposEnabledTags = tagger.tag(wordsInSentence)\n```", "```py\nprint(posEnabledTags)\n```", "```py\ntestSentence = \"Mysore is an amazing place on earth. I have visited Mysore 10 times.\"\n```", "```py\nlearnDefaultTagger(testSentence)\n```", "```py\nlearnRETagger(testSentence)\n```", "```py\nlearnLookupTagger(testSentence)\n```", "```py\nimport nltk\nimport pickle\n```", "```py\ndef sampleData():\n  return [\n    \"Bangalore is the capital of Karnataka.\",\n    \"Steve Jobs was the CEO of Apple.\",\n    \"iPhone was Invented by Apple.\",\n    \"Books can be purchased in Market.\",\n  ]\n```", "```py\ndef buildDictionary():\n  dictionary = {}\n  for sent in sampleData():\n    partsOfSpeechTags = nltk.pos_tag(nltk.word_tokenize(sent))\n    for tag in partsOfSpeechTags:\n      value = tag[0]\n      pos = tag[1]\n      dictionary[value] = pos\n    return dictionary\n```", "```py\ndef saveMyTagger(tagger, fileName):\n  fileHandle = open(fileName, \"wb\")\n  pickle.dump(tagger, fileHandle)\n  fileHandle.close()\n```", "```py\ndef saveMyTraining(fileName):\n  tagger = nltk.UnigramTagger(model=buildDictionary())\n  saveMyTagger(tagger, fileName)\n```", "```py\ndef loadMyTagger(fileName):\n  return pickle.load(open(fileName, \"rb\"))\n```", "```py\nsentence = 'Iphone is purchased by Steve Jobs in Bangalore Market'\nfileName = \"myTagger.pickle\"\n```", "```py\nsaveMyTraining(fileName)\n```", "```py\nmyTagger = loadMyTagger(fileName)\n```", "```py\nprint(myTagger.tag(nltk.word_tokenize(sentence)))\n```", "```py\nimport nltk\n```", "```py\nimport string\n```", "```py\nfrom nltk.parse.generate import generate\n```", "```py\nproductions = [\n  \"ROOT -> WORD\",\n  \"WORD -> ' '\",\n  \"WORD -> NUMBER LETTER\",\n  \"WORD -> LETTER NUMBER\",\n]\n```", "```py\ndigits = list(string.digits)\nfor digit in digits[:4]:\n  productions.append(\"NUMBER -> '{w}'\".format(w=digit))\n```", "```py\nletters = \"' | '\".join(list(string.ascii_lowercase)[:4])\nproductions.append(\"LETTER -> '{w}'\".format(w=letters))\n```", "```py\ngrammarString = \"\\n\".join(productions)\n```", "```py\ngrammar = nltk.CFG.fromstring(grammarString)\n```", "```py\nfor sentence in generate(grammar, n=5, depth=5):\n  palindrome = \"\".join(sentence).replace(\" \", \"\")\n  print(\"Generated Word: {}, Size : {}\".format(palindrome, len(palindrome)))\n```", "```py\nimport nltk\n```", "```py\nfrom nltk.parse.generate import generate\n```", "```py\nproductions = [\n  \"ROOT -> WORD [1.0]\",\n  \"WORD -> P1 [0.25]\",\n  \"WORD -> P1 P2 [0.25]\",\n  \"WORD -> P1 P2 P3 [0.25]\",\n  \"WORD -> P1 P2 P3 P4 [0.25]\",\n  \"P1 -> 'A' [1.0]\",\n  \"P2 -> 'B' [0.5]\",\n  \"P2 -> 'C' [0.5]\",\n  \"P3 -> 'D' [0.3]\",\n  \"P3 -> 'E' [0.3]\",\n  \"P3 -> 'F' [0.4]\",\n  \"P4 -> 'G' [0.9]\",\n  \"P4 -> 'H' [0.1]\",\n]\n```", "```py\ngrammarString = \"\\n\".join(productions)\n```", "```py\ngrammar = nltk.PCFG.fromstring(grammarString)\n```", "```py\nprint(grammar)\n```", "```py\nfor sentence in generate(grammar, n=10, depth=5):\n  palindrome = \"\".join(sentence).replace(\" \", \"\")\n  print(\"String : {}, Size : {}\".format(palindrome, len(palindrome)))\n```", "```py\nimport nltk\n```", "```py\nimport string\n```", "```py\nfrom nltk.parse.generate import generate\n```", "```py\nproductions = [\n  \"ROOT -> WORD\",\n  \"WORD -> ' '\"\n]\n```", "```py\nalphabets = list(string.digits)\n```", "```py\nfor alphabet in alphabets:\n  productions.append(\"WORD -> '{w}' WORD '{w}'\".format(w=alphabet))\n```", "```py\ngrammarString = \"\\n\".join(productions)\n```", "```py\ngrammar = nltk.CFG.fromstring(grammarString)\n```", "```py\nprint(grammar)\n```", "```py\nfor sentence in generate(grammar, n=5, depth=5):\n  palindrome = \"\".join(sentence).replace(\" \", \"\")\n  print(\"Palindrome : {}, Size : {}\".format(palindrome, len(palindrome)))\n```"]