- en: Deep Learning for Games
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Welcome to *Hands-on Deep Learning for Games*. This book is for anyone wanting
    an extremely practical approach to the complexity of **deep learning** (**DL**)
    for games. Importantly, the concepts discussed in this book aren't solely limited
    to games. Much of what we'll learn here will easily carry over to other applications/simulations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Reinforcement learning** (**RL**), which will be a core element we talk about
    in later chapters, is quickly becoming the dominant **machine learning** (**ML**)
    technology. It has been applied to everything from server optimization to predicting
    customer activity for retail markets. Our journey in this book will primarily
    be focused on game development, and our goal will be to build a working adventure
    game. Keep in the back of your mind how the same principles you discover in this
    book could be applied to other problems, such as simulations, robotics, and lots
    more.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to start from the very basics of neural networks
    and deep learning. We will discuss the background of neural networks, working
    our way toward building a neural network that can play a simple text game. Specifically,
    this chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The past, present, and future of DL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks – the foundation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multilayer perceptron in **TensorFlow** (**TF**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training neural networks with backpropagation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building an Autoencoder in Keras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This book assumes that you have a working knowledge of Python. You should be
    able to set up and activate a virtual environment. Later chapters will use Unity
    3D, which is limited to Windows and macOS (apologies to those hardcore Linux users).
  prefs: []
  type: TYPE_NORMAL
- en: You might be inclined to skip this chapter if you've already grasped deep learning.
    Regardless, this chapter is well worth reading and will establish the terminology we
    use throughout the book. At the very least, do the hands-on exercise—you will
    thank yourself later!
  prefs: []
  type: TYPE_NORMAL
- en: The past, present, and future of DL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the term *de**ep* *learning* was first associated with neural networks
    in 2000 by Igor Aizenberg and colleagues, it has only become popular in the last
    5 years. Prior to this, we called this type of algorithm an **artificial neural
    network **(**ANN**). However, deep learning refers to something broader than ANNs
    and includes many other areas of connected machines. Therefore, to clarify, we
    will be discussing the ANN form of DL for much of the remainder of this book.
    However, we will also discuss some other forms of DL that can be used in games,
    in [Chapter 5](6ca7a117-1a8c-49f9-89c0-ee2f2a1e8baf.xhtml), *Introducing DRL*.
  prefs: []
  type: TYPE_NORMAL
- en: The past
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first form of a **multilayer perceptron** (**MLP**) network, or what we
    now  call an ANN, was introduced by Alexey Ivakhnenko in 1965\. Ivakhnenko waited
    several years before writing about the multilayer perceptron in 1971\. The concept
    took a while to percolate and it wasn't until the 1980s that more research began.
    This time, image classification and speech recognition were attempted, and they
    failed, but progress was being made. It took another 10 years, and in the late
    90s, it became popular again. So much so that ANNs made their way into some games,
    again, until better methods came along. Things quietened down and another decade
    or so passed.
  prefs: []
  type: TYPE_NORMAL
- en: Then, in 2012, Andrew Ng and Jeff Dean used an ANN to recognize cats in videos,
    and the interest in deep learning exploded. Their stride was one of several trivial
    (yet entertaining) advancements which made people sit up and take notice of deep
    learning. Then, in 2015, Google's **DeepMind** team built AlphaGo, and this time
    the whole world sat up. AlphaGo was shown to solidly beat the best players in
    the world at the game of Go, and that changed everything. Other techniques soon
    followed, **Deep Reinforcement Learning** (**DRL**) being one, showing that human
    performance could be consistently beaten in areas where that was previously not
    thought of as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'While teaching their students about neural networks, there is a humorous and
    pertinent tale professors enjoy sharing: *The US Army did early research in the
    ''80s using an ANN to recognize enemy tanks. The algorithm worked 100% of the
    time, and the army organized a big demonstration to showcase its success. Unfortunately,
    nothing** worked at the demonstration, and every test failed miserably. After
    going back and analyzing things, the army realized the ANN wasn''t recognizing
    enemy tanks at all. Instead, it had been trained on images taken on a cloudy day,
    and all it was doing was recognizing the clouds.*'
  prefs: []
  type: TYPE_NORMAL
- en: The present
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At present, at least at the time of writing, we are still in the midst of a
    deep learning explosion with debris and chaos, and it is our job as developers
    to make sense of all this. Neural networks are currently the basis for many DL
    technologies, several of which we will cover in this book. Except, it seems that every
    day, new and more powerful techniques emerge, and researchers scramble to make
    sense of them. Now, this rush of ideas can actually stall a technology, as researchers
    spend more and more time trying to replicate results. It is most certainly a cause
    for much of the earlier stalling that ANNs (deep learning) previously suffered
    from. In fact, many skeptics in the industry are predicting yet another hiccup.
    So, should you be worried, is reading this book worth it? The short answer is
    *yes*. The long answer is *probably not,* this time things are very different
    and many deep learning concepts are now generating revenue, which is a good thing.
    The fact that DL technology is now a proven money-earner puts investors at ease
    and only encourages new investment and growth. Exactly how much growth is yet
    to be seen, but the machine and DL space is now ripe with opportunity and growth
    from all sectors.
  prefs: []
  type: TYPE_NORMAL
- en: So, is it still possible that the game industry will again turn its back on
    games? That is also unlikely, generally because many of the more recent major advances,
    like reinforcement learning, were built to play classic Atari games, and use games
    as the problem. This only encourages more research into deep learning using games.
    Unity 3D, the game platform, has made a major investment into reinforcement learning
    for playing games. In fact, Unity is developing some of the most cutting-edge
    technology in reinforcement learning and we will be working with this platform
    later. Unity does use C# for scripting but uses Python to build and train deep
    learning models.
  prefs: []
  type: TYPE_NORMAL
- en: The future
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Predicting the future of anything is extremely difficult, but if you watch carefully
    enough, you may gain some insight into what, where, or how things will develop.
    Of course, having a crystal ball or a well-trained neural network would certainly
    help, but a lot of what becomes popular often hinges on the next great achievement.
    Without any ability to predict that, what can we observe about the current trend
    in deep learning research and commercial development? Well, the current trend
    is to use ML to generate DL; that is, a machine essentially assembles itself a
    neural network that is addressed to solve a problem. Google is currently investing
    considerable resources into building a technology called **AutoML**, which generates
    a neural network inference model that can recognize objects/activities in images,
    speech recognition, or handwriting recognition, and more. Geoffery Hinton, who
    is often cited as the godfather of the ANN, has recently shown that complex deep
    network systems can be decomposed into reusable layers. Essentially, you can construct
    a network using layers extracted from various pre-trained models. This will certainly
    evolve into more interesting tech and plays well into the DL search but also makes
    way for the next phase in computing.
  prefs: []
  type: TYPE_NORMAL
- en: Now, programming code is going to become too tedious, difficult, and expensive
    at some point. We can already see this with the explosion of offshore development,
    with companies seeking the cheapest developers. It is now estimated that code
    costs an average of $10-$20 per line, yes, per *line*. So, at what point will
    the developer start building their code in the form of an ANN or **TensorFlow **(**TF**)
    inference graph? Well, for most of this book, the DL code we develop will be generated
    down to a TF inference graph; a brain, if you will. We will then use these brains
    in the last chapter of the book to build intelligence in our adventure game. The
    technique of building graph models is quickly becoming mainstream. Many online
    ML apps now allow users to build models that can recognize things in images, speech,
    and videos, all by just uploading training content and pressing a button. Does
    this mean that apps could be developed this way in the future without any programming?
    The answer is yes, and it is already happening.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have explored the past, present, and future of deep learning, we
    can start to dig into more of the nomenclature and how neural networks actually
    work, in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks – the foundation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The inspiration for neural networks or multilayer perceptrons is the human
    brain and nervous system. At the heart of our nervous system is the neuron pictured
    above the computer analog, which is a perceptron:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8455ea99-f7e7-4664-a948-86f3e3fb1811.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of human neuron beside a perceptron
  prefs: []
  type: TYPE_NORMAL
- en: 'The neurons in our brain collect input, do something, and then spit out a response
    much like the computer analog, the **perceptron**. A perceptron takes a set of
    inputs, sums them all up, and passes them through an activation function. That
    activation function determines whether to send output, and at what level to send
    it when activated. Let''s take a closer look at the perceptron, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9734ac86-d48c-4952-9f17-e790fe5fe746.png)'
  prefs: []
  type: TYPE_IMG
- en: Perceptron
  prefs: []
  type: TYPE_NORMAL
- en: 'On the left-hand side of the preceding diagram, you can see the set of inputs
    getting pushed in, plus a constant bias. We will get more into the bias later.
    Then the inputs are multiplied by a set of individual weights and passed through
    an activation function. In Python code, it is as simple as the one in `Chapter_1_1.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note how the `weights` list has one more element than the `inputs` list; that
    is to account for the bias (`weights[0]`). Other than that, you can see we just
    simply loop through the `inputs`, multiplying them by the designated weight and
    adding the bias. Then the `activation` is compared to `0.0`, and if it is greater
    than 0, we output. In this very simple example, we are just comparing the value
    to 0, which is essentially a simple step function. We will spend some time later
    revisiting various activation functions over and over again; consider this simple
    model an essential part of carrying out those functions.
  prefs: []
  type: TYPE_NORMAL
- en: What is the output from the preceding block of sample code? See whether you
    can figure it out, or take the less challenging route and copy and paste it into
    your favorite Python editor and run it. The code will run as is and requires no
    special libraries.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous code example, we are looking at one point of input data, `[1,2]`,
    which is hardly useful when it comes to DL. DL models typically require hundreds,
    thousands, or even millions of data points or sets of input data to train and
    learn effectively. Fortunately, with one perceptron, the amount of data we need
    is less than 10.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s expand on the preceding example and run a training set of 10 points
    through the `perceptron_predict` function by opening up your preferred Python
    editor and following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: We will use Visual Studio code for most of the major coding sections later in
    this book. By all means, use your preferred editor, but if you are relatively
    new to Python, give the code a try. Code is available for Windows, macOS, and
    Linux.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the following block of code in your preferred Python editor or open `Chapter_1_2.py`
    from the downloaded source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This code just extends the earlier example we looked at. In this case, we are
    testing multiple points of data defined in the `train` list. Then we just iterate
    through each item in the list and print out the predicted value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the code and observe the output. If you are unsure of how to run Python
    code, be sure to take that course first before going any further.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should see an output of repeating 1.0s, which essentially means all input
    values are recognized as the same. This is not something that is very useful.
    The reason for this is that we have not trained or adjusted the input weights
    to match a known output. What we need to do is train the weights to recognize
    the data, and we will look at how to do that in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Training a perceptron in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Perfect! We created a simple perceptron that takes input and spits out output
    but doesn''t really do anything. Our perceptron needs to have its weights trained
    in order to actually do something. Fortunately, there is a well-defined method,
    known as **gradient descent**, that we can use to adjust each of those weights.
    Open up your Python editor again and update or enter the following code or open
    `Chapter_1_3.py` from the code download:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The `train_weights` function is new and will be used to train the perceptron
    using iterative error minimization and will be a basis for when we use gradient
    descent in more complex networks. There is a lot going on here, so we will break
    it down piece by piece. First, we initialize the `weights` list to a value of
    `0.0` with this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we start training each epoch in a `for` loop. An **epoch** is essentially
    one pass through our training data. The reason we make multiple passes is to allow
    our weights to converge at a global minimum and not a local one. During each epoch,
    the weights are trained using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cc2e7fbe-9265-435e-bf04-279555c2ca09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6b8441cd-52a3-48a8-857d-e9280eb3ad9a.png) = weight'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e022d5c3-8424-4f64-8a6c-eec5b51c0975.png) = the rate at which the perceptron
    learns'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f83850ef-a8ce-4917-8535-66c37dad9d62.png) = the labeled training value'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c42999b3-45b8-4275-a516-20131ec52ec0.png) = the value returned from
    the perceptron'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d9d34cbd-58a9-4f2a-b685-5c0997c5c4fc.png) = ![](img/5937c8c0-55a8-459d-aa32-fe722b51b262.png) -
    ![](img/3ec50e08-1a20-4317-b539-4bb85fc26986.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The bias is trained in a similar manner, but just recall it is `weight`. Note
    also how we are labeling our data points now in the `train` list, with an end
    value of `0.0` or `1.0`. A value of `0.0` means *no match*, while a value of `1.0`
    means *perfect match*, as shown in the following code excerpt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This labeling of data is common in training neural networks and is called **supervised
    training**. We will explore other unsupervised and semi-supervised training methods
    in later chapters. If you run the preceding code, you will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2ce90bda-11c8-4219-b997-831957fcfed7.png)'
  prefs: []
  type: TYPE_IMG
- en: Example output from sample training run
  prefs: []
  type: TYPE_NORMAL
- en: Now, if you have some previous ML experience, you will immediately recognize
    the training wobbling going on around some local minima, making our training unable
    to converge. You will likely come across this type of wobble several more times
    in your DL career, so it is helpful to understand how to fix it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, our issue is likely the choice of the `activation` function,
    which, as you may recall, was just a simple step function. We can fix this by
    entering a new function, called a **Rectified Linear Unit** (**ReLU**). An example
    of the `step` and `ReLU` functions, side by side, are shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d11b04f2-d5cc-4206-8b6c-05ef1427b83c.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparison of step and ReLU activation functions
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to change the activation function, open up the previous code listing
    and follow along:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Locate the following line of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Modify it, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: That subtle difference in multiplying the activation function by itself if its
    value is greater than 0 is the implementation of the `ReLU` function. Yes, it
    is that deceptively easy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the code and observe the change in output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When you run the code, the values quickly converge and remain stable. This is
    a tremendous improvement in our training and a cause of changing the activation
    function to `ReLU`. The reason for this is that now our perceptron weights can
    more slowly converge to a global maximum, whereas before they just wobbled around
    a local minimum by using the `step` function. There are plenty of other activation
    functions we will test through the course of this book. In the next section, we
    look at how things get much more complicated when we start to combine our perceptrons
    into multiple layers.
  prefs: []
  type: TYPE_NORMAL
- en: Multilayer perceptron in TF
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Thus far, we have been looking at a simple example of a single perceptron and
    how to train it. This worked well for our small dataset, but as the number of
    inputs increases, the complexity of our networks increases, and this cascades
    into the math as well. The following diagram shows a multilayer perceptron, or
    what we commonly refer to as an ANN:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b188eaf0-7904-4c2b-9580-efb1446135d7.png)'
  prefs: []
  type: TYPE_IMG
- en: Multilayer perceptron or ANN
  prefs: []
  type: TYPE_NORMAL
- en: In the diagram, we see a network with one input, one hidden, and one output
    layer. The inputs are now shared across an input layer of neurons. The first layer
    of neurons processes the inputs, and outputs the results to be processed by the
    hidden layer and so on, until they finally reach the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: Multilayer networks can get quite complex, and the code for these models is
    often abstracted away by high-level interfaces such as Keras, PyTorch, and so
    on. These tools work well for quickly exploring network architecture and understanding
    DL concepts. However, when it comes to performance, which is key in games, it
    really requires the models to be built in TensorFlow or an API that supports low-level
    math operations. In this book, we will swap from Keras, a higher-level SDK, to
    TensorFlow and back for the introductory DL chapters. This will allow you to see
    the differences and similarities between working with either interface.
  prefs: []
  type: TYPE_NORMAL
- en: Unity ML-Agents was first prototyped with Keras but has since progressed to
    TensorFlow.  Most certainly, the team at Unity, as well as others, has done this
    for reasons of performance and, to some extent, control. Working with TensorFlow
    is akin to writing your own shaders. While it is quite difficult to write shaders
    and TF code, the ability to customize your own rendering and now learning will
    make your game be unique, and it will stand out.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a great TensorFlow example of a multilayer perceptron next for your
    reference, listing `Chapter_1_4.py`. In order to run this code using TensorFlow,
    follow the next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: We won't cover the basics of TensorFlow until the next section. This is so you
    can see TF in action first before we bore you with the details.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, install TensorFlow using the following command from a Python 3.5/3.6
    window on Windows or macOS. You can also use an Anaconda Prompt, with administrator
    rights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Make sure you install TensorFlow suited to the default Python environment. We
    will worry about creating more structured virtual environments later. If you are
    not sure what a Python virtual environment is, step away from the book and take
    a course in Python right away.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this exercise, we are loading the **MNIST** handwritten digits database.
    If you have read anything at all about ML and DL, you have most likely seen or
    heard about this dataset already. If you haven't, just quickly Google *MNIST* to
    get a sense of what these digits look like.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following Python code is from the `Chapter_1_4.py` listing, with each section
    explained in the following steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We start by loading the `mnist` training set. The `mnist` dataset is a collection
    of 28 x 28 pixel images showing hand-drawn representations of the digits 0-9,
    or what we will refer to as 10 classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we import the `tensorflow` library as `tf`. Next, we set a number of parameters
    we will use later. Note how we are defining the inputs and hidden parameters as
    well:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we set up a couple of TensorFlow placeholders with `tf.placeholder`,
    to hold the number of inputs and classes as type `''float''`. Then we create and
    initialize variables using `tf.Variable`, first doing the weights and then the
    biases. Inside the variable declaration, we initialize normally distributed data
    into a 2D matrix or tensor with dimensions equal to `n_input` and `n_hidden_1`
    using `tf.random_normal`, which fills a tensor with randomly distributed data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Then we create the model by multiplying the weights and biases for each layer
    operation. What we are doing here is essentially converting our activation equation
    into a matrix/tensor of equations. Now instead of doing a single pass, we perform
    multiple passes in one operation using matrix/tensor multiplication. This allows
    us to run multiple training images or sets of data at a time, which is a technique
    we use to better generalize learning.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each layer in our neural network, we use `tf.add` and `tf.matmul` to add
    matrix multiplication operations to what we commonly call a **TensorFlow inference
    graph**. You can see by the code we are creating that there are two hidden layers
    and one output layer for our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define a `loss` function and optimizer. `loss_op` is used to calculate
    the total loss of the network. Then `AdamOptimizer` is what does the optimizing
    according to the `loss` or `cost` function. We will explain these terms in detail
    later, so don''t worry if things are still fuzzy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we initialize a new TensorFlow session by creating a new session and running
    it. We use that epoch iterative training method again to loop over each batch
    of images. Remember, an entire batch of images goes through the network at the
    same time, not just one image. Then, we loop through each batch of images in each
    epoch and optimize (backpropagate and train) the cost, or minimize the cost if
    you will:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we output the results of each epoch run, showing how the network is minimizing
    the error:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we actually run the prediction with the preceding code and determine
    the percentage of correct values using the optimizer we selected before on the
    `logits` model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we calculate and output the `accuracy` of our model. If you run the
    exercise, don't just go into how accurate the model is but think of ways the accuracy
    could be improved.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There is plenty going on in the preceding reference example, and we will break
    it down further in the next sections. Hopefully, you can see at this point how
    complex things can get. This is why for most of the fundamental chapters in this
    book, we will teach the concepts with Keras first. Keras is a powerful and simple
    framework that will help us build complex networks in no time and makes it much
    simpler for us to teach and for you to learn. We will also provide duplicate examples
    developed in TensorFlow and show some of the key differences as we progress through
    the book.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we explain the basic concepts of TensorFlow, what it is,
    and how we use it.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow Basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**TensorFlow** (**TF**) is quickly becoming the technology that powers many
    DL applications. There are other APIs, such as Theano, but it is the one that
    has gathered the greatest interest and mostly applies to us. Overarching frameworks,
    such as Keras, offer the ability to deploy TF or Theano models, for instance.
    This is great for prototyping and building a quick proof of concept, but, as a
    game developer, you know that when it comes to games, the dominant requirements
    are always performance and control. TF provides better performance and more control
    than any higher-level framework such as Keras. In other words, to be a serious
    DL developer, you likely need and want to learn TF.'
  prefs: []
  type: TYPE_NORMAL
- en: TF, as its name suggests, is all about tensors. A tensor is a mathematical concept
    that describes a set of data organized in *n* dimensions, where *n* could be 1,
    2 x 2, 4 x 4 x 4, and so on. A one-dimensional tensor would describe a single
    number, say ![](img/6fa7dde2-1b00-44af-8f4c-041e252a6be9.png), a 2 x 2 tensor
    would be![](img/7077b58d-f2f0-4f9e-843e-fe60c0e44cfe.png)or what you may refer
    to as a matrix. A 3 x 3 x 3 tensor would describe a cube shape. Essentially, any
    operation that you would apply on a matrix can be applied to a tensor and everything
    in TF is a tensor. It is often helpful when you first start working with tensors,
    as someone with a game development background, to think of them as a matrix or
    vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tensors are nothing more than multidimensional arrays, vectors, or matrices,
    and many examples are shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/971d6c2e-1fa2-4e56-8d3b-7410e1ab3118.png)'
  prefs: []
  type: TYPE_IMG
- en: Tensor in many forms (placeholder)
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go back and open up `Chapter_1_4.py` and follow the next steps in order
    to better understand how the TF example runs:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, examine the top section again and pay special attention to where the
    placeholder and variable is declared; this is shown again in the following snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The `placeholder` is used to define the input and output tensors. `Variable`
    sets up a variable tensor that can be manipulated while the TF session or program
    executes. In the case of the example, a helper method called `random_normal` populates
    the hidden weights with a normally distributed dataset. There are other helper
    methods such as this that can be used; check the docs for more info.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we construct the `logits` model as a function called `multilayer_perceptron`, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Inside the function, we see the definition of three network layers, two input
    and one output. Each layer is constructed by using the add or `+` function to
    add the results of the `matmul (x, weights['h1'])` and the `biases['b1']`. `Matmul`
    does a simple matrix multiplication of each weight times the input *x*. Think
    back to our first example perceptron; this is the same as multiplying all our
    weights by the input and then adding the bias. Note how the resultant tensors
    `(layer_1, layer_2)` are used as inputs into the following layer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Skip down to around line 50 and note how we grab references to the `loss`,
    `optimizer`, and `initialization` functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: It is important to understand that we are storing references to the functions
    and not executing them just yet. The loss and optimizer functions have been covered
    in some depth already, but also pay special attention to the `global_variables_initalizer()`
    function. This function is where all the variables are initialized, and we are
    required to run this function first.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, scroll down to the start of the session initialization and start, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We construct `Session` in TF as a container of execution or what is called a
    graph. This is a mathematical graph that describes nodes and connections, not
    that unlike the networks we are simulating. Everything in TF needs to happen within
    a session. Then we run the first function, `(init)`, with `run`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As we have already covered the training in some detail, the next element we
    will look at is the next function, `run`, executed by the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: A lot is going on in the `run` function. We input as a set the training and
    loss functions `train_op` and `loss_op` using the current `feed_dict` dictionary
    as input. The resultant output value, `c`, is equal to the total cost. Note that
    the input function set is defined as `train_op` then `loss_op`. In this case,
    the order is defined as `train`/`loss`, but it could be also reversed if you choose.
    You would also need to reverse the output values as well, since the output order
    matches the input order.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The rest of the code has already been defined in some detail, but it is important
    to understand some of the key differences when building your models with TF. As
    you can see, it is relatively easy for us to now build complex neural networks
    quickly. Yet, we are still missing some critical knowledge that will be useful
    in constructing more complex networks later. What we have been missing is the
    underlying math used to train a neural network, which we will explore in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Training neural networks with backpropagation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Calculating the activation of a neuron, the forward part, or what we call **feed-forward
    propagation**, is quite straightforward to process. The complexity we encounter
    now is training the errors back through the network. When we train the network
    now, we start at the last output layer and determine the total error, just as
    we did with a single perceptron, but now we need to sum up all errors across the
    output layer. Then we need to use this value to backpropagate the error back through
    the network, updating each of the weights based on their contribution to the total
    error. Understanding the contribution of a single weight in a network with thousands
    or millions of weights could be quite complicated, except thankfully for the help
    of differentiation and the chain rule. Before we get to the complicated math,
    we first need to discuss the `Cost` function and how we calculate errors in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: While the math of backpropagation is complicated and may be intimidating, at
    some point, you will want or need to understand it well. However, for the purposes
    of this book, you can omit or just revisit this section as needed. All the networks
    we develop in later chapters will automatically handle backpropagation for us.
    Of course, you can't run away from the math either; it is everywhere in deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: The Cost function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A `Cost` function describes the average sum of errors for a batch in our entire
    network and is often defined by this equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/17490b69-202e-4ae1-bdb0-45b96d921c7f.png)'
  prefs: []
  type: TYPE_IMG
- en: The input is defined as each weight and the output is the total average cost
    we encountered over the processed batch. Think of this cost as the average sum
    of errors. Now, our goal here is to minimize this function or the cost of errors
    to the lowest value possible. In the previous couple of examples, we have seen
    a technique called **gradient descent** being used to minimize this cost function.
    Gradient descent works by differentiating the `Cost` function and determining
    the gradient with respect to each weight. Then, for each weight, or dimension
    if you will, the algorithm alters the weight based on the calculated gradient
    that minimizes the `Cost` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we get into the heavy math that explains the differentiation, let''s
    see how gradient descent works in two dimensions, with the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c32e3474-a1e4-4d14-9c54-0c9cb5b6d698.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of gradient descent finding a global minimum
  prefs: []
  type: TYPE_NORMAL
- en: In simpler terms, all that the algorithm is doing is just trying to find the
    minimum in slow gradual steps. We use small steps in order to avoid overshooting
    the minimum, which as you have seen earlier can happen (remember the wobble).
    That is where the term **learning rate** also comes in, which determines how fast
    we want to train. The slower the training, the more confident you will be in your
    results, but usually at a cost of time. The alternative is to train quicker, using
    a higher learning rate, but, as you can see now, it may be easy to overshoot any
    global minimum.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent is the simplest form we will talk about, but keep in mind that
    there are also several advanced variations of other optimization algorithms we
    will explore. In the TF example, for instance, we used `AdamOptimizer` to minimize
    the `Cost` function, but there are several other variations. For now, though,
    we will focus on how to calculate the gradient of the `Cost` function and understand
    the basics of backpropagation with gradient descent in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Partial differentiation and the chain rule
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we get into the details of calculating each weight, let''s review a
    little bit of calculus and differentiation. If you recall your favorite math class,
    calculus, you can determine the slope of change for any point on a function by
    differentiating. A calculus refresher is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c72438b-cc34-4723-9e40-cee35840839a.png)'
  prefs: []
  type: TYPE_IMG
- en: A review of basic calculus equations
  prefs: []
  type: TYPE_NORMAL
- en: In the diagram, we have a nonlinear function, **f**, that describes the equation
    of the blue line. We can determine the slope (rate of change) on any point by
    differentiating to f' and solving. Recall that we can also determine the functions
    of local and global minimum or maximum using this new function and as shown in
    the diagram. Simple differentiation allows us to solve for one variable, but we
    need to solve for multiple weights, so we will use partial derivatives or differentiating
    with respect to one variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you may recall, partial differentiation allows us to derive for a single
    variable with respect to the other variables, which we then treat as constants.
    Let''s go back to our `Cost` function and see how to differentiate that with respect
    to a single weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '*![](img/540eed90-acc5-4e90-9e5f-5a4a2da7a90f.png)* is our cost function described
    by the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/de02ffdb-0412-45e9-bdc9-d1b72f38f618.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can differentiate this function with respect to a single variable weight
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/80566a95-aafa-43b8-ba8a-9bc0d258169e.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/cc8b62c3-a3dd-4c94-9ff8-fc11d9a2a622.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we collect all of these partial derivatives together, we get the vector
    gradient for our `Cost` function, ![](img/0fb9abc8-223f-4fa3-96a3-b025e13774ac.png), denoted
    by the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/50074553-fd8d-432d-9d74-20562d73b5d4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This gradient defines a vector direction that we want to negate and use to
    minimize the `Cost` function. In the case of our previous example, there are over
    13,000 components to this vector. These correspond to over 13,000 weights in the
    network that we need to optimize. That is a lot of partial derivatives we need
    to combine in order to calculate the gradient. Fortunately, the chain rule in
    calculus can come to our rescue and greatly simplify the math. Recall that the
    chain rule is defined by the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/405bae41-bd8e-43fa-b46c-1be1b4d0657d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This now allows us to define the gradient for a single weight using the chain
    rule as such:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/95d4ef61-83e7-4680-b338-2637ad32a9df.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/237b0114-cc6f-4cb2-b9ca-f527d882243a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/53d1990c-21bb-4d13-97a4-d69c40d87558.png) represents the input
    number and ![](img/d7bf0016-5adf-4f73-88c6-a93ebacf1caa.png) the neuron position.
    Note how we now need to take the partial derivative of the activation function, *a*, for
    the given neuron, and that is again summarized by the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4ed6a86d-bbe9-435e-8490-8e05e0d56102.png)'
  prefs: []
  type: TYPE_IMG
- en: The superscript notation ![](img/674a1fc1-17c6-4627-a679-e4a020bc511c.png) denotes
    the current layer and ![](img/7768eb39-9ec9-40af-b61a-bd226e3544ca.png) denotes
    the previous layer. ![](img/b73cb21f-571d-4923-a76b-f6227090187d.png) denotes
    either the input or the output from the previous layer. ![](img/5b84bf4a-5db8-43b0-bcb0-d8a9531484ee.png) denotes
    the activation function, recall that we previously used the `Step` and `ReLU`
    functions for this role.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we take the partial derivative of this function, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2b7fef57-c426-4338-b802-fe934fdf278a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For convenience, we define the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e26b112d-5a95-468a-9e28-291bcd88df10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'At this point, things may look a lot more complicated than they are. Try to
    understand all the subtleties of the notation and remember all we are looking
    at is essentially the partial derivative of the activation with respect to the
    `Cost` function. All that the extra notation does is allow us to index the individual
    weight, neuron, and layer. We can then express this as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/700a7c49-24b2-4c81-81ac-1660a520c017.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Again, all we are doing is defining the gradient (![](img/c7be7304-2015-4fb0-bce6-d80275794496.png))
    for the weight at the ![](img/625ab8a1-2e70-4937-95b8-1ac620c209c5.png)^(th) input,
    ![](img/aa2eb4de-35af-441a-b21a-eedb4d796372.png)^(th) neuron, and layer ![](img/3fb99529-b043-4057-8400-e4d5924454df.png).
    Along with gradient descent, we need to backpropagate the adjustment to the weights
    using the preceding base formula. For the output layer (last layer), this now
    can be summarized as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a7244943-32ae-4e8c-8a70-5bdef000f42c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For an internal or a hidden layer, the equation comes out to this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/018674a5-8d61-42fd-a036-427bf65bab66.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And with a few more substitutions and manipulations of the general equation,
    we end up with this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6318bfc0-51f2-486e-ab6e-c87bc93d5e67.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *f'* denotes the derivative of the activation function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding equation allows us to run the network and backpropagate the errors
    back through, using the following procedure:'
  prefs: []
  type: TYPE_NORMAL
- en: You first calculate the activations ![](img/12a18170-2428-4904-bbc5-71fcfc00cffd.png) and ![](img/c475dd78-297d-41ea-99f8-582ae07a5009.png) for
    each layer starting with the input layer and propagate forward.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We then evaluate the term ![](img/4cad7f38-ff20-4529-a65a-046d1ca4dd6d.png)at
    the output layer using ![](img/abb13af1-a57e-435b-95b2-e8bd980a33ab.png).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We do this by using the remainder to evaluate each layer using ![](img/3a68e2e9-7e67-4bdc-9919-75611c86fe29.png), starting
    with the output layer and propagating backward.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Again, we are using the partial derivative ![](img/3fcd1213-41e8-4d5d-b7b9-2a737e0b210c.png) to
    obtain the required derivatives in each layer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It may take you a few reads through this section in order to grasp all the concepts.
    What can also be useful is to run the previous examples and watch the training,
    trying to imagine how each of the weights is getting updated. We are by no means
    completely done here, and there are a couple more steps—using automatic differentiation
    being one of them. Unless you are developing your own low-level networks, just
    having a basic understanding of that math should give you a better understanding
    of the needs in training a neural network. In the next section, we get back to
    some more hands-on basics and put our new knowledge to use by building a neural
    network agent.
  prefs: []
  type: TYPE_NORMAL
- en: Learning does not and likely should not all come from the same source. Be sure
    to diversify your learning to other books, videos, and courses. You will not only
    be more successful in learning but likely also understand more in the process.
  prefs: []
  type: TYPE_NORMAL
- en: Building an autoencoder with Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While we have covered a lot of important ground we will need for understanding
    DL, what we haven''t done yet is build something that can really do anything.
    One of the first problems we tackle when starting with DL is to build autoencoders
    to encode and reform data. Working through this exercise allows us to confirm
    that what goes into a network can also come back out of a network and essentially
    reassures us that an ANN is not a complete black box. Building and working with
    autoencoders also allows us to tweak and test various parameters in order to understand
    their function. Let''s get started by opening up the `Chapter_1_5.py` listing
    and following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will go through the listing section by section. First, we input the base
    layers `Input` and `Dense`, then `Model`, all from the `tensorflow.keras` module,
    with the following imports:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Instead of single neurons, we define our DL model in Keras using layers or neurons.
    The `Input` and `Dense` layers are the most common ones we use, but we will see
    others as well. As their name suggests, `Input` layers deal with input, while
    `Dense` layers are more or less your typical fully connected neuron layer, which
    we have already looked at.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We are using the embedded version of Keras here. The original sample was taken
    from the Keras blog and converted to TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we set the number of `encoding` dimensions with the following line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the number of dimensions we want to reduce our sample down to. In this
    case, it is just 32, which is just around 24 times the compression for an image
    with 784 input dimensions. Remember, we get `784` input dimensions because our
    input images are 28 x 28, and we flatten them to a vector of length 784, with
    each pixel representing a single value or dimension. Next, we set up the `Input` layer
    with the 784 input dimensions with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'That line creates an `Input` layer with a shape of 784 inputs. Then we are
    going to encode those 784 dimensions into our next `Dense` layer using the following
    line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code simply creates our fully connected hidden (`Dense`) layer
    of 32 (`encoding_dim`) neurons and builds the encoder. You can see that the `input_img`,
    the `Input` layer, is used as input and our activation function is `ReLU`. The
    next line constructs a `Model` using the `Input` layer (`input_img`) and the `Dense`
    (`encoded`) layer. With two layers, we encode the image from 784 dimensions to
    32.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we need to decode the image using more layers with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The next set of layers and model we build will be used to decode the images
    back to 784 dimensions. The last line of code at the bottom is where we compile
    the `autoencoder` model with an `adadelta` optimizer call, using a `loss` function
    of `binary_crossentropy`. We will spend more time on the types of loss and optimization
    parameters later, but for now just note that when we compile a model, we are in
    essence just setting it up to do backpropagation and use an optimization algorithm.
    Remember, all of this is automatically done for us, and we don't have to deal
    with any of that nasty math.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That sets up the main parts of our models, the encoder, decoder, and full autoencoder
    model, which we further compiled for later training. In the next section, we deal
    with training the model and making predictions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Training the model
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, we need to train our model with a sample set of data. We will again be
    using the MNIST set of handwritten digits; this is easy, free, and convenient.
    Get back into the code listing and continue the exercise as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Pick up where we left off and locate the following section of code:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We start by importing the `mnist` library and `numpy` then loads the data into
    `x_train` and `x_test` sets of data. As a general rule in data science and machine
    learning, you typically want a training set for learning and then an evaluation
    set for testing. These datasets are often generated by randomly splitting the
    data into `80` percent for training and `20` percent for testing.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then we further define our training and testing inputs with the following code:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The first two lines are normalizing our input gray scale pixel color values
    and a number from `0` to `255`, by dividing by `255`. This gives us a number from
    `0` to `1`. We generally want to try to normalize our inputs. Next, we reshape
    the training and testing sets into an input `Tensor`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With the models all built and compiled, it is time to start training. The next
    few lines are where the network will learn how to encode and decode the images:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can see in our code that we are setting up to fit the data using `x_train`
    as input and output. We are using `50` `epochs` with a `batch size` of `256` images.
    Feel free to play with these parameters on your own later to see what effect they
    have on training. After that, the `encoder` and then the `decoder` models are
    used to predict test images.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: That completes the model and training setup we need for this model, or models
    if you will. Remember, we are taking a 28 x 28 image, decompressing it to essentially
    32 numbers, and then rebuilding the image using a neural network. With our model
    complete and trained this time, we want to review the output and we will do that
    in the next section.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Examining the output
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our final step this time around will be to see what is actually happening with
    the images. We will finish this exercise by outputting a small sample of images
    in order to get our success rate. Follow along in the next exercise in order to
    finish the code and run the autoencoder:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Continuing from the last exercise, locate the following last section of code:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this section of code, we are just outputting the input and resultant auto-encoded
    images after all the training is done. This section of code starts with importing
    `mathplotlib` for plotting, and then we loop through a number of images to display
    the results. The rest of the code just outputs the images.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the Python code as you normally would, and this time expect the training
    to take several minutes. After everything is done, you should see an image similar
    to the following:![](img/57c7b3de-945e-42fb-af0a-cf5258f7f7f5.png)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Example of raw input images compared to encoded and decoded output images
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: That completes our look into building a simple Keras model that can encode and
    then decode images. This allows us to see how each small piece of a multilayer
    neural network is written in Keras functions. In the final section, we invite
    you, the reader, to undertake some additional exercises for further learning.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: Use these additional exercises to assist in your learning and test your knowledge
    further.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Answer the following questions:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Name three different activation functions. Remember, Google is your friend.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of a bias?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What would you expect to happen if you reduced the number of epochs in one of
    the chapter samples? Did you try it?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of backpropagation?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain the purpose of the Cost function.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What happens when you increase or decrease the number of encoding dimensions
    in the Keras autoencoder example?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the name of the layer type that we feed input into?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What happens when you increase or decrease the batch size?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'What is the shape of the input `Tensor` for the Keras example? Hint: we already
    have a print statement displaying this.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In the last exercise, how many MNIST samples do we train and test with?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: As we progress in the book, the additional exercises will certainly become more
    difficult. For now, though, take some time to answer the questions and test your
    knowledge.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the foundations of DL from the basics of the simple
    single perceptron to more complex multilayer perceptron models. We started with
    the past, present, and future of DL and, from there, we built a basic reference
    implementation of a single perceptron so that we could understand the raw simplicity
    of DL. Then we built on our knowledge by adding more perceptrons into a multiple
    layer implementation using TF. Using TF allowed us to see how a raw internal model
    is represented and trained with a much more complex dataset, MNIST. Then we took
    a long journey through the math, and although a lot of the complex math was abstracted
    away from us with Keras, we took an in-depth look at how gradient descent and
    backpropagation work. Finally, we finished off the chapter with another reference
    implementation from Keras that featured an autoencoder. Auto encoding allows us
    to train a network with multiple purposes and extends our understanding of how
    network architecture doesn't have to be linear.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For the next chapter, we will build on our current level of knowledge and discover
    **convolutional** and **recurrent** neural networks. These extensions provide
    additional capabilities to the base form of a neural network and have played a
    significant part in our most recent DL advances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For the next chapter, we will begin our journey into building components for
    games when we look at another element considered foundational to DL—the GAN. GANs
    are like a Swiss Army knife in DL and, as we will see in the next chapter, they
    offer us plenty of uses.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
