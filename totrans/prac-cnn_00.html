<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Preface</h1>
                </header>
            
            <article>
                
<p class="mce-root">CNNs are revolutionizing several application domains, such as visual recognition systems, self-driving cars, medical discoveries, innovative e-commerce, and many more. This book gets you started with the building blocks of CNNs, while also guiding you through the best practices for implementing real-life CNN models and solutions. You will learn to create innovative solutions for image and video analytics to solve complex machine learning and computer vision problems.</p>
<p class="mce-root">This book starts with an overview of deep neural networks, with an example of image classification, and walks you through building your first CNN model. You will learn concepts such as transfer learning and autoencoders <span>with CNN that will enable you </span>to build very powerful models, even with limited supervised (<span>labeled image</span>) training data.</p>
<p class="mce-root">Later we build upon these learnings to achieve advanced vision-related algorithms and solutions for object detection, instance segmentation, generative (adversarial) networks, image captioning, attention mechanisms, and recurrent attention models for vision.<br/>
Besides giving you hands-on experience with the most intriguing vision models and architectures, this book explores cutting-edge and very recent researches in the areas of CNN and computer vision. This enable the user to foresee the future in this field and quick-start their innovation journey using advanced CNN solutions.<br/>
By the end of this book, you should be ready to implement advanced, effective, and efficient CNN models in your professional projects or personal initiatives while working on complex images and video datasets.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Who this book is for</h1>
                </header>
            
            <article>
                
<p>This book is for data scientists, machine learning, and deep learning practitioners, and cognitive and artificial intelligence enthusiasts who want to move one step further in building CNNs. Get hands-on experience with extreme datasets and different CNN architectures to build efficient and smart ConvNet models. Basic knowledge of deep learning concepts and Python programming language is expected.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What this book covers</h1>
                </header>
            
            <article>
                
<p><a href="e445fc26-1e0e-45c8-bda2-8f389327364c.xhtml">Chapter 1</a>, <em>Deep Neural Networks - Overview</em><span>, it gives a quick refresher of the science of deep neural networks and different frameworks that can be used to implement such networks, with the mathematics behind them.<br/></span></p>
<p><a href="00f0eb08-6d6c-48b7-8ffe-db69c7f90a73.xhtml">Chapter 2</a>, <em>Introduction to Convolutional Neural Networks</em><span>, it introduces the readers to convolutional neural networks and shows how deep learning can be used to extract insights from images.</span></p>
<p><a href="8f3b65a2-d0d7-41a3-8a4f-c437aff3b3cf.xhtml">Chapter 3</a>, <em>Build Your First CNN and Performance Optimization</em><span>, constructs a simple CNN model for image classification from scratch, and explains how to tune hyperparameters and optimize training time and performance of CNNs for improved efficiency and accuracy respectively.</span></p>
<p><a href="d3aa1148-06d7-486e-bb3f-18fbd813e669.xhtml">Chapter 4</a>, <em>Popular CNN Model Architectures</em><span>, shows the advantages and working of different popular (and award winning) CNN architectures, how they differ from each other, and how to use them.</span></p>
<p><a href="6a8cae59-d4a9-42f8-9f3e-c4bade2a7b5c.xhtml">Chapter 5</a>, T<em>ransfer Learning</em><span>, teaches you to take an existing pretrained network and adapt it to a new and different dataset. There is also a custom classification problem for a real-life application using a technique called <strong>transfer learning</strong>.</span></p>
<p><a href="67b987dc-4122-46e9-9b14-94896467b7c1.xhtml">Chapter 6</a>, A<em>utoencoders for CNN</em><span>, introduces an unsupervised learning technique called <strong>autoencoders</strong>. We walk through different applications of autoencoders for CNN, such as image compression.</span></p>
<p><a href="20952d99-3977-420f-a5c7-a3320b96bed6.xhtml">Chapter 7</a>, <em>Object Detection and Instance Segmentation with CNN</em><span>, teaches the difference between object detection, instance segmentation, and image classification. We then learn multiple techniques for object detection and instance segmentation with CNNs.</span></p>
<p><a href="46a7bb81-0577-4e79-9edb-caff5a3a8201.xhtml">Chapter 8</a>, <em>GAN—Generating New Images with CNN</em><span>, explores generative CNN Networks, and then we combine them with our learned discriminative CNN networks to create new images with CNN/GAN.</span></p>
<p><a href="a5fbee93-c253-4a80-b51d-b03f6edf621e.xhtml">Chapter 9</a>, <em>Attention Mechanism for CNN and Visual Models</em><span>, teaches the intuition behind attention in deep learning and learn how attention-based models are used to implement some advanced solutions (image captioning and RAM). We also understand the different types of attention and the role of reinforcement learning with respect to the hard attention mechanism. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">To get the most out of this book</h1>
                </header>
            
            <article>
                
<p>This book is focused on building CNNs with Python programming language. We have used Python version 2.7 (2x) to build various applications and the open source and enterprise-ready professional software using Python, Spyder, Anaconda, and PyCharm. Many of the examples are also compatible with Python 3x. As a good practice, we encourage users to use Python virtual environments for implementing these codes.</p>
<p>We focus on how to utilize various Python and deep learning libraries (Keras, TensorFlow, and Caffe) in the best possible way to build real-world applications. In that spirit, we have tried to keep all of the code as friendly and readable as possible. We feel that this will enable our readers to easily understand the code and readily use it in different scenarios.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the example code files</h1>
                </header>
            
            <article>
                
<p>You can download the example code files for this book from your account at <a href="http://www.packtpub.com">www.packtpub.com</a>. If you purchased this book elsewhere, you can visit <a href="http://www.packtpub.com/support">www.packtpub.com/support</a> and register to have the files emailed directly to you.</p>
<p>You can download the code files by following these steps:</p>
<ol>
<li>Log in or register at <a href="http://www.packtpub.com/support">www.packtpub.com</a>.</li>
<li>Select the <span class="packt_screen">SUPPORT</span> tab.</li>
<li>Click on <span class="packt_screen">Code Downloads &amp; Errata</span>.</li>
<li>Enter the name of the book in the <span class="packt_screen">Search</span> box and follow the onscreen instructions.</li>
</ol>
<p>Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p>
<ul>
<li>WinRAR/7-Zip for Windows</li>
<li>Zipeg/iZip/UnRarX for Mac</li>
<li>7-Zip/PeaZip for Linux</li>
</ul>
<p><span>The code bundle for the book is also hosted on GitHub at</span><span> </span><a href="https://github.com/PacktPublishing/Practical-Convolutional-Neural-Networks" target="_blank"><span class="Object">https://github.com/PacktPublishing/Practical-Convolutional-Neural-Networks</span></a><span>. </span><span>In case there's an update to the code, it will be updated on the existing GitHub repository.<br/></span></p>
<p><span>We also have other code bundles from our rich catalog of books and videos available at</span><span> </span><strong><span class="Object"><a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a></span></strong><span>. Check them out!</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the color images</h1>
                </header>
            
            <article>
                
<p>We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a href="http://www.packtpub.com/sites/default/files/downloads/PracticalConvolutionalNeuralNetworks_ColorImages.pdf" target="_blank">http://www.packtpub.com/sites/default/files/downloads/PracticalConvolutionalNeuralNetworks_ColorImages.pdf</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conventions used</h1>
                </header>
            
            <article>
                
<p>There are a number of text conventions used throughout this book.</p>
<p><kbd>CodeInText</kbd>: <span>Indicates c</span>ode words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. <span>Here is an example:</span> "Mount the downloaded <kbd>WebStorm-10*.dmg</kbd> disk image file as another disk in your system."</p>
<p>A block of code is set as follows:</p>
<pre><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment">#Creating TensorFlow object </span>
hello_constant = tf.constant(<span class="hljs-string">'Hello World!', name = 'hello_constant'</span>)
#Creating a session object for execution of the computational graph
<span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:</pre>
<p>When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:</p>
<pre class="mce-root">x = tf.subtract(1, <strong>2</strong>,name=None) # -1<br/>y = <strong>tf.multiply</strong>(2, 5,name=None) # 10</pre>
<p><strong>Bold</strong>: Indicates a new term, an important word, or w<span>ords that you see onscreen. For example, words in menus or dialog boxes appear in the text like this. Here is an example: "Select <span class="packt_screen">System info</span> from the <span class="packt_screen">Administration</span> panel.</span><span>"</span></p>
<div class="packt_infobox">Warnings or important notes appear like this.</div>
<div class="packt_tip">Tips and tricks appear like this.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Get in touch</h1>
                </header>
            
            <article>
                
<p>Feedback from our readers is always welcome.</p>
<p class="mce-root"><strong>General feedback</strong>: Email <kbd>feedback@packtpub.com</kbd> and mention the book title in the subject of your message. If you have questions about any aspect of this book, please email us at <kbd>questions@packtpub.com</kbd>.</p>
<p><strong>Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packtpub.com/submit-errata">www.packtpub.com/submit-errata</a>, selecting your book, clicking on the Errata Submission Form link, and entering the details.</p>
<p><strong>Piracy</strong>: If you come across any illegal copies of our works in any form on the Internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <kbd>copyright@packtpub.com</kbd> with a link to the material.</p>
<p class="mce-root"><strong>If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com/">authors.packtpub.com</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reviews</h1>
                </header>
            
            <article>
                
<p>Please leave a review. Once you have read and used this book, why not leave a review on the site that you purchased it from? Potential readers can then see and use your unbiased opinion to make purchase decisions, we at Packt can understand what you think about our products, and our authors can see your feedback on their book. Thank you!</p>
<p>For more information about Packt, please visit <a href="https://www.packtpub.com/">packtpub.com</a>.<a href="https://www.packtpub.com/"/></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </body></html>