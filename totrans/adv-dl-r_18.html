<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Tips, Tricks, and the Road Ahead</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this book, we covered how to apply various deep learning networks to develop prediction and classification models. Several tips and tricks that we covered were unique to certain application areas and helped us arrive at better prediction or classification performance for the models that we developed.</p>
<p class="mce-root">In this chapter, we will go over certain tips and tricks that will be very handy when you continue your journey of applying these methods to new data and different problems. We will cover four topics in total. Note that these approaches haven't been covered in the previous chapters, but we will make use of some of the examples from them to illustrate their use.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>TensorBoard for training performance visualization</li>
<li>Visualizing deep network models with LIME</li>
<li>Visualizing model training with tfruns</li>
<li>Early stopping of network training</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">TensorBoard for training performance visualization</h1>
                </header>
            
            <article>
                
<p>For visualizing deep network training performance, TensorBoard is a useful tool that is available as part of the TensorFlow package. We will rerun the deep network model that we used in <a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">Chapter 2</a>, <em>Deep Neural Networks for Multi-Class Classification</em>, where we used CTG data to develop a multi-class classification model for patients. For the code related to data processing, the model architecture, and compiling the model, you can refer to <a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">Chapter 2</a><span>, </span><em>Deep Neural Networks for Multi-Class Classification</em>.</p>
<p>The following is the code for <kbd>model_one</kbd> from <a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">Chapter 2</a><span>, </span><em>Deep Neural Networks for Multi-Class Classification</em>:</p>
<pre># Fitting model and TensorBoard<br/>setwd("~/Desktop/")<br/>model_one &lt;- model %&gt;% fit(training, <br/>                         trainLabels, <br/>                         epochs = 200,  <br/>                         batch_size = 32,<br/>                         validation_split = 0.2,<br/>                         callbacks = callback_tensorboard('ctg/one'))<br/>tensorboard('ctg/one')</pre>
<p>From the preceding code, we can observe the following:</p>
<ul>
<li>We have set a working directory, which will be the desktop where the results of training the model will be stored for visualization on TensorBoard.</li>
<li>The model is fit using additional feature callbacks, where we use the <kbd>callback_tensorboard</kbd> function to store data in the <kbd>ctg/one</kbd> folder on the desktop for visualization later.</li>
<li>Note that the <kbd>ctg</kbd> directory is automatically created at the time of fitting the model.</li>
<li>Finally, the <kbd>tensorboard</kbd> function is used for visualization using data stored in the <kbd>ctg/one</kbd> folder.</li>
</ul>
<p>The following screenshot is of TensorBoard:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/168b0adc-e8e8-4b73-8638-39038396e058.png"/></p>
<p>The preceding screenshot shows the loss and accuracy plots for the training and validation data for 200 epochs. This was used for training the model. This visualization on TensorBoard is interactive in nature and provides the user with additional options so that they can explore and understand the model performance's during the training process.</p>
<p>As we have seen in all the chapters in this book that have illustrated the use of various deep learning methods, improving the performance of a classification or prediction model involves extensive experimentation. To help with such experimentation, one of the key benefits of using a TensorBoard is that it allows model performance to be compared very easily using interactive visualization.</p>
<p>We ran three more models from <a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">Chapter 2</a>, <em>Deep Neural Networks for Multi-Class Classification</em>, and stored model training data within subfolders <kbd>two</kbd>, <kbd>three</kbd>, and <kbd>four</kbd> of the <kbd>ctg</kbd> folder. Run the following code for TensorBoard visualization:</p>
<pre># TensorBoard visualization for multiple models<br/>tensorboard(c('ctg/one', 'ctg/two', 'ctg/three', 'ctg/four'))</pre>
<p>The preceding code creates TensorBoard visualizations for all four models. A screenshot of the resulting TensorBoard page is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a6774e36-15d5-47be-acb2-9b3164f5ecee.png"/></p>
<p>The preceding visualization shows the loss and accuracy values for the training and validation data for all four models. The following are some observations that we can make about this plot:</p>
<ul>
<li>The results for the four models that were run are presented in different colors to allow us to quickly identify them and make comparisons.</li>
<li>The loss and accuracy values based on the validation data show higher variability in the results compared to what can be observed by the training data.</li>
<li>An option to download any plot or related data is also provided.</li>
</ul>
<p>The ability to visualize different models with different parameter values can be useful when we're making choices about the type of architecture to use for the deep network, the number of epochs, the batch size, and other model-related attributes that are of interest. It can also provide us with directions for further experimentation if needed and help us compare current and past results.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Visualizing deep network models with LIME</h1>
                </header>
            
            <article>
                
<p>In the application examples that we've provided so far in this book, after we developed a classification or prediction deep network model, we carried out visualizations to view the overall performance of the models. These assessments are done using training and test data. The main idea behind such an assessment is to obtain an overall or global understanding of the model's performance. However, there are situations where we want to obtain a deeper understanding and also interpretations for a specific prediction. For example, we may be interested in understanding the main features or variables that have influenced a specific prediction in the test data. Such "local" interpretations are the focus of a package called <strong>Local Interpretable Model-Agnostic Explanations</strong>, or <strong>LIME</strong>. LIME can help provide deeper insights into each prediction.</p>
<p>The code for carrying out visualization using LIME for the model we developed in Keras is as follows:</p>
<pre># LIME package<br/>library(lime)<br/><br/># Using LIME with keras<br/>model_type.keras.engine.sequential.Sequential &lt;- <br/>function(x, ...) {"classification"}<br/>predict_model.keras.engine.sequential.Sequential &lt;- <br/>  function(x,newdata,type, ...) {p &lt;- predict_proba(object=x, x=as.matrix(newdata))<br/>         data.frame(p)}<br/><br/># Create explainer using lime<br/>explainer &lt;- lime(x = data.frame(training), <br/>             model = model, <br/>             bin_continuous = FALSE)<br/><br/># Create explanation<br/>explanation &lt;- explain(data.frame(test)[1:5,],  <br/>                  explainer    = explainer, <br/>                  n_labels     = 1,  <br/>                  n_features   = 4,  <br/>                  kernel_width = 0.5)<br/>testtarget[1:5]<br/>[1] 0 0 0 2 2</pre>
<p>As shown in the preceding code, we use two functions to be able to use LIME with the Keras model. In the first function, we indicate that we will be working with a classification model. The second function obtains prediction probabilities. In this section, we will use <kbd>model_one</kbd> from <a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">Chapter 2</a><span>, </span><em>Deep Neural Networks for Multi-Class Classification</em>. Then, we'll use the <kbd>lime</kbd> function with the training data, the model (that is, <kbd>model_one</kbd>), and specify the binning of continuous variables as <kbd>FALSE</kbd>. The resulting explainer is used with the <kbd>explain</kbd> function, where we will specify the number of labels to use as one and specify the number of most important features to use for each case as four. We specify the kernel width as 0.5. We can also see that the first three patients in the test data have the class labeled as 0, indicating that they belong to the normal patient category. Similarly, the 4th and 5th patients in the test data have been labeled as 2, indicating that they belong to the pathological patient category.</p>
<p>We obtained the following plot using <kbd>plot_features(explanation)</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/bbe08ddc-d37e-47b8-9e18-5da306e3e34c.png"/></p>
<p>The preceding plot provides individual plots for the first five patients in the test data. Here are some of the observations that can be made from this plot:</p>
<ul>
<li>All five patients have been correctly classified.</li>
<li>The first three patients have been classified as belonging to a class labeled as 0, representing a normal patient.</li>
</ul>
<ul>
<li>The remaining two patients are classified as belonging to a class labeled as 2, representing a pathological patient.</li>
<li>The prediction probability for the first three cases is 0.97 or above and the prediction probability for the 4th and 5th patients is 0.72 and above.</li>
<li>This plot depicts the four most important features that have contributed to the specific classification of each patient.</li>
<li>Features with blue bars support the model's conclusion, whereas features with red bars contradict the model's conclusion for each patient.</li>
<li>Higher values for the X8, X10, and X20 variables seem to have a higher influence on a patient being classified as pathological.</li>
<li>Higher values for the X12 variable seems to influence a patient being classified as normal.</li>
</ul>
<p>The following heatmap can be obtained using <kbd>plot_explanations(explanation)</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/72a2ebcc-8dd6-4cb3-addb-f361fa0fcd95.png" style="width:46.83em;height:25.75em;"/></p>
<p>We can make the following observations from the preceding heatmap:</p>
<ul>
<li>The heatmap makes comparing the different variables for each patient easier and thus helps with interpretation.</li>
<li>It summarizes the results of the case, feature, and label combination and doesn't provide as much detail as the previous plot.</li>
<li>For class-X1, or patients labeled as normal (1, 2, and 3), all four features (X8, X10, X12, and X20) have very similar weights.</li>
<li>For class-X3, or patients labeled as pathological (4 and 5), once again, all four features (X8, X10, X13, and X20) have an approximately similar weight.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Visualizing model training with tfruns</h1>
                </header>
            
            <article>
                
<p>When we run a deep network model using Keras, we can make use of <kbd>tfruns</kbd> to visualize a loss and accuracy plot, as well as other model-related summaries. Although we can also obtain the plot and related summaries when required, the main advantage of using <kbd>tfruns</kbd> is that we can obtain them all in one place. We can make use of the following code to achieve this:</p>
<pre>library(tfruns)<br/>training_run("mlp_ctg.R")</pre>
<p>In the preceding code, the <kbd>R</kbd> file that's being referenced contains the code to run <kbd>model_one</kbd> from <a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">Chapter 2</a><span>, </span><em>Deep Neural Networks for Multi-Class Classification</em>. The <kbd>mlp_ctg.R</kbd> file may be stored on the computer when we run the code. As soon as we have run the code, the following interactive screen is automatically presented:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/b1ad8926-326d-482f-bc21-a0938e178876.png"/></p>
<p>The page shown in the preceding screenshot provides the following:</p>
<ul>
<li>An interactive plot of the loss and accuracy values for the training and validation data</li>
<li>A model summary based on the model's architecture</li>
<li>Information regarding the run, including the time it took to complete all epochs</li>
<li>A numeric summary in the form of accuracy and loss, based on the training and validation data</li>
<li>The samples that were used, the number of epochs, and the batch size that was specified</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Early stopping of network training</h1>
                </header>
            
            <article>
                
<p>When training a network, we specify the number of epochs we need in advance, without knowing how many epochs will actually be needed. If we specify the number of epochs to be too few compared to what is actually required, we may have to train the network again by specifying more epochs. On the other hand, if we specify too many more epochs than what are actually needed, then this may lead to an overfitting situation and we may have to retrain the network by reducing the number of epochs. This trial and error approach can be very time-consuming for applications where each epoch takes a long time to complete. In such situations, we can make use of callbacks that can help stop the network training at a suitable time.</p>
<p>To illustrate this problem, let's develop a classification model with the CTG data from <a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">Chapter 2</a><span>, </span><em>Deep Neural Networks for Multi-Class Classification</em>, using the following code:</p>
<pre># Training network for classification with CTG data (chapter-2)<br/>model &lt;- keras_model_sequential()<br/>model %&gt;% <br/>  layer_dense(units = 25, activation = 'relu', input_shape = c(21)) %&gt;%<br/>  layer_dense(units = 3, activation = 'softmax') <br/>model %&gt;% compile(loss = 'categorical_crossentropy', <br/>                  optimizer = 'adam',<br/>                  metrics = 'accuracy')<br/>history &lt;- model %&gt;% fit(training, <br/>                         trainLabels, <br/>                         epochs = 50,  <br/>                         batch_size = 32,<br/>                         validation_split = 0.2)<br/>plot(history)</pre>
<p>In the preceding code, we have specified the number of epochs as 50. Once the training process is completed, we can plot the loss and accuracy values for the training and validation data, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/0c6c3241-00be-4b66-bf2c-429bd7d761f7.png" style="width:34.83em;height:30.00em;"/></p>
<p>From the preceding plot, we can observe the following: </p>
<ul>
<li>We can observe that the loss values for the validation data decrease initially for the first few epochs and then start to increase.</li>
<li>The plot also shows that, after the first few epochs, the loss values for the training and validation data show divergence and tend to go in the opposite direction.</li>
<li>If we would like to stop the training process much earlier instead of waiting for all 50 epochs to be completed, then we can make use of the callback feature that's available in Keras.</li>
</ul>
<p>The following code includes the callback feature within the <kbd>fit</kbd> function at the time of training the network:</p>
<pre># Training network with callback<br/>model &lt;- keras_model_sequential()<br/>model %&gt;% <br/>  layer_dense(units = 25, activation = 'relu', input_shape = c(21)) %&gt;%<br/>  layer_dense(units = 3, activation = 'softmax') <br/>model %&gt;% compile(loss = 'categorical_crossentropy', <br/>                  optimizer = 'adam',<br/>                  metrics = 'accuracy')<br/>history &lt;- model %&gt;% fit(training, <br/>                         trainLabels, <br/>                         epochs = 50,  <br/>                         batch_size = 32,<br/>                         validation_split = 0.2,<br/>                         callbacks = callback_early_stopping(monitor = "val_loss", <br/>                                                   patience = 10))<br/>plot(history)</pre>
<p>In the preceding code, early stopping is included for callbacks:</p>
<ul>
<li>The metric that we used for monitoring was validation loss values. Another metric that can be tried in this situation is validation accuracy since we are developing a classification model.</li>
<li>We have specified patience to be 10, which means that when there are no improvements for 10 epochs, the training process will be stopped automatically.</li>
</ul>
<p>The plot for the loss and accuracy are also useful in helping us decide on the appropriate values for patience. The following plot is for the loss and accuracy:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/2bff25de-803a-486c-b48f-da342857f91d.png" style="width:31.92em;height:27.50em;"/></p>
<p>As we can see, this time, the training process didn't run for all 50 epochs and stopped as soon as there were no improvements in the loss values for 10 epochs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Developing classification and prediction models using deep learning networks involves extensive experimentation to arrive at models with high-quality performance. To help with this process, there are various methods that are very useful for visualizing and controlling network training. In this chapter, we went over four such useful methods. We saw that TensorBoard provides a tool that we can use to assess and compare model performance after training the network with different architectures and other changes in the model. The advantage of using TensorBoard lies in the fact that it brings all the necessary information together in one place in a user-friendly way. There are also situations where we want to understand how the main features or variables on a specific prediction are influenced when using a classification or prediction model. In such situations, we can visualize the impact that the main features will have using LIME.</p>
<p>Another useful tip that we illustrated in this chapter is visualization with the help of tfruns. When developing a deep network model, we come across various plots and summaries related to a specific model. Using tfruns, we can visualize all the information in one place with the help of an interactive screen. Another tip or trick that will be very useful in the journey ahead is the use of callbacks to automatically stop the training process when a suitable classification or prediction model has been developed. All the methods that were discussed in this chapter can be very useful for the journey ahead, especially when you're working on complex and challenging problems.</p>


            </article>

            
        </section>
    </body></html>