- en: Cancer Types Prediction Using Recurrent Type Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Large-scale cancer genomics data often comes in multiplatform and heterogeneous
    forms. These datasets impose great challenges in terms of the bioinformatics approach
    and computational algorithms. Numerous researchers have proposed to utilize this
    data to overcome several challenges, using classical machine learning algorithms
    as either the primary subject or a supporting element for cancer diagnosis and
    prognosis.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will use some deep learning architectures for cancer type
    classification from a very-high-dimensional dataset curated from The Cancer Genome
    Atlas (TCGA). First, we will describe the dataset and perform some preprocessing
    such that the dataset can be fed to our networks. We will then see how to prepare
    our programming environment, before moving on to coding with an open source, deep
    learning library called **Deeplearning4j** (**DL4J**). First, we will revisit
    the Titanic survival prediction problem again using a **Multilayer Perceptron**
    (**MLP**) implementation from DL4J.
  prefs: []
  type: TYPE_NORMAL
- en: Then we will use an improved architecture of **Recurrent Neural Networks** (**RNN**)
    called **Long Short-Term Memory** (**LSTM**) for cancer type prediction. Finally,
    we will see some frequent questions related to this project and DL4J hyperparameters/nets
    tuning.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a nutshell, we will be learning the following topics in the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning in cancer genomics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cancer genomics dataset description
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started with Deeplearning4j
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing a cancer type predictive model using LSTM-RNN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequently asked questions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning in cancer genomics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Biomedical informatics includes all techniques regarding the development of
    data analytics, mathematical modeling, and computational simulation for the study
    of biological systems. In recent years, we've witnessed huge leaps in biological
    computing that has resulted in large, information-rich resources being at our
    disposal. These cover domains such as anatomy, modeling (3D printers), genomics,
    and pharmacology, among others.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most famous success stories of biomedical informatics is from the
    domain of genomics. The **Human Genome Project** (**HGP**) was an international
    research project with the objective of determining the full sequence of human
    DNA. This project has been one of the most important landmarks in computational
    biology and has been used as a base for other projects, including the Human Brain
    Project, which is determined to sequence the human brain. The data that was used
    in this thesis is also the indirect result of the HGP.
  prefs: []
  type: TYPE_NORMAL
- en: The era of big data starts from the last decade or so, which was marked by an
    overflow of digital information in comparison to its analog counterpart. Just
    in the year 2016, 16.1 zettabytes of digital data were generated, and it is predicted
    to reach 163 ZB/year by 2025\. As good a piece of news as this is, there are some
    problems lingering, especially of data storage and analysis. For the latter, simple
    machine learning methods that were used in normal-size data analysis won't be
    effective anymore and should be substituted by deep neural network learning methods.
    Deep learning is generally known to deal very well with these types of large and
    complex datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Along with other crucial areas, the biomedical area has also been exposed to
    these big data phenomena. One of the main largest data sources is omics data such
    as genomics, metabolomics, and proteomics. Innovations in biomedical techniques
    and equipment, such as DNA sequencing and mass spectrometry, have led to a massive
    accumulation of -omics data.
  prefs: []
  type: TYPE_NORMAL
- en: Typically -omics data is full of veracity, variability and high dimensionality.
    These datasets are sourced from multiple, and even sometimes incompatible, data
    platforms. These properties make these types of data suitable for applying DL
    approaches. Deep learning analysis of -omics data is one of the main tasks in
    the biomedical sector as it has a chance to be the leader in personalized medicine.
    By acquiring information about a person's omics data, diseases can be dealt with
    better and treatment can be focused on preventive measures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cancer is generally known to be one of the deadliest diseases in the world,
    which is mostly due to its complexity of diagnosis and treatment. It is a genetic
    disease that involves multiple gene mutations. As the importance of genetic knowledge
    in cancer treatment is increasingly addressed, several projects to document the
    genetic data of cancer patients has emerged recently. One of the most well known
    is **The Cancer Genome Atlas** (**TCGA**) project, which is available on the TCGA
    research network: [http://cancergenome.nih.gov/](http://cancergenome.nih.gov/).'
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned before, there have been a number of deep learning implementations
    in the biomedical sector, including cancer research. For cancer research, most
    researchers usually use -omics or medical imaging data as inputs. Several research
    works have focused on cancer analysis. Some of them use either a histopathology
    image or a PET image as a source. Most of that research focuses on classification
    based on that image data with **convolutional neural networks** (**CNNs**).
  prefs: []
  type: TYPE_NORMAL
- en: However, many of them use -omics data as their source. Fakoor et al. classified
    the various types of cancer using patients' gene expression data. Due to the different
    dimensionality of each data from each cancer type, they used **principal component
    analysis** (**PCA**) first to reduce the dimensionality of microarray gene expression
    data.
  prefs: []
  type: TYPE_NORMAL
- en: PCA is a statistical technique used to emphasize variation and extract the most
    significant patterns from a dataset; principal components are the simplest of
    the true eigenvector-based multivariate analyses. PCA is frequently used for making
    data exploration easy to visualize. Consequently, PCA is one of the most used
    algorithms in exploratory data analysis and for making predictive models.
  prefs: []
  type: TYPE_NORMAL
- en: Then they applied sparse and stacked autoencoders to classify various cancers,
    including acute myeloid leukemia, breast cancer, and ovarian cancer.
  prefs: []
  type: TYPE_NORMAL
- en: For detailed information, refer to the following publication, entitled *Using
    deep learning to enhance cancer diagnosis and classification* by R. Fakoor et
    al. in proceedings of the International Conference on Machine Learning, 2013.
  prefs: []
  type: TYPE_NORMAL
- en: Ibrahim et al. , on the other hand, used miRNA expression data from six types
    of cancer genes/miRNA feature selection. They proposed a novel multilevel feature
    selection approach named **MLFS** (short for **Multilevel gene**/**miRNA feature
    selection**), which was based on **Deep Belief Networks (DBN)** and unsupervised
    active learning.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more in the publication titled *Multilevel gene/miRNA feature selection
    using deep belief nets and active learning* (R. Ibrahim, et al.) in Proceedings
    36th annual International Conference Eng. Med. Biol. Soc. (EMBC), pp. 3957-3960,
    IEEE, 2014.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, Liang et al. clustered ovarian and breast cancer patients using multiplatform
    genomics and clinical data. The ovarian cancer dataset contained gene expression,
    DNA methylation, and miRNA expression data across 385 patients, which were downloaded
    from **The Cancer Genome Atlas (TCGA)**.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more more in the following publication entitled *Integrative data
    analysis of multi-platform cancer data with a multimodal deep learning approach*
    (by M. Liang et al.) in Molecular Pharmaceutics, vol. 12, pp. 928{937, IEEE/ACM
    Transaction Computational Biology and Bioinformatics, 2015.
  prefs: []
  type: TYPE_NORMAL
- en: The breast cancer dataset included GE data and corresponding clinical information,
    such as survival time and time to recurrence data, which was collected by the
    Netherlands Cancer Institute. To deal with this multiplatform data, they used
    **multimodal Deep Belief Networks** (**mDBN**).
  prefs: []
  type: TYPE_NORMAL
- en: First, they implemented a DBN for each of those data to get their latent features.
    Then, another DBN used to perform the clustering is implemented using those latent
    features as the input. Apart from these researchers, much research work is going
    on to give cancer genomics, identification, and treatment a significant boost.
  prefs: []
  type: TYPE_NORMAL
- en: Cancer genomics dataset description
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Genomics data covers all data related to DNA on living things. Although in this
    thesis we will also use other types of data like transcriptomic data (RNA and
    miRNA), for convenience purposes, all data will be termed as genomics data. Research
    on human genetics found a huge breakthrough in recent years due to the success
    of the HGP (1984-2000) on sequencing the full sequence of human DNA.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the areas that have been helped a lot due to this is the research of
    all diseases related to genetics, including cancer. Due to various biomedical
    analyses done on DNA, there exist various types of -omics or genomics data. Here
    are some types of -omics data that were crucial to cancer analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Raw sequencing data:** This corresponds to the DNA coding of whole chromosomes.
    In general, every human has 24 types of chromosomes in each cell of their body,
    and each chromosome consists of 4.6-247 million base pairs. Each base pair can
    be coded in four different types, which are **adenine** (**A**), **cytosine**
    (**C**), **guanine** (**G**), and **thymine** (**T**). Therefore, raw sequencing
    data consists of billions of base pair data, with each coded in one of these four
    different types.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Single-Nucleotide Polymorphism** (**SNP**) data: Each human has a different
    raw sequence, which causes genetic mutation. Genetic mutation can cause an actual
    disease, or just a difference in physical appearance (such as hair color), or
    nothing at all. When this mutation happens only on a single base pair instead
    of a sequence of base pairs, it is called **Single-Nucleotide Polymorphism** (**SNP**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Copy Number Variation** (**CNV**) data: This corresponds to a genetic mutation
    that happens in a sequence of base pairs. Several types of mutation can happen,
    including deletion of a sequence of base pairs, multiplication of a sequence of
    base pairs, and relocation of a sequence of base pairs into other parts of the
    chromosome.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DNA methylation data**: Which corresponds to the amount of methylation (methyl
    group connected to base pair) that happens to areas in the chromosome. A large
    amount of methylation in promoter regions of a gene can cause gene repression.
    DNA methylation is the reason each of our organs acts differently even though
    all of them have the same DNA sequence. In cancer, this DNA methylation is disrupted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gene expression data**: This corresponds to the number of proteins that were
    expressed from a gene at a given time. Cancer happens either because of high expression
    of an oncogene (that is, a gene that causes a tumor), low expression of a tumor
    suppressor gene (a gene that prevents a tumor), or both. Therefore, the analysis
    of gene expression data can help discover protein biomarkers in cancer. We will
    use this in this project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**miRNA expression data**: Corresponds to the amount of microRNA that was expressed
    at a given time. miRNA plays a role in protein silencing at the mRNA stage. Therefore,
    an analysis of gene expression data can help discover miRNA biomarkers in cancer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are several databases of genomics datasets, where the aforementioned
    data can be found. Some of them focus on the genomics data of cancer patients.
    These databases include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Cancer Genome Atlas** (**TCGA**): **[https://cancergenome.nih.gov/](https://cancergenome.nih.gov/)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**International Cancer Genome Consortium** (**ICGC**): **[https://icgc.org/](https://icgc.org/)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Catalog of Somatic Mutations in Cancer** (**COSMIC**): **[https://cancer.sanger.ac.uk/cosmic](https://cancer.sanger.ac.uk/cosmic)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This genomics data is usually accompanied by clinical data of the patient. This
    clinical data can comprise general clinical information (for example, age or gender)
    and their cancer status (for example, cancer location or cancer stage). All of
    this genomics data itself has a characteristic of high dimensions. For example,
    the gene expression data for each patient is structured based on the gene ID,
    which reaches around 60,000 types.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, some of the data itself comes from more than one format. For example,
    70% of the DNA methylation data is collected from breast cancer patients and the
    remaining 30% are curated from different platforms. Therefore, there are two different
    structures on in this dataset. Therefore, to analyze genomics data by dealing
    with the heterogeneity, researchers have often used powerful machine learning
    techniques or even deep neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's see what a real-life dataset looks like that can be used for our purpose.
    We will be using the gene expression cancer RNA-Seq dataset downloaded from the
    UCI machine learning repository (see [https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq#](https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq)
    for more information).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/918516cc-0429-4221-a5e6-b4b6a07981f9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The data collection pipeline for the pan-cancer analysis project (source: "Weinstein,
    John N., et al. ''The cancer genome atlas pan-cancer analysis project.'' Nature
    Genetics 45.10 (2013): 1113-1120")'
  prefs: []
  type: TYPE_NORMAL
- en: 'This dataset is a random subset of another dataset reported in the following
    paper: Weinstein, John N., et al. *The cancer genome atlas pan-cancer analysis
    project*. *Nature Genetics 45.10 (2013): 1113-1120*. The preceding diagram shows
    the data collection pipeline for the pan-cancer analysis project.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The name of the project is The Pan-Cancer analysis project. It assembled data
    from thousands of patients with primary tumors occurring in different sites of
    the body. It covered 12 tumor types (see the upper-left panel in the preceding
    figure) including:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Glioblastoma Multiform** (**GBM**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lymphoblastic acute myeloid leukemia** (**AML**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Head and Neck Squamous Carcinoma** (**HNSC**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lung Adenocarcinoma** (**LUAD**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lung Squamous Carcinoma** (**LUSC**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Breast Carcinoma** (**BRCA**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kidney Renal Clear Cell Carcinoma** (**KIRC**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ovarian Carcinoma** (**OV**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bladder Carcinoma** (**BLCA**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Colon Adenocarcinoma** (**COAD**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Uterine Cervical and Endometrial Carcinoma** (**UCEC**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rectal Adenocarcinoma** (**READ**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This collection of data is part of the RNA-Seq (HiSeq) PANCAN dataset. It is
    a random extraction of gene expressions of patients having different types of
    tumors: BRCA, KIRC, COAD, LUAD, and PRAD.'
  prefs: []
  type: TYPE_NORMAL
- en: This dataset is a random collection of cancer patients from 801 patients, each
    having 20,531 attributes. Samples (instances) are stored row-wise. Variables (attributes)
    of each sample are RNA-Seq gene expression levels measured by the illumina HiSeq
    platform. A dummy name (`gene_XX`) is given to each attribute. The attributes
    are ordered consistently with the original submission. For example, `gene_1` on
    `sample_0` is significantly and differentially expressed with a a value of `2.01720929003`.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you download the dataset, you will see there are two CSV files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`data.csv`**:** Contains the gene expression data of each sample'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels.csv`**:** The labels associated with each sample'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at the processed dataset. Note we will see only a few selected
    features considering the high dimensionality in the following screenshot, where
    the first column represents sample IDs (that is, anonymous patient IDs). The rest
    of the columns represent how a certain gene expression occurs in the tumor samples
    of the patients:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/52a7de3c-2b87-45db-992b-18d3fa4cf1bc.png)'
  prefs: []
  type: TYPE_IMG
- en: Sample gene expression dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Now look at the labels in *Figure 3*. Here, `id` contains the sample ids and
    `Class` represents the cancer labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/daf22379-e09a-4d38-bfde-7ef397fa9d83.png)'
  prefs: []
  type: TYPE_IMG
- en: Samples are classified into different cancer types
  prefs: []
  type: TYPE_NORMAL
- en: Now you can imagine why I have chosen this dataset. Well, although we will not
    have so many samples, the dataset is still very high dimensional. In addition,
    this type of high-dimensional dataset is very suitable for applying a deep learning
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Alright. Therefore, if the features and labels are given, can we classify these
    samples based on features and the ground truth. Why not? We will try to solve
    the problem with the DL4J library. First, we have to configure our programming
    environment so that we can start writing our codes.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing programming environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will discuss how to configure DL4J, ND4s, Spark, and ND4J
    before getting started with the coding. The following are prerequisites when working
    with DL4J:'
  prefs: []
  type: TYPE_NORMAL
- en: Java 1.8+ (64-bit only)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Maven for automated build and dependency manager
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IntelliJ IDEA or Eclipse IDE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Git for version control and CI/CD
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following libraries can be integrated with DJ4J to enhance your JVM experience
    while developing your ML applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**DL4J**: The core neural network framework, which comes up with many DL architectures
    and underlying functionalities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ND4J**: Can be considered as the NumPy of the JVM. It comes with some basic
    operations of linear algebra. Examples are matrix creation, addition, and multiplication.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DataVec**: This library enables ETL operation while performing feature engineering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**JavaCPP**: This library acts as the bridge between Java and Native C++.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Arbiter**: This library provides basic evaluation functionalities for the
    DL algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RL4J**: Deep reinforcement learning for the JVM.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ND4S**: This is a scientific computing library, and it also supports n-dimensional
    arrays for JVM-based languages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you are using Maven on your preferred IDE, let''s define the project properties
    to mention the versions in the `pom.xml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then use the following dependencies required for DL4J, ND4S, ND4J, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'By the way, DL4J comes with Spark 2.1.0\. Additionally, if a native system
    BLAS is not configured on your machine, ND4J''s performance will be reduced. You
    will experience the following warning once you execute simple code written in
    Scala:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'However, installing and configuring BLAS such as `OpenBLAS` or `IntelMKL` is
    not that difficult; you can invest some time and do it. Refer to the following
    URL for further details: [http://nd4j.org/getstarted.html#open](http://nd4j.org/getstarted.html#open).'
  prefs: []
  type: TYPE_NORMAL
- en: Well done! Our programming environment is ready for simple deep learning application
    development. Now it's time to get your hands dirty with some sample code.
  prefs: []
  type: TYPE_NORMAL
- en: Titanic survival revisited with DL4J
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding chapter, we solved the Titanic survival prediction problem
    using Spark-based MLP. We also saw that by using Spark-based MLP, the user has
    very little transparency of using the layering structure. Moreover, it was not
    explicit to define hyperparameters and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, what I have done is used the training dataset and then performed
    some preprocessing and feature engineering. Then I randomly split the pre-processed
    dataset into training and testing (to be precise, 70% for training and 30% for
    testing). First, we create the Spark session as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In this chapter, we have seen that there are two CSV files. However, `test.csv`
    one does not provide any ground truth. Therefore, I decided to use only the `training.csv`
    one, so that we can compare the model''s performance. So let''s read the training
    dataset using the spark `read()` API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We have seen in [Chapter 1](fba163f0-88c0-4278-a4a1-df5389cc3a10.xhtml), *Getting
    Started with Deep Learning* that the `Age` and `Fare` columns have many null values.
    So, instead of writing `UDF` for each column, here I just replace the missing
    values of the age and fare columns by their mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: To get more detailed insights into handling missing/null values and machine
    learning, interested readers can take a look at Boyan Angelov's blog at [https://towardsdatascience.com/working-with-missing-data-in-machine-learning-9c0a430df4ce](https://towardsdatascience.com/working-with-missing-data-in-machine-learning-9c0a430df4ce).
  prefs: []
  type: TYPE_NORMAL
- en: 'For simplicity, we can drop a few more columns too, such as `"PassengerId"`,
    `"Name"`, `"Ticket"`, and `"Cabin"`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, here comes the tricky part. Similar to Spark ML-based estimators, DL4J-based
    networks also need training data in numeric form. Therefore, we now have to convert
    the categorical features into numerics. For that, we can use a `StringIndexer()`
    transformer. What we will do is we will create two that is, `StringIndexer` for
    the `"Sex"` and `"Embarked"` columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we will chain them into a single pipeline. Next, we will perform the transformation
    operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we will fit the pipeline, transform, and drop both the `"Sex"` and `"Embarked"`
    columns to get the transformed dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then our final pre-processed dataset will have only the numerical features.
    Note that DL4J considers the last column as the label column. That means DL4J
    will consider `"Pclass"`, `"Age"`, `"SibSp"`, `"Parch"`, `"Fare"`, `"sexIndex"`,
    and `"embarkedIndex"` as features. Therefore, I placed the `"Survived"` column
    as the last column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we randomly split the dataset into training and testing as 70% and 30%,
    respectively. That is, we used 70% for training and the rest to evaluate the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we have both the DataFrames as separate CSV files to be used by DL4J:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Additionally, DL4J does not support the header info in the training set, so
    I intentionally skipped writing the header.
  prefs: []
  type: TYPE_NORMAL
- en: Multilayer perceptron network construction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As I informed you in the preceding chapter, DL4J-based neural networks are made
    of multiple layers. Everything starts with a `MultiLayerConfiguration`, which
    organizes those layers and their hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameters are a set of variables that determine how a neural network would
    learn. There are many parameters, for example, how many times and how often to
    update the weights of the model (called an **epoch**), how to initialize network
    weights, which activation function to be used, which updater and optimization
    algorithms to be used, the learning rate (that is, how fast the model should learn),
    how many hidden layers are there, how many neurons are there in each layer, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now create the network. First, let us create the layers. Similar to the
    MLP we created in [Chapter 1](fba163f0-88c0-4278-a4a1-df5389cc3a10.xhtml), *Getting
    Started with Deep Learning*, our MLP will have four layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Layer 0**: Input layer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lauer 1**: Hidden layer 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Layer 2**: Hidden layer 2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Layer 3**: Output layer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More technically, the first layer is the input layer, and then two layers are
    placed as hidden layers. For the first three layers, we initialized the weights
    using Xavier and the activation function is ReLU. Finally, the output layer is
    placed. This setting is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/afcd3570-cc02-41ad-b098-30f8d1fb93f5.png)'
  prefs: []
  type: TYPE_IMG
- en: Multilayer perceptron for Titanic survival prediction input layer
  prefs: []
  type: TYPE_NORMAL
- en: 'We have specified the neurons (that is, nodes), which are an equal number of
    inputs, and an arbitrary number of neurons as output. We set a smaller value considering
    very few inputs and features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Hidden layer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The number of input neurons is equal to the output of the input layer. Then
    the number of outputs is an arbitrary value. We set a smaller value considering
    very few inputs and features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Hidden layer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The number of input neurons is equal to the output of hidden layer 1\. Then
    the number of outputs is an arbitrary value. Again we set a smaller value considering
    very few inputs and features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Output layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The number of input neurons is equal to the output of the hidden layer 1\. Then
    the number of outputs is equal to the number of predicted labels. We set a smaller
    value yet again, considering a very few inputs and features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we used the Softmax activation function, which gives us a probability
    distribution over classes (the outputs sum to 1.0), and the losses function as
    cross-entropy for binary classification (XNET) since we want to convert the output
    (probability) to a discrete class, that is, zero or one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: XNET is used for binary classification with logistic regression. Check out more
    about this in `LossFunctions.java` class in DL4J.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we create a `MultiLayerConfiguration` by specifying `NeuralNetConfiguration`
    before conducting the training. With DL4J, we can add a layer by calling `layer`
    on the `NeuralNetConfiguration.Builder()`, specifying its place in the order of
    layers (the zero-indexed layer in the following code is the input layer):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Apart from these, we also specify how to set the network's weights. For example,
    as discussed, we use Xavier as the weight initialization and **Stochastic Gradient
    Descent** (**SGD**) optimization algorithm with Adam as the updater. Finally,
    we also specify that we do not need to do any pre-training (which is typically
    needed in DBN or stacked autoencoders). Nevertheless, since MLP is a feedforward
    network, we set backpropagation as true.
  prefs: []
  type: TYPE_NORMAL
- en: Network training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we create a `MultiLayerNetwork` using the preceding `MultiLayerConfiguration`.
    Then we initialize the network and start the training on the training set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, we start training the model by invoking the `model.fit()`
    on the training set (`trainingDataIt` in our case). Now we will discuss how we
    prepared the training and test set. Well, for reading the training set or test
    set that are in an inappropriate format (features are numeric and labels are integers),
    I have created a method called `readCSVDataset()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'If you see the previous code block, you can realize that it is basically a
    wrapper that reads the data in CSV format, and then the `RecordReaderDataSetIterator()`
    method converts the record reader as a dataset iterator. Technically, `RecordReaderDataSetIterator()`
    is the main constructor for classification. It takes the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`RecordReader`: This is the `RecordReader` that provides the source of the
    data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batchSize`: Batch size (that is, number of examples) for the output `DataSet`
    objects'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labelIndex`: The index of the label writable (usually an `IntWritable`) as
    obtained by `recordReader.next()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numPossibleLabels`: The number of classes (possible labels) for classification'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This will then convert the input class index (at position `labelIndex`, with
    integer values `0` to `numPossibleLabels-1`, inclusive) to the appropriate one-hot
    output/labels representation. So let''s see how to proceed. First, we show the
    path of training and test sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s prepare the data we want to use for training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let''s prepare the data we want to classify:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Fantastic! We have managed to prepare the training and test `DataSetIterator`.
    Remember, we will be following nearly the same approach to prepare the training
    and test sets for other problems too.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the training has been completed, the next task would be evaluating the
    model. We will evaluate the model''s performance on the test set. For the evaluation,
    we will be using `Evaluation()`; it creates an evaluation object with two possible
    classes (survived or not survived). More technically, the Evaluation class computes
    the evaluation metrics such as precision, recall, F1, accuracy, and Matthews''
    correlation coefficient. The last one is used to evaluate a binary classifier.
    Now let''s take a brief overview on these metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Accuracy** is the ratio of correctly predicted samples to total samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/76057702-d43e-4861-ac12-6a036a553a83.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Precision** is the ratio of correctly predicted positive samples to the total
    predicted positive samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1ebcd216-45df-45d1-a389-681ce465fa30.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Recall** is the ratio of correctly predicted positive samples to all samples
    in the actual class—yes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/557e92fb-f546-40eb-8e6f-f24718421d69.png)'
  prefs: []
  type: TYPE_IMG
- en: '**F1 score** is the weighted average (harmonic mean) of Precision and Recall::'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a931ec3c-90b7-41a3-9800-5114b46a9dc2.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Matthews Correlation Coefficient** (**MCC**) is a measure of the quality
    of binary (two-class) classifications. MCC can be calculated directly from the
    confusion matrix as follows (given that TP, FP, TN, and FN are already available):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/69ca053d-0119-46ca-b39e-722ed60ced3c.png)'
  prefs: []
  type: TYPE_IMG
- en: Unlike the Apache Spark-based classification evaluator, when solving a binary
    classification problem using the DL4J-based evaluator, special care should be
    taken for binary classification metrics such as F1, precision, recall, and so
    on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, we will see these later on. First, let''s iterate the evaluation over
    every test sample and get the network''s prediction from the trained model. Finally,
    the `eval()` method checks the prediction against the true classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Oops! Unfortunately, we have not managed to achieve very high classification
    accuracy for class 1 (that is, 65%). Now, we compute another metric called MCC
    for this binary classification problem.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s try to interpret this result based on the Matthews paper (see more
    at [www.sciencedirect.com/science/article/pii/0005279575901099](http://www.sciencedirect.com/science/article/pii/0005279575901099)),
    which describes the following properties: A correlation of C = 1 indicates perfect
    agreement, C = 0 is expected for a prediction no better than random, and C = -1
    indicates total disagreement between prediction and observation.'
  prefs: []
  type: TYPE_NORMAL
- en: Following this, our result shows a weak positive relationship. Alright! Although
    we have not achieved good accuracy, you guys can still try by tuning hyperparameters
    or even by changing other networks such as LSTM, which we are going to discuss
    in the next section. But we'll do so for solving our cancer prediction problem,
    which is the main goal of this chapter. So stay with me!
  prefs: []
  type: TYPE_NORMAL
- en: Cancer type prediction using an LSTM network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we have seen what our data (that is, features and labels)
    looks like. Now in this section, we try to classify those samples according to
    their labels. However, as we have seen, DL4J needs the data in a well-defined
    format so that it can be used to train the model. So let us perform the necessary
    preprocessing and feature engineering.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset preparation for training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we do not have any unlabeled data, I would like to select some samples
    randomly for test. Well, one more thing is that features and labels come in two
    separate files. Therefore, we can perform the necessary preprocessing and then
    join them together so that our pre-processed data will have features and labels
    together.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then the rest will be used for training. Finally, we''ll save the training
    and testing set in a separate CSV file to be used later on. First, let''s load
    the samples and see the statistics. By the way, we use the `read()` method of
    Spark but specify the necessary options and format too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we see some related statistics such as number of features and number of
    samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Therefore, there are `801` samples from `801` distinct patients and the dataset
    is too high in dimensions, having `20532` features. In addition, in *Figure 2*,
    we have seen that the `id` column represents only the patient''s anonymous ID,
    so we can simply drop it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we load the labels using the `read()` method of Spark and also specify
    the necessary options and format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/9d270be1-d0f0-4c68-b1c2-36f293e6f48b.png)'
  prefs: []
  type: TYPE_IMG
- en: We have already seen how the labels dataframe looks. We will skip the `id`.
    However, the `Class` column is categorical. Now, as I said, DL4J does not support
    categorical labels to be predicted. Therefore, we have to convert it to numeric
    (integer, to be more specific); for that I would use `StringIndexer()` from Spark.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create a `StringIndexer()`; we apply the index operation to the `Class`
    column and rename it as `label`. Additionally, we skip null entries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we perform the indexing operation by calling the `fit()` and `transform()`
    operations as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s take a look at the indexed DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/3af96ada-3e47-48e5-a11b-9d22419e50a8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fantastic! Now all of our columns (including features and labels) are numeric.
    Thus, we can join both features and labels into a single DataFrame. For that,
    we can use the `join()` method from Spark as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can generate both the training and test sets by randomly splitting the
    `combindedDF`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s see the count of samples in each set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Thus, our training set has `561` samples and the test set has `240` samples.
    Finally, save these two sets as separate CSV files to be used later on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have the training and test sets, we can now train the network with
    the training set and evaluate the model with the test set. Considering the high
    dimensionality, I would rather try a better network such as LSTM, which is an
    improved variant of RNN. At this point, some contextual information about LSTM
    would be helpful to grasp the idea.
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent and LSTM networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As discussed in [Chapter 1](fba163f0-88c0-4278-a4a1-df5389cc3a10.xhtml), *Getting
    Started with Deep Learning*, RNNs make use of information from the past; they
    can make predictions in data with high temporal dependencies. A more explicit
    architecture can be found in following diagram where the temporally shared weights
    **w2** (for the hidden layer) must be learned in addition to **w1** (for the input
    layer) and **w3** (for the output layer). From a computational point of view,
    an RNN takes many input vectors to process and generate output vectors. Imagine
    that each rectangle in the following diagram has a vectorial depth and other special
    hidden quirks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2bc80381-93a3-4b60-90ce-4b00ea30e9a5.png)'
  prefs: []
  type: TYPE_IMG
- en: An RNN architecture where all weights in all layers have to be learned with
    time
  prefs: []
  type: TYPE_NORMAL
- en: 'However, we often need to look at only recent information to perform the present
    task, rather than stored information or information that arrived a long time ago.
    This happens frequently in NLP for language modeling. Let''s see a common example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cbde902a-d013-4124-b453-f9ba290d0684.png)'
  prefs: []
  type: TYPE_IMG
- en: If the gap between the relevant information is small, RNNs can learn to use
    past information
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we want to develop a DL-based NLP model to predict the next word based
    on the previous words. As a human being, if we try to predict the last word in
    *Berlin is the capital of...,* without further context, the next word is most
    likely *Germany*. In such cases, the gap between the relevant information and
    the position is small. Thus, RNNs can learn to use past information easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, consider another example that is a bit longer: *Reza grew up in Bangladesh.
    He studied in Korea. He speaks fluent...* Now to predict the last word, we would
    need a little bit more context. In this sentence, the most recent information
    advises the network that the next word would probably be the name of a language.
    However, if we narrow down to language level, the context of Bangladesh (from
    the previous words) would be needed.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de957c74-8ffe-4f84-a18a-14e11aa94883.png)'
  prefs: []
  type: TYPE_IMG
- en: If the gap between the relevant information and the place that is needed is
    bigger, RNNs can't learn to use past information
  prefs: []
  type: TYPE_NORMAL
- en: Here, the gap is larger than in the previous example, so an RNN is unable to
    learn to map the information. Nevertheless, gradients for deeper layers are calculated
    by multiplication (that is, the product) of many gradients coming from activation
    functions in the multilayer network. If those gradients are very small or close
    to zero, gradients will easily vanish. On the other hand, when they are bigger
    than 1, it will possibly explode. So, it becomes very hard to calculate and update.
    Let's explain them in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: These two issues of RNN are jointly called a **vanishing-exploding gradient**
    problem, which directly affects performance. In fact, the backpropagation time
    rolls out the RNN, creating *a very deep* feedforward neural network. The impossibility
    of getting a long-term context from the RNN is precisely due to this phenomenon;
    if the gradient vanishes or explodes within a few layers, the network will not
    be able to learn high-temporal-distance relationships between the data.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the inability of handling long-term dependency, gradient exploding
    and vanishing problems is a serious drawback of RNNs. Here comes LSTM as the savior.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the name signifies, short-term patterns are not forgotten in the long term.
    An LSTM network is composed of cells (LSTM blocks) linked to each other. Each
    LSTM block contains three types of gates: an input gate, an output gate, and a
    forget gate. They implement the functions of writing, reading, and reset on the
    cell memory, respectively. These gates are not binary but analog (generally managed
    by a sigmoidal activation function mapped in the range *[0, 1]*, where zero indicates
    total inhibition and one shows total activation).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can consider an LSTM cell very much like a basic cell, but still the training
    will converge more quickly and it will detect long-term dependencies in the data.
    Now the question would be: how does an LSTM cell work? The architecture of a basic
    LSTM cell is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1fc7d7b2-006a-4aff-99c1-89e49f6facb1.png)'
  prefs: []
  type: TYPE_IMG
- en: Block diagram of an LSTM cell
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s see the mathematical notation behind this architecture. If we don''t
    look at what''s inside the LSTM box, the LSTM cell itself looks exactly like a
    regular memory cell, except that its state is split into two vectors, *h(t)* and
    *c(t)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '*c* is a cell'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*h(t)* is the short-term state'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*c(t)* is the long-term state'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s open the box! The key idea is that the network can learn the following:'
  prefs: []
  type: TYPE_NORMAL
- en: What to store in the long-term state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What to throw away
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What to read
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In more simplified words, in an STM, all hidden units of the original RNN are
    replaced by memory blocks, where each memory block contains a memory cell to store
    input history information and three gates to define how to update the information.
    These gates are an input gate, a forget gate, and an output gate.
  prefs: []
  type: TYPE_NORMAL
- en: The presence of these gates allows LSTM cells to remember information for an
    indefinite period. In fact, if the input gate is below the activation threshold,
    the cell will retain the previous state, and if the current state is enabled,
    it will be combined with the input value. As the name suggests, the forget gate
    resets the current state of the cell (when its value is cleared to zero), and
    the output gate decides whether the value of the cell must be carried out or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although the long-term state is copied and passed through the tanh function,
    internally in an LSTM cell, incorporation between two activation functions is
    needed. For example, in the following diagram, tanh decides which values to add
    to the state, with the help of the sigmoid gate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/21bcb1c3-96e4-41ff-b57f-6281f0e45715.png)'
  prefs: []
  type: TYPE_IMG
- en: The internal organization of the LSTM cell structure
  prefs: []
  type: TYPE_NORMAL
- en: Now, since this book is not meant to teach theory, I would like to stop the
    discussion here, but interested readers can find more details on the DL4J website
    at [https://deeplearning4j.org/lstm.html](https://deeplearning4j.org/lstm.html).
  prefs: []
  type: TYPE_NORMAL
- en: Dataset preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we prepared the training and test sets. However, we
    need to put some extra efforts into making them consumable by DL4J. To be more
    specific, DL4J expects the training data as numeric and the last column to be
    the label column, and the remaining are features.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now try to prepare our training and test sets like that. First, we
    show the files where we saved the training and test sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we define the required parameters, such as the number of features, number
    of classes, and batch size. Here, I use `128` as the `batchSize` but adjust it
    accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This dataset is used for training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the data we want to classify:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: If you see the preceding two lines, you can realize that `readCSVDataset()`
    is basically a wrapper that reads the data in CSV format, and then the `RecordReaderDataSetIterator()`
    method converts the record reader as a dataset iterator. For more details, refer
    to the *Titanic survival revisited with DL4J* section.
  prefs: []
  type: TYPE_NORMAL
- en: LSTM network construction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in the Titanic survival prediction section, again everything starts
    with `MultiLayerConfiguration`, which organizes those layers and their hyperparameters.
    Our LSTM network consists of five layers. The input layer is followed by three
    LSTM layers. Then the last layer is an RNN layer, which is also the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: More technically, the first layer is the input layer, and then three layers
    are placed as LSTM layers. For the LSTM layers, we initialized the weights using
    Xavier. We use SGD as the optimization algorithm with Adam updater and the activation
    function is tanh.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the RNN output layer has a softmax activation function, which gives
    us a probability distribution over classes (that is, outputs sum to *1.0*), and
    MCXENT, which is the Multiclass cross-entropy loss function. This setting is shown
    in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a036774-db9c-4e74-bbec-5e29b818ca01.png)'
  prefs: []
  type: TYPE_IMG
- en: Multilayer perceptron for Titanic survival prediction. It takes 20,531 features
    and fixed bias (that is, 1) and generates multi-class outputs.
  prefs: []
  type: TYPE_NORMAL
- en: For creating LSTM layers, DL4J provides both LSTM and GravesLSTM classes. The
    latter is an LSTM recurrent net, based on *Supervised Sequence Labelling with
    Recurrent Neural Networks* (see more at [http://www.cs.toronto.edu/~graves/phd.pdf](http://www.cs.toronto.edu/~graves/phd.pdf)).
  prefs: []
  type: TYPE_NORMAL
- en: GravesLSTM is not compatible with CUDA. Thus, using LSTM is recommended while
    performing the training on GPU. Otherwise, GravesLSTM is faster than LSTM.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now before, we start creating the network, let''s define required hyperparameters
    such as the number of input/hidden/output nodes (neurons):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We now create a network configuration and conduct network training. With DL4J,
    you add a layer by calling `layer` on the `NeuralNetConfiguration.Builder()`,
    specifying its place in the order of layers (the zero-indexed layer in the following
    code is the input layer):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we also specify that we do not need to do any pre-training (which is
    typically needed in DBN or stacked autoencoders).
  prefs: []
  type: TYPE_NORMAL
- en: Network training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we create a `MultiLayerNetwork` using the preceding `MultiLayerConfiguration`.
    Then we initialize the network and start the training on the training set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Typically, this type of network has so many hyperparameters. Let''s print the
    number of parameters in the network (and for each layer):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: As I said, our network has 910 million parameters, which is huge. This also
    poses a great challenge while tuning hyperparameters. However, we will see some
    tricks in the FAQs section.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the training has been completed, the next task would be evaluating the
    model. We will evaluate the model''s performance on the test set. For the evaluation,
    we will be using `Evaluation(). This method` creates an evaluation object with
    five possible classes. First, let''s iterate the evaluation over every test sample
    and get the network''s prediction from the trained model. Finally, the `eval()`
    method checks the prediction against the true class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Wow! Unbelievable! Our LSTM network has accurately classified the samples so
    accurately. Finally, let''s see how the classifier predicts across each class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The predictive accuracy for cancer type prediction using LSTM is suspiciously
    higher. Did our network underfit? Is there any way to observe how the training
    went? In other words, the question would be why our LSTM neural net shows 100%
    accuracy. We will try to answer these questions in the next section. So stay with
    me!
  prefs: []
  type: TYPE_NORMAL
- en: Frequently asked questions (FAQs)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have solved the Titanic survival prediction problem with an acceptable
    level of accuracy, there are other practical aspects of this problem and overall
    deep learning phenomena that need to be considered too. In this section, we will
    see some frequently asked questions that might be already in your mind. Answers
    to these questions can be found in *Appendix A*.
  prefs: []
  type: TYPE_NORMAL
- en: Can't we use MLP to solve the cancer type prediction by handling this too high-dimensional
    data?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which activation and loss function can be used with RNN type nets?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the best way of recurrent net weight initialization?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which updater and optimization algorithm should be used?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the Titanic survival prediction problem, we did not experience good accuracy.
    What could be possible reasons and how can we improve the accuracy?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The predictive accuracy for cancer type prediction using LSTM is suspiciously
    higher. Did our network underfit? Is there any way to observe how the training
    went?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which type RNN variants should I use, that is, LSTM or GravesLSTM?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is my neural net throwing nan score values?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to configure/change the DL4J UI port?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw how to classify cancer patients on the basis of tumor
    types from a very-high-dimensional gene expression dataset curated from TCGA.
    Our LSTM architecture managed to achieve 100% accuracy, which is outstanding.
    Nevertheless, we discussed many aspects of DL4J, which will be helpful in upcoming
    chapters. Finally, we saw answers to some frequent questions related to this project,
    LSTM network, and DL4J hyperparameters/nets tuning.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how to develop an end-to-end project for handling
    a multilabel (each entity can belong to multiple classes) image classification
    problem using CNN based on Scala and the DL4J framework on real Yelp image datasets.
    We will also discuss some theoretical aspects of CNNs before getting started.
    Nevertheless, we will discuss how to tune hyperparameters for better classification
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Answers to questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Answer** **to question 1**: The answer is yes, but not very comfortably.
    That means a very deep feedforward network such as deep MLP or DBN can classify
    them with too many iterations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, also to speak frankly, MLP is the weakest deep architecture and is
    not ideal for very high dimensions like this. Moreover, DL4J has deprecated DBN
    since the DL4J 1.0.0-alpha release. Finally, I would still like to show an MLP
    network config just in case you want to try it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Then, just change the line from `MultiLayerNetwork model = new MultiLayerNetwork(LSTMconf);`
    to `**MultiLayerNetwork** model = **new** **MultiLayerNetwork**(MLPconf);`. Readers
    can see the full source in the `CancerPreddictionMLP.java` file.
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question 2**: There are two aspects to be aware of with regard
    to the choice of activation function.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Activation** **function for hidden layers:** Usually, ReLU or leakyrelu activations
    are good choices. Some other activation functions (tanh, sigmoid, and so on) are
    more prone to vanishing gradient problems. However, for LSTM layers, the tanh
    activation function is still commonly used.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A note here: The reason some people do not want to use Rectified Linear Unit
    (ReLU) is that it seems not to perform very well relative to smoother nonlinearity,
    such as sigmoid in the case of RNNs (see more at [https://arxiv.org/pdf/1312.4569.pdf](https://arxiv.org/pdf/1312.4569.pdf)).
    Even tanh works much better with LSTM. Therefore, I used tanh as the activation
    function in the LSTM layers.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The activation** **function for the output layer:** For classification problems,
    using the Softmax activation function combined with the negative log-likelihood
    / MCXENT is recommended. However, for a regression problem, the "IDENTITY" activation
    function is a good choice, with MSE as the loss function. In short, the choice
    is really application-specific.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question 3:** Well, we need to make sure that the network weights
    are neither too big nor too small. I will not recommend using random or zero;
    rather, Xavier weight initialization is usually a good choice for this.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question 4:** Unless SGD converges well, momentum/rmsprop/adagrad
    optimizers are a good choice. However, I''ve often used Adam as the updater and
    observed good performance too.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question 5:** Well, there is no concrete answer to this question.
    In fact, there could be several reasons. For example, probably we have not chosen
    the appropriate hyperparameters. Secondly, we may not have enough data. Thirdly,
    we could be using another network such as LSTM. Fourthly, we did not normalize
    our data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, for the third one, you can of course try using an LSTM network similarly;
    I did it for cancer type prediction. For the fourth one, of course normalized
    data always gives better classification accuracy. Now the question would be: what
    is the distribution of your data? Are you scaling it properly? Well, continuous
    values have to be in the range of -1 to 1, 0 to 1, or distributed normally with
    mean 0 and standard deviation 1.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, I would like to give you a concrete example of data normalization
    in the Titanic example. For that, we can use DL4J''s `NormalizerMinMaxScaler()`.
    Once we created the training dataset iterator, we can instantiate a `NormalizerMinMaxScaler()`
    object and then normalize the data by invoking the `fit()` method. Finally, we
    perform the transformation using the `setPreProcessor()` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, for the test dataset iterator, we apply the same normalization for better
    results but without invoking the `fit()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'More elaborately, `NormalizerMinMaxScaler ()` acts as the pre-processor for
    datasets that normalizes feature values (and optionally label values) to lie between
    a minimum and maximum value (by default, between 0 and 1). Readers can see the
    full source in the `CancerPreddictionMLP.java` file. After this normalization,
    I experienced slightly better result for class 1, as follows (you could try the
    same for class 0 too):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '**Answer to question 6:** In the real world, it''s a rare case that a neural
    net would achieve 100% accuracy. However, if the data is linearly separable, then
    yes, it''s possible! Take a look at the following scatter plots, which show that
    the black line clearly separates the red points and the dark blue points:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/184293ff-a744-4941-b1c5-8084d6786233.png)'
  prefs: []
  type: TYPE_IMG
- en: Very clearly and linearly separable data points
  prefs: []
  type: TYPE_NORMAL
- en: More technically, since a neuron's output (before it passes through an activation
    function) is a linear combination of its inputs, a network consisting of a single
    neuron can learn this pattern. That means if our neural net got the line right,
    it is possible to achieve 100% accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, to answer the second part: probably no. To prove this, we can observe
    the training loss, score, and so on on the DL4J UI, which is the interface used
    to visualize the current network status and progress of training in real time
    on your browser.'
  prefs: []
  type: TYPE_NORMAL
- en: The UI is typically used to help with tuning neural networks, that is, the selection
    of hyperparameters to obtain good performance for a network. These are already
    in the `CancerPreddictionLSTM.java` file, so do not worry but just keep going.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1: Adding the dependency for DL4J to your project**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following dependency tag, `_2.11 suffix` is used to specify which Scala
    version should be used for the Scala play framework. You should setting accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 2: Enabling UI in your project**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is relatively straightforward. First, you have to initialize the user
    interface backend as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'You then configure where the network information is to be stored. Then the
    StatsListener can be added to collect this information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we attach the StatsStorage instance to the UI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 3: Start collecting information by invoking the fit() method** Information
    will then be collected and routed to the UI when you call the `fit` method on
    your network.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4: Accessing the UI** Once it is configured, the UI can be accessed
    at [http://localhost:9000/train](http://localhost:9000/train). Now to answer "Did
    our network under fit? Is there any way to observe how the training went?" We
    can observe the **Model Score versus Iteration Chart** on the overview page**.**
    As suggested in the model tuning section at [https://deeplearning4j.org/visualization](https://deeplearning4j.org/visualization)**,**
    we have the following observation**:**'
  prefs: []
  type: TYPE_NORMAL
- en: The overall score versus iteration should go down over time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The score does not increase consistently but decreases drastically when the
    iteration moves on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The issue might be that there is no noise in the line chart, which is ideally
    expected (that is, the line will go up and down within a small range).
  prefs: []
  type: TYPE_NORMAL
- en: Now to deal with this, again we can normalize the data and perform the training
    again to see how the performance differs. Well, I would like to leave this up
    to you, folks. One more clue would be following the same data normalization that
    we discussed in question 5.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2cbc83a2-105b-4027-a354-c9bddef68089.png)'
  prefs: []
  type: TYPE_IMG
- en: LSTM model score over iterations
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, another observation would be worth mentioning too. For example, the gradients
    did not vanish until the end, which becomes clearer from this figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/49b98b00-61ba-44dc-bb37-9622cb4545c3.png)'
  prefs: []
  type: TYPE_IMG
- en: The LSTM network's gradients across different iterations
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the activation functions performed their role consistently, which
    becomes clearer from the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5c7ef990-ef40-45d1-948f-343bfa31c34f.png)'
  prefs: []
  type: TYPE_IMG
- en: The LSTM network's activation functions performed their role consistently across
    different layers
  prefs: []
  type: TYPE_NORMAL
- en: The thing is that there are many more factors to be considered too. However,
    in reality, tuning a neural network is often more an art than a science, and we
    have not considered many aspects as I said. Yet, do not worry; we will see them
    in upcoming projects. So hang on and let's move on to the next question.
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question 7:** LSTM allows both GPU/CUDA support, but GravesLSTM
    supports only CUDA, hence no support for CuDNN yet. Nonetheless, if you want faster
    training and convergence, using LSTM type is recommended.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question 8:** While training a neural network, the backpropagation
    involves multiplications across very small gradients. This happens due to limited
    precision when representing real numbers; values very close to zero cannot be
    represented.'
  prefs: []
  type: TYPE_NORMAL
- en: It introduces an arithmetic underflow issue, which often happens in a deeper
    network such as DBN, MLP, or CNN. Moreover, if your network throws NaN, then you'll
    need to retune your network to avoid very small gradients.
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question 9:** You can set the port by using the org.deeplearning4j.ui.port
    system property. To be more specific, to use port `9001` for example, pass the
    following to the JVM on launch:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-Dorg.deeplearning4j.ui.port=9001`'
  prefs: []
  type: TYPE_NORMAL
