["```py\n# Libraries and MNIST data\nlibrary(keras)\nlibrary(EBImage)\nmnist <- dataset_mnist()\nstr(mnist)\nList of 2\n $ train:List of 2\n ..$ x: int [1:60000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...\n ..$ y: int [1:60000(1d)] 5 0 4 1 9 2 1 3 1 4 ...\n $ test :List of 2\n ..$ x: int [1:10000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...\n ..$ y: int [1:10000(1d)] 7 2 1 0 4 1 4 9 5 9 ...\n```", "```py\n# Data on digit five\nc(c(trainx, trainy), c(testx, testy)) %<-% mnist\ntrainx <- trainx[trainy==5,,]\nstr(trainx)\n int [1:5421, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...\nsummary(trainx)\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    0.00   33.32    0.00  255.00 \n\npar(mfrow = c(8,8), mar = rep(0, 4))\nfor (i in 1:64) plot(as.raster(trainx[i,,], max = 255))\npar(mfrow = c(1,1))\n\n```", "```py\n# Reshaping data\ntrainx <- array_reshape(trainx, c(nrow(trainx), 28, 28, 1))\ntrainx <- trainx / 255\n```", "```py\n# Generator network\nh <- 28; w <- 28; c <- 1; l <- 28  \ngi <- layer_input(shape = l)\ngo <- gi %>% layer_dense(units = 32 * 14 * 14) %>%\n         layer_activation_leaky_relu() %>% \n         layer_reshape(target_shape = c(14, 14, 32)) %>% \n         layer_conv_2d(filters = 32, \n                       kernel_size = 5,\n                       padding = \"same\") %>% \n         layer_activation_leaky_relu() %>% \n         layer_conv_2d_transpose(filters = 32, \n                                 kernel_size = 4,\n                                 strides = 2,\n                                 padding = \"same\") %>% \n         layer_activation_leaky_relu() %>% \n         layer_conv_2d(filters = 1, \n                       kernel_size = 5,\n                       activation = \"tanh\", \n                       padding = \"same\")\ng <- keras_model(gi, go)\n```", "```py\n# Summary of generator network model \nsummary(g)\n____________________________________________________________________________\nLayer (type)                      Output Shape                 Param # \n============================================================================\ninput_7 (InputLayer)              [(None, 28)]                   0 \n____________________________________________________________________________\ndense_4 (Dense)                   (None, 6272)                181888 \n____________________________________________________________________________\nleaky_re_lu_8 (LeakyReLU)         (None, 6272)                   0 \n____________________________________________________________________________\nreshape_2 (Reshape)               (None, 14, 14, 32)             0 \n____________________________________________________________________________\nconv2d_6 (Conv2D)                 (None, 14, 14, 32)            25632 \n____________________________________________________________________________\nleaky_re_lu_9 (LeakyReLU)          (None, 14, 14, 32)             0 \n____________________________________________________________________________\nconv2d_transpose_2 (Conv2DTranspose) (None, 28, 28, 32)         16416 \n____________________________________________________________________________\nleaky_re_lu_10 (LeakyReLU)          (None, 28, 28, 32)            0 \n____________________________________________________________________________\nconv2d_7 (Conv2D)                    (None, 28, 28, 1)           801 \n============================================================================\nTotal params: 224,737\nTrainable params: 224,737\nNon-trainable params: 0\n_______________________________________________________________________________________\n```", "```py\n# Discriminator network\ndi <- layer_input(shape = c(h, w, c))\ndo <- di %>% \n         layer_conv_2d(filters = 64, kernel_size = 4) %>% \n         layer_activation_leaky_relu() %>% \n         layer_flatten() %>%\n         layer_dropout(rate = 0.3) %>%  \n         layer_dense(units = 1, activation = \"sigmoid\")\nd <- keras_model(di, do)\n```", "```py\n# Summary of discriminator network model \nsummary(d)\n___________________________________________________\nLayer (type) Output Shape Param # \n===================================================\ninput_10 (InputLayer) [(None, 28, 28, 1)] 0 \n___________________________________________________\nconv2d_12 (Conv2D) (None, 25, 25, 64) 1088 \n____________________________________________________\nleaky_re_lu_17 (LeakyReLU) (None, 25, 25, 64) 0 \n____________________________________________________\nflatten_2 (Flatten) (None, 40000) 0 \n____________________________________________________\ndropout_2 (Dropout) (None, 40000) 0 \n____________________________________________________\ndense_7 (Dense) (None, 1) 40001 \n====================================================\nTotal params: 41,089\nTrainable params: 41,089\nNon-trainable params: 0\n_____________________________________________________\n```", "```py\n# Compile discriminator network\nd %>% compile(optimizer = 'rmsprop',\n         loss = \"binary_crossentropy\")\n```", "```py\n# Freeze weights and compile\nfreeze_weights(d) \ngani <- layer_input(shape = l)\ngano <- gani %>% g %>% d\ngan <- keras_model(gani, gano)\ngan %>% compile(optimizer = 'rmsprop', \n                loss = \"binary_crossentropy\")\n```", "```py\n# Initial settings\nb <- 50  \nsetwd(\"~/Desktop/\")\ndir <- \"FakeImages\"\ndir.create(dir)\nstart <- 1; dloss <- NULL; gloss <- NULL\n```", "```py\n# 1\\. Generate 50 fake images from noise\nfor (i in 1:100) {noise <- matrix(rnorm(b*l), nrow = b, ncol= l)}\nfake <- g %>% predict(noise)\n\n# 2\\. Combine real & fake images\nstop <- start + b - 1 \nreal <- trainx[start:stop,,,]\nreal <- array_reshape(real, c(nrow(real), 28, 28, 1))\nrows <- nrow(real)\nboth <- array(0, dim = c(rows * 2, dim(real)[-1]))\nboth[1:rows,,,] <- fake\nboth[(rows+1):(rows*2),,,] <- real\nlabels <- rbind(matrix(runif(b, 0.9,1), nrow = b, ncol = 1),\n matrix(runif(b, 0, 0.1), nrow = b, ncol = 1))\nstart <- start + b\n\n# 3\\. Train discriminator\ndloss[i] <- d %>% train_on_batch(both, labels) \n\n# 4\\. Train generator using gan \nfakeAsReal <- array(runif(b, 0, 0.1), dim = c(b, 1))\ngloss[i] <- gan %>% train_on_batch(noise, fakeAsReal) \n\n# 5\\. Save fake image\nf <- fake[1,,,] \ndim(f) <- c(28,28,1)\nimage_array_save(f, path = file.path(dir, paste0(\"f\", i, \".png\")))}\n```", "```py\n# Fake image data\nlibrary(EBImage)\nsetwd(\"~/Desktop/FakeImages\")\ntemp = list.files(pattern = \"*.png\")\nmypic <- list()\nfor (i in 1:length(temp)) {mypic[[i]] <- readImage(temp[[i]])}\npar(mfrow = c(10,10))\nfor (i in 1:length(temp)) plot(mypic[[i]])\n```", "```py\n# Generator network\ngi <- layer_input(shape = l)\ngo <- gi %>% layer_dense(units = 32 * 14 * 14) %>%\n         layer_activation_leaky_relu() %>% \n         layer_reshape(target_shape = c(14, 14, 32)) %>% \n         layer_conv_2d(filters = 32, \n                       kernel_size = 5,\n                       padding = \"same\") %>% \n         layer_activation_leaky_relu() %>% \n         layer_conv_2d_transpose(filters = 32, \n                                 kernel_size = 4,\n                                 strides = 2, \n                                 padding = \"same\") %>% \n         layer_activation_leaky_relu() %>%      \n         layer_conv_2d(filters = 64, \n                      kernel_size = 5, \n                      padding = \"same\") %>% \n         layer_activation_leaky_relu() %>% \n         layer_conv_2d(filters = 1, \n                       kernel_size = 5,\n                       activation = \"tanh\", \n                       padding = \"same\")\ng <- keras_model(gi, go)\n```", "```py\n# Discriminator network\ndi <- layer_input(shape = c(h, w, c))\ndo <- di %>% \n         layer_conv_2d(filters = 64, kernel_size = 4) %>% \n         layer_activation_leaky_relu() %>% \n         layer_conv_2d(filters = 64, kernel_size = 4, strides = 2) %>% \n         layer_activation_leaky_relu() %>% \n         layer_flatten() %>%\n         layer_dropout(rate = 0.3) %>%  \n         layer_dense(units = 1, activation = \"sigmoid\")\nd <- keras_model(di, do)\n```"]