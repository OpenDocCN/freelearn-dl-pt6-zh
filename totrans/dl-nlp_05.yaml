- en: '*Chapter 5*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第五章*'
- en: Recurrent Neural Networks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，你将能够：
- en: Describe classical feedforward networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述经典的前馈神经网络
- en: Differentiate between feedforward neural networks and recurrent neural networks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分前馈神经网络和循环神经网络
- en: Evaluate the application of backpropagation through time for recurrent neural
    networks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估通过时间反向传播应用于循环神经网络的效果
- en: Describe the drawbacks of recurrent neural networks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述循环神经网络的缺点
- en: Use recurrent neural networks with keras to solve the author attribution problem
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Keras 中的循环神经网络解决作者归属问题
- en: This chapter aims to introduce you to recurrent neural networks and their applications,
    as well as their drawbacks.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在介绍循环神经网络及其应用，并讨论它们的缺点。
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: We encounter different kinds of data in our day-to-day lives, and some of this
    data has temporal dependencies (dependencies over time) while some does not. For
    example, an image by itself contains the information it wants to convey. However,
    data forms such as audio and video have dependencies over time. They cannot convey
    information if a fixed point in time is taken into consideration. Based on the
    problem statement, the input that's needed in order to solve the problem can differ.
    If we have a model to detect a particular person in a frame, a single image can
    be used as input. However, if we need to detect their actions, we need a stream
    of images, contiguous in time, as the input. We can understand the person's actions
    by analyzing these images together, but not independently.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在日常生活中会遇到不同种类的数据，其中一些数据具有时间依赖性（随时间变化的依赖关系），而另一些则没有。例如，一张图片本身就包含了它想要传达的信息。然而，音频和视频等数据形式则具有时间依赖性。如果只考虑一个固定的时间点，它们无法传递信息。根据问题的描述，解决问题所需的输入可能会有所不同。如果我们有一个模型来检测某个特定人物在一帧中的出现，那么可以使用单张图片作为输入。然而，如果我们需要检测他们的动作，我们需要一系列连续的图像作为输入。我们可以通过分析这些图像来理解一个人的动作，但不能仅仅通过单独的图像来分析。
- en: While watching a movie, a particular scene makes sense because its context is
    known, and we remember all the information gathered before in the movie to understand
    the current scene. This is very important, and we, as humans, can do this because
    our brains can store memory, analyze past data, and retrieve useful information
    to understand the current scene.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在观看电影时，某个特定场景之所以能够理解，是因为已知其上下文，并且我们记住了电影中之前收集的所有信息，来理解当前场景。这一点非常重要，而我们作为人类之所以能够做到这一点，是因为我们的脑袋能够存储记忆，分析过去的数据，并提取有用信息以理解当前的场景。
- en: Networks such as multi-layered perceptron and convolutional neural networks
    lack this capability. Every input given to these networks is treated independently,
    and they don't store any information from past inputs to analyze the current inputs
    because they lack memory in their architecture. That being the case, maybe there
    is a way we can enable neural networks to have memory. We can try and make them
    store useful information from the past and make them retrieve information from
    the past that helps them to analyze the current input. This is indeed possible,
    and the architecture for it is called the **Recurrent** **Neural** **Network**
    (**RNN**).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 像多层感知机和卷积神经网络这样的网络缺乏这种能力。它们对每个输入都视为独立处理，并且不会存储任何来自过去输入的信息来分析当前输入，因为它们在架构上缺乏记忆功能。在这种情况下，也许我们可以让神经网络具有记忆功能。我们可以尝试让它们存储过去的有用信息，并从过去获取有助于分析当前输入的信息。这是完全可能的，其架构被称为**循环神经网络**（**RNN**）。
- en: 'Before we delve deep into the theory of RNNs, let''s take a look at their applications.
    Currently, RNNs are widely used. Some of the applications are as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解 RNN 的理论之前，我们先来看一下它们的应用。目前，RNN 被广泛应用。以下是一些应用：
- en: '*Speech recognition*: Whether it''s Amazon''s Alexa, Apple''s Siri, Google''s
    voice assistant, or Microsoft''s Cortana, all their speech recognition systems
    use RNNs.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*语音识别*：无论是亚马逊的 Alexa，苹果的 Siri，谷歌的语音助手，还是微软的 Cortana，它们的所有语音识别系统都使用 RNN。'
- en: '*Time series predictions*: Any application with time series data, such as stock
    market data, website traffic, call center traffic, movie recommendations, Google
    Maps routes, and so on, uses RNNs to predict future data, the optimal path, optimal
    resource allocations, and so on.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*时间序列预测*：任何具有时间序列数据的应用程序，如股市数据、网站流量、呼叫中心流量、电影推荐、Google Maps 路线等等，都使用 RNN 来预测未来数据、最佳路径、最佳资源分配等。'
- en: '*Natural language processing*: Applications such as machine translation (for
    Google Translate, for instance), chatbots (such as those for Slack and Google),
    and question answering all use RNNs to model dependencies.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自然语言处理*：机器翻译（例如Google Translate）、聊天机器人（如Slack和Google的聊天机器人）以及问答系统等应用都使用RNN来建模依赖关系。'
- en: Previous Versions of Neural Networks
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络的早期版本
- en: Around 40 years ago, it became clear that **Feed** **Forward** **Neural** **Networks**
    (**FFNNs**) could not capture time-variable dependencies, which are essential
    for capturing the time-variable properties of a signal. Modeling time-variable
    dependencies is very important in many applications involving real-world data,
    such as speech and video, in which data has time-variable properties. Also, human
    biological neural networks have a recurrent relationship, so it is the most obvious
    direction to take. How could this recurrent relationship be added to existing
    feedforward networks?
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 大约40年前，人们发现**前馈神经网络**（**FFNNs**）无法捕捉时间变化的依赖关系，而这对于捕捉信号的时间变化特性至关重要。建模时间变化的依赖关系在许多涉及现实世界数据的应用中非常重要，例如语音和视频，这些数据具有时间变化的特性。此外，人类生物神经网络具有递归关系，因此这是最明显的发展方向。如何将这种递归关系添加到现有的前馈网络中呢？
- en: One of the first attempts to achieve this was done by adding delay elements,
    and the network was called the **Time-Delay** **Neural** **Network**, or **TDNN**
    for short.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这一目标的首次尝试之一是通过添加延迟元素，网络被称为**时延神经网络**，简称**TDNN**。
- en: In this network, as the following figure shows, the delay elements are added
    to the network and the past inputs are given to the network along with the current
    timestep as the input to the network. This definitely has an advantage over the
    traditional feed forward networks but has the disadvantage of having only so many
    inputs from the past as the window allows. If the window is too large, the network
    grows with increasing parameters and computational complexities.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个网络中，正如下图所示，延迟元素被添加到网络中，过去的输入与当前时刻一起作为网络的输入。与传统的前馈网络相比，这种方法无疑具有优势，但也有一个缺点，即只能接收来自过去的有限输入，这取决于窗口的大小。如果窗口太大，网络随着参数的增加而增长，计算复杂度也随之增加。
- en: '![Figure 5.1: TDNN structure'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.1：TDNN结构'
- en: '](img/C13783_5_01.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_5_01.jpg)'
- en: 'Figure 5.1: TDNN structure'
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.1：TDNN结构
- en: Then came Elman networks, or simple RNNs. Elman networks are very similar to
    feedforward networks, except that the hidden layer of output is stored and used
    for the next input. This way, information from the previous timesteps can be captured
    in these hidden states.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 随后出现了Elman网络，或称为简单RNN（**Simple RNN**）。Elman网络与前馈网络非常相似，不同之处在于其输出的隐藏层会被存储并用于下一个输入。这样，前一个时刻的信息可以在这些隐藏状态中被捕获。
- en: One way of looking at Elman networks is that at each input, we append the previous
    hidden layers' outputs along with the inputs and send them all as the inputs to
    the network. So, if the input size is **m** and the hidden layer size is **n**,
    the effective input layer size becomes **m+n**.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 观察Elman网络的一种方式是，在每个输入时，我们将前一个隐藏层的输出与当前输入一起附加，并将它们作为网络的输入。因此，如果输入大小是**m**，隐藏层大小是**n**，则有效的输入层大小变为**m+n**。
- en: The following figure shows a simple three-layer network, where the previous
    state is fed back to the network to store the context, and therefore it is called
    **SimpleRNN**. There are other variations to this architecture, such as Jordan
    networks, which we will not study in this chapter. For those are interested in
    the early history of RNNs, reading more on Elman networks and Jordan networks
    might be the best place to start.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了一个简单的三层网络，其中之前的状态被反馈到网络中以存储上下文，因此称之为**SimpleRNN**。这种架构有其他变种，例如Jordan网络，我们在本章中不会学习这些变种。对于那些对RNN早期历史感兴趣的人来说，阅读更多关于Elman网络和Jordan网络的资料可能是一个很好的起点。
- en: '![Figure 5.2: SimpleRNN structure'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.2：SimpleRNN结构'
- en: '](img/C13783_5_02.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_5_02.jpg)'
- en: 'Figure 5.2: SimpleRNN structure'
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.2：SimpleRNN结构
- en: And then came the **RNN**, which is the topic of this chapter. We will look
    into RNNs in detail in the coming sections It is important to note that in recurrent
    networks, since there are memory units and weights associated to these units,
    they need to be learned during backpropagation. Since these gradients are also
    backpropagated through time, we call it **Back** **Propagation** **Through** **Time**,
    or **BPTT**. We will discuss BPTT in detail in the upcoming sections. However,
    TDNN, Elman networks, and RNNs have a major drawback due to BPTT, and it is called
    vanishing gradients. Vanishing gradients is a problem where gradients get smaller
    and smaller as they backpropagate, and in these networks, as timesteps increase,
    back-propagated gradients get smaller and smaller, resulting in vanishing gradients.
    It's almost impossible to capture time dependencies greater than 20 timesteps.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: To address this issue, an architecture called the **Long** **Short-Term** **Memory**
    (**LSTM**) architecture was introduced. The key idea here is to hold some cell
    states constant and introduce them as needed in future timesteps. These decisions
    are made by gates, including forget gates and output gates. Another commonly used
    variant of the LSTM is called the **Gated** **Recurrent** **Unit**, or **GRU**
    for short. Don't worry much if you didn't understand this completely. There are
    two chapters following that are dedicated to making these concepts clear.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: RNNs
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recurrent often means occurring repeatedly. The recurrent part of RNNs simply
    means that the same task is done over all the inputs in the input sequence (for
    RNNs, we give a sequence of timesteps as the input sequence). One main difference
    between feed forward networks and RNNs is that RNNs have memory elements called
    states that capture the information from the previous inputs. So, in this architecture,
    the current output not only depends on the current input, but also on the current
    state, which takes into account past inputs.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: RNNs are trained by sequences of inputs rather than a single input; similarly,
    we can consider each input to an RNN as a sequence of timesteps. The state elements
    in RNNs contain information about past inputs to process the current input sequence.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3: RNN structure'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_03.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.3: RNN structure'
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For each input in the input sequence, the RNN gets a state, calculates its output,
    and sends its state to the next input in the sequence. The same set of tasks is
    repeated for all the elements in the sequence.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: It's easy to understand RNNs and their operations by comparing them to feedforward
    networks. Let's do that now.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: By now, it's very clear that the inputs are independent of each other in feedforward
    neural networks, so we train the network by randomly drawing pairs of inputs and
    outputs. There is no significance to the sequence. At any given time, the output
    is a function of input and weights.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4: Expression for the output of an RNN'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_05_04.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.4: Expression for the output of an RNN'
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In RNNs, our output at time **t** depends not only on the current input and
    the weight, but also on previous inputs. In this case, the output at time **t**
    will be defined as shown:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5: Expression for the output of an RNN at time t'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_05_05.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.5: Expression for the output of an RNN at time t'
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let's look at a simple structure of an RNN that is called a folded model. In
    the following figure, the **S****t** state vector is fed back into the network
    from the previous timestep. One important takeaway from this representation is
    that RNNs share the same weight matrices across timesteps. By increasing the timesteps,
    we are not learning more parameters, but we are looking at a bigger sequence.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6: Folded model of an RNN'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_06.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.6: Folded model of an RNN'
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This is a folded model of an RNN:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '**Xt** : Current input vector in the input sequence'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '**Yt**: Current output vector in the output sequence'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '**St**: Current state vector'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '**Wx**: Weight matrix connecting the input vector to the state vector'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '**Wy**: Weight matrix connecting the state vector to the output vector'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '**Ws**: Weight matrix connecting the state vector of previous timestep to the
    next one'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Since the input, **x** is a sequence of timesteps and we perform the same task
    for elements in this sequence, we can unfold this model.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7: Unfolding of an RNN'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_07.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.7: Unfolding of an RNN'
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For example, the output at time **t+1**,**y****t+1** depends on input at time
    **t+1**, weight matrices, and all the inputs before it.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8: Unfolded RNN'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_08.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.8: Unfolded RNN'
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Since RNNs are extensions of FFNNs, it's best to understand the differences
    between these architectures.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9: Differences between FFNNs and RNNs'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_09.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.9: Differences between FFNNs and RNNs'
  id: totrans-71
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The output expressions for FFNNs and RNNs are as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.10: Output expressions for FFNNs and RNNs'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_10.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.10: Output expressions for FFNNs and RNNs'
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: From the previous figure and equations, it is very evident that there are a
    lot of similarities between these two architectures. In fact, they are the same
    if **Ws=0**. This is obviously the case since **Ws** is the weight associated
    with the state that is fed back to the network. Without **Ws**, there is no feedback,
    which is the basis of the RNN.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: In FFNNs, the output at **t** depends on the input at **t** and weight matrices.
    In RNNs, the output at **t** depends on input at **t**, **t-1**, **t-2**, and
    so on, as well as the weight matrices. This is explained with the further calculation
    of hidden vector **h** in the case of an FFNN and **s** in the case of an RNN.
    At first glance, it might look like the state at **t** depends on the input at
    **t**, the state at **t-1**, and the weight matrices; and the state at **t-1**
    depends on the input at **t-1**, the state at **t-2**, and so on; creating a chain
    that goes back all the way to the first timestep considered. The output calculations
    of both FFNNs and RNNs are same, though.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在 FFNN（前馈神经网络）中，输出依赖于**t**时刻的输入和权重矩阵。在 RNN 中，输出不仅依赖于**t**时刻的输入，还依赖于**t-1**、**t-2**等时刻的输入，以及权重矩阵。这可以通过进一步计算隐藏向量**h**（对于
    FFNN）和**s**（对于 RNN）来解释。乍一看，似乎**t**时刻的状态依赖于**t**时刻的输入、**t-1**时刻的状态和权重矩阵；而**t-1**时刻的状态依赖于**t-1**时刻的输入、**t-2**时刻的状态，依此类推，形成一个从第一时刻开始回溯的链条。不过，FFNN
    和 RNN 的输出计算是相同的。
- en: RNN Architectures
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RNN 架构
- en: RNNs can come in many forms, and the appropriate architecture needs to be chosen
    depending on the problem we are solving.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: RNN（循环神经网络）可以有多种形式，具体使用哪种架构需要根据我们要解决的问题来选择。
- en: '![Figure 5.11 Different architectures of RNNs'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.11 不同架构的 RNN'
- en: '](img/C13783_05_11.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_05_11.jpg)'
- en: Figure 5.11 Different architectures of RNNs
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.11 不同架构的 RNN
- en: '*One to many*: In this architecture, a single input is given, and the output
    is a sequence. An example of this is image captioning, where the input is a single
    image, and the output is a sequence of words explaining the image.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*一对多*：在这种架构中，给定一个单一的输入，输出是一个序列。一个例子是图像描述，其中输入是单一的图像，输出是一系列描述图像的单词。'
- en: '*Many to one*: In this architecture, a sequence of inputs is given, but a single
    output is expected. An example is any time series prediction where the next timestep
    in the sequence needs to be predicted, given the previous timesteps.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*多对一*：在这种架构中，给定一个输入序列，但期望一个单一的输出。一个例子是时间序列预测，其中需要预测下一个时刻的值，基于之前的时刻。'
- en: '*Many to many*: In this architecture, an input sequence is given to the network,
    and the network outputs a sequence. In this case, the sequence can be either synced
    or not synced. For example, in machine translation, the whole sentence needs to
    be fed in before the networks starts to translate it. Sometimes, the input and
    output are not in sync; for example, in the case of speech enhancement, where
    an audio frame is given as input and a cleaner version of the input frame is the
    output expected. In such cases, the input and output are in sync.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*多对多*：在这种架构中，输入序列被提供给网络，网络输出一个序列。在这种情况下，序列可以是同步的，也可以是不同步的。例如，在机器翻译中，整个句子需要先输入网络，然后网络才开始进行翻译。有时，输入和输出不是同步的；例如，在语音增强中，输入是一个音频帧，而输出是该音频帧的清晰版本。在这种情况下，输入和输出是同步的。'
- en: RNNs can also be stacked on top of each other. It is important to note that
    each RNN in the stack has its own weight matrices. So, the weight matrices are
    shared on the horizontal axis (the time axis) and not on the vertical axis (the
    number of RNNs).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: RNN 也可以堆叠在一起。需要注意的是，每个堆叠中的 RNN 都有自己的权重矩阵。因此，权重矩阵在横向（时间轴）上是共享的，而不是在纵向（RNN 数量轴）上共享的。
- en: '![Figure 5.12: Stacked RNNs'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.12: 堆叠的 RNN'
- en: '](img/C13783_5_11.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_5_11.jpg)'
- en: 'Figure 5.12: Stacked RNNs'
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 5.12: 堆叠的 RNN'
- en: BPTT
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: BPTT
- en: RNNs can deal with varying sequence lengths, can be used in different forms,
    and can be stacked on top of each other. Previously, you have come across the
    back propagation technique to backpropagate loss values to adjust weights. In
    the case of RNNs, something similar can be done, with a bit of a twist, which
    is a gate loss through time. It's called **BPTT**.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: RNN 可以处理不同长度的序列，能以不同形式使用，且可以堆叠在一起。之前，你已经遇到过反向传播技术，用于反向传播损失值以调整权重。对于 RNN，也可以进行类似的操作，不过稍有不同，那就是通过时间传递的门控损失。它被称为**BPTT**（反向传播通过时间）。
- en: 'From the basic theory of back propagation, we know the following:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 根据反向传播的基本理论，我们知道以下内容：
- en: '![Figure 5.13: Expression for weight update'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.13: 权重更新的表达式'
- en: '](img/C13783_05_13.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_05_13.jpg)'
- en: 'Figure 5.13: Expression for weight update'
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 5.13: 权重更新的表达式'
- en: 'The update value is calculated through gradient calculations using the chain
    rule:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 更新值是通过链式法则的梯度计算得出的：
- en: '![Figure 5.14 Partial derivative of error with regards to weight'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.14 权重的误差偏导数'
- en: '](img/C13783_05_14.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_05_14.jpg)'
- en: Figure 5.14 Partial derivative of error with regards to weight
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.14 误差相对于权重的偏导数
- en: Here, **α** is the learning rate. The partial derivative of **Error** (**loss**)
    with respect to the weight matrix is the main calculation. Once this new matrix
    is obtained, adjusting the weight matrices is simply adding this new matrix, scaled
    by a learning factor, to itself.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，**α** 是学习率。误差（**损失**）相对于权重矩阵的偏导数是主要的计算。获得新的矩阵后，调整权重矩阵就是将这个新矩阵按学习因子缩放后加到原矩阵上。
- en: When calculating the update values for RNNs, we will use BPTT.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算 RNN 的更新值时，我们将使用 BPTT。
- en: 'Let''s look at an example to understand this better. Consider a loss function,
    such as the mean squared error (which is commonly used for regression problems):'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来更好地理解这一点。考虑一个损失函数，例如均方误差（常用于回归问题）：
- en: '![Figure 5.15: Loss function'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.15：损失函数'
- en: '](img/C13783_5_15.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_5_15.jpg)'
- en: 'Figure 5.15: Loss function'
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.15：损失函数
- en: 'At timestep **t = 3**, the loss calculated is as shown:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间步 **t = 3** 时，计算得到的损失如图所示：
- en: '![Figure 5.16 Loss at time t=3'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.16 时间 t=3 时的损失'
- en: '](img/C13783_05_16.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_05_16.jpg)'
- en: Figure 5.16 Loss at time t=3
  id: totrans-109
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.16 时间 t=3 时的损失
- en: This loss needs to be backpropagated, and the **Wy**, **Wx**, and **Ws** weights
    need to be updated.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这个损失需要进行反向传播，**Wy**、**Wx** 和 **Ws** 权重需要更新。
- en: As seen previously, we need to calculate the update value to adjust these weights,
    and this update value can be calculated using partial derivatives and the chain
    rule.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们需要计算更新值来调整这些权重，这个更新值可以通过偏导数和链式法则来计算。
- en: 'There are three parts to doing this:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此操作有三个部分：
- en: Update Weight **Wy** by calculating the partial derivative of the error with
    respect to **Wy**
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过计算误差相对于 **Wy** 的偏导数来更新权重 **Wy**
- en: Update Weight **Ws** by calculating the partial derivative of the error with
    respect to **Ws**
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过计算误差相对于 **Ws** 的偏导数来更新权重 **Ws**
- en: Update Weight **Wx** by calculating the partial derivative of the error with
    respect to **Wx**
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过计算误差相对于 **Wx** 的偏导数来更新权重 **Wx**
- en: Before we look at these updates, let's unroll the model and keep the part of
    the network that's actually relevant for our calculations.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们查看这些更新之前，先将模型展开，并保留对我们计算有实际意义的网络部分。
- en: '![Figure 5.17 Unfolded RNN with loss at time t=3'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.17 展开后的 RNN，时间 t=3 时的损失'
- en: '](img/C13783_5_18.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_5_18.jpg)'
- en: Figure 5.17 Unfolded RNN with loss at time t=3
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.17 展开后的 RNN，时间 t=3 时的损失
- en: Since we are looking at how loss at **t=3** affects the weight matrices, the
    loss values at and previous to **t=2** are not relevant. Now, we need to understand
    how to backpropagate this loss through the network.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们关注的是时间 **t=3** 时的损失如何影响权重矩阵，时间 **t=2** 及之前的损失值不再相关。现在，我们需要理解如何将损失反向传播通过网络。
- en: Let's look at each of these updates and show the gradient flow for each of the
    updates shown in the preceding figure.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来逐个查看这些更新，并展示前图中每个更新的梯度流动。
- en: Updates and Gradient Flow
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更新与梯度流
- en: 'The updates can be listed as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 更新可以列出如下：
- en: Adjusting weight matrix **Wy**
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整权重矩阵 **Wy**
- en: Adjusting weight matrix **Ws**
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整权重矩阵 **Ws**
- en: For updating **Wx**
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新 **Wx** 的过程
- en: Adjusting Weight Matrix **Wy**
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调整权重矩阵 **Wy**
- en: 'The model can be visualized as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型可以通过如下方式进行可视化：
- en: '![Figure 5.18: Back propagation of loss through weight matrix Wy'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.18：通过权重矩阵 **Wy** 对损失进行反向传播'
- en: '](img/C13783_5_19.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_5_19.jpg)'
- en: 'Figure 5.18: Back propagation of loss through weight matrix Wy'
  id: totrans-131
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.18：通过权重矩阵 **Wy** 对损失进行反向传播
- en: 'For Wy, the update is very simple since there are no additional paths or variables
    between Wy and the error. The matrix can be realized as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 **Wy**，更新非常简单，因为 **Wy** 和误差之间没有其他路径或变量。该矩阵可以按以下方式表示：
- en: '![Figure 5.19: Expression for weight matrix Wy'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.19：权重矩阵 **Wy** 的表达式'
- en: '](img/C13783_05_19.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_05_19.jpg)'
- en: 'Figure 5.19: Expression for weight matrix Wy'
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.19：权重矩阵 **Wy** 的表达式
- en: Adjusting Weight Matrix **Ws**
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调整权重矩阵 **Ws**
- en: '![Figure 5.20: Back propagation of loss through weight matrix Ws with respect
    to S3'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.20：通过权重矩阵 **Ws** 对损失进行反向传播，关于 S3'
- en: '](img/C13783_5_20.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_5_20.jpg)'
- en: 'Figure 5.20: Back propagation of loss through weight matrix Ws with respect
    to S3'
  id: totrans-139
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.20：通过权重矩阵 **Ws** 对损失进行反向传播，关于 S3
- en: 'We can calculate the partial derivate of error with respect to **Ws** using
    the chain rule, as shown in the previous figure. It looks like that is what is
    needed, but it''s important to remember that **S****t**is dependent on **S****t-1**,
    and therefore **S****3** is dependent on **S****2**, so we need to consider **S****2**
    also, as shown here:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.21: Back propagation of loss through weight matrix Ws with respect
    to S2'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_21.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.21: Back propagation of loss through weight matrix Ws with respect
    to S2'
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Again, **S****2** in turn depends on **S****1**, and therefore **S****1** needs
    to be considered, too, as shown here:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.22: Back propagation of loss through weight matrix Ws with respect
    to S1'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_22.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.22: Back propagation of loss through weight matrix Ws with respect
    to S1'
  id: totrans-147
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'At **t=3**, we must consider the contribution of state **S****3** to the error,
    the contribution of state **S****2** to the error, and the contribution of state
    **S****1** to the error, **E****3**. The final value looks like this:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.23: Sum of all derivatives of error with respect to Ws at t=3'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_23.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.23: Sum of all derivatives of error with respect to Ws at t=3'
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In general, for timestep **N**, all the contributions of the previous timesteps
    need to be considered. So, the general formula looks like this:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.24: General expression for the derivative of error with respect
    to Ws'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_24.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.24: General expression for the derivative of error with respect to
    Ws'
  id: totrans-155
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For Updating **Wx**
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can calculate the partial derivate of error with respect to **Wx** using
    the chain rule, as shown in the next few figures. With the same reasoning that
    **S****t** is dependent on **S****t-1**, the calculation of partial derivative
    of error with respect to **Wx** can be divided into three stages at **t=3**.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.25: Back propagation of loss through weight matrix Wx with respect
    to S2'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_25.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.25: Back propagation of loss through weight matrix Wx with respect
    to S2'
  id: totrans-160
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Back propagation of loss through weight matrix Wx with respect to S2:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.26: Back propagation of loss through weight matrix Wx with respect
    to S2'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_26.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.26: Back propagation of loss through weight matrix Wx with respect
    to S2'
  id: totrans-164
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Back propagation of loss through weight matrix Wx with respect to S1:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.27: Back propagation of loss through weight matrix Wx with respect
    to S1'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_27.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.27: Back propagation of loss through weight matrix Wx with respect
    to S1'
  id: totrans-168
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Similar to the previous discussion, at **t=3**, we must consider the contribution
    of state **S****3** to the error, the contribution of state **S****2** to the
    error, and the contribution of state **S****1** to the error, **E****3**. The
    final value looks like this:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.28: Sum of all derivatives of error with respect to Wx at t=3'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_28.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.28: Sum of all derivatives of error with respect to Wx at t=3'
  id: totrans-172
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 5.28: 在 t=3 时关于 Wx 的所有误差导数之和'
- en: 'In general, for timestep N, all the contributions of the previous timesteps
    need to be considered. So, the general formula looks as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，对于时间步 N，需要考虑前面所有时间步的贡献。因此，通用公式如下所示：
- en: '![Figure 5.29: General expression of derivative of error with respect to Wx'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.29: 关于 Wx 的误差导数的通用表达式'
- en: '](img/C13783_5_29.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_5_29.jpg)'
- en: 'Figure 5.29: General expression of derivative of error with respect to Wx'
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 5.29: 关于 Wx 的误差导数的通用表达式'
- en: Since the chain of derivatives already has 5 multiplicative terms at **t=3**,
    this number grows to 22 multiplicative terms for timestep 20\. It's possible that
    each of these derivatives could be either greater than 0 or less than 0\. Due
    to consecutive multiplications with longer timesteps, the total derivative gets
    smaller or larger. This problem is either vanishing gradients or exploding gradients.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 由于链式导数在**t=3**时已经有 5 个相乘项，到第 20 时间步时，这个数量增长到了 22 个相乘项。每一个导数可能大于 0 或小于 0。由于连续乘法和更长的时间步，总导数会变得更小或更大。这个问题即为消失梯度或爆炸梯度。
- en: Gradients
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 梯度
- en: 'The two types of gradients that have been identified are:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 已识别的两种梯度类型是：
- en: Exploding gradients
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爆炸梯度
- en: Vanishing gradients
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消失梯度
- en: Exploding Gradients
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 爆炸梯度
- en: As the name indicates, this happens when gradients explode to much bigger values.
    This could be one of the problems that RNN architectures could encounter with
    larger timesteps. This could happen when each of the partial derivatives is larger
    than **1**, and multiplication of these partial derivatives leads to an even larger
    value. These larger gradient values cause a dramatic shift in the weight values
    each time they are adjusted using back propagation, leading to a network that
    doesn't learn well.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 正如名称所示，当梯度爆炸到更大的值时，就会发生这种情况。这可能是 RNN 架构在较大时间步时遇到的问题之一。当每个偏导数大于 **1** 时，乘法会导致一个更大的值。这些更大的梯度值每次通过反向传播调整权重时，会导致权重发生剧烈变化，从而使网络无法很好地学习。
- en: There are some techniques used to mitigate this issue, such as gradient clipping,
    wherein the gradient is normalized once it exceeds a set threshold.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些技术可以缓解这个问题，比如梯度裁剪，当梯度超过设定的阈值时会进行归一化处理。
- en: Vanishing Gradients
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消失梯度
- en: Whether it is RNNs or CNNs, vanishing gradients could be a problem if calculated
    loss has to travel back a lot. In CNNs, this problem could occur when there are
    a lot of layers with activations such as sigmoid or tanh. The loss has to travel
    all the way back to the initial layers, and these activations generally dilute
    them by the time they reach the initial layers, which means there are almost no
    weight updates for the initial layers, resulting in underfitting. This is even
    common in RNNs, since even if a network has one RNN layer but a large number of
    timesteps, the loss has to travel all the way through the timesteps due to backpropagation
    through time. Since the gradients are multiplicative, as seen in the generalized
    derivative expressions earlier, these values tend to become low, and weights are
    not updated after a certain timestep. This means that even if more timesteps are
    shown to a network, the network can't benefit because the gradients cannot travel
    all the way back. This limitation in RNNs is due to vanishing gradients.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是 RNN 还是 CNN，如果计算出的损失需要反向传播很长时间，消失梯度可能会成为问题。在 CNN 中，当有很多层并且激活函数是 sigmoid 或
    tanh 时，这个问题可能会出现。损失需要反向传播到最初的层，而这些激活函数通常会在损失到达最初的层时将其稀释，意味着初始层几乎没有权重更新，导致欠拟合。即使是在
    RNN 中也很常见，因为即使网络只有一个 RNN 层但时间步长较多，损失也需要通过时间反向传播穿越所有的时间步。由于梯度是相乘的，如前面所见的广义导数表达式，这些值往往变得较小，且在某个时间步后权重不会被更新。这意味着即使给网络显示更多的时间步，网络也无法受益，因为梯度无法完全反向传播。这种
    RNN 的限制是由消失梯度引起的。
- en: As the name indicates, this happens when the gradients become too small. This
    could happen when each of partial derivatives is smaller than 1 and multiplication
    of these partial derivatives leads to a much smaller value. With this geometric
    decay of information, the network cannot learn properly. There are almost no changes
    in the weight values, which leads to underfitting.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: There must be a better mechanism to use to know what parts of the previous timesteps
    to remember, what to forget, and so on. To address this issue, architectures such
    as LSTM networks and GRUs were created.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: RNNs with Keras
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, we have discussed the theory behind RNNs, but there are a lot of frameworks
    available that can abstract away the implementation details. As long as we know
    how to use these frameworks, we can successfully get our projects working. **TensorFlow**,
    **Theano**, **Keras**, **PyTorch**, and **CNTK** are some of these frameworks.
    In this chapter, let's take a closer look at the most commonly used framework,
    called **Keras**. It uses either Tensorflow or Theano as the backend, indicating
    that it creates an even higher level of abstraction than other frameworks. It
    is a tool best suited for beginners. Once comfortable with Keras, tools such as
    TensorFlow give much more power in implementing custom functions.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many variants of RNNs that you will study in the next few chapters,
    but all of them use the same base class, called RNN:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In this chapter, we have discussed the simple form of the RNN, which is called
    **SimpleRNN** in Keras:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As you can see from the arguments here, there are two kinds: one for regular
    kernels, used to compute the outputs of a layer, and the other for recurrent kernels
    used to compute states. Don''t worry too much about constraints, regularizers,
    initializers, and dropout. You can find more about them at https://keras.io/layers/recurrent/.
    They are mostly used to avoid overfitting. The role of activation here is the
    same as the role of activation with any other layer.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: The units are the number of recurrent units in a particular layer. The greater
    the number of units, the more parameters there are that need to be learned.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '`return_sequences` is the argument that specifies whether the RNN layer should
    return the whole sequence or just the last timestep. If `return_sequences` is
    false, the output of the RNN layer is just the last timestep, so we cannot stack
    this with another RNN layer. In other words, if an RNN layer needs to be stacked
    by another RNN layer, `return_sequences` need to be true. If an RNN layer is connected
    to the Dense layer, this can argument can be either true or false, depending on
    the application.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: The `return_state` argument specifies whether the last state of the RNN needs
    to be returned along with the output. This can be set to either True or False,
    depending on the application.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '`go_backwards` can be used if, for any reason, the input sequence needs to
    be processed backward. Keep a note that if this is set to True, even the returned
    sequence is reversed.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '`stateful` is an argument that can be set to true if a state needs to be passed
    between batches. If this argument is set to true, the data needs to be handled
    carefully; we have a topic covering this in detail.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '`unroll` is an argument that leads to the network being unrolled if set to
    true, which can speed up operations but can be very memory extensive depending
    on the timesteps. Generally, this argument is set to true for short sequences.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: 'The number of timesteps is not an argument for a particular layer since it
    stays the same for the whole network, which is represented in the input shape.
    This brings us to the important point of the shape of the network when using RNNs:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-204
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you start building a network with an RNN layer, `input_shape` must be specified.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: After a model is built, `model.summary()` can be used to see the shapes of each
    layer and the total number of parameters.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 23: Building an RNN Model to Show the Stability of Parameters over
    Time'
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's build a simple RNN model to show that the parameters do not change with
    timesteps. Note that while mentioning the `input_shape` argument, `batch_size`
    need not be mentioned unless needed. It is needed for a stateful network, which
    we will discuss next. `batch_size` is mentioned while training the model with
    the fit() or `fit_generator()` functions.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you with the solution:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Import the necessary Python packages. We will be using Sequential, SimpleRNN,
    and Dense.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we define the model and its layers:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You can check the summary of the model:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`model.summary()` gives the following output:'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/C13783_05_30.jpg)'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.30: Model summary for model layers'
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: In this case, `batch_size` parameter, which will be provided by the `fit()`
    function. The output of the RNN layer is **(None, 64)** since it is not returning
    the sequence.
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s look at the model that returns sequence:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The summary of the model that returns sequence looks like this:'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/C13783_05_31.jpg)'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.31: Model summary of sequence-returning model'
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Now the RNN layer is returning a sequence, and therefore its output shape is
    3D instead of 2D, as seen earlier. Also, note that the **Dense** layer is automatically
    adjusted to this change in its input. The **Dense** layer with the current Keras
    version has the capability of adjusting to time_steps from a previous RNN layer.
    In the previous versions of Keras, **TimeDistributed**(**Dense**) was used to
    achieve this.
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We have previously discussed how the RNN shares its parameters over timesteps.
    Let''s see that in action and change the timesteps of the previous model from
    10 to 1,000:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Figure 5.32: Model summary for timesteps'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_05_32.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.32: Model summary for timesteps'
  id: totrans-230
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Clearly, the output shapes of the network changed to this new time_steps. However,
    there is no change in the parameters between the two models.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: This indicates that the parameters are shared over time and are not impacted
    by changing the number of timesteps. Note that the same is applicable to the **Dense**
    layer when operating on more than one timestep.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Stateful versus Stateless
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two modes of operation available with RNNs considering the states:
    the stateless and stateful modes. If the **argument stateful=True**, you are working
    with stateful mode, and **False** signifies stateless mode.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Stateless mode is basically saying that one example in a batch is not related
    to any example in the next batch; that is, every example is independent in the
    given case. The state is reset after every example. Each example has a certain
    number of timesteps depending on the model architecture. For example, the last
    model we saw had 1,000 timesteps, and between these 1000 timesteps, the state
    vector was calculated and passed from one timestep to the next. However, at the
    end of the example or the beginning of the next example, there was no state passed.
    Each example was independent and therefore there was no consideration needed regarding
    the way the data was shuffled.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: In stateful mode, the state from example **i** of **batch 1** is passed to the
    **i+1** example of **batch 2**. This means that the state is passed from one example
    to the next among batches. For this reason, the examples must be contiguous across
    batches and cannot be random. The following figure explains this situation. The
    examples **i**, **i+1**, **i+2**, and so on are contiguous, and so are **j**,
    **j+1**, **j+2**, and so on, and **k**, **k+1**, **k+2**, and so on.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.33 Batch formations for stateful RNN'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_5_33.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.33 Batch formations for stateful RNN
  id: totrans-239
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 24: Turning a Stateless Network into a Stateful Network by Only Changing
    Arguments'
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to turn a network from stateless to stateful by changing the arguments,
    the following steps should be taken.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we would need to import the required Python packages:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, build the model using `Sequential` and define the layers:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Set the optimizer to `Adam`, set `categorical` `crosstropy` as the loss parameter,
    and set the metrics to fit the model. Compile the model and fit the model over
    100 epochs:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Assume that `X` and `Y` are training data as contiguous examples. Turn this
    model into a stateful one:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Set the optimizer to `Adam`, set `categorical` `crossentropy` as the loss parameter,
    and set the metrics to fit the model. Compile the model and fit the model over
    100 epochs:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: You can use a box and whisker plot to visualize the output.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**Expected output:**'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.34: Box and whisker plot for stateful vs stateless'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_05_34.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.34: Box and whisker plot for stateful vs stateless'
  id: totrans-257
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  id: totrans-258
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The output may vary depending on the data used.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: From the concept of stateful models, we understand that the data fed in batches
    need to be contiguous, so turn randomization **OFF**. However, even with **batch_size
    >1**, the data across batches will not be contiguous, so make **batch_size=1**.
    By turning the network to **stateful=True** and fitting it with the mentioned
    parameters, we are essentially training the model correctly in a stateful manner.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: However, we are not using the concept of mini batch gradient descent, and nor
    are we shuffling the data. So, a generator needs to be implemented that can carefully
    train a stateful network, which is outside the scope of this chapter.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '`model.compile` is a function where an optimizer and a loss function are assigned
    to the network, along with the metrics that we care about.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '`model.fit()` is a function that is used to train a model by specifying its
    training data, validation data, the number of epochs, the batch size, the mode
    of shuffling, and more.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 6: Solving a Problem with an RNN – Author Attribution'
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Author attribution is a classic text classification problem that comes under
    the umbrella of natural language processing (NLP). Authorship attribution is a
    well-studied problem that led to the field of **stylometry**.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: In this problem, we are given a set of documents from certain authors. We need
    to train a model to understand the authors' styles and use the model to identify
    the authors of the unknown documents. As with many other NLP problems, it has
    benefited greatly from the increase in available computer power, data, and advanced
    machine learning techniques. This makes authorship attribution a natural candidate
    for the use of **deep learning (DL**). In particular, we can benefit from DL's
    ability to automatically extract the relevant features for a specific problem.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: 'In this activity, we will focus on the following:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Extracting character-level features from the text of each author (to get each
    author's style)
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using those features to build a classification model for authorship attribution
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Applying the model for identifying the author of a set of unknown documents
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: You can find the required data for the activity at https://github.com/TrainingByPackt/Deep-Learning-for-Natural-Language-Processing/tree/master/Lesson%2005.
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The following steps will help you with the solution.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Import the necessary Python packages.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Upload the text document to be used. Then, pre-process the text file by converting
    all text into lowercase, converting all newlines and multiple whitespaces into
    single whitespaces, and removing any mention of the authors' names, otherwise
    we risk data leakage.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To break the long texts into smaller sequences, we use the `Tokenizer` class
    from the Keras framework.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Proceed to create the training and validation sets.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We construct the model graph and perform the training procedure.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the model to the unknown papers. Do this for all the papers in the **Unknown**
    folder.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Expected output:**'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.35: Output for author attribution'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C13783_05_35.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.35: Output for author attribution'
  id: totrans-283
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  id: totrans-284
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for the activity can be found on page 309.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we were introduced to RNNs and covered the major differences
    between the architectures of RNNs and FFNNs. We looked at BPTT and how weight
    matrices are updated. We learned how to use RNNs using Keras and solved a problem
    of author attribution using RNNs in Keras. We looked at the shortcomings of RNNs
    by looking at vanishing gradients and exploding gradients. In the next chapters,
    we will look into architectures that will address these issues.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
