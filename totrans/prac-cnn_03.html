<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Build Your First CNN and Performance Optimization</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>A</span> <strong>convolutional neural network</strong> <span>(</span><strong>CNN</strong><span>) is a type of</span> <strong>feed-forward neural network</strong> <span>(</span><strong>FNN</strong><span>) in which the connectivity pattern between its neurons is inspired by an animal's visual cortex. In the last few years, CNNs have demonstrated superhuman performance in image search services, self-driving cars, automatic video classification, voice recognition, and</span> <strong>natural language processing </strong><span>(</span><strong>NLP</strong><span>).</span></p>
<p class="mce-root"><span>Considering these motivations, in this chapter, we will construct a simple CNN model for image classification from scratch, followed by some theoretical aspects, such as convolutional and pooling operations. Then we will discuss how to tune hyperparameters and optimize the training time of CNNs for improved classification accuracy. Finally, we will build the second CNN model by considering some best practices.</span> <span>In a nutshell, the following topics will be covered in this chapter:</span><br/></p>
<ul>
<li>CNN architectures and drawbacks of DNNs</li>
<li>The convolution operations and pooling layers</li>
<li>Creating and training a CNN for image classification</li>
<li>Model performance optimization</li>
<li>Creating an improved CNN for optimized performance</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CNN architectures and drawbacks of DNNs</h1>
                </header>
            
            <article>
                
<p class="chapter-content CDPAlignLeft CDPAlign">In <a href="00f0eb08-6d6c-48b7-8ffe-db69c7f90a73.xhtml" target="_blank">Chapter 2</a>, <em>Introduction to Convolutional Neural Networks</em>, we discussed that a regular multilayer perceptron works fine for small images (for example, MNIST or CIFAR-10). However, it breaks down for larger images because of the huge number of parameters it requires. For example, a 100 × 100 image has 10,000 pixels, and if the first layer has just 1,000 neurons (which already severely restricts the amount of information transmitted to the next layer), this means 10 million connections; and that is just for the first layer.</p>
<p class="chapter-content CDPAlignLeft CDPAlign">CNNs solve this problem using partially connected layers. Because consecutive layers are only partially connected and because it heavily reuses its weights, a CNN has far fewer parameters than a fully connected DNN, which makes it much faster to train, reduces the risk of overfitting, and requires much less training data. Moreover, when a CNN has learned a kernel that can detect a particular feature, it can detect that feature anywhere on the image. In contrast, when a DNN learns a feature in one location, it can detect it only in that particular location.</p>
<p class="chapter-content CDPAlignLeft CDPAlign">Since images typically have very repetitive features, CNNs are able to generalize much better than DNNs for image processing tasks such as classification, using fewer training examples. Importantly, a DNN has no prior knowledge of how pixels are organized; it does not know that nearby pixels are close. A CNN's architecture embeds this prior knowledge. Lower layers typically identify features in small areas of the images, while higher layers combine the lower-level features into larger features. This works well with most natural images, giving CNNs a decisive head start compared to DNNs:</p>
<div class="chapter-content CDPAlignCenter CDPAlign"><img src="assets/685a8fc6-999c-4f76-92ef-0377bfa260f0.png"/></div>
<div class="chapter-content CDPAlignCenter CDPAlign packt_figref">Figure 1: Regular DNN versus CNN, where each layer has neurons arranged in 3D</div>
<p class="chapter-content">For example, in <em>Figure 1</em>, on the left, you can see a regular three-layer neural network. On the right, a ConvNet arranges its neurons in three dimensions (width, height, and depth) as visualized in one of the layers. Every layer of a ConvNet transforms the 3D input volume to a 3D output volume of neuron activations. The red input layer holds the image, so its width and height would be the dimensions of the image, and the depth would be three (red, green, and blue channels). Therefore, all the multilayer neural networks we looked at had layers composed of a long line of neurons, and we had to flatten input images or data to 1D before feeding them to the neural network.</p>
<p class="chapter-content">However, what happens once you try to feed them a 2D image directly? The answer is that in CNNs, each layer is represented in 2D, which makes it easier to match neurons with their corresponding inputs. We will see examples of this in upcoming sections. Another important fact is that all the neurons in a feature map share the same parameters, so it dramatically reduces the number of parameters in the model; but more importantly, it means that once the CNN has learned to recognize a pattern in one location, it can recognize it in any other location.</p>
<p class="chapter-content">In contrast, once a regular DNN has learned to recognize a pattern in one location, it can recognize it only in that particular location. In multilayer networks such as MLP or DBN, the outputs of all neurons of the input layer are connected to each neuron in the hidden layer, and then the output will again act as the input to the fully connected layer. In CNN networks, the connection scheme that defines the convolutional layer is significantly different. The convolutional layer is the main type of layer in a CNN, where each neuron is connected to a certain region of the input area called the <strong>receptive field</strong>.</p>
<p class="chapter-content">In a typical CNN architecture, a few convolutional layers are connected in a cascade style. Each layer is followed by a <strong>Rectified Linear Unit</strong> (<strong>ReLU</strong>) layer, then a pooling layer, then one or more convolutional layers (+ReLU), then another pooling layer, and finally one or more fully connected layers. Pretty much depending on problem type, the network might be deep though. The output from each convolution layer is a set of objects called <strong>feature maps</strong>, generated by a single kernel filter. Then the feature maps can be used to define a new input to the next layer.</p>
<p class="chapter-content">Each neuron in a CNN network produces an output, followed by an activation threshold, which is proportional to the input and not bound:</p>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="168" src="assets/03186daf-dff9-499d-ad13-731d480942fd.png" width="524"/></div>
<div class="chapter-content CDPAlignCenter CDPAlign packt_figref">Figure 2: A conceptual architecture of a CNN</div>
<p class="chapter-content">As you can see in <em>Figure 2</em>, the pooling layers are usually placed after the convolutional layers <span>(for example, between two convolutional layers)</span>. A pooling layer into subregions then divides the convolutional region. Then, a single representative value is selected, using either a max-pooling or an average pooling technique, to reduce the computational time of subsequent layers. This way, a CNN can be thought of as a feature extractor. To understand this more clearly, refer to the following figure:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f6a1addd-d986-4e6a-b27b-388aa2bfd8f3.png"/></div>
<p class="chapter-content">In this way, the robustness of the feature with respect to its spatial position is increased too. To be more specific, when feature maps are used as image properties and pass through the grayscale image, it gets smaller and smaller as it progresses through the network; but it also typically gets deeper and deeper, as more feature maps will be added.</p>
<p class="chapter-content">We've already discussed the limitations of such FFNN - that is, a very high number of neurons would be necessary, even in a shallow architecture, due to the very large input sizes associated with images, where each pixel is a relevant variable. The convolution operation brings a solution to this problem as it reduces the number of free parameters, allowing the network to be deeper with fewer parameters.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Convolutional operations</h1>
                </header>
            
            <article>
                
<p class="chapter-content">A convolution is a mathematical operation that slides one function over another and measures the integral of their pointwise multiplication. It has deep connections with the Fourier transformation and the Laplace transformation and is heavily used in signal processing. Convolutional layers actually use cross-correlations, which are very similar to convolutions.</p>
<div class="packt_infobox">In mathematics, convolution is a mathematical operation on two functions that produces a third function—that is, the modified (convoluted) version of one of the original functions. The resulting function gives in integral of the pointwise multiplication of the two functions as a function of the amount that one of the original functions is translated. Interested readers can refer to this URL for more information: <a href="https://en.wikipedia.org/wiki/Convolution">https://en.wikipedia.org/wiki/Convolution</a>.</div>
<p class="chapter-content">Thus, the most important building block of a CNN is the convolutional layer. Neurons in the first convolutional layer are not connected to every single pixel in the input image (that is, like FNNs—for example, MLP and DBN) but only to pixels in their receptive fields. See <em>Figure 3</em>. In turn, each neuron in the second convolutional layer is connected only to neurons located within a small rectangle in the first layer:</p>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="212" src="assets/e7c30e9b-9df7-4948-9dc4-617c8ef86b52.png" width="423"/></div>
<div class="chapter-content CDPAlignCenter CDPAlign packt_figref">Figure 3: Each convolutional neuron processes data only for its receptive field</div>
<p class="chapter-content">In <a href="00f0eb08-6d6c-48b7-8ffe-db69c7f90a73.xhtml" target="_blank">Chapter 2</a>, <em>Introduction to Convolutional Neural Networks</em>, we have seen that all multilayer neural networks (for example, MLP) have layers composed of so many neurons, and we have to flatten input images to 1D before feeding them to the neural network. Instead, in a CNN, each layer is represented in 2D, which makes it easier to match neurons with their corresponding inputs.</p>
<div class="packt_infobox">The receptive fields concept is used by CNNs to exploit spatial locality by enforcing a local connectivity pattern between neurons of adjacent layers.</div>
<p class="chapter-content">This architecture allows the network to concentrate on low-level features in the first hidden layer, and then assemble them into higher-level features in the next hidden layer, and so on. This hierarchical structure is common in real-world images, which is one of the reasons why CNNs work so well for image recognition.</p>
<p class="chapter-content">Finally, it not only requires a low number of neurons but also reduces the number of trainable parameters significantly. For example, regardless of image size, building regions of size 5 x 5, each with the same-shared weights, requires only 25 learnable parameters. In this way, it resolves the vanishing or exploding gradients problem in training traditional multilayer neural networks with many layers by using backpropagation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pooling, stride, and padding operations</h1>
                </header>
            
            <article>
                
<p class="chapter-content">Once you've understood how convolutional layers work, the pooling layers are quite easy to grasp. A pooling layer typically works on every input channel independently, so the output depth is the same as the input depth. You may alternatively pool over the depth dimension, as we will see next, in which case the image's spatial dimensions (for example, height and width) remain unchanged but the number of channels is reduced. Let's see a formal definition of pooling layers from the well-known TensorFlow website:</p>
<div class="packt_quote">"The pooling ops sweep a rectangular window over the input tensor, computing a reduction operation for each window (average, max, or max with argmax). Each pooling op uses rectangular windows of size called ksize separated by offset strides. For example, if strides are all ones, every window is used, if strides are all twos, every other window is used in each dimension, and so on."</div>
<p class="chapter-content">Therefore, in summary, just like convolutional layers, each neuron in a pooling layer is connected to the outputs of a limited number of neurons in the previous layer, located within a small rectangular receptive field. However, we must define its size, the stride, and the padding type. So in summary, the output can be computed as follows:</p>
<pre>output[i] = reduce(value[strides * i:strides * i + ksize]),</pre>
<p class="chapter-content">Here, the indices also take the padding values <span>into consideration</span><span>.</span></p>
<div class="packt_infobox">A pooling neuron has no weights. Therefore, all it does is aggregate the inputs using an aggregation function such as max or mean.</div>
<p class="chapter-content">In other words, the goal of using pooling is to subsample the input image in order to reduce the computational load, memory usage, and number of parameters. This helps to avoid overfitting in the training stage. Reducing the input image size also makes the neural network tolerate a little bit of image shift. The spatial semantics of the convolution ops depend on the padding scheme chosen.</p>
<p class="chapter-content">Padding is an operation to increase the size of the input data. In the case of one-dimensional data, you just append/prepend the array with a constant; in two-dimensional data, you surround the matrix with these constants. In n-dimensional, you surround your n-dimensional hypercube with the constant. In most of the cases, this constant is zero and it is called <strong>zero padding</strong>:</p>
<ul>
<li><strong>VALID padding</strong>: Only drops the rightmost columns (or bottommost rows)</li>
<li><strong>SAME padding</strong>: Tries to pad evenly left and right, but if the number of columns to be added is odd, it will add the extra column to the right, as is the case in this example</li>
</ul>
<p class="chapter-content">Let's explain the preceding definition graphically, in the following figure. If we want a layer to have the same height and width as the previous layer, it is common to add zeros around the inputs, as shown in the diagram. This is called <strong>SAME</strong> or <strong>zero</strong> <strong>padding</strong>.</p>
<div class="packt_tip">The term <strong>SAME</strong> means that the output feature map has the same spatial dimensions as the input feature map.</div>
<p class="chapter-content">On the other hand, zero padding is introduced to make the shapes match as needed, equally on every side of the input map. <strong>VALID</strong> means no padding and only drops the rightmost columns (or bottommost rows):</p>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="235" src="assets/fdd19f4b-8552-4d31-8035-6101490b48c9.png" width="391"/></div>
<div class="chapter-content CDPAlignCenter CDPAlign packt_figref">Figure 4: SAME versus VALID padding with CNN</div>
<p class="chapter-content">In the following example (<em>Figure 5</em>), we use a 2 × 2 pooling kernel and a stride of 2 with no padding. Only the <strong>max</strong> input value in each kernel makes it to the next layer since the other inputs are dropped (we will see this later on):</p>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="179" src="assets/10a39cda-7b65-48aa-8ef5-1f412325d5c7.png" width="426"/></div>
<div class="chapter-content CDPAlignCenter CDPAlign packt_figref">Figure 5: An example using max pooling, that is, subsampling</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fully connected layer</h1>
                </header>
            
            <article>
                
<p class="chapter-content">At the top of the stack, a regular fully connected layer (also known as <strong>FNN</strong> or <strong>dense layer</strong>) is added; it acts similar to an MLP, which might be composed of a few fully connected layers (+ReLUs). The final layer outputs (for example, softmax) the prediction. An example is a softmax layer that outputs estimated class probabilities for a multiclass classification.</p>
<p class="chapter-content">Fully connected layers connect every neuron in one layer to every neuron in another layer. Although fully connected FNNs can be used to learn features as well as classify data, it is not practical to apply this architecture to images.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Convolution and pooling operations in TensorFlow</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now that we have seen how convolutional and pooling operations are performed theoretically, let's see how we can perform these operation hands-on using TensorFlow. So let's get started.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applying pooling operations in TensorFlow</h1>
                </header>
            
            <article>
                
<p class="chapter-content"><span class="NormalPACKTCarattere">Using TensorFlow, a</span> <span class="NormalPACKTCarattere">subsampling layer can normally be represented by a <kbd>max_pool</kbd> operation by maintaining the initial parameters of the layer.</span> For <kbd>max_pool</kbd>, it has the following signature in TensorFlow:</p>
<pre>tf.nn.max_pool(value, ksize, strides, padding, data_format, name) </pre>
<p class="chapter-content">Now let's learn how to create a function that utilizes the preceding signature and returns a tensor with type <kbd>tf.float32</kbd>, that is, the max pooled output tensor:</p>
<pre>import tensorflow as tf<br/> 
def maxpool2d(x, k=2): 
   return tf.nn.max_pool(x,  
               ksize=[1, k, k, 1],  
               strides=[1, k, k, 1],  
               padding='SAME') </pre>
<p class="chapter-content">In the preceding code segment, the parameters can be described as follows:</p>
<ul>
<li><kbd>value</kbd>: This is a 4D tensor of <kbd>float32</kbd> elements and shape (batch length, height, width, and channels)</li>
<li><kbd>ksize</kbd>: A list of integers representing the window size on each dimension</li>
<li><kbd>strides</kbd>: The step of the moving windows on each dimension</li>
<li><kbd>data_format</kbd>: <kbd>NHWC</kbd>, <kbd>NCHW</kbd>, and <kbd>NCHW_VECT_C</kbd> are supported</li>
<li><kbd>ordering</kbd>: <kbd>NHWC</kbd> or <kbd>NCHW</kbd></li>
<li><kbd>padding</kbd>: <kbd>VALID</kbd> or <kbd>SAME</kbd></li>
</ul>
<p class="chapter-content">However, depending upon the layering structures in a CNN, there are other pooling operations supported by TensorFlow, as follows:</p>
<ul>
<li><kbd>tf.nn.avg_pool</kbd>: This returns a reduced tensor with the average of each window</li>
<li><kbd>tf.nn.max_pool_with_argmax</kbd>: This returns the <kbd>max_pool</kbd> tensor and a tensor with the flattened index of <kbd>max_value</kbd></li>
<li><kbd>tf.nn.avg_pool3d</kbd>: This performs an <kbd>avg_pool</kbd> operation with a cubic-like</li>
<li>window; the input has an added depth</li>
<li><kbd>tf.nn.max_pool3d</kbd>: This performs the same function as (...) but applies the max operation</li>
</ul>
<p class="chapter-content"><span class="pl-c">Now let's see a concrete example of how the padding thing works in TensorFlow. Suppose we have an input image <kbd>x</kbd> with shape</span> <kbd>[2, 3]</kbd> and one channel. Now we want to see the effect of both <kbd>VALID</kbd> and <kbd>SAME</kbd> paddings:</p>
<ul>
<li><kbd>valid_pad</kbd>: Max pool with 2 x 2 kernel, stride 2, and <kbd>VALID</kbd> padding</li>
<li><kbd>same_pad</kbd>: Max pool with 2 x 2 kernel, stride 2, and <kbd>SAME</kbd> padding</li>
</ul>
<p class="chapter-content">Let's see how we can attain this in Python and TensorFlow. Suppose we have an input image of shape <kbd>[2, 4]</kbd>, which is one channel:</p>
<pre>import tensorflow as tf 
x = tf.constant([[2., 4., 6., 8.,], 
                 [10., 12., 14., 16.]]) </pre>
<p class="chapter-content">Now let's give it a shape accepted by <kbd>tf.nn.max_pool</kbd>:</p>
<pre>x = tf.reshape(x, [1, 2, 4, 1]) </pre>
<p class="chapter-content"><span class="NormalPACKTCarattere">If we want to apply the</span> <kbd>VALID</kbd> <span class="NormalPACKTCarattere">padding with the max pool with a 2 x 2 kernel, stride 2</span>:</p>
<pre>VALID = tf.nn.max_pool(x, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID') </pre>
<p class="chapter-content">On the other hand, using the max pool with a 2 x 2 kernel, stride 2 and <kbd>SAME</kbd> padding:</p>
<pre>SAME = tf.nn.max_pool(x, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME') </pre>
<p class="chapter-content">For <kbd>VALID</kbd> padding, since there is no padding, the output shape is <kbd>[1, 1]</kbd>. However, for the <kbd>SAME</kbd> padding, since we pad the image to the shape <kbd>[2, 4]</kbd> (with - <kbd>inf</kbd>) and then apply the max pool, the output shape is <kbd>[1, 2]</kbd>. Let's validate them:</p>
<pre>print(VALID.get_shape())  
print(SAME.get_shape())  </pre>
<pre>&gt;&gt;&gt; 
(1, 1, 2, 1) 
(1, 1, 2, 1) </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Convolution operations in TensorFlow</h1>
                </header>
            
            <article>
                
<p class="chapter-content">TensorFlow provides a variety of methods for convolution. The canonical form is applied by the <kbd>conv2d</kbd> operation. Let's have a look at the usage of this operation:</p>
<pre class="chapter-content">conv2d(<br/>     input,<br/>     filter,<br/>     strides,<br/>     padding,<br/>     use_cudnn_on_gpu=True,<br/>     data_format='NHWC',<br/>     dilations=[1, 1, 1, 1],<br/>     name=None<br/> )</pre>
<p class="chapter-content">The parameters we use are as follows:</p>
<ul>
<li><kbd>input</kbd>: The operation will be applied to this original tensor. It has a definite format of four dimensions, and the default dimension order is shown next.</li>
<li><kbd>filter</kbd>: This is a tensor representing a kernel or filter. It has a very generic method: (<kbd>filter_height</kbd>, <kbd>filter_width</kbd>, <kbd>in_channels</kbd>, and <kbd>out_channels</kbd>).</li>
<li><kbd>strides</kbd>: This is a list of four <kbd>int</kbd> tensor datatypes, which indicate the sliding windows for each dimension.</li>
<li><kbd>padding</kbd>: This can be <kbd>SAME</kbd> or <kbd>VALID</kbd>. <kbd>SAME</kbd> will try to conserve the initial tensor dimension, but <kbd>VALID</kbd> will allow it to grow if the output size and padding are computed. We will see later how to perform padding along with the pooling layers.</li>
<li><kbd>use_cudnn_on_gpu</kbd>: This indicates whether to use the <kbd>CUDA GPU CNN</kbd> library to accelerate calculations.</li>
<li><kbd>data_format</kbd>: This specifies the order in which data is organized (<kbd>NHWC</kbd> or <kbd>NCWH</kbd>).</li>
<li class="chapter-content"><kbd>dilations</kbd>: This signifies an optional list of <kbd>ints</kbd>. It defaults to (1, 1, 1, 1). 1D tensor of length 4. The dilation factor for each dimension of input. If it is set to k &gt; 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of <kbd>data_format</kbd>; see the preceding code example for details. Dilations in the batch and depth dimensions must be 1.</li>
<li><kbd>name</kbd>: A name for the operation (optional).</li>
</ul>
<p class="chapter-content">The following is an example of a convolutional layer. It concatenates a convolution, adds a bias parameter sum, and finally returns the activation function we have chosen for the whole layer (in this case, the ReLU operation, which is a frequently used one):</p>
<pre>def conv_layer(data, weights, bias, strides=1): 
   x = tf.nn.conv2d(x,  
               weights,  
               strides=[1, strides, strides, 1],  
               padding='SAME') 
   x = tf.nn.bias_add(x, bias) 
   return tf.nn.relu(x) </pre>
<p class="chapter-content">Here, x is the 4D t<span class="pl-c">ensor input (batch size, height, width, and channel).</span> TensorFlow also offers a few other kinds of convolutional layers. For example:</p>
<ul>
<li><kbd>tf.layers.conv1d()</kbd> creates a convolutional layer for 1D inputs. This is useful, for example, in NLP, where a sentence may be represented as a 1D array of words, and the receptive field covers a few neighboring words.</li>
<li><kbd>tf.layers.conv3d()</kbd> creates a convolutional layer for 3D inputs.</li>
<li><kbd>tf.nn.atrous_conv2d()</kbd> creates an a trous convolutional layer (<em>a</em> tro<em>us</em> is French for with holes). This is equivalent to using a regular convolutional layer with a filter dilated by inserting rows and columns of zeros. For example, a 1 × 3 filter equal to (1, 2, 3) may be dilated with a dilation rate of 4, resulting in a dilated filter (1, 0, 0, 0, 2, 0, 0, 0, 3). This allows the convolutional layer to have a larger receptive field at no computational price and using no extra parameters.</li>
<li><kbd>tf.layers.conv2d_transpose ()</kbd> creates a transpose convolutional layer, sometimes called a <strong>deconvolutional layer,</strong> which up-samples an image. It does so by inserting zeros between the inputs, so you can think of this as a regular convolutional layer using a fractional stride.</li>
<li><kbd>tf.nn.depthwise_conv2d()</kbd> creates a depth-wise convolutional layer that applies every filter to every individual input channel independently. Thus, if there are <em>f<sub>n</sub></em> filters and <em>f<sub>n</sub></em><sub>′</sub> input channels, then this will output <em>f<sub>n </sub></em>× <em>f<sub>n</sub></em><sub>′</sub> feature maps.</li>
<li><kbd>tf.layers.separable_conv2d()</kbd> creates a separable convolutional layer that first acts like a depth-wise convolutional layer and then applies a 1 × 1 convolutional layer to the resulting feature maps. This makes it possible to apply filters to arbitrary sets of inputs channels.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training a CNN</h1>
                </header>
            
            <article>
                
<p class="chapter-content">In the previous section, we have seen how to construct a CNN and apply different operations on its different layers. Now when it comes to training a CNN, it is much trickier as it needs a lot of considerations to control those operations such as applying appropriate activation function, weight and bias initialization, and of course, using optimizers intelligently.</p>
<p class="chapter-content">There are also some advanced considerations such as hyperparameter tuning for optimized too. However, that will be discussed in the next section. We first start our discussion with weight and bias initialization.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Weight and bias initialization</h1>
                </header>
            
            <article>
                
<p class="chapter-content">One of the most common initialization techniques in training a DNN is random initialization. The idea of using random initialization is just sampling each weight from a normal distribution of the input dataset with low deviation. Well, a low deviation allows you to bias the network towards the simple 0 solutions.</p>
<p class="chapter-content">But what does it mean? The thing is that, the initialization can be completed without the bad repercussions of actually initializing the weights to 0. Secondly, Xavier initialization is often used to train CNNs. It is similar to random initialization but often turns out to work much better. Now let me explain the reason for this:</p>
<ul>
<li>Imagine that you initialize the network weights randomly but they turn out to start too small. Then the signal shrinks as it passes through each layer until it is too tiny to be useful.</li>
<li>On the other hand, if the weights in a network start too large, then the signal grows as it passes through each layer until it is too massive to be useful.</li>
</ul>
<p class="chapter-content">The good thing is that using Xavier initialization makes sure the weights are just right, keeping the signal in a reasonable range of values through many layers. In summary, it can automatically determine the scale of initialization based on the number of input and output neurons.</p>
<div class="packt_infobox"><span>Interested readers should refer to this publication for detailed information: Xavier Glorot and Yoshua Bengio, <em>Understanding the difficulty of training deep FNNs</em>, Proceedings of the 13th International Conference on <strong>Artificial Intelligence and Statistics</strong> (<strong>AISTATS</strong>) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: W&amp;CP.</span></div>
<p class="chapter-content">Finally, you may ask an intelligent question, <em>Can't I get rid of the random initialization while training a regular DNN (for example, MLP or DBN)</em>? Well, recently, some researchers have been talking about random orthogonal matrix initializations that perform better than just any random initialization for training DNNs:</p>
<ul>
<li><strong>When it comes to initializing the biases</strong>, it is possible and common to initialize the biases to be zero since the asymmetry breaking is provided by the small random numbers in the weights. Setting the biases to a small constant value such as 0.01 for all biases ensures that all ReLU units can propagate some gradient. However, it neither performs well nor does consistent improvement. Therefore, sticking with zero is recommended.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Regularization</h1>
                </header>
            
            <article>
                
<p class="chapter-content">There are several ways of controlling training of CNNs to prevent overfitting in the training phase. For example, L2/L1 regularization, max norm constraints, and drop out:</p>
<ul>
<li><strong>L2 regularization</strong>: This is perhaps the most common form of regularization. It can be implemented by penalizing the squared magnitude of all parameters directly in the objective. For example, using the gradient descent parameter update, L2 regularization ultimately means that every weight is decayed linearly: <em>W += -</em>lambda * <em>W</em> towards zero.</li>
<li><strong>L1 regularization</strong>: This is another relatively common form of regularization, where for each weight <em>w</em> we add the term <em>λ∣w∣</em> to the objective. However, it is also possible to possible to combine the L1 regularization with the L2 regularization: <em>λ1∣w∣+λ2w2</em>, which is commonly known as <strong>Elastic-net regularization</strong>.</li>
<li><strong>Max-norm constraints</strong>: Another form of regularization is to enforce an absolute upper bound on the magnitude of the weight vector for every neuron and use projected gradient descent to enforce the constraint.</li>
</ul>
<p class="mce-root">Finally, dropout is an advanced variant of regularization, which will be discussed later in this chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Activation functions</h1>
                </header>
            
            <article>
                
<p class="chapter-content">The activation ops provide different types of nonlinearities for use in neural networks. These include smooth nonlinearities, such as <kbd>sigmoid</kbd>, <kbd>tanh</kbd>, <kbd>elu</kbd>, <kbd>softplus</kbd>, and <kbd>softsign</kbd>. On the other hand, some continuous but not-everywhere-differentiable functions that can be used are <kbd>relu</kbd>, <kbd>relu6</kbd>, <kbd>crelu</kbd>, and <kbd>relu_x</kbd>. All activation ops apply component-wise and produce a tensor of the same shape as the input tensor. Now let us see how to use a few commonly used activation functions in TensorFlow syntax.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using sigmoid</h1>
                </header>
            
            <article>
                
<p class="chapter-content">In TensorFlow, the signature <kbd>tf.sigmoid(x, name=None)</kbd> computes sigmoid of <kbd>x</kbd> element-wise using <em>y = 1 / (1 + exp(-x))</em> and returns a tensor with the same type <kbd>x</kbd>. Here is the parameter description:</p>
<ul>
<li><kbd>x</kbd>: A tensor. This must be one of the following types: <kbd>float32</kbd>, <kbd>float64</kbd>, <kbd>int32</kbd>, <kbd>complex64</kbd>, <kbd>int64</kbd>, or <kbd>qint32</kbd>.</li>
<li><kbd>name</kbd>: A name for the operation (optional).</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using tanh</h1>
                </header>
            
            <article>
                
<p class="mce-root">In TensorFlow, the signature <kbd>tf.tanh(x, name=None)</kbd> computes a hyperbolic tangent of <kbd>x</kbd> element-wise and returns a tensor with the same type <kbd>x</kbd>. Here is the parameter description:</p>
<ul>
<li><kbd>x</kbd>: A tensor or sparse. This is a tensor with type <kbd>float</kbd>, <kbd>double</kbd>, <kbd>int32</kbd>, <kbd>complex64</kbd>, <kbd>int64</kbd>, or <kbd>qint32</kbd>.</li>
<li><kbd>name</kbd>: A name for the operation (optional).</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using ReLU</h1>
                </header>
            
            <article>
                
<p class="mce-root">In TensorFlow, the signature <kbd>tf.nn.relu(features, name=None)</kbd> computes a rectified linear using <kbd>max(features, 0)</kbd> and returns a tensor having the same type as features. Here is the parameter description:</p>
<ul>
<li><kbd>features</kbd>: A tensor. This must be one of the following types: <kbd>float32</kbd>, <kbd>float64</kbd>, <kbd>int32</kbd>, <kbd>int64</kbd>, <kbd>uint8</kbd>, <kbd>int16</kbd>, <kbd>int8</kbd>, <kbd>uint16</kbd>, and <kbd>half</kbd>.</li>
<li><kbd>name</kbd>: A name for the operation (optional).</li>
</ul>
<p class="mce-root">For more on how to use other activation functions, please refer to the TensorFlow website. Up to this point, we have the minimal theoretical knowledge to build our first CNN network for making a prediction.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building, training, and evaluating our first CNN</h1>
                </header>
            
            <article>
                
<p class="chapter-content">In the next section, we will<span> look at</span> how to classify and distinguish between dogs from cats based on their raw images. We will also look at how to implement our first CNN model to deal with the raw and color image having three channels. This network design and implementation are not straightforward; TensorFlow low-level APIs will be used for this. However, do not worry; later in this chapter, we will see another example of implementing a CNN using TensorFlow's high-level contrib API. Before we formally start, a short description of the dataset is a mandate.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dataset description</h1>
                </header>
            
            <article>
                
<p class="chapter-content">For this example, we will use the dog versus cat dataset from Kaggle that was provided for the infamous Dogs versus Cats classification problem as a playground competition with kernels enabled. The dataset can be downloaded from <a href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data">https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data</a>.</p>
<p class="chapter-content">The train folder contains 25,000 images of dogs and cats. Each image in this folder has the label as part of the filename. The test folder contains 12,500 images, named according to a numeric ID. For each image in the test set, you should predict a probability that the image is a dog (1 = dog, 0 = cat); that is, a binary classification problem. For this example, there are three Python scripts.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 1 – Loading the required packages</h1>
                </header>
            
            <article>
                
<p class="chapter-content">Here we import the required packages and libraries. Note that depending upon the platform, your imports might be different:</p>
<pre>import time 
import math 
import random 
import os 
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import tensorflow as tf 
import Preprocessor 
import cv2 
import LayersConstructor 
from sklearn.metrics import confusion_matrix 
from datetime import timedelta 
from sklearn.metrics.classification import accuracy_score 
from sklearn.metrics import precision_recall_fscore_support </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 2 – Loading the training/test images to generate train/test set</h1>
                </header>
            
            <article>
                
<p class="chapter-content">We set the number of color channels as 3 for the images. In the previous section, we have seen that it should be 1 for grayscale images:</p>
<pre>num_channels = 3 </pre>
<p class="chapter-content">For the simplicity, we assume the image dimensions should be squares only. Let's set the size to be <kbd>128</kbd>:</p>
<pre>img_size = 128 </pre>
<p class="chapter-content">Now that we have the image size (that is, <kbd>128</kbd>) and the number of the channel (that is, 3), the size of the image when flattened to a single dimension would be the multiplication of the image dimension and the number of channels, as follows:</p>
<pre>img_size_flat = img_size * img_size * num_channels </pre>
<p class="chapter-content">Note that, at a later stage, we might need to reshape the image for the max pooling and convolutional layers, so we need to reshape the image. For our case, it would be the tuple with height and width of images used to reshape arrays:</p>
<pre>img_shape = (img_size, img_size)  </pre>
<p class="chapter-content">We should have explicitly defined the labels (that is, classes) since we only have the raw color image, and so the images do not have the labels like other numeric machine learning dataset, have. Let's explicitly define the class info as follows:</p>
<pre>classes = ['dogs', 'cats']  
num_classes = len(classes) </pre>
<p class="chapter-content">We need to define the batch size that needs to be trained on our CNN model later on:</p>
<pre>batch_size = 14  </pre>
<p class="chapter-content">Note that we also can define what portion of the training set will be used as the validation split. Let's assume that 16% will be used, for simplicity:</p>
<pre>validation_size = 0.16  </pre>
<p class="chapter-content">One <span>important</span> thing to set <span>is</span> how long to wait after the validation loss stops improving before terminating the training. We should use none if we do not want to implement early stopping:</p>
<pre>early_stopping = None   </pre>
<p class="chapter-content">Now, download the dataset and you have to do one thing manually: separate the images of dogs and cats and place them in two separate folders. To be more specific, suppose you put your training set under the path <kbd>/home/DoG_CaT/data/train/</kbd>. In the train folder, create two separate folders <kbd>dogs</kbd> and <kbd>cats</kbd> but only show the path to <kbd>DoG_CaT/data/train/</kbd>. We also assume that our test set is in the <kbd>/home/DoG_CaT/data/test/</kbd> directory. In addition, you can define the checkpoint directory where the logs and model checkpoint files will be written:</p>
<pre>train_path = '/home/DoG_CaT/data/train/' 
test_path = '/home/DoG_CaT/data/test/' 
checkpoint_dir = "models/" </pre>
<p class="chapter-content"><span class="NormalPACKTCarattere">Then we start reading the training set and prepare it for the CNN model. For processing the test and train set, we have another script <kbd>Preprocessor.py</kbd>. Nonetheless, it would be better to prepare the test set as well</span><strong>:</strong></p>
<pre>data = Preprocessor.read_train_sets(train_path, img_size, classes, validation_size=validation_size) </pre>
<p class="chapter-content">The preceding line of code reads the raw images of cats and dogs and creates the training set. The <kbd>read_train_sets()</kbd> function goes as follows:</p>
<pre>def read_train_sets(train_path, image_size, classes, validation_size=0): 
  class DataSets(object): 
      pass 
      data_sets = DataSets() 
      images, labels, ids, cls = load_train(train_path, image_size, classes) 
      images, labels, ids, cls = shuffle(images, labels, ids, cls) <br/>  
      if isinstance(validation_size, float): 
          validation_size = int(validation_size * images.shape[0]) 
          validation_images = images[:validation_size] 
          validation_labels = labels[:validation_size] 
          validation_ids = ids[:validation_size] 
          validation_cls = cls[:validation_size] 
          train_images = images[validation_size:] 
          train_labels = labels[validation_size:] 
          train_ids = ids[validation_size:] 
          train_cls = cls[validation_size:] 
          data_sets.train = DataSet(train_images, train_labels, train_ids, train_cls) 
          data_sets.valid = DataSet(validation_images, validation_labels, validation_ids, validation_cls) 
  return data_sets </pre>
<p class="chapter-content">In the previous code segment, we have used the method <kbd>load_train()</kbd> to load the images which is an instance of a class called <kbd>DataSet</kbd>:</p>
<pre>def load_train(train_path, image_size, classes): 
    images = [] 
    labels = [] 
    ids = [] 
    cls = [] 
 
    print('Reading training images') 
    for fld in classes:    
        index = classes.index(fld) 
        print('Loading {} files (Index: {})'.format(fld, index)) 
        path = os.path.join(train_path, fld, '*g') 
        files = glob.glob(path) <br/>        for fl in files: 
            image = cv2.imread(fl) 
            image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR) 
            images.append(image) 
            label = np.zeros(len(classes)) 
            label[index] = 1.0 
            labels.append(label) 
            flbase = os.path.basename(fl) 
            ids.append(flbase) 
            cls.append(fld) <br/>    images = np.array(images) 
    labels = np.array(labels) 
    ids = np.array(ids) 
    cls = np.array(cls) 
    return images, labels, ids, cls </pre>
<p class="chapter-content">The <kbd>DataSet</kbd> class, which is used to generate the batches of the training set, is as follows:</p>
<pre>class DataSet(object): 
   
  def next_batch(self, batch_size): 
    """Return the next `batch_size` examples from this data set.""" 
    start = self._index_in_epoch 
    self._index_in_epoch += batch_size 
    if self._index_in_epoch &gt; self._num_examples: 
      # Finished epoch 
      self._epochs_completed += 1 
      start = 0 
      self._index_in_epoch = batch_size 
      assert batch_size &lt;= self._num_examples 
    end = self._index_in_epoch 
    return self._images[start:end], self._labels[start:end], self._ids[start:end], self._cls[start:end] </pre>
<p class="chapter-content">Then, similarly, we prepare the test set from the test images that are mixed (dogs and cats):</p>
<pre>test_images, test_ids = Preprocessor.read_test_set(test_path, img_size) </pre>
<p class="chapter-content">We have the <kbd>read_test_set()</kbd> function for ease, as follows:</p>
<pre>def read_test_set(test_path, image_size): 
  images, ids  = load_test(test_path, image_size) 
  return images, ids </pre>
<p class="chapter-content">Now, similar to the training set, we have a dedicated function called <kbd>load_test ()</kbd> for loading the test set, which goes as follows:</p>
<pre>def load_test(test_path, image_size): 
  path = os.path.join(test_path, '*g') 
  files = sorted(glob.glob(path)) 
 
  X_test = [] 
  X_test_id = [] 
  print("Reading test images") 
  for fl in files: 
      flbase = os.path.basename(fl) 
      img = cv2.imread(fl) 
      img = cv2.resize(img, (image_size, image_size), cv2.INTER_LINEAR) 
      X_test.append(img) 
      X_test_id.append(flbase) <br/>  X_test = np.array(X_test, dtype=np.uint8) 
  X_test = X_test.astype('float32') 
  X_test = X_test / 255 
  return X_test, X_test_id </pre>
<p class="chapter-content">Well done! We can now see some randomly selected images. For this, we have the helper function called <kbd>plot_images()</kbd>; it creates a figure with 3 x 3 sub-plots. So, all together, nine images will be plotted, along with their true label. It goes as follows:</p>
<pre>def plot_images(images, cls_true, cls_pred=None): 
    if len(images) == 0: 
        print("no images to show") 
        return  
    else: 
        random_indices = random.sample(range(len(images)), min(len(images), 9))         
        images, cls_true  = zip(*[(images[i], cls_true[i]) for i in random_indices])     
    fig, axes = plt.subplots(3, 3) 
    fig.subplots_adjust(hspace=0.3, wspace=0.3) 
    for i, ax in enumerate(axes.flat): 
        # Plot image. 
        ax.imshow(images[i].reshape(img_size, img_size, num_channels)) 
        if cls_pred is None: 
            xlabel = "True: {0}".format(cls_true[i]) 
        else: 
            xlabel = "True: {0}, Pred: {1}".format(cls_true[i], cls_pred[i]) 
        ax.set_xlabel(xlabel)         
        ax.set_xticks([]) 
        ax.set_yticks([])     
    plt.show() </pre>
<p class="chapter-content">Let's get some random images and their labels from the train set:</p>
<pre>images, cls_true  = data.train.images, data.train.cls </pre>
<p>Finally, we plot the images and labels using our helper-function in the preceding code:</p>
<pre>  
plot_images(images=images, cls_true=cls_true) </pre>
<p class="mce-root">The preceding line of code generates the true labels of the images that are randomly selected:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="295" src="assets/c9839726-b1c1-4883-87a7-19b3883db8a9.png" width="354"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 6: The true labels of the images that are randomly selected</div>
<p class="chapter-content">Finally, we can print the dataset statistics:</p>
<pre class="mce-root">print("Size of:") 
print("  - Training-set:tt{}".format(len(data.train.labels)))  
print("  - Test-set:tt{}".format(len(test_images))) 
print("  - Validation-set:t{}".format(len(data.valid.labels))) </pre>
<pre class="mce-root">&gt;&gt;&gt;<br/>Reading training images<br/> Loading dogs files (Index: 0)<br/> Loading cats files (Index: 1)<br/> Reading test images<br/> Size of:<br/> - Training-set: 21000<br/> - Test-set: 12500<br/> - Validation-set: 4000</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 3- Defining CNN hyperparameters</h1>
                </header>
            
            <article>
                
<p class="chapter-content">Now that we have the training and test set, it's time to define the hyperparameters for the CNN model before we start constructing. In the first and the second convolutional layers, we define the width and height of each filter, that is, <kbd>3</kbd>, where the number of filters is <kbd>32</kbd>:</p>
<pre class="mce-root">filter_size1 = 3  
num_filters1 = 32  
filter_size2 = 3  
num_filters2 = 32  </pre>
<p class="chapter-content">The third convolutional layer has equal dimensions but twice the filters; that is, <kbd>64</kbd> filters:</p>
<pre class="chapter-content">filter_size3 = 3<br/>num_filters3 = 64  </pre>
<p class="chapter-content"><span class="NormalPACKTCarattere">The last two layers are fully connected layers, specifying the number of neurons:</span></p>
<pre class="mce-root">fc_size = 128     </pre>
<p class="chapter-content">Now let's make the training slower for more intensive training by setting a lower value of the learning rate, as follows:</p>
<pre class="mce-root">learning_rate=1e-4  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 4 – Constructing the CNN layers</h1>
                </header>
            
            <article>
                
<p class="chapter-content">Once we have defined the CNN hyperparameters, the next task is to implement the CNN network. As you can guess, for our task, we will construct a CNN network having three convolutional layers, a flattened layer and two fully connected layers (refer to <kbd>LayersConstructor.py</kbd>). Moreover, we need to define the weight and the bias as well. Furthermore, we will have implicit max-pooling layers too. At first, let's define the weight. In the following, we have the <kbd>new_weights()</kbd> method that asks for the image shape and returns the truncated normal shapes:</p>
<pre class="mce-root">def new_weights(shape): 
    return tf.Variable(tf.truncated_normal(shape, stddev=0.05)) </pre>
<p class="chapter-content">Then we define the biases using the <kbd>new_biases()</kbd> method:</p>
<pre class="mce-root">def new_biases(length): 
    return tf.Variable(tf.constant(0.05, shape=[length])) </pre>
<p class="chapter-content">Now let's define a method, <kbd>new_conv_layer()</kbd>, for constructing a convolutional layer. The method takes the input batch, number of input channels, filter size, and number of filters and it also uses the max pooling (if true, we use a 2 x 2 max pooling) to construct a new convolutional layer. The workflow of the method is as follows:</p>
<ol>
<li>Define the shape of the filter weights for the convolution, which is determined by the TensorFlow API.</li>
<li>Create the new weights (that is, filters) with the given shape and new biases, one for each filter.</li>
<li>Create the TensorFlow operation for the convolution where the strides are set to 1 in all dimensions. The first and last stride must always be 1, because the first is for the image-number and the last is for the input channel. For example, strides= (1, 2, 2, 1) would mean that the filter is moved two pixels across the <em>x</em> axis and <em>y</em> axis of the image.</li>
<li>Add the biases to the results of the convolution. Then a bias-value is added to each filter-channel.</li>
<li>It then uses the pooling to downsample the image resolution. This is 2 x 2 max pooling, which means that we consider 2 x 2 windows and select the largest value in each window. Then we move two pixels to the next window.</li>
<li>ReLU is then used to calculate the <em>max(x, 0)</em> for each input pixel <em>x</em>. As stated earlier, a ReLU is normally executed before the pooling, but since <kbd>relu(max_pool(x)) == max_pool(relu(x))</kbd> we can save 75% of the relu-operations by max-pooling first.</li>
<li>Finally, it returns both the resulting layer and the filter-weights because we will plot the weights later.</li>
</ol>
<p class="mce-root">Now we define a function to construct the convolutional layer to be used:</p>
<pre class="mce-root">def new_conv_layer(input,  num_input_channels, filter_size, num_filters,                    use_pooling=True):   
    shape = [filter_size, filter_size, num_input_channels, num_filters] 
    weights = new_weights(shape=shape) 
    biases = new_biases(length=num_filters) 
    layer = tf.nn.conv2d(input=input, 
                         filter=weights, 
                         strides=[1, 1, 1, 1], 
                         padding='SAME') 
    layer += biases 
    if use_pooling: 
        layer = tf.nn.max_pool(value=layer, 
                               ksize=[1, 2, 2, 1], 
                               strides=[1, 2, 2, 1], 
                               padding='SAME') 
    layer = tf.nn.relu(layer) 
    return layer, weights </pre>
<p class="chapter-content">The next task is to define the flattened layer:</p>
<ol>
<li>Get the shape of the input layer.</li>
<li>The number of features is <kbd>img_height * img_width * num_channels</kbd>. The <kbd>get_shape()</kbd> function TensorFlow is used to calculate this.</li>
<li>It will then reshape the layer to (<kbd>num_images</kbd><span><span> and</span></span> <kbd>num_features</kbd>). We just set the size of the second dimension to <kbd>num_features</kbd> and the size of the first dimension to -1, which means the size in that dimension is calculated so the total size of the tensor is unchanged from the reshaping.</li>
<li>Finally, it returns both the flattened layer and the number of features.</li>
</ol>
<p class="mce-root">The following code does exactly the same as described before <kbd>defflatten_layer(layer)</kbd>:</p>
<pre class="mce-root">    layer_shape = layer.get_shape() 
    num_features = layer_shape[1:4].num_elements() 
    layer_flat = tf.reshape(layer, [-1, num_features]) 
    return layer_flat, num_features </pre>
<p class="chapter-content">Finally, we need to construct the fully connected layers. The following function, <kbd>new_fc_layer()</kbd>, takes the input batches, number of batches, and number of outputs (that is, predicted classes) and it uses the ReLU. It then creates the weights and biases based on the methods we define earlier in this step. Finally, it calculates the layer as the matrix multiplication of the input and weights, and then adds the bias values:</p>
<pre class="mce-root">def new_fc_layer(input, num_inputs, num_outputs, use_relu=True):  
    weights = new_weights(shape=[num_inputs, num_outputs]) 
    biases = new_biases(length=num_outputs) 
    layer = tf.matmul(input, weights) + biases 
    if use_relu: 
        layer = tf.nn.relu(layer) 
    return layer </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 5 – Preparing the TensorFlow graph</h1>
                </header>
            
            <article>
                
<p class="chapter-content">We now create the placeholders for the TensorFlow graph:</p>
<pre class="mce-root">x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x') 
x_image = tf.reshape(x, [-1, img_size, img_size, num_channels]) 
y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true') 
y_true_cls = tf.argmax(y_true, axis=1) </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 6 – Creating a CNN model</h1>
                </header>
            
            <article>
                
<p class="chapter-content">Now we have the input; that is, <kbd>x_image</kbd> is ready to feed to the convolutional layer. We formally create a convolutional layer, followed by the max pooling:</p>
<pre class="mce-root">layer_conv1, weights_conv1 =  
    LayersConstructor.new_conv_layer(input=x_image, 
                   num_input_channels=num_channels, 
                   filter_size=filter_size1, 
                   num_filters=num_filters1, 
                   use_pooling=True) </pre>
<p class="chapter-content">We must have the second convolutional layer, where the input is the first convolutional layer, <kbd>layer_conv1</kbd>, followed by the max pooling:</p>
<pre class="mce-root">layer_conv2, weights_conv2 =  
    LayersConstructor.new_conv_layer(input=layer_conv1, 
                   num_input_channels=num_filters1, 
                   filter_size=filter_size2, 
                   num_filters=num_filters2, 
                   use_pooling=True) </pre>
<p class="chapter-content">We now have the third convolutional layer where the input is the output of the second convolutional layer, that is, <kbd>layer_conv2</kbd> followed by the max pooling:</p>
<pre class="mce-root">layer_conv3, weights_conv3 =  
    LayersConstructor.new_conv_layer(input=layer_conv2, 
                   num_input_channels=num_filters2, 
                   filter_size=filter_size3, 
                   num_filters=num_filters3, 
                   use_pooling=True) </pre>
<p class="chapter-content">Once the third convolutional layer is instantiated, we then instantiate the flattened layer as follows:</p>
<pre class="mce-root">layer_flat, num_features = LayersConstructor.flatten_layer(layer_conv3) </pre>
<p class="chapter-content">Once we have flattened the images, they are ready to be fed to the first fully connected layer. We use the ReLU:</p>
<pre class="mce-root">layer_fc1 = LayersConstructor.new_fc_layer(input=layer_flat, 
                         num_inputs=num_features, 
                         num_outputs=fc_size, 
                         use_relu=True) </pre>
<p class="chapter-content">Finally, we have to have the second and the final fully connected layer where the input is the output of the first fully connected layer:</p>
<pre class="mce-root">layer_fc2 = LayersConstructor.new_fc_layer(input=layer_fc1, 
                         num_inputs=fc_size, 
                         num_outputs=num_classes, 
                         use_relu=False) </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 7 – Running the TensorFlow graph to train the CNN model</h1>
                </header>
            
            <article>
                
<p class="chapter-content">The following steps are used to perform the training. The codes are self-explanatory, like the ones that we have already used in our previous examples. We use softmax to predict the classes by comparing them with true classes:</p>
<pre class="mce-root">y_pred = tf.nn.softmax(layer_fc2) 
y_pred_cls = tf.argmax(y_pred, axis=1) 
cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc2,                                               labels=y_true) </pre>
<p class="chapter-content">We define the <kbd>cost</kbd> function and then the optimizer (Adam optimizer in this case). Then we compute the accuracy:</p>
<pre class="mce-root">cost_op= tf.reduce_mean(cross_entropy) 
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost_op) 
correct_prediction = tf.equal(y_pred_cls, y_true_cls) 
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) </pre>
<p class="chapter-content">Then we initialize all the ops using the <kbd>global_variables_initializer()</kbd> function from TensorFlow:</p>
<pre class="mce-root">init_op = tf.global_variables_initializer() </pre>
<p class="mce-root">Then we create and run the TensorFlow session to carry the training across the tensors:</p>
<pre class="mce-root">session = tf.Session() 
session.run(init_op) </pre>
<p class="chapter-content">We then feed out training data so that the batch size to 32 (see <em>Step 2</em>):</p>
<pre class="mce-root">train_batch_size = batch_size </pre>
<p class="chapter-content">We maintain two lists to track the training and validation accuracy:</p>
<pre class="mce-root">acc_list = [] 
val_acc_list = [] </pre>
<p class="chapter-content">We then count the total number of iterations performed so far and create an empty list to keep track of all the iterations:</p>
<pre class="mce-root">total_iterations = 0 
iter_list = [] </pre>
<p class="chapter-content">We formally start the training by invoking the <kbd>optimize()</kbd> function, which takes a number of iterations. It needs two:</p>
<ul>
<li>The <kbd>x_batch</kbd> of training examples that holds a batch of images and</li>
<li><kbd>y_true_batch</kbd>, the true labels for those images</li>
</ul>
<p class="chapter-content">It then converts the shape of each image from (<kbd>num</kbd> examples, rows, columns, depth) to (<kbd>num</kbd> examples, flattened image shape). After that, we put the batch into a <kbd>dict</kbd> for placeholder variables in the TensorFlow graph. Later on, we run the optimizer on the batch of training data.</p>
<p class="chapter-content">Then, TensorFlow assigns the variables in <kbd>feed_dict_train</kbd> to the placeholder variables. Optimizer is then executed to print the status at end of each epoch. Finally, it updates the total number of iterations that we performed:</p>
<pre class="mce-root">def optimize(num_iterations): 
    global total_iterations 
    best_val_loss = float("inf") 
    patience = 0 
    for i in range(total_iterations, total_iterations + num_iterations): 
        x_batch, y_true_batch, _, cls_batch = data.train.next_batch(train_batch_size) 
        x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(train_batch_size) 
        x_batch = x_batch.reshape(train_batch_size, img_size_flat) <br/>        x_valid_batch = x_valid_batch.reshape(train_batch_size, img_size_flat) 
        feed_dict_train = {x: x_batch, y_true: y_true_batch}         
        feed_dict_validate = {x: x_valid_batch, y_true: y_valid_batch} 
        session.run(optimizer, feed_dict=feed_dict_train)         
 
        if i % int(data.train.num_examples/batch_size) == 0:  
            val_loss = session.run(cost, feed_dict=feed_dict_validate) 
            epoch = int(i / int(data.train.num_examples/batch_size)) 
            acc, val_acc = print_progress(epoch, feed_dict_train, feed_dict_validate, val_loss) 
            acc_list.append(acc) 
            val_acc_list.append(val_acc) 
            iter_list.append(epoch+1) 
             
            if early_stopping:     
                if val_loss &lt; best_val_loss: 
                    best_val_loss = val_loss 
                    patience = 0 
                else: 
                    patience += 1 
                if patience == early_stopping: 
                    break 
    total_iterations += num_iterations </pre>
<p class="chapter-content">We will show how our training went along in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 8 – Model evaluation</h1>
                </header>
            
            <article>
                
<p class="chapter-content">We have managed to finish the training. It is time to evaluate the model. Before, we start evaluating the model, let's implement some auxiliary functions for plotting the example errors and printing the validation accuracy. The <kbd>plot_example_errors()</kbd> takes two parameters. The first is <kbd>cls_pred</kbd>, which is an array of the predicted class-number for all images in the test set.</p>
<p class="chapter-content">The second parameter, <kbd>correct</kbd>, is a <kbd>boolean</kbd> array to predict whether the predicted class is equal to <kbd>true</kbd> class for each image in the test set. At first, it gets the images from the test set that have been incorrectly classified. Then it gets the predicted and the true classes for those images, and finally it plots the first nine images with their classes (that is, predicted versus true labels):</p>
<pre class="mce-root">def plot_example_errors(cls_pred, correct): 
    incorrect = (correct == False)     
    images = data.valid.images[incorrect]     
    cls_pred = cls_pred[incorrect] 
    cls_true = data.valid.cls[incorrect]     
    plot_images(images=images[0:9], cls_true=cls_true[0:9], cls_pred=cls_pred[0:9]) </pre>
<p class="chapter-content">The second auxiliary function is called <kbd>print_validation_accuracy()</kbd>; it prints the validation accuracy. It allocates an array for the predicted classes, which will be calculated in batches and filled into this array, and then it calculates the predicted classes for the batches:</p>
<pre class="mce-root">def print_validation_accuracy(show_example_errors=False, show_confusion_matrix=False): 
    num_test = len(data.valid.images) 
    cls_pred = np.zeros(shape=num_test, dtype=np.int) 
    i = 0 
    while i &lt; num_test: 
        # The ending index for the next batch is denoted j. 
        j = min(i + batch_size, num_test) 
        images = data.valid.images[i:j, :].reshape(batch_size, img_size_flat)    
        labels = data.valid.labels[i:j, :] 
        feed_dict = {x: images, y_true: labels} 
        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict) 
        i = j 
 
    cls_true = np.array(data.valid.cls) 
    cls_pred = np.array([classes[x] for x in cls_pred])  
    correct = (cls_true == cls_pred) 
    correct_sum = correct.sum() 
    acc = float(correct_sum) / num_test 
 
    msg = "Accuracy on Test-Set: {0:.1%} ({1} / {2})" 
    print(msg.format(acc, correct_sum, num_test)) 
 
    if show_example_errors: 
        print("Example errors:") 
        plot_example_errors(cls_pred=cls_pred, correct=correct)     </pre>
<p class="chapter-content">Now that we have our auxiliary functions, we can start the optimization. At the first place, let's iterate the fine-tuning 10,000 times and see the performance:</p>
<pre class="mce-root"> optimize(num_iterations=1000) </pre>
<p class="chapter-content">After 10,000 iterations, we observe the following result:</p>
<pre class="mce-root">Accuracy on Test-Set: 78.8% (3150 / 4000) 
Precision: 0.793378626929 
Recall: 0.7875 
F1-score: 0.786639298213 </pre>
<p class="chapter-content">This means the accuracy on the test set is about 79%. Also, let's see how well our classifier performs on a sample image:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="266" src="assets/0972b7f4-b784-4307-b74c-87f81c5a50d3.png" width="344"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 7: Random prediction on the test set (after 10,000 iterations)</div>
<p class="chapter-content">After that, we further iterate the optimization up to 100,000 times and observe better accuracy:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="260" src="assets/d5393dde-dbf3-406f-b795-50d28d431e2e.png" width="337"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 8: Random prediction on the test set (after 100,000 iterations)</div>
<pre class="mce-root">&gt;&gt;&gt; 
Accuracy on Test-Set: 81.1% (3244 / 4000) 
Precision: 0.811057239265 
Recall: 0.811 
F1-score: 0.81098298755 </pre>
<p class="chapter-content">So it did not improve that much but was a 2% increase on the overall accuracy. Now is the time to evaluate our model for a single image. For simplicity, we will take two random images of a dog and a cat and see the prediction power of our model:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="140" src="assets/45e9ed02-1b51-41d2-8f8a-e50e99679671.png" width="322"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 9: Example image for the cat and dog to be classified</div>
<p class="chapter-content">At first, we load these two images and prepare the test set accordingly, as we have seen in an earlier step in this example:</p>
<pre class="mce-root">test_cat = cv2.imread('Test_image/cat.jpg') 
test_cat = cv2.resize(test_cat, (img_size, img_size), cv2.INTER_LINEAR) / 255 
preview_cat = plt.imshow(test_cat.reshape(img_size, img_size, num_channels)) 
 
test_dog = cv2.imread('Test_image/dog.jpg') 
test_dog = cv2.resize(test_dog, (img_size, img_size), cv2.INTER_LINEAR) / 255 
preview_dog = plt.imshow(test_dog.reshape(img_size, img_size, num_channels)) </pre>
<p class="chapter-content">Then we have the following function for making the prediction:</p>
<pre class="mce-root">def sample_prediction(test_im):     
    feed_dict_test = { 
        x: test_im.reshape(1, img_size_flat), 
        y_true: np.array([[1, 0]]) 
    } 
    test_pred = session.run(y_pred_cls, feed_dict=feed_dict_test) 
    return classes[test_pred[0]] 
print("Predicted class for test_cat: {}".format(sample_prediction(test_cat))) 
print("Predicted class for test_dog: {}".format(sample_prediction(test_dog))) 
 
&gt;&gt;&gt;  
Predicted class for test_cat: cats 
Predicted class for test_dog: dogs </pre>
<p class="chapter-content">Finally, when we're done, we close the TensorFlow session by invoking the <kbd>close()</kbd> method:</p>
<pre class="mce-root">session.close() </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model performance optimization</h1>
                </header>
            
            <article>
                
<p class="chapter-content">Since <span>CNNs are different </span><span>from the layering architecture's perspective, they have different requirements as well as tuning criteria. How do you know what combination of hyperparameters is the best for your task? Of course, you can use a grid search with cross-validation to find the right hyperparameters for linear machine learning models.</span></p>
<p class="chapter-content"><span>However, for CNNs, there are many hyperparameters to tune, and since training a neural network on a large dataset takes a lot of time, you will only be able to explore a tiny part of the hyperparameter space in a reasonable amount of time. Here are some insights that can be followed.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Number of hidden layers</h1>
                </header>
            
            <article>
                
<p class="chapter-content">For many problems, you can just begin with a single hidden layer and you will get reasonable results. It has actually been shown that an MLP with just one hidden layer can model even the most complex functions provided it has enough neurons. For a long time, these facts convinced researchers that there was no need to investigate any deeper neural networks. However, they overlooked the fact that deep networks have a much higher parameter efficiency than shallow ones; they can model complex functions using exponentially fewer neurons than shallow nets, making them much faster to train.</p>
<p class="chapter-content">It is to be noted that this might not be always the case. However, in summary, for many problems, you can start with just one or two hidden layers. It will work just fine using two hidden layers with the same total amount of neurons, in roughly the same amount of training time. For a more complex problem, you can gradually ramp up the number of hidden layers, until you start overfitting the training set. Very complex tasks, such as large image classification or speech recognition, typically require networks with dozens of layers and a huge amount of training data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Number of neurons per hidden layer</h1>
                </header>
            
            <article>
                
<p class="chapter-content">Obviously, the number of neurons in the input and output layers is determined by the type of input and output your task requires. For example, if your dataset has the shape of 28 x 28 it should expect to have input neurons with size 784 and the output neurons should be equal to the number of classes to be predicted. As for the hidden layers, a common practice is to size them to form a funnel, with fewer and fewer neurons at each layer, the rationale being that many low-level features can coalesce into far fewer high-level features. However, this practice is not as common now, and you may simply use the same size for all hidden layers.</p>
<p class="chapter-content">If there are four convolutional layers with 256 neurons, that's just one hyperparameter to tune instead of one per layer. Just like the number of layers, you can try increasing the number of neurons gradually until the network starts overfitting. Another important question is: when would you want to add a max pooling layer rather than a convolutional layer with the same stride? The thing is that a max-pooling layer has no parameters at all, whereas a convolutional layer has quite a few.</p>
<p class="chapter-content">Sometimes, adding a local response normalization layer that makes the neurons that most strongly activate inhibit neurons at the same location but in neighboring feature maps, encourages different feature maps to specialize and pushes them apart, forcing them to explore a wider range of features. It is typically used in the lower layers to have a larger pool of low-level features that the upper layers can build upon.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Batch normalization</h1>
                </header>
            
            <article>
                
<p class="chapter-content CDPAlignLeft CDPAlign"><strong>Batch normalization</strong> (<strong>BN</strong>) is a method to reduce internal covariate shift while training regular DNNs. This can apply to CNNs too. Due to the normalization, BN further prevents smaller changes to the parameters to amplify and thereby allows higher learning rates, making the network even faster:</p>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="254" src="assets/844dd566-706b-49c2-81d2-3d64964ff092.png" width="546"/></div>
<p class="chapter-content CDPAlignCenter CDPAlign CDPAlignLeft">The idea is placing an additional step between the layers, in which the output of the layer before is normalized. To be more specific, in the case of non-linear operations (for example, ReLU), BN transformation has to be applied to the non-linear operation. Typically, the overall process has the following workflow:</p>
<ul>
<li>Transforming the network into a BN network (see <em>Figure 1</em>)</li>
<li>Then training the new network</li>
<li>Transforming the batch statistic into a population statistic</li>
</ul>
<p class="chapter-content">This way, BN can fully partake in the process of backpropagation. As shown in <em>Figure 1</em>, BN is performed before the other processes of the network in this layer are applied. However, any kind of gradient descent (for example, <strong>stochastic gradient descent</strong> (<strong>SGD</strong>) and its variants) can be applied to train the BN network.</p>
<div class="packt_tip">Interested readers can refer to the original paper to get to more information: Ioffe, Sergey, and Christian Szegedy. <em>Batch normalization: Accelerating deep network training by reducing internal covariate shift</em>. arXiv preprint arXiv:1502.03167 (2015).</div>
<p class="mce-root">Now a valid question would be: where to place the BN layer? Well, to know the answer, a quick evaluation of BatchNorm layer performance on ImageNet-2012 (<a href="https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md">https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md</a>) shows the following benchmark:</p>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="143" src="assets/2ea9e9c0-8cf4-42a0-a436-c50a531f1857.png" width="371"/></div>
<p class="chapter-content CDPAlignCenter CDPAlign CDPAlignLeft">From the preceding table, it can be seen that placing BN after non-linearity would be the right way. The second question would be: what activation function should be used in a BN layer? Well, from the same benchmark, we can see the following result:</p>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="221" src="assets/71798011-3bf7-421a-a5dd-05a4786e3b4e.png" width="281"/></div>
<p class="chapter-content">From the preceding table, we can assume that using ReLU or its variants would be a better idea. Now, another question would be how to use these using deep learning libraries. Well, in TensorFlow, it is:</p>
<pre class="chapter-content">training = tf.placeholder(tf.bool)<br/>x = tf.layers.dense(input_x, units=100)<br/>x = tf.layers.batch_normalization(x, training=training)<br/>x = tf.nn.relu(x)</pre>
<p class="chapter-content">A general warning: set this to <kbd>True</kbd> for training and <kbd>False</kbd> for testing. However, the preceding addition introduces extra ops to be performed on the graph, which is updating its mean and variance variables in such a way that they will not be dependencies of your training op. To do it, we can just run the ops separately, as follows:</p>
<pre class="chapter-content">extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)<br/>sess.run([train_op, extra_update_ops], ...)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Advanced regularization and avoiding overfitting</h1>
                </header>
            
            <article>
                
<p class="chapter-content">As mentioned in the previous chapter, one of the main disadvantages observed during the training of large neural networks is overfitting, that is, generating very good approximations for the training data but emitting noise for the zones between single points. There are a couple of ways to reduce or even prevent this issue, such as dropout, early stop, and limiting the number of parameters.</p>
<p class="chapter-content">In the case of overfitting, the model is specifically adjusted to the training dataset, so it will not be used for generalization. Therefore, although it performs well on the training set, its performance on the test dataset and subsequent tests is poor because it lacks the generalization property:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="164" src="assets/a06dfa25-f5a6-4e97-bd16-c73552f1582a.png" width="377"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Figure 10: Dropout versus without dropout</div>
<p class="chapter-content">The main advantage of this method is that it avoids holding all the neurons in a layer to optimize their weights synchronously. This adaptation made in random groups prevents all the neurons from converging to the same goals, thus de-correlating the adapted weights. A second property found in the dropout application is that the activation of the hidden units becomes sparse, which is also a desirable characteristic.</p>
<p class="chapter-content">In the preceding figure, we have a representation of an original fully connected multilayer neural network and the associated network with the dropout linked. As a result, approximately half of the input was zeroed (this example was chosen to show that probabilities will not always give the expected four zeroes). One factor that could have surprised you is the scale factor applied to the non-dropped elements.</p>
<p class="chapter-content">This technique is used to maintain the same network, and restore it to the original architecture when training, using <kbd>dropout_keep_prob</kbd> as 1. A major drawback of using dropout is that it does not have the same benefits for convolutional layers, where the neurons are not fully connected. To address this issue, there are a few techniques can be applied, such as DropConnect and stochastic pooling:</p>
<ul>
<li>DropConnect is similar to dropout as it introduces dynamic sparsity within the model, but it differs in that the sparsity is on the weights, rather than the output vectors of a layer. The thing is that a fully connected layer with DropConnect becomes a sparsely connected layer in which the connections are chosen at random during the training stage.</li>
<li>In stochastic pooling, the conventional deterministic pooling operations are replaced with a stochastic procedure, where the activation within each pooling region is picked randomly according to a multinomial distribution, given by the activities within the pooling region. The approach is hyperparameter free and can be combined with other regularization approaches, such as dropout and data augmentation.</li>
</ul>
<div class="packt_infobox"><strong>Stochastic pooling versus standard max pooling:</strong> Stochastic pooling is equivalent to standard max pooling but with many copies of an input image, each having small local deformations.</div>
<p class="chapter-content">Secondly, one of the simplest methods to prevent overfitting of a network is to simply stop the training before overfitting gets a chance to occur. This comes with the disadvantage that the learning process is halted. Thirdly, limiting the number of parameters is <span>sometimes </span>helpful and helps avoid overfitting. When it comes to CNN training, the filter size also affects the number of parameters. Thus, limiting this type of parameter restricts the predictive power of the network directly, reducing the complexity of the function that it can perform on the data, and that limits the amount of overfitting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applying dropout operations with TensorFlow</h1>
                </header>
            
            <article>
                
<p class="chapter-content">If we apply the dropout operation to a sample vector, it will work on transmitting the dropout to all the architecture-dependent units. In order to apply the dropout operation, TensorFlow implements the <kbd>tf.nn.dropout</kbd> method, which works as follows:</p>
<pre class="mce-root">tf.nn.dropout (x, keep_prob, noise_shape, seed, name)</pre>
<p class="chapter-content">Where <kbd>x</kbd> is the original tensor. The <kbd>keep_prob</kbd> means the probability of keeping a neuron and the factor by which the remaining nodes are multiplied. The <kbd>noise_shape</kbd> signifies a four-element list that determines whether a dimension will apply zeroing independently or not. Let's have a look at this code segment:</p>
<pre class="mce-root">import tensorflow as tf X = [1.5, 0.5, 0.75, 1.0, 0.75, 0.6, 0.4, 0.9] <br/>drop_out = tf.nn.dropout(X, 0.5) <br/>sess = tf.Session() with sess.as_default(): <br/>    print(drop_out.eval()) <br/>sess.close() </pre>
<pre class="mce-root">[ 3. 0. 1.5 0. 0. 1.20000005 0. 1.79999995]</pre>
<p class="chapter-content">In the preceding example, you can see the results of applying dropout to the <em>x</em> variable, with a 0.5 probability of zero; in the cases in which it didn't occur, the values were doubled (multiplied by 1/1.5, the dropout probability).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Which optimizer to use?</h1>
                </header>
            
            <article>
                
<p class="chapter-content">When using a CNN, since one of the objective functions is to minimize the evaluated cost, we must define an optimizer. Using the most common optimizer , such as SGD, the learning rates must scale with <em>1/T</em> to get convergence, where <em>T</em> is the number of iterations. Adam or RMSProp try to overcome this limitation automatically by adjusting the step size so that the step is on the same scale as the gradients. In addition, in the previous example, we have used Adam optimizer, which performs well in most cases.</p>
<p class="chapter-content">Nevertheless, if you are training a neural network but computing the gradients is mandatory, using the <kbd>RMSPropOptimizer</kbd> function (which implements the <kbd>RMSProp</kbd> algorithm) is a better idea since it would be the faster way of learning in a mini-batch setting. Researchers also recommend using the momentum optimizer, while training a deep CNN or DNN. Technically, <kbd>RMSPropOptimizer</kbd> is an advanced form of gradient descent that divides the learning rate by an exponentially decaying average of squared gradients. The suggested setting value of the decay parameter is 0.9, while a good default value for the learning rate is 0.001. For example, in TensorFlow, <kbd>tf.train.RMSPropOptimizer()</kbd> helps us to use this with ease:</p>
<pre class="mce-root">optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost_op)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Memory tuning</h1>
                </header>
            
            <article>
                
<p class="chapter-content">In this section, we try to provide some insights. We start with an issue and its solution; convolutional layers require a huge amount of RAM, especially during training, because the reverse pass of backpropagation requires all the intermediate values computed during the forward pass. During inference (that is, when making a prediction for a new instance), the RAM occupied by one layer can be released as soon as the next layer has been computed, so you only need as much RAM as required by two consecutive layers.</p>
<p class="chapter-content">Nevertheless, during training, everything computed during the forward pass needs to be preserved for the reverse pass, so the amount of RAM needed is (at least) the total amount of RAM required by all layers. If your GPU runs out of memory while training a CNN, here are five things you can try to solve the problem (other than purchasing a GPU with more RAM):</p>
<ul>
<li>Reduce the mini-batch size</li>
<li>Reduce dimensionality using a larger stride in one or more layers</li>
<li>Remove one or more layers</li>
<li>Use 16-bit floats instead of 32-bit</li>
<li>Distribute the CNN across multiple devices (see more at <a href="https://www.tensorflow.org/deploy/distributed"><span class="URLPACKT">https://www.tensorflow.org/deploy/distributed</span></a>)</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Appropriate layer placement</h1>
                </header>
            
            <article>
                
<p class="chapter-content">Another important question would be: when do you want to add a max pooling layer rather than a convolutional layer with the same stride? The thing is that a max-pooling layer has no parameters at all, whereas a convolutional layer has quite a few.</p>
<p class="chapter-content">Even adding a local response normalization layer <span>sometimes</span> <span>makes the neurons that most strongly activate inhibit neurons at the same location but in neighboring feature maps, which encourages different feature maps to specialize and pushes them apart, forcing them</span> <span>to explore a wider range of features. It is typically used in the lower layers to have a larger pool of low-level features that the upper layers can build upon.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building the second CNN by putting everything together</h1>
                </header>
            
            <article>
                
<p class="chapter-content">Now we know how to optimize the layering structure in a CNN by adding dropout, BN, and biases initializers, such as Xavier. Let's try to apply these to a less complex CNN. Throughout this example, we will see how to solve a real-life classification problem. To be more specific, our CNN model will be able to classify the traffic sign from a bunch of images.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dataset description and preprocessing</h1>
                </header>
            
            <article>
                
<p class="chapter-content CDPAlignLeft CDPAlign">For this we will be using the Belgian traffic dataset (BelgiumTS for Classification (cropped images)). This dataset can be download from <a href="http://btsd.ethz.ch/shareddata/">http://btsd.ethz.ch/shareddata/</a>. Here are a quick glimpse about the traffic signs convention in Belgium:</p>
<ul>
<li>Belgian traffic signs are usually in Dutch and French. This is good to know, but for the dataset that you'll be working with, it's not too important!</li>
<li>There are six categories of traffic signs in Belgium: warning signs, priority signs, prohibitory signs, mandatory signs, signs related to parking and standing still on the road and, lastly, designatory signs.</li>
</ul>
<p class="chapter-content CDPAlignLeft CDPAlign">Once we download the aforementioned dataset, we will see the following directory structure (training left, test right):</p>
<div class="CDPAlignCenter CDPAlign"><img height="184" src="assets/ce5f8479-60f0-4703-8e95-c991d7d6b829.png" width="454"/></div>
<p class="chapter-content CDPAlignLeft CDPAlign">The images are in <kbd>.ppm</kbd> format; otherwise we could've used TensorFlow built-in image loader (example, <kbd>tf.image.decode_png</kbd>). However, we can use the <kbd>skimage</kbd> Python package.</p>
<p class="chapter-content CDPAlignLeft CDPAlign">In Python 3, execute <kbd>$ sudo pip3 install scikit-image</kbd> for <kbd>skimage</kbd> to install and use this package. So let's get started by showing the directory path as follows:</p>
<pre class="chapter-content CDPAlignLeft CDPAlign">Train_IMAGE_DIR = "&lt;path&gt;/BelgiumTSC_Training/"<br/>Test_IMAGE_DIR = ""&lt;path&gt;/BelgiumTSC_Testing/"</pre>
<p class="chapter-content CDPAlignLeft CDPAlign">Then let's write a function using the <kbd>skimage</kbd> library to read the images and returns two lists:</p>
<ul>
<li><kbd>images</kbd>: A list of Numpy arrays, each representing an image</li>
<li><kbd>labels</kbd>: A list of numbers that represent the images labels</li>
</ul>
<pre class="chapter-content">def load_data(data_dir):<br/>    # All subdirectories, where each folder represents a unique label<br/>    directories = [d for d in os.listdir(data_dir)if os.path.isdir(os.path.join(data_dir, d))]<br/><br/>    # Iterate label directories and collect data in two lists, labels and images.<br/>    labels = []<br/>    images = []<br/>    for d in directories:label_dir = os.path.join(data_dir, d)<br/>    file_names = [os.path.join(label_dir, f) <br/>                for f in os.listdir(label_dir) if f.endswith(".ppm")]<br/><br/>    # For each label, load it's images and add them to the images list.<br/>    # And add the label number (i.e. directory name) to the labels list.<br/>    for f in file_names:images.append(skimage.data.imread(f))<br/>    labels.append(int(d))<br/>    return images, labels</pre>
<p class="chapter-content">The preceding code block is straightforward and contains inline comments. How about showing related statistics about images? However, before that, let's invoke the preceding function:</p>
<pre class="chapter-content"># Load training and testing datasets.<br/>train_data_dir = os.path.join(Train_IMAGE_DIR, "Training")<br/>test_data_dir = os.path.join(Test_IMAGE_DIR, "Testing")<br/><br/>images, labels = load_data(train_data_dir)</pre>
<p class="chapter-content">Then let's see some statistics:</p>
<pre class="chapter-content">print("Unique classes: {0} \nTotal Images: {1}".format(len(set(labels)), len(images)))</pre>
<pre class="chapter-content">&gt;&gt;&gt;<br/>Unique classes: 62<br/>Total Images: 4575</pre>
<p class="chapter-content">So we have 62 classes to be predicted (that is, a multiclass image classification problem) and we have many images too that should be sufficient to satisfy a smaller CNN.Now let's see the class distribution visually:</p>
<pre># Make a histogram with 62 bins of the `labels` data and show the plot: <br/>plt.hist(labels, 62)<br/>plt.xlabel('Class')<br/>plt.ylabel('Number of training examples')<br/>plt.show()</pre>
<div class="CDPAlignCenter CDPAlign"><img height="311" src="assets/03894908-617b-4b51-9011-b3d5f4a084e3.png" width="415"/></div>
<p class="chapter-content">Therefore, from the preceding figure, we can see that classes are very imbalanced. However, to make it simpler, we won't take care of this but next, it would be great to visually inspect some files, say displaying the first image of each label:</p>
<pre class="chapter-content">def display_images_and_labels(images, labels):<br/>    unique_labels = set(labels)<br/>    plt.figure(figsize=(15, 15))<br/>    i = 1<br/>    for label in unique_labels:<br/>        # Pick the first image for each label.<br/>        image = images[labels.index(label)]<br/>        plt.subplot(8, 8, i) # A grid of 8 rows x 8 column<br/>        splt.axis('off')<br/>        plt.title("Label {0} ({1})".format(label, labels.count(label)))<br/>        i += 1        <br/>        _= plt.imshow(image)<br/>        plt.show()<br/>display_images_and_labels(images, labels)</pre>
<div class="chapter-content CDPAlignCenter CDPAlign"><img height="329" src="assets/05a6bed9-b026-42a6-ac02-e2dc40663a60.png" width="536"/></div>
<p class="chapter-content">Now you can see from the preceding figure that the images come in different sizes and shapes. Moreover, we can see it using Python code, as follows:</p>
<pre class="chapter-content">for img in images[:5]:<br/>    print("shape: {0}, min: {1}, max: {2}".format(img.shape, img.min(), img.max()))</pre>
<pre class="chapter-content">&gt;&gt;&gt;<br/>shape: (87, 84, 3), min: 12, max: 255<br/>shape: (289, 169, 3), min: 0, max: 255<br/>shape: (205, 76, 3), min: 0, max: 255<br/>shape: (72, 71, 3), min: 14, max: 185<br/>shape: (231, 228, 3), min: 0, max: 255</pre>
<p class="chapter-content">Therefore, we need to apply some pre-processing such as resizing, reshaping, and so on to each image. Let's say each image will have size of 32 x 32:</p>
<pre class="chapter-content">images32 = [skimage.transform.resize(img, (32, 32), mode='constant') <br/><br/>for img in images]for img in images32[:5]:<br/>    print("shape: {0}, min: {1}, max: {2}".format(img.shape, img.min(), img.max()))</pre>
<pre class="chapter-content">&gt;&gt;&gt;<br/>shape: (32, 32, 3), min: 0.06642539828431372, max: 0.9704350490196079<br/>shape: (32, 32, 3), min: 0.0, max: 1.0<br/>shape: (32, 32, 3), min: 0.03172870710784261, max: 1.0<br/>shape: (32, 32, 3), min: 0.059474571078431314, max: 0.7036305147058846<br/>shape: (32, 32, 3), min: 0.01506204044117481, max: 1.0</pre>
<p class="chapter-content">Now, all of our images have same size. The next task would be to convert labels and image features as a <kbd>numpy</kbd> array:</p>
<pre class="chapter-content">labels_array = np.array(labels)<br/>images_array = np.array(images32)<br/>print("labels: ", labels_array.shape, "nimages: ", images_array.shape)</pre>
<pre class="chapter-content">&gt;&gt;&gt;<br/>labels: (4575,)<br/>images: (4575, 32, 32, 3)</pre>
<p class="chapter-content">Fantastic! The next task would be creating our second CNN, but this time we will be using TensorFlow <kbd>contrib</kbd> package, which is a high-level API that supports layering ops.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating the CNN model</h1>
                </header>
            
            <article>
                
<p class="chapter-content">We are going to construct a complex network. However, it has a straightforward architecture. At the beginning, we use Xavier as the network initializer. Once we initialize the network bias using the Xavier initializer. The input layer is followed by a convolutional layer (convolutional layer 1), which is again followed by a BN layer (that is, BN layer 1). Then there is a pooling layer with strides of two and a kernel size of two. Then another BN layer follows the second convolutional layer. Next, there is the second pooling layer with strides of two and kernel size of two. Well, then the max polling layer is followed by a flattening layer that flattens the input from (None, height, width, channels) to (None, height * width * channels) == (None, 3072).</p>
<p class="chapter-content">Once the flattening is completed, the input is fed into the first fully connected layer 1. Then third BN is applied as a normalizer function. Then we will have a dropout layer before we feed the lighter network into the fully connected layer 2 that generates logits of size (None, 62). Too much of a mouthful? Don't worry; we will see it step by step. Let's start the coding by creating the computational graph, creating both features, and labeling placeholders:</p>
<pre class="chapter-content">graph = tf.Graph()<br/>with graph.as_default():<br/>    # Placeholders for inputs and labels.<br/>    images_X = tf.placeholder(tf.float32, [None, 32, 32, 3]) # each image's 32x32 size<br/>    labels_X = tf.placeholder(tf.int32, [None])<br/><br/>    # Initializer: Xavier<br/>     biasInit = tf.contrib.layers.xavier_initializer(uniform=True, seed=None, dtype=tf.float32)<br/><br/>    # Convolution layer 1: number of neurons 128 and kernel size is 6x6.<br/>     conv1 = tf.contrib.layers.conv2d(images_X, num_outputs=128, kernel_size=[6, 6],     <br/>            biases_initializer=biasInit)<br/><br/>    # Batch normalization layer 1: can be applied as a normalizer <br/>    # function for conv2d and fully_connected<br/>    bn1 = tf.contrib.layers.batch_norm(conv1, center=True, scale=True, is_training=True)<br/><br/>    # Max Pooling (down sampling) with strides of 2 and kernel size of 2<br/>    pool1 = tf.contrib.layers.max_pool2d(bn1, 2, 2)<br/><br/>    # Convolution layer 2: number of neurons 256 and kernel size is 6x6.<br/>    conv2 = tf.contrib.layers.conv2d(pool1, num_outputs=256, kernel_size=[4, 4], stride=2,     <br/>        biases_initializer=biasInit)<br/><br/>    # Batch normalization layer 2: <br/>    bn2 = tf.contrib.layers.batch_norm(conv2, center=True, scale=True, is_training=True)<br/><br/>    # Max Pooling (down-sampling) with strides of 2 and kernel size of 2<br/>    pool2 = tf.contrib.layers.max_pool2d(bn2, 2, 2)<br/><br/>    # Flatten the input from [None, height, width, channels] to <br/>    # [None, height * width * channels] == [None, 3072]<br/>    images_flat = tf.contrib.layers.flatten(pool2)<br/><br/>    # Fully connected layer 1<br/>    fc1 = tf.contrib.layers.fully_connected(images_flat, 512, tf.nn.relu)<br/><br/>    # Batch normalization layer 3<br/>    bn3 = tf.contrib.layers.batch_norm(fc1, center=True, scale=True, is_training=True)<br/><br/>    # apply dropout, if is_training is False, dropout is not applied<br/>    fc1 = tf.layers.dropout(bn3, rate=0.25, training=True)<br/><br/>    # Fully connected layer 2 that generates logits of size [None, 62]. <br/>    # Here 62 means number of classes to be predicted.<br/>    logits = tf.contrib.layers.fully_connected(fc1, 62, tf.nn.relu)</pre>
<p class="chapter-content">Up to this point, we have managed to generate the logits of size (<kbd>None, 62</kbd>). Then we need to convert the logits to label indexes (<kbd>int</kbd>) with the shape (<kbd>None</kbd>), which is a 1D vector of <kbd>length == batch_size:predicted_labels = tf.argmax(logits, axis=1)</kbd>. Then we define cross-entropy as the <kbd>loss</kbd> function, which is a good choice for classification:</p>
<pre class="chapter-content">loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels_X))</pre>
<p class="chapter-content">Now one of the most important parts is updating the ops and creating an optimizer (Adam in our case):</p>
<pre class="chapter-content">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)<br/>with tf.control_dependencies(update_ops):<br/>    # Create an optimizer, which acts as the training op.train =             <br/>    tf.train.AdamOptimizer(learning_rate=0.10).minimize(loss_op)</pre>
<p class="chapter-content">Finally, we initialize all the ops:</p>
<pre class="chapter-content">init_op = tf.global_variables_initializer()</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training and evaluating the network</h1>
                </header>
            
            <article>
                
<p class="chapter-content">We start by create a session to run the graph we created. Note that for faster training, we should use a GPU. However, if you do not have a GPU, just set <kbd>log_device_placement=False</kbd>:</p>
<pre class="chapter-content">session = tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True))<br/>session.run(init_op)<br/>for i in range(300):<br/>    _, loss_value = session.run([train, loss_op], feed_dict={images_X: images_array, labels_X: <br/>    labels_array})<br/>    if i % 10 == 0:<br/>        print("Loss: ", loss_value)</pre>
<pre class="chapter-content">&gt;&gt;&gt;<br/>Loss: 4.7910895<br/>Loss: 4.3410876<br/>Loss: 4.0275432<br/>...<br/>Loss: 0.523456</pre>
<p class="chapter-content">Once the training is completed, let us pick 10 random images and see the predictive power of our model:</p>
<pre class="chapter-content">random_indexes = random.sample(range(len(images32)), 10)<br/>random_images = [images32[i]<br/>for i in random_indexes]<br/>    random_labels = [labels[i]<br/>for i in random_indexes]</pre>
<p class="chapter-content">Then let's run the <kbd>predicted_labels op</kbd>:</p>
<pre class="chapter-content">predicted = session.run([predicted_labels], feed_dict={images_X: random_images})[0]<br/>print(random_labels)<br/>print(predicted)</pre>
<pre class="chapter-content">&gt;&gt;&gt;<br/>[38, 21, 19, 39, 22, 22, 45, 18, 22, 53]<br/>[20  21  19  51  22  22  45  53  22  53]</pre>
<p class="chapter-content">So we can see that some images were correctly classified and some wrongly. However, visual inspection would be more helpful. So let's display the predictions and the ground truth:</p>
<pre class="chapter-content">fig = plt.figure(figsize=(5, 5))<br/>for i in range(len(random_images)):<br/>    truth = random_labels[i]<br/>    prediction = predicted[i]<br/>    plt.subplot(5, 2,1+i)<br/>    plt.axis('off')color='green' <br/>    if truth == prediction <br/>    else<br/>     'red'plt.text(40, 10, "Truth: {0}nPrediction: {1}".format(truth, prediction), fontsize=12,     <br/>    color=color)<br/>plt.imshow(random_images[i])<br/><q>&gt;&gt;&gt;<br/></q></pre>
<div class="CDPAlignCenter CDPAlign"><img height="266" src="assets/bc955eb3-eac0-47a3-b447-c0b6722c80cf.png" width="322"/></div>
<p class="chapter-content">Finally, we can evaluate our model using the test set. To see the predictive power, we compute the accuracy:</p>
<pre class="chapter-content"># Load the test dataset.<br/>test_X, test_y = load_data(test_data_dir)<br/><br/># Transform the images, just as we did with the training set.<br/>test_images32 = [skimage.transform.resize(img, (32, 32), mode='constant') <br/>for img in test_X]<br/>    display_images_and_labels(test_images32, test_y)<br/><br/># Run predictions against the test <br/>setpredicted = session.run([predicted_labels], feed_dict={images_X: test_images32})[0]<br/><br/># Calculate how many matches<br/>match_count = sum([int(y == y_) for y, y_ in zip(test_y, predicted)])<br/>accuracy = match_count / len(test_y)print("Accuracy: {:.3f}".format(accuracy))</pre>
<pre class="chapter-content">&gt;&gt;<br/>Accuracy: 87.583 <q><br/></q></pre>
<p>Not that bad in terms of accuracy. In addition to this, we can also compute other performance metrics such as precision, recall, f1 measure and also visualize the result in a confusion matrix to show the predicted versus actual labels count. Nevertheless, we can still improve the accuracy by tuning the network and hyperparameters. But I leave these up to the readers.</p>
<p class="chapter-content">Finally, we are done, so let's close the TensorFlow session:</p>
<pre>session.close()</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="chapter-content">In this chapter, we discussed how to use CNNs, which are a type of feed-forward artificial neural network in which the connectivity pattern between neurons is inspired by the organization of an animal's visual cortex. We saw how to cascade a set of layers to construct a CNN and perform different operations in each layer. Then we saw how to train a CNN. Later on, we discussed how to optimize the CNN hyperparameters and optimization.</p>
<p class="chapter-content">Finally, we built another CNN, where we utilized all the optimization techniques. Our CNN models did not achieve outstanding accuracy since we iterated both of the CNNs a few times and did not <span>even </span>apply any grid searching techniques; that means we did not hunt for the best combinations of the hyperparameters. Therefore, the takeaway would be to apply more robust feature engineering in the raw images, iterate the training for more epochs with the best hyperparameters, and observe the performance.</p>
<p class="chapter-content">I<span class="cdp-organizer-chapter-number">n the next chapter, we will see how to use some deeper and</span> <span class="cdp-organizer-chapter-title">popular CNN architectures, such as</span> ImageNet, AlexNet, VGG, GoogLeNet, and ResNet. We will see how to utilize these trained models for transfer learning.</p>


            </article>

            
        </section>
    </body></html>