["```py\ndef build_generator(inputs, image_size):\n    \"\"\"Build a Generator Model\n\n    Stack of BN-ReLU-Conv2DTranpose to generate fake images.\n    Output activation is sigmoid instead of tanh in [1].\n    Sigmoid converges easily.\n\n    # Arguments\n        inputs (Layer): Input layer of the generator (the z-vector)\n        image_size: Target size of one side (assuming square image)\n\n    # Returns\n        Model: Generator Model\n    \"\"\"\n\n    image_resize = image_size // 4\n    # network parameters \n    kernel_size = 5\n    layer_filters = [128, 64, 32, 1]\n\n    x = Dense(image_resize * image_resize * layer_filters[0])(inputs)\n    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n\n    for filters in layer_filters:\n        # first two convolution layers use strides = 2\n        # the last two use strides = 1\n        if filters > layer_filters[-2]:\n            strides = 2\n        else:\n            strides = 1\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(filters=filters,\n                            kernel_size=kernel_size,\n                            strides=strides,\n                            padding='same')(x)\n\n    x = Activation('sigmoid')(x)\n    generator = Model(inputs, x, name='generator')\n    return generator\n```", "```py\ndef build_discriminator(inputs):\n    \"\"\"Build a Discriminator Model\n\n    Stack of LeakyReLU-Conv2D to discriminate real from fake.\n    The network does not converge with BN so it is not used here\n    unlike in [1] or original paper.\n\n    # Arguments\n        inputs (Layer): Input layer of the discriminator (the image)\n\n    # Returns\n        Model: Discriminator Model\n    \"\"\"\n    kernel_size = 5\n    layer_filters = [32, 64, 128, 256]\n\n    x = inputs\n    for filters in layer_filters:\n        # first 3 convolution layers use strides = 2\n        # last one uses strides = 1\n        if filters == layer_filters[-1]:\n            strides = 1\n        else:\n            strides = 2\n        x = LeakyReLU(alpha=0.2)(x)\n        x = Conv2D(filters=filters,\n                   kernel_size=kernel_size,\n                   strides=strides,\n                   padding='same')(x)\n\n    x = Flatten()(x)\n    x = Dense(1)(x)\n    x = Activation('sigmoid')(x)\n    discriminator = Model(inputs, x, name='discriminator')\n    return discriminator\n```", "```py\ndef build_and_train_models():\n    # load MNIST dataset\n    (x_train, _), (_, _) = mnist.load_data()\n\n    # reshape data for CNN as (28, 28, 1) and normalize\n    image_size = x_train.shape[1]\n    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n    x_train = x_train.astype('float32') / 255\n\n    model_name = \"dcgan_mnist\"\n    # network parameters\n    # the latent or z vector is 100-dim\n    latent_size = 100\n    batch_size = 64\n    train_steps = 40000\n    lr = 2e-4\n    decay = 6e-8\n    input_shape = (image_size, image_size, 1)\n\n    # build discriminator model\n    inputs = Input(shape=input_shape, name='discriminator_input')\n    discriminator = build_discriminator(inputs)\n    # [1] or original paper uses Adam, \n    # but discriminator converges easily with RMSprop\n    optimizer = RMSprop(lr=lr, decay=decay)\n    discriminator.compile(loss='binary_crossentropy',\n                          optimizer=optimizer,\n                          metrics=['accuracy'])\n    discriminator.summary()\n\n    # build generator model\n    input_shape = (latent_size, )\n    inputs = Input(shape=input_shape, name='z_input')\n    generator = build_generator(inputs, image_size)\n    generator.summary()\n\n    # build adversarial model\n    optimizer = RMSprop(lr=lr * 0.5, decay=decay * 0.5)\n    # freeze the weights of discriminator \n    # during adversarial training\n    discriminator.trainable = False\n    # adversarial = generator + discriminator\n    adversarial = Model(inputs,\n                        discriminator(generator(inputs)),\n                        name=model_name)\n    adversarial.compile(loss='binary_crossentropy',\n                        optimizer=optimizer,\n                        metrics=['accuracy'])\n    adversarial.summary()\n\n    # train discriminator and adversarial networks\n    models = (generator, discriminator, adversarial)\n    params = (batch_size, latent_size, train_steps, model_name)\n    train(models, x_train, params)\n```", "```py\npython3 dcgan-mnist-4.2.1.py --generator=dcgan_mnist.h5\n\n```", "```py\ndef train(models, x_train, params):\n    \"\"\"Train the Discriminator and Adversarial Networks\n\n    Alternately train Discriminaor and Adversarial networks by batch.\n    Discriminator is trained first with properly real and fake images.\n    Adversarial is trained next with fake images pretending to be real\n    Generate sample images per save_interval.\n\n    # Arguments\n        models (list): Generator, Discriminator, Adversarial models\n        x_train (tensor): Train images\n        params (list) : Networks parameters\n\n    \"\"\"\n    # the GAN models\n    generator, discriminator, adversarial = models\n    # network parameters\n    batch_size, latent_size, train_steps, model_name = params\n    # the generator image is saved every 500 steps\n    save_interval = 500\n    # noise vector to see how the generator output evolves \n    # during training\n    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n    # number of elements in train dataset\n    train_size = x_train.shape[0]\n    for i in range(train_steps):\n        # train the discriminator for 1 batch\n        # 1 batch of real (label=1.0) and fake images (label=0.0)\n        # randomly pick real images from dataset\n        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n        real_images = x_train[rand_indexes]\n        # generate fake images from noise using generator \n        # generate noise using uniform distribution\n        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n        # generate fake images\n        fake_images = generator.predict(noise)\n        # real + fake images = 1 batch of train data\n        x = np.concatenate((real_images, fake_images))\n        # label real and fake images\n        # real images label is 1.0\n        y = np.ones([2 * batch_size, 1])\n        # fake images label is 0.0\n        y[batch_size:, :] = 0.0\n        # train discriminator network, log the loss and accuracy\n        loss, acc = discriminator.train_on_batch(x, y)\n        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n\n        # train the adversarial network for 1 batch\n        # 1 batch of fake images with label=1.0\n        # since the discriminator weights are frozen in adversarial network\n        # only the generator is trained\n        # generate noise using uniform distribution\n        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n        # label fake images as real or 1.0\n        y = np.ones([batch_size, 1])\n        # train the adversarial network \n        # note that unlike in discriminator training, \n        # we do not save the fake images in a variable\n        # the fake images go to the discriminator input of the adversarial\n        # for classification\n        # log the loss and accuracy\n        loss, acc = adversarial.train_on_batch(noise, y)\n        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n        print(log)\n        if (i + 1) % save_interval == 0:\n            if (i + 1) == train_steps:\n                show = True\n            else:\n                show = False\n\n            # plot generator images on a periodic basis\n            plot_images(generator,\n                        noise_input=noise_input,\n                        show=show,\n                        step=(i + 1),\n                        model_name=model_name)\n\n    # save the model after training the generator\n    # the trained generator can be reloaded for future MNIST digit generation\n    generator.save(model_name + \".h5\")\n```", "```py\n39997: [discriminator loss: 0.423329, acc: 0.796875] [adversarial loss: 0.819355, acc: 0.484375]\n39998: [discriminator loss: 0.471747, acc: 0.773438] [adversarial loss: 1.570030, acc: 0.203125]\n39999: [discriminator loss: 0.532917, acc: 0.742188] [adversarial loss: 0.824350, acc: 0.453125]\n```", "```py\ndef build_discriminator(inputs, y_labels, image_size):\n    \"\"\"Build a Discriminator Model\n\n    Inputs are concatenated after Dense layer.\n    Stack of LeakyReLU-Conv2D to discriminate real from fake.\n    The network does not converge with BN so it is not used here\n    unlike in DCGAN paper.\n\n    # Arguments\n        inputs (Layer): Input layer of the discriminator (the image)\n        y_labels (Layer): Input layer for one-hot vector to condition\n            the inputs\n        image_size: Target size of one side (assuming square image)\n\n    # Returns\n        Model: Discriminator Model\n    \"\"\"\n    kernel_size = 5\n    layer_filters = [32, 64, 128, 256]\n\n    x = inputs\n\n    y = Dense(image_size * image_size)(y_labels)\n    y = Reshape((image_size, image_size, 1))(y)\n    x = concatenate([x, y])\n\n    for filters in layer_filters:\n        # first 3 convolution layers use strides = 2\n        # last one uses strides = 1\n        if filters == layer_filters[-1]:\n            strides = 1\n        else:\n            strides = 2\n        x = LeakyReLU(alpha=0.2)(x)\n        x = Conv2D(filters=filters,\n                   kernel_size=kernel_size,\n                   strides=strides,\n                   padding='same')(x)\n\n    x = Flatten()(x)\n    x = Dense(1)(x)\n    x = Activation('sigmoid')(x)\n\n# input is conditioned by y_labels\n discriminator = Model([inputs, y_labels], \n x,\n name='discriminator')\n    return discriminator\n```", "```py\ndef build_generator(inputs, y_labels, image_size):\n    \"\"\"Build a Generator Model\n\n    Inputs are concatenated before Dense layer.\n    Stack of BN-ReLU-Conv2DTranpose to generate fake images.\n    Output activation is sigmoid instead of tanh in orig DCGAN.\n    Sigmoid converges easily.\n\n    # Arguments\n        inputs (Layer): Input layer of the generator (the z-vector)\n        y_labels (Layer): Input layer for one-hot vector to condition\n            the inputs\n        image_size: Target size of one side (assuming square image)\n\n    # Returns\n        Model: Generator Model\n    \"\"\"\n    image_resize = image_size // 4\n    # network parameters\n    kernel_size = 5\n    layer_filters = [128, 64, 32, 1]\n\n x = concatenate([inputs, y_labels], axis=1)\n    x = Dense(image_resize * image_resize * layer_filters[0])(x)\n    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n\n    for filters in layer_filters:\n        # first two convolution layers use strides = 2\n        # the last two use strides = 1\n        if filters > layer_filters[-2]:\n            strides = 2\n        else:\n            strides = 1\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(filters=filters,\n                            kernel_size=kernel_size,\n                            strides=strides,\n                            padding='same')(x)\n\n    x = Activation('sigmoid')(x)\n # input is conditioned by y_labels\n generator = Model([inputs, y_labels], x, name='generator')\n    return generator\n```", "```py\ndef train(models, data, params):\n    \"\"\"Train the Discriminator and Adversarial Networks\n\n    Alternately train Discriminator and Adversarial networks by batch.\n    Discriminator is trained first with properly labelled real and fake images.\n    Adversarial is trained next with fake images pretending to be real.\n    Discriminator inputs are conditioned by train labels for real images,\n    and random labels for fake images.\n    Adversarial inputs are conditioned by random labels.\n    Generate sample images per save_interval.\n\n    # Arguments\n        models (list): Generator, Discriminator, Adversarial models\n        data (list): x_train, y_train data\n        params (list): Network parameters\n\n    \"\"\"\n    # the GAN models\n    generator, discriminator, adversarial = models\n    # images and labels\n    x_train, y_train = data\n    # network parameters\n    batch_size, latent_size, train_steps, num_labels, model_name = params\n    # the generator image is saved every 500 steps\n    save_interval = 500\n    # noise vector to see how the generator output evolves during training\n    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n # one-hot label the noise will be conditioned to\n noise_class = np.eye(num_labels)[np.arange(0, 16) % num_labels]\n    # number of elements in train dataset\n    train_size = x_train.shape[0]\n\n    print(model_name,\n          \"Labels for generated images: \",\n          np.argmax(noise_class, axis=1))\n\n    for i in range(train_steps):\n        # train the discriminator for 1 batch\n        # 1 batch of real (label=1.0) and fake images (label=0.0)\n        # randomly pick real images from dataset\n        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n        real_images = x_train[rand_indexes]\n\n# corresponding one-hot labels of real images\n real_labels = y_train[rand_indexes]\n        # generate fake images from noise using generator\n        # generate noise using uniform distribution\n        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n # assign random one-hot labels\n fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n batch_size)]\n\n # generate fake images conditioned on fake labels\n fake_images = generator.predict([noise, fake_labels])\n        # real + fake images = 1 batch of train data\n        x = np.concatenate((real_images, fake_images))\n        # real + fake one-hot labels = 1 batch of train one-hot labels\n y_labels = np.concatenate((real_labels, fake_labels))\n\n        # label real and fake images\n        # real images label is 1.0\n        y = np.ones([2 * batch_size, 1])\n        # fake images label is 0.0\n        y[batch_size:, :] = 0.0\n        # train discriminator network, log the loss and accuracy\n\nloss, acc = discriminator.train_on_batch([x, y_labels], y)\n        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n\n        # train the adversarial network for 1 batch\n # 1 batch of fake images conditioned on fake 1-hot labels w/ label=1.0\n        # since the discriminator weights are frozen in adversarial network\n        # only the generator is trained\n        # generate noise using uniform distribution        \n        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n # assign random one-hot labels\n fake_labels = np.eye(num_labels)[np.random.choice(num_labels,batch_size)]\n        # label fake images as real or 1.0\n        y = np.ones([batch_size, 1])\n        # train the adversarial network \n        # note that unlike in discriminator training, \n        # we do not save the fake images in a variable\n        # the fake images go to the discriminator input of the adversarial\n        # for classification\n        # log the loss and accuracy\n loss, acc = adversarial.train_on_batch([noise, fake_labels], y)\n        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n        print(log)\n        if (i + 1) % save_interval == 0:\n            if (i + 1) == train_steps:\n                show = True\n            else:\n                show = False\n\n            # plot generator images on a periodic basis\n plot_images(generator,\n noise_input=noise_input,\n noise_class=noise_class,\n show=show,\n step=(i + 1),\n model_name=model_name)\n\n    # save the model after training the generator\n    # the trained generator can be reloaded for \n    # future MNIST digit generation\n    generator.save(model_name + \".h5\")\n```", "```py\npython3 cgan-mnist-4.3.1.py --generator=cgan_mnist.h5\n\n```", "```py\ncgan-mnist-4.3.1.py --generator=cgan_mnist.h5 --digit=8\n\n```"]