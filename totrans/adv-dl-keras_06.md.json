["```py\n# generate 64 fake images from 64 x 100-dim uniform noise\nnoise = np.random.uniform(-1.0, 1.0, size=[64, 100])\nfake_images = generator.predict(noise)\n```", "```py\ndef generator(inputs,\n              image_size,\n              activation='sigmoid',\n              labels=None,\n              codes=None):\n    \"\"\"Build a Generator Model\n\n    Stack of BN-ReLU-Conv2DTranpose to generate fake images.\n    Output activation is sigmoid instead of tanh in [1].\n    Sigmoid converges easily.\n\n    # Arguments\n        inputs (Layer): Input layer of the generator (the z-vector)\n        image_size (int): Target size of one side (assuming square image)\n        activation (string): Name of output activation layer\n        labels (tensor): Input labels\n        codes (list): 2-dim disentangled codes for InfoGAN\n\n    # Returns\n        Model: Generator Model\n    \"\"\"\n    image_resize = image_size // 4\n    # network parameters\n    kernel_size = 5\n    layer_filters = [128, 64, 32, 1]\n\n    if labels is not None:\n        if codes is None:\n            # ACGAN labels\n            # concatenate z noise vector and one-hot labels\n            inputs = [inputs, labels]\n        else:\n # infoGAN codes\n # concatenate z noise vector, one-hot labels, \n # and codes 1 & 2\n inputs = [inputs, labels] + codes\n        x = concatenate(inputs, axis=1)\n    elif codes is not None:\n        # generator 0 of StackedGAN\n        inputs = [inputs, codes]\n        x = concatenate(inputs, axis=1)\n    else:\n        # default input is just 100-dim noise (z-code)\n        x = inputs\n\n    x = Dense(image_resize * image_resize * layer_filters[0])(x)\n    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n\n    for filters in layer_filters:\n        # first two convolution layers use strides = 2\n        # the last two use strides = 1\n        if filters > layer_filters[-2]:\n            strides = 2\n        else:\n            strides = 1\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(filters=filters,\n                            kernel_size=kernel_size,\n                            strides=strides,\n                            padding='same')(x)\n\n    if activation is not None:\n        x = Activation(activation)(x)\n\n    # generator output is the synthesized image x\n    return Model(inputs, x, name='generator')\n```", "```py\ndef discriminator(inputs,\n                  activation='sigmoid',\n                  num_labels=None,\n                  num_codes=None):\n    \"\"\"Build a Discriminator Model\n\n    Stack of LeakyReLU-Conv2D to discriminate real from fake\n    The network does not converge with BN so it is not used here\n    unlike in [1]\n\n    # Arguments\n        inputs (Layer): Input layer of the discriminator (the image)\n        activation (string): Name of output activation layer\n        num_labels (int): Dimension of one-hot labels for ACGAN & InfoGAN\n        num_codes (int): num_codes-dim Q network as output \n                    if StackedGAN or 2 Q networks if InfoGAN\n\n    # Returns\n        Model: Discriminator Model\n    \"\"\"\n    kernel_size = 5\n    layer_filters = [32, 64, 128, 256]\n\n    x = inputs\n    for filters in layer_filters:\n        # first 3 convolution layers use strides = 2\n        # last one uses strides = 1\n        if filters == layer_filters[-1]:\n            strides = 1\n        else:\n            strides = 2\n        x = LeakyReLU(alpha=0.2)(x)\n        x = Conv2D(filters=filters,\n                   kernel_size=kernel_size,\n                   strides=strides,\n                   padding='same')(x)\n\n    x = Flatten()(x)\n    # default output is probability that the image is real\n    outputs = Dense(1)(x)\n    if activation is not None:\n        print(activation)\n        outputs = Activation(activation)(outputs)\n\n    if num_labels:\n # ACGAN and InfoGAN have 2nd output\n # 2nd output is 10-dim one-hot vector of label\n layer = Dense(layer_filters[-2])(x)\n labels = Dense(num_labels)(layer)\n labels = Activation('softmax', name='label')(labels)\n if num_codes is None:\n outputs = [outputs, labels]\n else:\n # InfoGAN have 3rd and 4th outputs\n # 3rd output is 1-dim continous Q of 1st c given x\n code1 = Dense(1)(layer)\n code1 = Activation('sigmoid', name='code1')(code1)\n\n # 4th output is 1-dim continuous Q of 2nd c given x\n code2 = Dense(1)(layer)\n code2 = Activation('sigmoid', name='code2')(code2)\n\n outputs = [outputs, labels, code1, code2]\n    elif num_codes is not None:\n\t   # StackedGAN Q0 output\n        # z0_recon is reconstruction of z0 normal distribution\n        z0_recon =  Dense(num_codes)(x)\n        z0_recon = Activation('tanh', name='z0')(z0_recon)\n        outputs = [outputs, z0_recon]\n\n return Model(inputs, outputs, name='discriminator')\n```", "```py\n# call discriminator builder with 4 outputs: source, label, \n# and 2 codes\ndiscriminator = gan.discriminator(inputs, num_labels=num_labels, with_codes=True)\n```", "```py\n# call generator with inputs, labels and codes as total inputs \n# to generator\ngenerator = gan.generator(inputs, image_size, labels=labels, codes=[code1, code2])\n```", "```py\ndef mi_loss(c, q_of_c_given_x):\n \"\"\" Mutual information, Equation 5 in [2], assuming H(c) is constant\"\"\"\n # mi_loss = -c * log(Q(c|x))\n return K.mean(-K.sum(K.log(q_of_c_given_x + K.epsilon()) * c, axis=1))\n\ndef build_and_train_models(latent_size=100):\n    # load MNIST dataset\n    (x_train, y_train), (_, _) = mnist.load_data()\n\n    # reshape data for CNN as (28, 28, 1) and normalize\n    image_size = x_train.shape[1]\n    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n    x_train = x_train.astype('float32') / 255\n\n    # train labels\n    num_labels = len(np.unique(y_train))\n    y_train = to_categorical(y_train)\n\n    model_name = \"infogan_mnist\"\n    # network parameters\n    batch_size = 64\n    train_steps = 40000\n    lr = 2e-4\n    decay = 6e-8\n    input_shape = (image_size, image_size, 1)\n label_shape = (num_labels, )\n code_shape = (1, )\n\n    # build discriminator model\n    inputs = Input(shape=input_shape, name='discriminator_input')\n # call discriminator builder with 4 outputs: \n # source, label, and 2 codes\n discriminator = gan.discriminator(inputs,\n num_labels=num_labels,\n num_codes=2)\n # [1] uses Adam, but discriminator converges easily with RMSprop\n optimizer = RMSprop(lr=lr, decay=decay)\n # loss functions: 1) probability image is real (binary crossentropy)\n # 2) categorical cross entropy image label,\n # 3) and 4) mutual information loss\n loss = ['binary_crossentropy', 'categorical_crossentropy', mi_loss, mi_loss]\n # lamda or mi_loss weight is 0.5\n loss_weights = [1.0, 1.0, 0.5, 0.5]\n discriminator.compile(loss=loss,\n loss_weights=loss_weights,\n optimizer=optimizer,\n metrics=['accuracy'])\n    discriminator.summary()\n    # build generator model\n    input_shape = (latent_size, )\n inputs = Input(shape=input_shape, name='z_input')\n labels = Input(shape=label_shape, name='labels')\n code1 = Input(shape=code_shape, name=\"code1\")\n code2 = Input(shape=code_shape, name=\"code2\")\n # call generator with inputs, \n # labels and codes as total inputs to generator\n generator = gan.generator(inputs,\n image_size,\n labels=labels,\n codes=[code1, code2])\n    generator.summary()\n\n    # build adversarial model = generator + discriminator\n    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n    discriminator.trainable = False\n # total inputs = noise code, labels, and codes\n inputs = [inputs, labels, code1, code2]\n adversarial = Model(inputs,\n discriminator(generator(inputs)),\n name=model_name)\n # same loss as discriminator\n adversarial.compile(loss=loss,\n loss_weights=loss_weights,\n optimizer=optimizer,\n metrics=['accuracy'])\n    adversarial.summary()\n\n    # train discriminator and adversarial networks\n    models = (generator, discriminator, adversarial)\n    data = (x_train, y_train)\n    params = (batch_size, latent_size, train_steps, num_labels, model_name)\n    train(models, data, params)\n```", "```py\ndef train(models, data, params):\n    \"\"\"Train the Discriminator and Adversarial networks\n\n    Alternately train discriminator and adversarial networks by batch.\n    Discriminator is trained first with real and fake images,\n    corresponding one-hot labels and continuous codes.\n    Adversarial is trained next with fake images pretending to be real,\n    corresponding one-hot labels and continous codes.\n    Generate sample images per save_interval.\n\n    # Arguments\n        models (Models): Generator, Discriminator, Adversarial models\n        data (tuple): x_train, y_train data\n        params (tuple): Network parameters\n    \"\"\"\n    # the GAN models\n    generator, discriminator, adversarial = models\n    # images and their one-hot labels\n    x_train, y_train = data\n    # network parameters\n    batch_size, latent_size, train_steps, num_labels, model_name = params\n    # the generator image is saved every 500 steps\n    save_interval = 500\n    # noise vector to see how the generator output evolves \n    # during training\n    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n    # random class labels and codes\n    noise_label = np.eye(num_labels)[np.arange(0, 16) % num_labels]\n noise_code1 = np.random.normal(scale=0.5, size=[16, 1])\n noise_code2 = np.random.normal(scale=0.5, size=[16, 1])\n    # number of elements in train dataset\n    train_size = x_train.shape[0]\n    print(model_name,\n          \"Labels for generated images: \",\n          np.argmax(noise_label, axis=1))\n\n    for i in range(train_steps):\n        # train the discriminator for 1 batch\n        # 1 batch of real (label=1.0) and fake images (label=0.0)\n        # randomly pick real images and corresponding labels from dataset \n        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n        real_images = x_train[rand_indexes]\n        real_labels = y_train[rand_indexes]\n # random codes for real images\n real_code1 = np.random.normal(scale=0.5, size=[batch_size, 1])\n real_code2 = np.random.normal(scale=0.5, size=[batch_size, 1])\n        # generate fake images, labels and codes\n        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n                                                          batch_size)]\n fake_code1 = np.random.normal(scale=0.5, size=[batch_size, 1])\n fake_code2 = np.random.normal(scale=0.5, size=[batch_size, 1])\n inputs = [noise, fake_labels, fake_code1, fake_code2]\n        fake_images = generator.predict(inputs)\n\n        # real + fake images = 1 batch of train data\n        x = np.concatenate((real_images, fake_images))\n        labels = np.concatenate((real_labels, fake_labels))\n codes1 = np.concatenate((real_code1, fake_code1))\n codes2 = np.concatenate((real_code2, fake_code2))\n\n        # label real and fake images\n        # real images label is 1.0\n        y = np.ones([2 * batch_size, 1])\n        # fake images label is 0.0\n        y[batch_size:, :] = 0\n\n # train discriminator network, log the loss and label accuracy\n outputs = [y, labels, codes1, codes2]\n # metrics = ['loss', 'activation_1_loss', 'label_loss',\n # 'code1_loss', 'code2_loss', 'activation_1_acc',\n # 'label_acc', 'code1_acc', 'code2_acc']\n # from discriminator.metrics_names\n metrics = discriminator.train_on_batch(x, outputs)\n fmt = \"%d: [discriminator loss: %f, label_acc: %f]\"\n log = fmt % (i, metrics[0], metrics[6])\n\n        # train the adversarial network for 1 batch\n        # 1 batch of fake images with label=1.0 and\n        # corresponding one-hot label or class + random codes\n        # since the discriminator weights are frozen in \n        # adversarial network only the generator is trained\n        # generate fake images, labels and codes\n        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n                                                          batch_size)]\n fake_code1 = np.random.normal(scale=0.5, size=[batch_size, 1])\n fake_code2 = np.random.normal(scale=0.5, size=[batch_size, 1])\n        # label fake images as real\n        y = np.ones([batch_size, 1])\n\n        # note that unlike in discriminator training, \n        # we do not save the fake images in a variable\n        # the fake images go to the discriminator input of the \n        # adversarial for classification\n        # log the loss and label accuracy\n inputs = [noise, fake_labels, fake_code1, fake_code2]\n outputs = [y, fake_labels, fake_code1, fake_code2]\n metrics  = adversarial.train_on_batch(inputs, outputs)\n fmt = \"%s [adversarial loss: %f, label_acc: %f]\"\n log = fmt % (log, metrics[0], metrics[6])\n\n        print(log)\n        if (i + 1) % save_interval == 0:\n            if (i + 1) == train_steps:\n                show = True\n            else:\n                show = False\n\n            # plot generator images on a periodic basis\n            gan.plot_images(generator,\n                            noise_input=noise_input,\n                            noise_label=noise_label,\n                            noise_codes=[noise_code1, noise_code2],\n                            show=show,\n                            step=(i + 1),\n                            model_name=model_name)\n\n    # save the model after training the generator\n    # the trained generator can be reloaded for\n    # future MNIST digit generation\n    generator.save(model_name + \".h5\")\n```", "```py\n    python3 infogan-mnist-6.1.1.py --generator=infogan_mnist.h5 --digit=0 --code1=0 --code2=0\n    ```", "```py\n    python3 infogan-mnist-6.1.1.py --generator=infogan_mnist.h5 --digit=9 --code1=0 --code2=0\n\n    ```", "```py\n    python3 infogan-mnist-6.1.1.py --generator=infogan_mnist.h5 --digit=0 --code1=0 --code2=0 --p1\n\n    ```", "```py\n    python3 infogan-mnist-6.1.1.py --generator=infogan_mnist.h5 --digit=0 --code1=0 --code2=0 --p2\n\n    ```", "```py\ndef build_encoder(inputs, num_labels=10, feature1_dim=256):\n    \"\"\" Build the Classifier (Encoder) Model sub networks\n\n    Two sub networks: \n    1) Encoder0: Image to feature1 (intermediate latent feature)\n    2) Encoder1: feature1 to labels\n\n    # Arguments\n        inputs (Layers): x - images, feature1 - feature1 layer output\n        num_labels (int): number of class labels\n        feature1_dim (int): feature1 dimensionality\n\n    # Returns\n        enc0, enc1 (Models): Description below \n    \"\"\"\n    kernel_size = 3\n    filters = 64\n\n    x, feature1 = inputs\n    # Encoder0 or enc0\n    y = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               padding='same',\n               activation='relu')(x)\n    y = MaxPooling2D()(y)\n    y = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               padding='same',\n               activation='relu')(y)\n    y = MaxPooling2D()(y)\n    y = Flatten()(y)\n    feature1_output = Dense(feature1_dim, activation='relu')(y)\n    # Encoder0 or enc0: image to feature1 \n    enc0 = Model(inputs=x, outputs=feature1_output, name=\"encoder0\")\n\n    # Encoder1 or enc1\n    y = Dense(num_labels)(feature1)\n    labels = Activation('softmax')(y)\n    # Encoder1 or enc1: feature1 to class labels\n    enc1 = Model(inputs=feature1, outputs=labels, name=\"encoder1\")\n\n    # return both enc0 and enc1\n    return enc0, enc1\n```", "```py\n# gen0: feature1 + z0 to feature0 (image)\ngen0 = gan.generator(feature1, image_size, codes=z0)\n```", "```py\ndef build_generator(latent_codes, image_size, feature1_dim=256):\n    \"\"\"Build Generator Model sub networks\n\n    Two sub networks: 1) Class and noise to feature1 (intermediate feature)\n    2) feature1 to image\n\n    # Arguments\n        latent_codes (Layers): discrete code (labels), noise and feature1 features\n        image_size (int): Target size of one side (assuming square image)\n        feature1_dim (int): feature1 dimensionality\n\n    # Returns\n        gen0, gen1 (Models): Description below\n    \"\"\"\n\n    # Latent codes and network parameters\n    labels, z0, z1, feature1 = latent_codes\n    # image_resize = image_size // 4\n    # kernel_size = 5\n    # layer_filters = [128, 64, 32, 1]\n\n    # gen1 inputs\n    inputs = [labels, z1]      # 10 + 50 = 62-dim\n    x = concatenate(inputs, axis=1)\n    x = Dense(512, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dense(512, activation='relu')(x)\n    x = BatchNormalization()(x)\n    fake_feature1 = Dense(feature1_dim, activation='relu')(x)\n    # gen1: classes and noise (feature2 + z1) to feature1\n    gen1 = Model(inputs, fake_feature1, name='gen1')\n\n    # gen0: feature1 + z0 to feature0 (image)\n    gen0 = gan.generator(feature1, image_size, codes=z0)\n\n    return gen0, gen1\n```", "```py\ndis0 = gan.discriminator(inputs, num_codes=z_dim)\n```", "```py\ndef build_discriminator(inputs, z_dim=50):\n    \"\"\"Build Discriminator 1 Model\n\n    Classifies feature1 (features) as real/fake image and recovers\n    the input noise or latent code (by minimizing entropy loss)\n\n    # Arguments\n        inputs (Layer): feature1\n        z_dim (int): noise dimensionality\n\n    # Returns\n        dis1 (Model): feature1 as real/fake and recovered latent code\n    \"\"\"\n\n    # input is 256-dim feature1\n    x = Dense(256, activation='relu')(inputs)\n    x = Dense(256, activation='relu')(x)\n\n    # first output is probability that feature1 is real\n    f1_source = Dense(1)(x)\n    f1_source = Activation('sigmoid', name='feature1_source')(f1_source)\n\n    # z1 reonstruction (Q1 network)\n    z1_recon = Dense(z_dim)(x)\n    z1_recon = Activation('tanh', name='z1')(z1_recon)\n\n    discriminator_outputs = [f1_source, z1_recon]\n    dis1 = Model(inputs, discriminator_outputs, name='dis1')\n    return dis1 \n```", "```py\ndef build_and_train_models():\n    # load MNIST dataset\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n    # reshape and normalize images\n    image_size = x_train.shape[1]\n    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n    x_train = x_train.astype('float32') / 255\n\n    x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n    x_test = x_test.astype('float32') / 255\n\n    # number of labels\n    num_labels = len(np.unique(y_train))\n    # to one-hot vector\n    y_train = to_categorical(y_train)\n    y_test = to_categorical(y_test)\n\n    model_name = \"stackedgan_mnist\"\n    # network parameters\n    batch_size = 64\n    train_steps = 40000\n    lr = 2e-4\n    decay = 6e-8\n    input_shape = (image_size, image_size, 1)\n    label_shape = (num_labels, )\n    z_dim = 50\n    z_shape = (z_dim, )\n    feature1_dim = 256\n    feature1_shape = (feature1_dim, )\n\n    # build discriminator 0 and Q network 0 models\n    inputs = Input(shape=input_shape, name='discriminator0_input')\n    dis0 = gan.discriminator(inputs, num_codes=z_dim)\n    # [1] uses Adam, but discriminator converges easily with RMSprop\n    optimizer = RMSprop(lr=lr, decay=decay)\n    # loss fuctions: 1) probability image is real (adversarial0 loss)\n    # 2) MSE z0 recon loss (Q0 network loss or entropy0 loss)\n    loss = ['binary_crossentropy', 'mse']\n    loss_weights = [1.0, 10.0]\n    dis0.compile(loss=loss,\n                 loss_weights=loss_weights,\n                 optimizer=optimizer,\n                 metrics=['accuracy'])\n    dis0.summary() # image discriminator, z0 estimator \n\n    # build discriminator 1 and Q network 1 models\n    input_shape = (feature1_dim, )\n    inputs = Input(shape=input_shape, name='discriminator1_input')\n    dis1 = build_discriminator(inputs, z_dim=z_dim )\n    # loss fuctions: 1) probability feature1 is real (adversarial1 loss)\n    # 2) MSE z1 recon loss (Q1 network loss or entropy1 loss)\n    loss = ['binary_crossentropy', 'mse']\n    loss_weights = [1.0, 1.0]\n    dis1.compile(loss=loss,\n                 loss_weights=loss_weights,\n                 optimizer=optimizer,\n                 metrics=['accuracy'])\n    dis1.summary() # feature1 discriminator, z1 estimator\n\n    # build generator models\n    feature1 = Input(shape=feature1_shape, name='feature1_input')\n    labels = Input(shape=label_shape, name='labels')\n    z1 = Input(shape=z_shape, name=\"z1_input\")\n    z0 = Input(shape=z_shape, name=\"z0_input\")\n    latent_codes = (labels, z0, z1, feature1)\n    gen0, gen1 = build_generator(latent_codes, image_size)\n    gen0.summary() # image generator \n    gen1.summary() # feature1 generator\n\n    # build encoder models\n    input_shape = (image_size, image_size, 1)\n    inputs = Input(shape=input_shape, name='encoder_input')\n    enc0, enc1 = build_encoder((inputs, feature1), num_labels)\n    enc0.summary() # image to feature1 encoder\n    enc1.summary() # feature1 to labels encoder (classifier)\n    encoder = Model(inputs, enc1(enc0(inputs)))\n    encoder.summary() # image to labels encoder (classifier)\n\n    data = (x_train, y_train), (x_test, y_test)\n    train_encoder(encoder, data, model_name=model_name)\n\n    # build adversarial0 model =\n    # generator0 + discriminator0 + encoder0\n    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n    # encoder0 weights frozen\n    enc0.trainable = False\n    # discriminator0 weights frozen\n    dis0.trainable = False\n    gen0_inputs = [feature1, z0]\n    gen0_outputs = gen0(gen0_inputs)\n    adv0_outputs = dis0(gen0_outputs) + [enc0(gen0_outputs)]\n    # feature1 + z0 to prob feature1 is \n    # real + z0 recon + feature0/image recon\n    adv0 = Model(gen0_inputs, adv0_outputs, name=\"adv0\")\n    # loss functions: 1) prob feature1 is real (adversarial0 loss)\n    # 2) Q network 0 loss (entropy0 loss)\n    # 3) conditional0 loss\n    loss = ['binary_crossentropy', 'mse', 'mse']\n    loss_weights = [1.0, 10.0, 1.0]\n    adv0.compile(loss=loss,\n                 loss_weights=loss_weights,\n                 optimizer=optimizer,\n                 metrics=['accuracy'])\n    adv0.summary()\n\n    # build adversarial1 model = \n    # generator1 + discriminator1 + encoder1\n    # encoder1 weights frozen\n    enc1.trainable = False\n    # discriminator1 weights frozen\n    dis1.trainable = False\n    gen1_inputs = [labels, z1]\n    gen1_outputs = gen1(gen1_inputs)\n    adv1_outputs = dis1(gen1_outputs) + [enc1(gen1_outputs)]\n    # labels + z1 to prob labels are real + z1 recon + feature1 recon\n    adv1 = Model(gen1_inputs, adv1_outputs, name=\"adv1\")\n    # loss functions: 1) prob labels are real (adversarial1 loss)\n    # 2) Q network 1 loss (entropy1 loss)\n    # 3) conditional1 loss (classifier error)\n    loss_weights = [1.0, 1.0, 1.0]\n    loss = ['binary_crossentropy', 'mse', 'categorical_crossentropy']\n    adv1.compile(loss=loss,\n                 loss_weights=loss_weights,\n                 optimizer=optimizer,\n                 metrics=['accuracy'])\n    adv1.summary()\n\n    # train discriminator and adversarial networks\n    models = (enc0, enc1, gen0, gen1, dis0, dis1, adv0, adv1)\n    params = (batch_size, train_steps, num_labels, z_dim, model_name)\n    train(models, data, params)\n```", "```py\ndef train(models, data, params):\n    \"\"\"Train the discriminator and adversarial Networks\n\n    Alternately train discriminator and adversarial networks by batch.\n    Discriminator is trained first with real and fake images,\n    corresponding one-hot labels and latent codes.\n    Adversarial is trained next with fake images pretending to be real,\n    corresponding one-hot labels and latent codes.\n    Generate sample images per save_interval.\n\n    # Arguments\n        models (Models): Encoder, Generator, Discriminator, Adversarial models\n        data (tuple): x_train, y_train data\n        params (tuple): Network parameters\n\n    \"\"\"\n    # the StackedGAN and Encoder models\n    enc0, enc1, gen0, gen1, dis0, dis1, adv0, adv1 = models\n    # network parameters\n    batch_size, train_steps, num_labels, z_dim, model_name = params\n    # train dataset\n    (x_train, y_train), (_, _) = data\n    # the generator image is saved every 500 steps\n    save_interval = 500\n\n    # label and noise codes for generator testing\n    z0 = np.random.normal(scale=0.5, size=[16, z_dim])\n    z1 = np.random.normal(scale=0.5, size=[16, z_dim])\n    noise_class = np.eye(num_labels)[np.arange(0, 16) % num_labels]\n    noise_params = [noise_class, z0, z1]\n    # number of elements in train dataset\n    train_size = x_train.shape[0]\n    print(model_name,\n          \"Labels for generated images: \",\n          np.argmax(noise_class, axis=1))\n\n    for i in range(train_steps):\n        # train the discriminator1 for 1 batch\n        # 1 batch of real (label=1.0) and fake feature1 (label=0.0)\n        # randomly pick real images from dataset\n        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n        real_images = x_train[rand_indexes]\n        # real feature1 from encoder0 output\n        real_feature1 = enc0.predict(real_images)\n        # generate random 50-dim z1 latent code\n        real_z1 = np.random.normal(scale=0.5, size=[batch_size, z_dim])\n        # real labels from dataset\n        real_labels = y_train[rand_indexes]\n\n        # generate fake feature1 using generator1 from\n        # real labels and 50-dim z1 latent code\n        fake_z1 = np.random.normal(scale=0.5, size=[batch_size, z_dim])\n        fake_feature1 = gen1.predict([real_labels, fake_z1])\n\n        # real + fake data\n        feature1 = np.concatenate((real_feature1, fake_feature1))\n        z1 = np.concatenate((fake_z1, fake_z1))\n\n        # label 1st half as real and 2nd half as fake\n        y = np.ones([2 * batch_size, 1])\n        y[batch_size:, :] = 0\n\n        # train discriminator1 to classify feature1 \n        # as real/fake and recover\n        # latent code (z1). real = from encoder1, \n        # fake = from genenerator1 \n        # joint training using discriminator part of advserial1 loss\n        # and entropy1 loss\n        metrics = dis1.train_on_batch(feature1, [y, z1])\n        # log the overall loss only (fr dis1.metrics_names)\n        log = \"%d: [dis1_loss: %f]\" % (i, metrics[0])\n\n        # train the discriminator0 for 1 batch\n        # 1 batch of real (label=1.0) and fake images (label=0.0)\n        # generate random 50-dim z0 latent code\n        fake_z0 = np.random.normal(scale=0.5, size=[batch_size, z_dim])\n        # generate fake images from real feature1 and fake z0\n        fake_images = gen0.predict([real_feature1, fake_z0])\n\n        # real + fake data\n        x = np.concatenate((real_images, fake_images))\n        z0 = np.concatenate((fake_z0, fake_z0))\n\n        # train discriminator0 to classify image as real/fake and recover\n        # latent code (z0)\n        # joint training using discriminator part of advserial0 loss\n        # and entropy0 loss\n        metrics = dis0.train_on_batch(x, [y, z0])\n        # log the overall loss only (fr dis0.metrics_names)\n        log = \"%s [dis0_loss: %f]\" % (log, metrics[0])\n\n        # adversarial training \n        # generate fake z1, labels\n        fake_z1 = np.random.normal(scale=0.5, size=[batch_size, z_dim])\n        # input to generator1 is sampling fr real labels and\n        # 50-dim z1 latent code\n        gen1_inputs = [real_labels, fake_z1]\n\n        # label fake feature1 as real\n        y = np.ones([batch_size, 1])\n\n        # train generator1 (thru adversarial) by \n        # fooling the discriminator\n        # and approximating encoder1 feature1 generator\n        # joint training: adversarial1, entropy1, conditional1\n        metrics = adv1.train_on_batch(gen1_inputs, [y, fake_z1, real_labels])\n        fmt = \"%s [adv1_loss: %f, enc1_acc: %f]\"\n        # log the overall loss and classification accuracy\n        log = fmt % (log, metrics[0], metrics[6])\n\n        # input to generator0 is real feature1 and \n        # 50-dim z0 latent code\n        fake_z0 = np.random.normal(scale=0.5, size=[batch_size, z_dim])\n        gen0_inputs = [real_feature1, fake_z0]\n\n        # train generator0 (thru adversarial) by \n        # fooling the discriminator\n        # and approximating encoder1 image source generator\n        # joint training: adversarial0, entropy0, conditional0\n        metrics = adv0.train_on_batch(gen0_inputs, [y, fake_z0, real_feature1])\n        # log the overall loss only\n        log = \"%s [adv0_loss: %f]\" % (log, metrics[0])\n\n        print(log)\n        if (i + 1) % save_interval == 0:\n            if (i + 1) == train_steps:\n                show = True\n            else:\n                show = False\n            generators = (gen0, gen1)\n            plot_images(generators,\n                        noise_params=noise_params,\n                        show=show,\n                        step=(i + 1),\n                        model_name=model_name)\n\n    # save the modelis after training generator0 & 1\n    # the trained generator can be reloaded for\n    # future MNIST digit generation\n    gen1.save(model_name + \"-gen1.h5\")\n    gen0.save(model_name + \"-gen0.h5\")\n```", "```py\n    python3 stackedgan-mnist-6.2.1.py \n    --generator0=stackedgan_mnist-gen0.h5 \n    --generator1=stackedgan_mnist-gen1.h5 --digit=0\n    python3 stackedgan-mnist-6.2.1.py \n    --generator0=stackedgan_mnist-gen0.h5 \n    --generator1=stackedgan_mnist-gen1.h5 --digit=9\n\n    ```", "```py\n    python3 stackedgan-mnist-6.2.1.py \n    --generator0=stackedgan_mnist-gen0.h5 \n    --generator1=stackedgan_mnist-gen1.h5 --z0=0 --z1=0 –p0 \n    --digit=8\n\n    ```", "```py\n    python3 stackedgan-mnist-6.2.1.py \n    --generator0=stackedgan_mnist-gen0.h5 \n    --generator1=stackedgan_mnist-gen1.h5 --z0=0 --z1=0 –p1 \n    --digit=8\n\n    ```"]