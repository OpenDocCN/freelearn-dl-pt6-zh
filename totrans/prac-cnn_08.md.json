["```py\n#import all necessary libraries and load data set\n%matplotlib inline\n\nimport pickle as pkl\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('MNIST_data')\n```", "```py\n#place holder for model inputs \ndef model_inputs(dim_real, dim_z):\n    real_input = tf.placeholder(tf.float32, name='dim_real')\n    z_input = tf.placeholder(tf.float32, name='dim_z')\n\n    return real_input, z_input\n```", "```py\n#Following code builds Generator Network\ndef generator(z, out_dim, n_units=128, reuse=False, alpha=0.01):\n    ''' Build the generator network.\n\n        Arguments\n        ---------\n        z : Input tensor for the generator\n        out_dim : Shape of the generator output\n        n_units : Number of units in hidden layer\n        reuse : Reuse the variables with tf.variable_scope\n        alpha : leak parameter for leaky ReLU\n\n        Returns\n        -------\n        out: \n    '''\n    with tf.variable_scope('generator', reuse=reuse) as generator_scope: # finish this\n        # Hidden layer\n        h1 = tf.layers.dense(z, n_units, activation=None )\n        # Leaky ReLU\n        h1 = tf.nn.leaky_relu(h1, alpha=alpha,name='leaky_generator')\n\n        # Logits and tanh output\n        logits = tf.layers.dense(h1, out_dim, activation=None)\n        out = tf.tanh(logits)\n\n        return out\n```", "```py\n\ndef discriminator(x, n_units=128, reuse=False, alpha=0.01):\n    ''' Build the discriminator network.\n\n        Arguments\n        ---------\n        x : Input tensor for the discriminator\n        n_units: Number of units in hidden layer\n        reuse : Reuse the variables with tf.variable_scope\n        alpha : leak parameter for leaky ReLU\n\n        Returns\n        -------\n        out, logits: \n    '''\n    with tf.variable_scope('discriminator', reuse=reuse) as discriminator_scope:# finish this\n        # Hidden layer\n        h1 = tf.layers.dense(x, n_units, activation=None )\n        # Leaky ReLU\n        h1 = tf.nn.leaky_relu(h1, alpha=alpha,name='leaky_discriminator')\n\n        logits = tf.layers.dense(h1, 1, activation=None)\n        out = tf.sigmoid(logits)\n\n        return out, logits\n```", "```py\n#Hyperparameters\n# Size of input image to discriminator\ninput_size = 784 # 28x28 MNIST images flattened\n# Size of latent vector to generator\nz_size = 100\n# Sizes of hidden layers in generator and discriminator\ng_hidden_size = 128\nd_hidden_size = 128\n# Leak factor for leaky ReLU\nalpha = 0.01\n# Label smoothing \nsmooth = 0.1\n```", "```py\n#Build the network\ntf.reset_default_graph()\n# Create our input placeholders\ninput_real, input_z = model_inputs(input_size, z_size)\n\n# Build the model\ng_model = generator(input_z, input_size, n_units=g_hidden_size, alpha=alpha)\n# g_model is the generator output\n\nd_model_real, d_logits_real = discriminator(input_real, n_units=d_hidden_size, alpha=alpha)\nd_model_fake, d_logits_fake = discriminator(g_model, reuse=True, n_units=d_hidden_size, alpha=alpha)\n```", "```py\ntf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n```", "```py\n# Calculate losses\nd_loss_real = tf.reduce_mean(\n                  tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, \n                                                          labels=tf.ones_like(d_logits_real) * (1 - smooth)))\nd_loss_fake = tf.reduce_mean(\n                  tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, \n                                                          labels=tf.zeros_like(d_logits_real)))\nd_loss = d_loss_real + d_loss_fake\n\ng_loss = tf.reduce_mean(\n             tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n                                                     labels=tf.ones_like(d_logits_fake)))\n```", "```py\n# Optimizers\nlearning_rate = 0.002\n\n# Get the trainable_variables, split into G and D parts\nt_vars = tf.trainable_variables()\ng_vars = [var for var in t_vars if var.name.startswith('generator')]\nd_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n\nd_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\ng_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n```", "```py\nbatch_size = 100\nepochs = 100\nsamples = []\nlosses = []\n# Only save generator variables\nsaver = tf.train.Saver(var_list=g_vars)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for e in range(epochs):\n        for ii in range(mnist.train.num_examples//batch_size):\n            batch = mnist.train.next_batch(batch_size)\n\n            # Get images, reshape and rescale to pass to D\n            batch_images = batch[0].reshape((batch_size, 784))\n            batch_images = batch_images*2 - 1\n\n            # Sample random noise for G\n            batch_z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n\n            # Run optimizers\n            _ = sess.run(d_train_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n            _ = sess.run(g_train_opt, feed_dict={input_z: batch_z})\n\n        # At the end of each epoch, get the losses and print them out\n        train_loss_d = sess.run(d_loss, {input_z: batch_z, input_real: batch_images})\n        train_loss_g = g_loss.eval({input_z: batch_z})\n\n        print(\"Epoch {}/{}...\".format(e+1, epochs),\n              \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n              \"Generator Loss: {:.4f}\".format(train_loss_g)) \n        # Save losses to view after training\n        losses.append((train_loss_d, train_loss_g))\n\n        # Sample from generator as we're training for viewing afterwards\n        sample_z = np.random.uniform(-1, 1, size=(16, z_size))\n        gen_samples = sess.run(\n                       generator(input_z, input_size, n_units=g_hidden_size, reuse=True, alpha=alpha),\n                       feed_dict={input_z: sample_z})\n        samples.append(gen_samples)\n        saver.save(sess, './checkpoints/generator.ckpt')\n\n# Save training generator samples\nwith open('train_samples.pkl', 'wb') as f:\n    pkl.dump(samples, f)\n```", "```py\ncost of labeled data  = cross_entropy ( logits, labels)\ncost of unlabeled data =   cross_entropy ( logits, real)\n```", "```py\nreal prob = sum (softmax(real_classes))\n```", "```py\ndef model_inputs(real_dim, z_dim):\n    inputs_real = tf.placeholder(tf.float32, (None, *real_dim), name='input_real')\n    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name='input_z')\n    y = tf.placeholder(tf.int32, (None), name='y')\n    label_mask = tf.placeholder(tf.int32, (None), name='label_mask')\n\n    return inputs_real, inputs_z, y, label_mask\n```", "```py\ndef generator(z, output_dim, reuse=False, alpha=0.2, training=True, size_mult=128):\n    with tf.variable_scope('generator', reuse=reuse):\n        # First fully connected layer\n        x1 = tf.layers.dense(z, 4 * 4 * size_mult * 4)\n        # Reshape it to start the convolutional stack\n        x1 = tf.reshape(x1, (-1, 4, 4, size_mult * 4))\n        x1 = tf.layers.batch_normalization(x1, training=training)\n        x1 = tf.maximum(alpha * x1, x1)\n\n        x2 = tf.layers.conv2d_transpose(x1, size_mult * 2, 5, strides=2, padding='same')\n        x2 = tf.layers.batch_normalization(x2, training=training)\n        x2 = tf.maximum(alpha * x2, x2)\n\n        x3 = tf.layers.conv2d_transpose(x2, size_mult, 5, strides=2, padding='same')\n        x3 = tf.layers.batch_normalization(x3, training=training)\n        x3 = tf.maximum(alpha * x3, x3)\n\n        # Output layer\n        logits = tf.layers.conv2d_transpose(x3, output_dim, 5, strides=2, padding='same')\n\n        out = tf.tanh(logits)\n\n        return out\n```", "```py\ndef discriminator(x, reuse=False, alpha=0.2, drop_rate=0., num_classes=10, size_mult=64):\n    with tf.variable_scope('discriminator', reuse=reuse):\n        x = tf.layers.dropout(x, rate=drop_rate/2.5)\n\n        # Input layer is 32x32x3\n        x1 = tf.layers.conv2d(x, size_mult, 3, strides=2, padding='same')\n        relu1 = tf.maximum(alpha * x1, x1)\n        relu1 = tf.layers.dropout(relu1, rate=drop_rate)\n\n        x2 = tf.layers.conv2d(relu1, size_mult, 3, strides=2, padding='same')\n        bn2 = tf.layers.batch_normalization(x2, training=True)\n        relu2 = tf.maximum(alpha * x2, x2)\n\n        x3 = tf.layers.conv2d(relu2, size_mult, 3, strides=2, padding='same')\n        bn3 = tf.layers.batch_normalization(x3, training=True)\n        relu3 = tf.maximum(alpha * bn3, bn3)\n        relu3 = tf.layers.dropout(relu3, rate=drop_rate)\n\n        x4 = tf.layers.conv2d(relu3, 2 * size_mult, 3, strides=1, padding='same')\n        bn4 = tf.layers.batch_normalization(x4, training=True)\n        relu4 = tf.maximum(alpha * bn4, bn4)\n\n        x5 = tf.layers.conv2d(relu4, 2 * size_mult, 3, strides=1, padding='same')\n        bn5 = tf.layers.batch_normalization(x5, training=True)\n        relu5 = tf.maximum(alpha * bn5, bn5)\n\n        x6 = tf.layers.conv2d(relu5, 2 * size_mult, 3, strides=2, padding='same')\n        bn6 = tf.layers.batch_normalization(x6, training=True)\n        relu6 = tf.maximum(alpha * bn6, bn6)\n        relu6 = tf.layers.dropout(relu6, rate=drop_rate)\n\n        x7 = tf.layers.conv2d(relu5, 2 * size_mult, 3, strides=1, padding='valid')\n        # Don't use bn on this layer, because bn would set the mean of each feature\n        # to the bn mu parameter.\n        # This layer is used for the feature matching loss, which only works if\n        # the means can be different when the discriminator is run on the data than\n        # when the discriminator is run on the generator samples.\n        relu7 = tf.maximum(alpha * x7, x7)\n\n        # Flatten it by global average pooling\n        features = raise NotImplementedError()\n\n        # Set class_logits to be the inputs to a softmax distribution over the different classes\n        raise NotImplementedError()\n\n        # Set gan_logits such that P(input is real | input) = sigmoid(gan_logits).\n        # Keep in mind that class_logits gives you the probability distribution over all the real\n        # classes and the fake class. You need to work out how to transform this multiclass softmax\n        # distribution into a binary real-vs-fake decision that can be described with a sigmoid.\n        # Numerical stability is very important.\n        # You'll probably need to use this numerical stability trick:\n        # log sum_i exp a_i = m + log sum_i exp(a_i - m).\n        # This is numerically stable when m = max_i a_i.\n        # (It helps to think about what goes wrong when...\n        # 1\\. One value of a_i is very large\n        # 2\\. All the values of a_i are very negative\n        # This trick and this value of m fix both those cases, but the naive implementation and\n        # other values of m encounter various problems)\n        raise NotImplementedError()\n\n        return out, class_logits, gan_logits, features\n```", "```py\ndef model_loss(input_real, input_z, output_dim, y, num_classes, label_mask, alpha=0.2, drop_rate=0.):\n    \"\"\"\n    Get the loss for the discriminator and generator\n    :param input_real: Images from the real dataset\n    :param input_z: Z input\n    :param output_dim: The number of channels in the output image\n    :param y: Integer class labels\n    :param num_classes: The number of classes\n    :param alpha: The slope of the left half of leaky ReLU activation\n    :param drop_rate: The probability of dropping a hidden unit\n    :return: A tuple of (discriminator loss, generator loss)\n    \"\"\"\n\n    # These numbers multiply the size of each layer of the generator and the discriminator,\n    # respectively. You can reduce them to run your code faster for debugging purposes.\n    g_size_mult = 32\n    d_size_mult = 64\n\n    # Here we run the generator and the discriminator\n    g_model = generator(input_z, output_dim, alpha=alpha, size_mult=g_size_mult)\n    d_on_data = discriminator(input_real, alpha=alpha, drop_rate=drop_rate, size_mult=d_size_mult)\n    d_model_real, class_logits_on_data, gan_logits_on_data, data_features = d_on_data\n    d_on_samples = discriminator(g_model, reuse=True, alpha=alpha, drop_rate=drop_rate, size_mult=d_size_mult)\n    d_model_fake, class_logits_on_samples, gan_logits_on_samples, sample_features = d_on_samples\n\n    # Here we compute `d_loss`, the loss for the discriminator.\n    # This should combine two different losses:\n    # 1\\. The loss for the GAN problem, where we minimize the cross-entropy for the binary\n    # real-vs-fake classification problem.\n    # 2\\. The loss for the SVHN digit classification problem, where we minimize the cross-entropy\n    # for the multi-class softmax. For this one we use the labels. Don't forget to ignore\n    # use `label_mask` to ignore the examples that we are pretending are unlabeled for the\n    # semi-supervised learning problem.\n    raise NotImplementedError()\n\n    # Here we set `g_loss` to the \"feature matching\" loss invented by Tim Salimans at OpenAI.\n    # This loss consists of minimizing the absolute difference between the expected features\n    # on the data and the expected features on the generated samples.\n    # This loss works better for semi-supervised learning than the tradition GAN losses.\n    raise NotImplementedError()\n\n    pred_class = tf.cast(tf.argmax(class_logits_on_data, 1), tf.int32)\n    eq = tf.equal(tf.squeeze(y), pred_class)\n    correct = tf.reduce_sum(tf.to_float(eq))\n    masked_correct = tf.reduce_sum(label_mask * tf.to_float(eq))\n\n    return d_loss, g_loss, correct, masked_correct, g_model\n```", "```py\ndef model_opt(d_loss, g_loss, learning_rate, beta1):\n    \"\"\"\n    Get optimization operations\n    :param d_loss: Discriminator loss Tensor\n    :param g_loss: Generator loss Tensor\n    :param learning_rate: Learning Rate Placeholder\n    :param beta1: The exponential decay rate for the 1st moment in the optimizer\n    :return: A tuple of (discriminator training operation, generator training operation)\n    \"\"\"\n    # Get weights and biases to update. Get them separately for the discriminator and the generator\n    raise NotImplementedError()\n\n    # Minimize both players' costs simultaneously\n    raise NotImplementedError()\n    shrink_lr = tf.assign(learning_rate, learning_rate * 0.9)\n\n    return d_train_opt, g_train_opt, shrink_lr\n```", "```py\nclass GAN:\n    \"\"\"\n    A GAN model.\n    :param real_size: The shape of the real data.\n    :param z_size: The number of entries in the z code vector.\n    :param learnin_rate: The learning rate to use for Adam.\n    :param num_classes: The number of classes to recognize.\n    :param alpha: The slope of the left half of the leaky ReLU activation\n    :param beta1: The beta1 parameter for Adam.\n    \"\"\"\n    def __init__(self, real_size, z_size, learning_rate, num_classes=10, alpha=0.2, beta1=0.5):\n        tf.reset_default_graph()\n\n        self.learning_rate = tf.Variable(learning_rate, trainable=False)\n        inputs = model_inputs(real_size, z_size)\n        self.input_real, self.input_z, self.y, self.label_mask = inputs\n        self.drop_rate = tf.placeholder_with_default(.5, (), \"drop_rate\")\n\n        loss_results = model_loss(self.input_real, self.input_z,\n                                  real_size[2], self.y, num_classes,\n                                  label_mask=self.label_mask,\n                                  alpha=0.2,\n                                  drop_rate=self.drop_rate)\n        self.d_loss, self.g_loss, self.correct, self.masked_correct, self.samples = loss_results\n\n        self.d_opt, self.g_opt, self.shrink_lr = model_opt(self.d_loss, self.g_loss, self.learning_rate, beta1)\n```", "```py\ndef train(net, dataset, epochs, batch_size, figsize=(5,5)):\n\n    saver = tf.train.Saver()\n    sample_z = np.random.normal(0, 1, size=(50, z_size))\n\n    samples, train_accuracies, test_accuracies = [], [], []\n    steps = 0\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        for e in range(epochs):\n            print(\"Epoch\",e)\n\n            t1e = time.time()\n            num_examples = 0\n            num_correct = 0\n            for x, y, label_mask in dataset.batches(batch_size):\n                assert 'int' in str(y.dtype)\n                steps += 1\n                num_examples += label_mask.sum()\n\n                # Sample random noise for G\n                batch_z = np.random.normal(0, 1, size=(batch_size, z_size))\n\n                # Run optimizers\n                t1 = time.time()\n                _, _, correct = sess.run([net.d_opt, net.g_opt, net.masked_correct],\n                                         feed_dict={net.input_real: x, net.input_z: batch_z,\n                                                    net.y : y, net.label_mask : label_mask})\n                t2 = time.time()\n                num_correct += correct\n\n            sess.run([net.shrink_lr])\n\n            train_accuracy = num_correct / float(num_examples)\n\n            print(\"\\t\\tClassifier train accuracy: \", train_accuracy)\n\n            num_examples = 0\n            num_correct = 0\n            for x, y in dataset.batches(batch_size, which_set=\"test\"):\n                assert 'int' in str(y.dtype)\n                num_examples += x.shape[0]\n\n                correct, = sess.run([net.correct], feed_dict={net.input_real: x,\n                                                   net.y : y,\n                                                   net.drop_rate: 0.})\n                num_correct += correct\n\n            test_accuracy = num_correct / float(num_examples)\n            print(\"\\t\\tClassifier test accuracy\", test_accuracy)\n            print(\"\\t\\tStep time: \", t2 - t1)\n            t2e = time.time()\n            print(\"\\t\\tEpoch time: \", t2e - t1e)\n\n            gen_samples = sess.run(\n                                   net.samples,\n                                   feed_dict={net.input_z: sample_z})\n            samples.append(gen_samples)\n            _ = view_samples(-1, samples, 5, 10, figsize=figsize)\n            plt.show()\n\n            # Save history of accuracies to view after training\n            train_accuracies.append(train_accuracy)\n            test_accuracies.append(test_accuracy)\n\n        saver.save(sess, './checkpoints/generator.ckpt')\n\n    with open('samples.pkl', 'wb') as f:\n        pkl.dump(samples, f)\n\n    return train_accuracies, test_accuracies, samples\n```"]