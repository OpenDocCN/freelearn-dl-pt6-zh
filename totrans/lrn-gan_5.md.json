["```py\ntrain_datagen = ImageDataGenerator(\n\tpreprocessing_function=preprocess_input,\n\trotation_range=30,\n\twidth_shift_range=0.2,\n\theight_shift_range=0.2,\n\tshear_range=0.2,\n\tzoom_range=0.2,\n\thorizontal_flip=True\n)\ntest_datagen = ImageDataGenerator(\n\tpreprocessing_function=preprocess_input,\n\trotation_range=30,\n\twidth_shift_range=0.2,\n\theight_shift_range=0.2,\n\tshear_range=0.2,\n\tzoom_range=0.2,\n\thorizontal_flip=True\n)\ntrain_generator = train_datagen.flow_from_directory(\n\targs.train_dir,\n\ttarget_size=(IM_WIDTH, IM_HEIGHT),\n\tbatch_size=batch_size,\n)\nvalidation_generator = test_datagen.flow_from_directory(\n\targs.val_dir,\n\ttarget_size=(IM_WIDTH, IM_HEIGHT),\n\tbatch_size=batch_size,\n)\n```", "```py\nbase_model = InceptionV3(weights='imagenet', include_top=False)\n```", "```py\ndef addNewLastLayer(base_model, nb_classes):\n\tx = base_model.output\n\tx = GlobalAveragePooling2D()(x)\n\tx = Dense(FC_SIZE, activation='relu')(x)\n\tpredictions = Dense(nb_classes, activation='softmax')(x)\n\tmodel = Model(input=base_model.input, output=predictions)\n\treturn model\n\n```", "```py\ndef setupTransferLearn(model, base_model):\n\tfor layer in base_model.layers:\n\t  layer.trainable = False\nmodel.compile(optimizer='rmsprop',\n\t\t\t  loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n```", "```py\ndef setupFineTune(model):\n   for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n      layer.trainable = False\n   for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n\t  layer.trainable = True\n   model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\nloss='categorical_crossentropy')\n\n```", "```py\nhistory = model.fit_generator(\n\ttrain_generator,\n\tsamples_per_epoch=nb_train_samples,\n\tnb_epoch=nb_epoch,\n\tvalidation_data=validation_generator,\n\tnb_val_samples=nb_val_samples,\n\tclass_weight='auto')\nmodel.save(args.output_model_file)\n\n```", "```py\npython training-fine-tune.py --train_dir <path to training images> --val_dir <path to validation images>\n```", "```py\npython predict.py --image_url https://goo.gl/DCbuq8 --model inceptionv3-ft.model\n```", "```py\n    pyspark --master local[*] --packages databricks:spark-deep-learning:0.1.0-spark2.1-s_2.11\n    ```", "```py\n    img_dir= \"path to base image directory\"\n    roses_df = readImages(img_dir + \"/roses\").withColumn(\"label\", lit(1))\n    daisy_df = readImages(img_dir + \"/daisy\").withColumn(\"label\", lit(0))\n    roses_train, roses_test = roses_df.randomSplit([0.6, 0.4])\n    daisy_train, daisy_test = daisy_df.randomSplit([0.6, 0.4])\n    train_df = roses_train.unionAll(daisy_train)\n    ```", "```py\n    featurizer = DeepImageFeaturizer(inputCol=\"image\", outputCol=\"features\", modelName=\"InceptionV3\")\n    lr = LogisticRegression(maxIter=20, regParam=0.05, elasticNetParam=0.3, labelCol=\"label\")\n    p = Pipeline(stages=[featurizer, lr])\n    ```", "```py\n    p_model = p.fit(train_df)   \n    ```", "```py\n    tested_df = p_model.transform(test_df)\n    evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n    print(\"Test set accuracy = \" + str(evaluator.evaluate(tested_df.select(\"prediction\", \"label\"))))\n    ```", "```py\nsample_img_dir=<path to your image>\n\nimage_df = readImages(sample_img_dir)\n\npredictor = DeepImagePredictor(inputCol=\"image\", outputCol=\"predicted_labels\", modelName=\"InceptionV3\", decodePredictions=True, topK=10)\npredictions_df = predictor.transform(image_df)\n\npredictions_df.select(\"filePath\", \"predicted_labels\").show(10,False)\n```", "```py\nmodel = InceptionV3(weights=\"imagenet\")\nmodel.save('model-full.h5')\n```", "```py\ndef loadAndPreprocessKerasInceptionV3(uri):\n    # this is a typical way to load and prep images in keras\n    image = img_to_array(load_img(uri, target_size=(299, 299)))\n    image = np.expand_dims(image, axis=0)\n    return preprocess_input(image)\n\ntransformer = KerasImageFileTransformer(inputCol=\"uri\", \n  outputCol=\"predictions\",\n                                        modelFile=\"model-full.h5\",\n                                    imageLoader=loadAndPreprocessKerasInceptionV3,\n                                        outputMode=\"vector\")\ndirpath=<path to mix-img>\n\nfiles = [os.path.abspath(os.path.join(dirpath, f)) for f in os.listdir(dirpath) if f.endswith('.jpg')]\nuri_df = sqlContext.createDataFrame(files, StringType()).toDF(\"uri\")\n\nfinal_df = transformer.transform(uri_df)\nfinal_df.select(\"uri\", \"predictions\").show()\n```", "```py\nmnist_path = \"datasets/mnist\"\n(train_data, test_data) = get_mnist(sc, mnist_path)\nprint train_data.count()\nprint test_data.count()\n```", "```py\ndef build_model(class_num):\n    model = Sequential()\n    model.add(Reshape([1, 28, 28]))\n    model.add(SpatialConvolution(1, 6, 5, 5).set_name('conv1'))\n    model.add(Tanh())\n    model.add(SpatialMaxPooling(2, 2, 2, 2).set_name('pool1'))\n    model.add(Tanh())\n    model.add(SpatialConvolution(6, 12, 5, 5).set_name('conv2'))\n    model.add(SpatialMaxPooling(2, 2, 2, 2).set_name('pool2'))\n    model.add(Reshape([12 * 4 * 4]))\n    model.add(Linear(12 * 4 * 4, 100).set_name('fc1'))\n    model.add(Tanh())\n    model.add(Linear(100, class_num).set_name('score'))\n    model.add(LogSoftMax())\n    return model\nlenet_model = build_model(10)\n```", "```py\noptimizer = Optimizer(\n    model=lenet_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=SGD(learningrate=0.4, learningrate_decay=0.0002),\n    end_trigger=MaxEpoch(20),\n    batch_size=2048)\n\noptimizer.set_validation(\n    batch_size=2048,\n    val_rdd=test_data,\n    trigger=EveryEpoch(),\n    val_method=[Top1Accuracy()]\n)\n\ntrained_model = optimizer.optimize()\n```", "```py\npredictions = trained_model.predict(test_data)\n```", "```py\nSPARK_HOME= <path to Spark>\nBigDL_HOME= <path to BigDL>\nPYTHON_API_ZIP_PATH=${BigDL_HOME}/bigdl-python-<version>.zip\nBigDL_JAR_PATH=${BigDL_HOME}/bigdl-SPARK-<version>.jar\nexport PYTHONPATH=${PYTHON_API_ZIP_PATH}:${BigDL_HOME}/conf/spark-bigdl.conf:$PYTHONPATH\n\n${SPARK_HOME}/bin/spark-submit \\\n      --master <local or spark master url>\\\n      --driver-cores 5  \\\n      --driver-memory 5g  \\\n      --total-executor-cores 16  \\\n      --executor-cores 8  \\\n      --executor-memory 10g \\\n      --py-files ${PYTHON_API_ZIP_PATH},${BigDL_HOME}/BigDL-MNIST.py\\\n      --properties-file ${BigDL_HOME}/conf/spark-bigdl.conf \\\n      --jars ${BigDL_JAR_PATH} \\\n      --conf spark.driver.extraClassPath=${BigDL_JAR_PATH} \\\n      --conf spark.executor.extraClassPath=bigdl-SPARK<version>.jar \\\n      ${BigDL_HOME}/BigDL-MNIST.py\n```", "```py\nINFO  DistriOptimizer$:536 - Top1Accuracy is Accuracy(correct: 9568, count: 10000, accuracy: 0.9568)\n```", "```py\ndef generator(self, x, is_training, reuse):\n    with tf.variable_scope('generator', reuse=reuse):\n      with tf.variable_scope('deconv1'):\n          x = deconv_layer(\n               x, [3, 3, 64, 3], [self.batch_size, 24, 24, 64], 1)\n          x = tf.nn.relu(x)\n          shortcut = x\n# 5 Residual block with identical layout of deconvolution layers having batch norm and relu as activation function.\n    for i in range(5):\n       mid = x\n       with tf.variable_scope('block{}a'.format(i+1)):\n         x = deconv_layer(x, [3, 3, 64, 64], [self.batch_size, 24, \n24, 64], 1)\n         x = batch_normalize(x, is_training)\n         x = tf.nn.relu(x)\n\n# 2 deconvolution layers having pixel-suffle and relu as activation function. \n     with tf.variable_scope('deconv3'):\n         x = deconv_layer(x, [3, 3, 256, 64], [self.batch_size, 24, \n24, 256], 1)\n         x = pixel_shuffle_layer(x, 2, 64) # n_split = 256 / 2 ** 2\n         x = tf.nn.relu(x)\n     with tf.variable_scope('deconv4'):\n         x = deconv_layer(x, [3, 3, 64, 64], [self.batch_size, 48, \n48, 64], 1)\n         x = pixel_shuffle_layer(x, 2, 16)\n         x = tf.nn.relu(x)\n\n     . . . . . . . . [code omitted for clarity]\n\nreturn x\t\n```", "```py\ndef deconv_layer(x, filter_shape, output_shape, stride, trainable=True):\n    filter_ = tf.get_variable(\n        name='weight',\n        shape=filter_shape,\n        dtype=tf.float32,\n        initializer=tf.contrib.layers.xavier_initializer(),\n        trainable=trainable)\n    return tf.nn.conv2d_transpose(\n        value=x,\n        filter=filter_,\n        output_shape=output_shape,\n        strides=[1, stride, stride, 1])\n```", "```py\ndef discriminator(self, x, is_training, reuse):\n        with tf.variable_scope('discriminator', reuse=reuse):\n            with tf.variable_scope('conv1'):\n                x = conv_layer(x, [3, 3, 3, 64], 1)\n                x = lrelu(x)\n            with tf.variable_scope('conv2'):\n                x = conv_layer(x, [3, 3, 64, 64], 2)\n                x = lrelu(x)\n                x = batch_normalize(x, is_training)\n\n         .  .   .   .   .   . [code omitted for clarity]\n\n            x = flatten_layer(x)\n            with tf.variable_scope('fc'):\n                x = full_connection_layer(x, 1024)\n                x = lrelu(x)\n            with tf.variable_scope('softmax'):\n                x = full_connection_layer(x, 1)\n\nreturn x\n```", "```py\ndef lrelu(x, trainbable=None):\n    alpha = 0.2\n    return tf.maximum(alpha * x, x)\n```", "```py\ndef conv_layer(x, filter_shape, stride, trainable=True):\n    filter_ = tf.get_variable(\n        name='weight', \n        shape=filter_shape,\n        dtype=tf.float32, \n        initializer=tf.contrib.layers.xavier_initializer(),\n        trainable=trainable)\n    return tf.nn.conv2d(\n        input=x,\n        filter=filter_,\n        strides=[1, stride, stride, 1],\n        padding='SAME')\n```", "```py\ndef inference_adversarial_loss(real_output, fake_output):\nalpha = 1e-5\ng_loss = tf.reduce_mean(\ntf.nn.l2_loss(fake_output - tf.ones_like(fake_output)))\nd_loss_real = tf.reduce_mean(\ntf.nn.l2_loss(real_output - tf.ones_like(true_output)))\nd_loss_fake = tf.reduce_mean(\ntf.nn.l2_loss(fake_output + tf.zeros_like(fake_output)))\nd_loss = d_loss_real + d_loss_fake\nreturn (g_loss * alpha, d_loss * alpha)\n\ngenerator_loss, discriminator_loss = (\ninference_adversarial_loss(true_output, fake_output))\n```", "```py\npython download-preprocess-lfw.py\n\n```", "```py\npython trainSrgan.py\n\n```", "```py\nsettings_preset = {\n    'dreamy': {\n        'features': {\n            'block5_conv1': 0.05,\n            'block5_conv2': 0.02\n        },\n        'continuity': 0.1,\n        'dream_l2': 0.02,\n        'jitter': 0\n    }\n}\n\nsettings = settings_preset['dreamy']\n```", "```py\ndef preprocess_image(image_path):\n    img = load_img(image_path, target_size=(img_height, img_width))\n    img = img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = vgg16.preprocess_input(img)\n    return img\n```", "```py\ndef continuity_loss(x):\n    assert K.ndim(x) == 4\n    a = K.square(x[:, :img_height-1, :img_width-1, :] -\n                 x[:, 1:, :img_width-1, :])\n    b = K.square(x[:, :img_height-1, :img_width-1, :] -\n                 x[:, :img_height-1, 1:, :])\n\n# (a+b) is the squared spatial gradient, 1.25 is a hyperparameter # that should be >1.0 as discussed in the aforementioned paper\n    return K.sum(K.pow(a+b, 1.25))\n```", "```py\nmodel = vgg16.VGG16(input_tensor=dream, weights='imagenet', include_top=False)\n```", "```py\nloss += settings['continuity'] * continuity_loss(dream) / np.prod(img_size)\nloss += settings['dream_l2'] * K.sum(K.square(dream)) / np.prod(img_size)\ngrads = K.gradients(loss, dream)\n```", "```py\nrandom_jitter = (settings['jitter']*2) * (np.random.random(img_size)-0.5)\nx += random_jitter\n\n# run L-BFGS \nx, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n                              fprime=evaluator.grads, maxfun=7)\n```", "```py\n    x = x.reshape(img_size)\n    x -= random_jitter\n    img = deprocess_image(np.copy(x))\n    fn = result_prefix + '_at_iteration_%d.png' % i\n    imsave(fn, img)\n```", "```py\nX = tf.placeholder(tf.float32, shape=[None, X_dim])\nz = tf.placeholder(tf.float32, shape=[None, z_dim])\n\nQ_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\nQ_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n\nQ_W2_mu = tf.Variable(xavier_init([h_dim, z_dim]))\nQ_b2_mu = tf.Variable(tf.zeros(shape=[z_dim]))\nQ_W2_sigma = tf.Variable(xavier_init([h_dim, z_dim]))\nQ_b2_sigma = tf.Variable(tf.zeros(shape=[z_dim]))\n\ndef Q(X):\n    h = tf.nn.relu(tf.matmul(X, Q_W1) + Q_b1)\n    z_mu = tf.matmul(h, Q_W2_mu) + Q_b2_mu\n    z_logvar = tf.matmul(h, Q_W2_sigma) + Q_b2_sigma\n    return z_mu, z_logvar\n```", "```py\nP_W1 = tf.Variable(xavier_init([z_dim, h_dim]))\nP_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n\nP_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\nP_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n\ndef P(z):\n    h = tf.nn.relu(tf.matmul(z, P_W1) + P_b1)\n    logits = tf.matmul(h, P_W2) + P_b2\n    prob = tf.nn.sigmoid(logits)\n    return prob, logits\n```", "```py\nrecon_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=X), 1)\nkl_loss = 0.5 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1\\. - z_logvar, 1)\n# VAE loss\nvae_loss = tf.reduce_mean(recon_loss + kl_loss)\n```", "```py\nsolver = tf.train.AdamOptimizer().minimize(vae_loss)\n```"]