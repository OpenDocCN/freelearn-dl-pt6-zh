["```py\nmlagents-learn config/trainer_config.yaml --run-id=visualhallway --train\n```", "```py\nmlagents-learn config/trainer_config.yaml --run-id=hallway --train\n```", "```py\npublic override void CollectObservations()\n{\n  if (useVectorObs)\n  {\n    float rayDistance = 12f;\n    float[] rayAngles = { 20f, 60f, 90f, 120f, 160f };\n    string[] detectableObjects = { \"orangeGoal\", \"redGoal\", \"orangeBlock\", \"redBlock\", \"wall\" };\n    AddVectorObs(GetStepCount() / (float)agentParameters.maxStep);\n    AddVectorObs(rayPer.Perceive(rayDistance, rayAngles, detectableObjects, 0f, 0f));\n  }\n}\n```", "```py\nfloat[] rayAngles = { 20f, 60f };\n```", "```py\nmlagents-learn config/trainer_config.yaml --run-id=vh_reduced --train\n```", "```py\ndef create_visual_observation_encoder(self, image_input, h_size, activation, num_layers, scope,reuse):\n  #comments removed        \n  with tf.variable_scope(scope):\n    conv1 = tf.layers.conv2d(image_input, 16, kernel_size=[8, 8], strides=[4, 4],activation=tf.nn.elu, reuse=reuse, name=\"conv_1\")\n conv2 = tf.layers.conv2d(conv1, 32, kernel_size=[4, 4], strides=[2, 2],activation=tf.nn.elu, reuse=reuse, name=\"conv_2\")\n    hidden = c_layers.flatten(conv2)\n\n    with tf.variable_scope(scope + '/' + 'flat_encoding'):\n      hidden_flat = self.create_vector_observation_encoder(hidden, h_size, activation, num_layers, scope, reuse)\n return hidden_flat\n```", "```py\nconv1 = tf.layers.conv2d(image_input, 16, kernel_size=[8, 8], strides=[4, 4], activation=tf.nn.elu, reuse=reuse, name=\"conv_1\")\nconv2 = tf.layers.conv2d(conv1, 32, kernel_size=[4, 4], strides=[2, 2], activation=tf.nn.elu, reuse=reuse, name=\"conv_2\")\nconv3 = tf.layers.conv2d(image_input, 64, kernel_size=[2, 2], strides=[2, 2], activation=tf.nn.elu, reuse=reuse, name=\"conv_3\")\n\nhidden = c_layers.flatten(conv3)\n```", "```py\nmlagents-learn config/trainer_config.yaml --run-id=vh_conv1 --train\n```", "```py\nconv1 = tf.layers.conv2d(image_input, 16, kernel_size=[8, 8], strides=[4, 4], activation=tf.nn.elu, reuse=reuse, name=\"conv_1\")\nconv2 = tf.layers.conv2d(conv1, 32, kernel_size=[4, 4], strides=[2, 2], activation=tf.nn.elu, reuse=reuse, name=\"conv_2\")\nconv3 = tf.layers.conv2d(image_input, 64, kernel_size=[2, 2], strides=[2, 2], activation=tf.nn.elu, reuse=reuse, name=\"conv_3\")\n\nhidden = c_layers.flatten(conv3)\n```", "```py\nconv1 = tf.layers.conv2d(image_input, 16, kernel_size=[8, 8], strides=[4, 4], activation=tf.nn.elu, reuse=reuse, name=\"conv_1\")\n#################### ADD POOLING\nconv2 = tf.layers.conv2d(conv1, 32, kernel_size=[4, 4], strides=[2, 2], activation=tf.nn.elu, reuse=reuse, name=\"conv_2\")\nconv3 = tf.layers.conv2d(image_input, 64, kernel_size=[2, 2], strides=[2, 2], activation=tf.nn.elu, reuse=reuse, name=\"conv_3\")\n\nhidden = c_layers.flatten(conv3)\n```", "```py\nmlagents-learn config/trainer_config.yaml --run-id=vh_conv_wpool1 --train\n```", "```py\nHallwayLearning:\n    use_recurrent: true\n    sequence_length: 64\n    num_layers: 2\n    hidden_units: 128\n    memory_size: 256\n    beta: 1.0e-2\n    gamma: 0.99\n    num_epoch: 3\n    buffer_size: 1024\n    batch_size: 128\n    max_steps: 5.0e5\n    summary_freq: 1000\n    time_horizon: 64\n```", "```py\nHallwayLearning:\n    use_recurrent: false\n```", "```py\nVisualHallwayLearning:\n    use_recurrent: true\n    sequence_length: 64\n    num_layers: 1\n    hidden_units: 128\n    memory_size: 256\n    beta: 1.0e-2\n    gamma: 0.99\n    num_epoch: 3\n    buffer_size: 1024\n    batch_size: 64\n    max_steps: 5.0e5\n    summary_freq: 1000\n    time_horizon: 64\n```", "```py\nVisualHallwayLearning:\n    use_recurrent: true\n    sequence_length: 128\n    num_layers: 1\n    hidden_units: 128\n    memory_size: 2048 without pooling, 1024 with pooling\n    beta: 1.0e-2\n    gamma: 0.99\n    num_epoch: 3\n    buffer_size: 1024\n    batch_size: 64\n    max_steps: 5.0e5\n    summary_freq: 1000\n    time_horizon: 64\n```", "```py\nmlagents-learn config/trainer_config.yaml --run-id=vh_recurrent --train\n```"]