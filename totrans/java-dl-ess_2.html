<html><head></head><body><div class="chapter" title="Chapter&#xA0;2.&#xA0;Algorithms for Machine Learning &#x2013; Preparing for Deep Learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch02"/>Chapter 2. Algorithms for Machine Learning – Preparing for Deep Learning</h1></div></div></div><p>In the previous chapter, you read through how deep learning has been developed by looking back through the history of AI. As you should have noticed, machine learning and deep learning are inseparable. Indeed, you learned that deep learning is the developed method of machine learning algorithms.</p><p>In this chapter, as a pre-exercise to understand deep learning well, you will see the mode details of machine learning, and in particular, you will learn the actual code for the method of machine learning, which is closely related to deep learning.</p><p>In this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The core concepts of machine learning</li><li class="listitem" style="list-style-type: disc">An overview of popular machine learning algorithms, especially focusing on neural networks</li><li class="listitem" style="list-style-type: disc">Theories and implementations of machine learning algorithms related to deep learning: perceptrons, logistic regression, and multi-layer perceptrons</li></ul></div><div class="section" title="Getting started"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec12"/>Getting started</h1></div></div></div><p>We will insert the source code of machine learning and deep learning with Java from this chapter. The version of JDK used in the code is 1.8, hence Java versions greater than 8 are required. Also, IntelliJ IDEA 14.1 is used for the IDE. We will use the external library from <a class="link" href="ch05.html" title="Chapter 5. Exploring Java Deep Learning Libraries – DL4J, ND4J, and More">Chapter 5</a>, <span class="emphasis"><em>Exploring Java Deep Learning Libraries – DL4J, ND4J, and More</em></span>, so we are starting with a new Maven project.</p><p>The root package name of the code used in this book is <code class="literal">DLWJ</code>, the initials of <span class="emphasis"><em>Deep Learning with Java</em></span>, and we will add a new package or a class under <code class="literal">DLWJ</code> as required. Please refer to the screenshot below, which shows the screen immediately after the new project is made:</p><div class="mediaobject"><img src="graphics/B04779_02_45.jpg" alt="Getting started"/></div><p>There will be some names of variables and methods in the code that don't follow the Java coding standard. This is to improve your understanding together with some characters in the formulas to increase readability. Please bear this in mind in advance.</p></div></div>
<div class="section" title="The need for training in machine learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec13"/>The need for training in machine learning</h1></div></div></div><p>You<a id="id64" class="indexterm"/> have already seen that machine learning is a method of pattern recognition. Machine learning reaches an answer by recognizing and sorting out patterns from the given learning data. It may seem easy when you just look at the sentence, but the fact is that it takes quite a long time for machine learning to sort out unknown data, in other words, to build the appropriate model. Why is that? Is it that difficult to just sort out? Does it even bother to have a "learning" phase in between?</p><p>The answer is, of course, yes. It is extremely difficult to sort out data appropriately. The more complicated a problem becomes, the more it becomes impossible to perfectly classify data. This is because there are almost infinite patterns of categorization when you simply say "pattern classifier." Let's look at a very simple example in the following graph:</p><div class="mediaobject"><img src="graphics/B04779_02_46.jpg" alt="The need for training in machine learning"/></div><p>There <a id="id65" class="indexterm"/>are two types of data, circles and triangles, and the unknown data, the square. You don't know which group the square belongs to in the two-dimensional coordinate space, so the task is to find out which group the square belongs to.</p><p>You might instantly know that there seems to be a boundary that separates two data types. And if you decide where to set this boundary, it looks like you should be able to find out to which group the square belongs. Well then, let's decide the boundary. In reality, however, it is not so easy to clearly define this boundary. If you want to set a boundary, there are various lines to consider, as you can see in the following figure:</p><div class="mediaobject"><img src="graphics/B04779_02_47.jpg" alt="The need for training in machine learning"/></div><p>Additionally, depending on the placement of the boundary, you can see that the square might be allocated to a different group or pattern. Furthermore, it is also possible to consider that the boundary might be a nonlinear boundary.</p><p>In<a id="id66" class="indexterm"/> machine learning, what a machine does in training is choose the most likely boundary from these possible patterns. It will automatically learn how to sort out patterns when processing massive amounts of training data one after another. In other words, it adjusts the parameters of a mathematical model and eventually decides the boundary. The boundary decided by machine learning is called <a id="id67" class="indexterm"/>the <span class="strong"><strong>decision boundary</strong></span> and is not necessarily a linear or nonlinear boundary. A decision boundary can also be a hyperplane if it classifies the data best. The more complicated the distribution of the data is, the more likely it is that the decision boundary would be nonlinear boundary or a hyperplane. A typical case is the multi-dimensional classification problem. We have already faced such difficulty by just setting a boundary in this simple problem, so it's not hard to imagine that it would be very time-consuming to solve a more complicated problem.</p></div>
<div class="section" title="Supervised and unsupervised learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec14"/>Supervised and unsupervised learning</h1></div></div></div><p>In the<a id="id68" class="indexterm"/> previous section, we saw that there could be millions of <a id="id69" class="indexterm"/>boundaries even for a simple classification problem, but it is difficult to say which one of them is the most appropriate. This is because, even if we could properly sort out patterns in the known data, it doesn't mean that unknown data can also be classified in the same pattern. However, you can increase the percentage of correct pattern categorization. Each method of machine learning sets a standard to perform a better pattern classifier and decides the most possible boundary—the decision boundary—to increase the percentage. These standards are, of course, greatly varied in each method. In this section, we'll see what all the approaches we can take are.</p><p>First, machine learning can be broadly classified into <span class="strong"><strong>supervised learning</strong></span> and <span class="strong"><strong>unsupervised learning</strong></span>. The difference between these two categories is the dataset for machine learning is labeled data or unlabeled data. With supervised learning, a machine uses labeled data, the combination of input data and output data, and mentions which pattern each type of data is to be classified as. When a machine is given unknown data, it will derive what pattern can be applied and classify the data based on labeled data, that is, the past correct answers. As an example, in the field of image recognition, when you input some images into a machine, if you prepare and provide a certain number of images of a cat, labeled <code class="literal">cat</code>, and the same number of images of a human, labeled <code class="literal">human</code>, for a machine to learn, it can judge by itself which group out of cat or human (or none of them) that an image belongs to. Of course, just deciding whether the image is a cat or a human doesn't really provide a practical use, but if you apply the same approach to other fields, you can create a system that can automatically tag who is who in a photo uploaded on social media. As you can now see, in supervised training, the learning proceeds when a machine is provided with the correct data prepared by humans in advance.</p><p>On the other hand, with unsupervised learning, a machine uses unlabeled data. In this case, only input data is given. Then, what the machine learns is patterns and rules that the dataset includes and contains. The purpose of unsupervised learning is to grasp the structure <a id="id70" class="indexterm"/>of the data. It can include a process called <span class="strong"><strong>clustering</strong></span>, which classifies a data constellation in each group that has a common character, or the process of extracting the correlation rule. For example, imagine there is data relating to a user's age, sex, and purchase trend for an online shopping website. Then, you might find out that the tastes of men in their 20s and women in their 40s are close, and you want to make use of this trend to improve your product marketing. We have a famous story here—it was discovered from unsupervised training that a large number of people buy beer and diapers at the same time.</p><p>You now know there are big differences between supervised learning and unsupervised learning, but that's not all. There are also different learning methods and algorithms for each learning method, respectively. Let's look at some representative examples in the following section.</p><div class="section" title="Support Vector Machine (SVM)"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec10"/>Support Vector Machine (SVM)</h2></div></div></div><p>You could <a id="id71" class="indexterm"/>say that SVM is the most <a id="id72" class="indexterm"/>popular supervised training method in machine learning. The method is still used for broad fields in the data mining industry. With SVM, data from each category located the closest to other categories is marked as the standard, and the decision boundary is determined using the standard so that the sum of the Euclidean distance from each marked data and the boundary is maximized. This marked data is<a id="id73" class="indexterm"/> called <span class="strong"><strong>support vectors</strong></span>. Simply put, SVM sets the decision boundary in the middle point where the distance from every pattern is maximized. Therefore, what <a id="id74" class="indexterm"/>SVM does in its algorithm is known as <span class="strong"><strong>maximizing the margin</strong></span>. The following is the figure of the concept of SVM:</p><div class="mediaobject"><img src="graphics/B04779_02_80.jpg" alt="Support Vector Machine (SVM)"/></div><p>If you<a id="id75" class="indexterm"/> only hear this statement, you<a id="id76" class="indexterm"/> might think "is that it?" but what makes SVM the most valuable is a math technique: the kernel trick, or the kernel method. This technique takes the data that seems impossible to be classified linearly in the original dimension and intentionally maps it to a higher dimensional space so that it can be classified linearly without any difficulties. Take a look at the following figure so you can understand how the kernel trick works:</p><div class="mediaobject"><img src="graphics/B04779_02_56.jpg" alt="Support Vector Machine (SVM)"/></div><p>We <a id="id77" class="indexterm"/>have two types of data, represented <a id="id78" class="indexterm"/>by circles and triangles, and it is obvious that it would be impossible to separate both data types linearly in a two-dimensional space. However, as you can see in the preceding figure, by applying the kernel function to the data (strictly speaking, the feature vectors of training data), whole data is transformed into a higher dimensional space, that is, a three-dimensional space, and it is possible to separate them with a two-dimensional plane.</p><p>While SVM is useful and elegant, it has one demerit. Since it maps the data into a higher dimension, the number of calculations often increases, so it tends to take more time in processing as the calculation gets more complicated.</p></div><div class="section" title="Hidden Markov Model (HMM)"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec11"/>Hidden Markov Model (HMM)</h2></div></div></div><p>HMM is <a id="id79" class="indexterm"/>an unsupervised training method that assumes data follows the <span class="strong"><strong>Markov process</strong></span>. The Markov process is a stochastic<a id="id80" class="indexterm"/> process in which a future condition is decided solely <a id="id81" class="indexterm"/>on the present value and is not related to the past condition. HMM is used to predict which state the observation comes from when only one observation is visible.</p><p>The previous explanation alone may not help you fully understand how HMM works, so let's look at an example. HMM is often used to analyze a base sequence. You may know that a base sequence consists of four nucleotides, for example, A, T, G, C, and the sequence is actually a string of these nucleotides. You won't get anything just by looking through the string, but you do have to analyze which part is related to which gene. Let's say that if any base sequence is lined up randomly, then each of the four characters should be output by one-quarter when you cut out any part of the base sequence.</p><p>However, if there is a regularity, for example, where C tends to come next to G or the combination of ATT shows up frequently, then the probability of each character being output would vary accordingly. This regularity is the probability model and if the probability of being output relies only on an immediately preceding base, you can find out genetic information (= state) from a base sequence (= observation) using HMM.</p><p>Other <a id="id82" class="indexterm"/>than these bioinformatic fields, HMM is<a id="id83" class="indexterm"/> often used in fields where time sequence patterns, such as syntax analysis of <span class="strong"><strong>natural language processing</strong></span> (<span class="strong"><strong>NLP</strong></span>) or<a id="id84" class="indexterm"/> sound signal processing, are needed. We don't explore HMM deeper here because its algorithm is less related to deep learning, but you can reference a very famous book, <span class="emphasis"><em>Foundations of statistical natural language processing</em></span>, from MIT Press if you are interested.</p></div><div class="section" title="Neural networks"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec12"/>Neural networks</h2></div></div></div><p>Neural<a id="id85" class="indexterm"/> networks are a little different to the machine learning algorithms. While other methods of machine learning take an approach based on probability or statistics, neural networks are algorithms that imitate the structure of a human brain. A human brain is made of a neuron network. Take a look at the following figure to get an idea of this:</p><div class="mediaobject"><img src="graphics/B04779_02_50.jpg" alt="Neural networks"/></div><p>One neuron is linked to the network through another neuron and takes electrical stimulation from the synapse. When that electricity goes above the threshold, it gets ignited and transmits the electrical stimulation to the next neuron linked to the network. Neural networks distinguish things based on how electrical stimulations are transmitted.</p><p>Neural networks have originally been the type of supervised learning that represents this electrical<a id="id86" class="indexterm"/> stimulation with numbers. Recently, especially with deep learning, various types of neural networks algorithms have been introduced, and some of them are unsupervised learning. The algorithm increases the predictability by adjusting the weight of the networks through the process of learning. Deep learning is an algorithm based on neural networks. More details on neural networks will be explained later, with implementations.</p></div><div class="section" title="Logistic regression"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec13"/>Logistic regression</h2></div></div></div><p>Logistic <a id="id87" class="indexterm"/>regression is one of the statistical regression models of variables with the Bernoulli distribution. While SVM and neural networks are classification models, logistic regression is a regression model, yet it certainly is one of the supervised learning methods. Although logistic regression has a different base of thinking, as a matter of fact, it can be thought of as one of the neural networks when you look at its formula. Details on logistic regression will also be explained with implementations later.</p><p>As you can see, each machine learning method has unique features. It's important to choose the right algorithm based on what you would like to know or what you would would like to use the data for. You can say the same of deep learning. Deep learning has different methods, so not only should you consider which the best method among them is, but you should also consider that there are some cases where you should not use deep learning. It's important to choose the best method for each case.</p></div><div class="section" title="Reinforcement learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec14"/>Reinforcement learning</h2></div></div></div><p>Just for your<a id="id88" class="indexterm"/> reference, there is another method of machine learning called <span class="strong"><strong>reinforcement learning</strong></span>. While some categorize reinforcement learning as unsupervised learning, others declare that all three learning algorithms, supervised learning, unsupervised learning, and reinforcement learning, should be divided into different types of algorithms, respectively. The following image shows the basic framework of reinforcement learning:</p><div class="mediaobject"><img src="graphics/B04779_02_49.jpg" alt="Reinforcement learning"/></div><p>An agent<a id="id89" class="indexterm"/> takes an action based on the state of an environment and an environment will change based on the action. A mechanism with some sort of reward is provided to an agent following the change of an environment and the agent learns a better choice of act (decision-making).</p></div></div>
<div class="section" title="Machine learning application flow"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec15"/>Machine learning application flow</h1></div></div></div><p>We have<a id="id90" class="indexterm"/> looked at the methods that machine learning has and how these methods recognize patterns. In this section, we'll see which flow is taken, or has to be taken, by data mining using machine learning. A decision boundary is set based on the model parameters in each of the machine learning methods, but we can't say that adjusting the model parameters is the only thing we have to care about. There is another troublesome problem, and it is actually the weakest point of machine learning: feature engineering. Deciding which features are to be created from raw data, that is, the analysis subject, is a necessary step in making an appropriate classifier. And doing this, which is the same as adjusting the model parameters, also requires a massive amount of trial and error. In some cases, feature engineering requires far more effort than deciding a parameter.</p><p>Thus, when we simply say "machine learning," there are certain tasks that need to be completed in advance as preprocessing to build an appropriate classifier to deal with actual problems. Generally speaking, these tasks can be summarized as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Deciding which machine learning method is suitable for a problem</li><li class="listitem" style="list-style-type: disc">Deciding what features should be used</li><li class="listitem" style="list-style-type: disc">Deciding which setting is used for model parameters</li></ul></div><p>Only when these tasks are completed does machine learning become valuable as an application.</p><p>So, how<a id="id91" class="indexterm"/> do you decide the suitable features and parameters? How do you get a machine to learn? Let's first take a look at the following diagram as it might be easier for you to grasp the whole picture of machine learning. This is the summary of a learning flow:</p><div class="mediaobject"><img src="graphics/B04779_02_48.jpg" alt="Machine learning application flow"/></div><p>As you can see from the preceding image, the learning phase of machine learning can be roughly divided into these two steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Training</li><li class="listitem" style="list-style-type: disc">Testing</li></ul></div><p>Literally, model<a id="id92" class="indexterm"/> parameters are renewed and adjusted in the training phase and the machine examines the merit of a model in the test phase. We have no doubt that the research or experiment will hardly ever succeed with just one training and one test set. We need to repeat the process of training → test, training → test … until we get the right model.</p><p>Let's consider the preceding flowchart in order. First, you need to divide the raw data into two: a training dataset and a test dataset. What you need to be very careful of here is that the training data and the test data are separated. Let's take an example so you can easily imagine what this means: you are trying to predict the daily price of S&amp;P 500 using machine learning with historical price data. (In fact, predicting the prices of financial instruments using machine learning is one of the most active research fields.)</p><p>Given that you have historical stock price data from 2001 to 2015 as raw data, what would happen if you performed the training with all the data from 2001 to 2015 and similarly performed the test for the same period? The situation would occur that even if you used simple machine learning or feature engineering, the probability of getting the right prediction would be 70%, or even higher at 80% or 90%. Then, you might think: <span class="emphasis"><em>What a great discovery! The market is actually that simple! Now I can be a billionaire!</em></span>
</p><p>But this would end as short-lived elation. The reality doesn't go that well. If you actually start investment management with that model, you wouldn't get the performance you were expecting and would be confused. This is obvious if you think about it and pay a little attention. If a training dataset and a test dataset are the same, you do the test with the data for which you already know the answer. Therefore, it is a natural consequence to get high precision, as you have predicted a correct answer using a correct answer. But this doesn't make any sense for a test. If you would like to evaluate the model properly, be sure to use data with different time periods, for example, you should use the data from 2001 to 2010 for the training dataset and 2011 to 2015 for the test. In this case, you perform the test using the data you don't know the answer for, so you can get a proper prediction precision rate. Now you can avoid going on your way to bankruptcy, believing in investments that will never go well.</p><p>So, it is obvious that you should separate a training dataset and a test dataset but you may not think this is a big problem. However, in the actual scenes of data mining, the case often occurs that we conduct an experiment with the same data without such awareness, so please be extra careful. We've talked about this in the case of machine learning, but it also applies to deep learning.</p><p>If you divide <a id="id93" class="indexterm"/>a whole dataset into two datasets, the first dataset to be used is the training dataset. To get a better precision rate, we first need to think about creating features in the training dataset. This feature engineering partly depends on human experience or intuition. It might take a long time and a lot of effort before you can choose the features to get the best results. Also, each machine learning method has different types of data formats of features to be accepted because the theory of models and formulas are unique to each method. As an example, we have a model that can only take an integer, a model that can only take a non-negative number/value, and a model that can only take real numbers from 0 to 1. Let's look back at the previous example of stock prices. Since the value of the price varies a lot within a broader range, it may be difficult to make a prediction with a model that can only take an integer.</p><p>Additionally, we have to be careful to ensure that there is compatibility between the data and the model. We don't say we can't use a model that can take all the real numbers from 0 if you would like to use a stock price as is for features. For example, if you divide all the stock price data by the maximum value during a certain period, the data range can fit into 0-1, hence you can use a model that can only take real numbers from 0 to 1. As such, there is a possibility that you can apply a model if you slightly change the data format. You need to keep this point in mind when you think about feature engineering. Once you create features and decide which method of machine learning to apply, then you just need to examine it.</p><p>In machine learning, features are, of course, important variables when deciding on the precision of a model; however, a model itself, in other words a formula within the algorithm, also has parameters. Adjusting the speed of learning or adjusting how many errors to be allowed are good examples of this. The faster the learning speed, the less time it takes to finish the calculation, hence it's better to be fast. However, making the learning speed faster means that it only provides solutions in brief. So, we should be careful not to lose our expected precision rates. Adjusting the permissible range of errors is effective for the case where a noise is blended in the data. The standard by which a machine judges "is this data weird?" is decided by humans.</p><p>Each method, of course, has a set of peculiar parameters. As for neural networks, how many neurons there should be in one of the parameters is a good example. Also, when we think of the kernel trick in SVM, how we set the kernel function is also one of the parameters to be determined. As you can see, there are so many parameters that machine learning needs to define, and which parameter is best cannot be found out in advance. In terms of how we define model parameters in advance, there is a research field that focuses on the study of parameters.</p><p>Therefore, we need to test many combinations of parameters to examine which combination can return the best precision. Since it takes a lot of time to test each combination one by one, the standard flow is to test multiple models with different parameter combinations in concurrent processing and then compare them. It is usually the case that a range of parameters that should be set to some extent is decided, so it's not that the problem can't be solved within a realistic time frame.</p><p>When the <a id="id94" class="indexterm"/>model that can get good precision is ready in the training dataset, next comes the test step. The rough flow of the test is to apply the same feature engineering applied to the training dataset and the same model parameters respectively and then verify the precision. There isn't a particularly difficult step in the test. The calculation doesn't take time either. It's because finding a pattern from data, in other words optimizing a parameter in a formula, creates a calculation cost. However, once a parameter adjustment is done, then the calculation is made right away as it only applies the formula to new datasets. The reason for performing a test is, simply put, to examine whether a model is too optimized by the training dataset. What does this mean? Well, in machine learning, there are two patterns where a training set goes well but a test set doesn't.</p><p>The first case is incorrect optimization by classifying noisy data blended into a training dataset. This can be related to the adjustment of a permissible range of errors mentioned earlier in this chapter. Data in the world is not usually clean. It can be said that there is almost no data that can be properly classified into clean patterns. The prediction of stock prices is a good example again. Stock prices usually repeat moderate fluctuations from previous stock prices, but sometimes they suddenly surge or drop sharply. And, there is, or should be, no regularity in this irregular movement. Another case is if you would like to predict the yield of a crop for a country; the data of the year affected by abnormal weather should be largely different from the normal years' data. These examples are extreme and easy to understand, but most for a data in the real world also contains noises, making it difficult to classify data into proper patterns. If you just do training without adjusting the parameters of machine learning, the model forces it to classify the noise data into a pattern. In this case, data from the training dataset might be classified correctly, but since noise data in the training dataset is also classified and the noise doesn't exist in the test dataset, the predictability in a test should be low.</p><p>The second case is incorrect optimizing by classifying data that is characteristic only in a training dataset. For example, let's think about making an app of English voice inputs. To build your app, you should prepare the data of pronunciation for various words as a training dataset. Now, let's assume you prepared enough voice data of British English native speakers and were able to create a high precision model that could correctly classify the pronunciation in the training dataset. The next step is a test. Since it's a test, let's use the voice data of American English native speakers for the means of providing different data. What would be the result then? You probably wouldn't get good precision. Furthermore, if you try the app to recognize the pronunciation of non-native speakers of English, the precision would be much lower. As you know, English has different pronunciations for different areas. If you don't take this into consideration and optimize the model with the training data set of British English, even though you may get a good result in the training set, you won't get a good result in the test set and it won't be useful for the actual application.</p><p>These two<a id="id95" class="indexterm"/> problems occur because the machine learning model learns from a training dataset and fits into the dataset too much. This problem is<a id="id96" class="indexterm"/> literally called the <span class="strong"><strong>overfitting problem</strong></span>, and you should be very careful to avoid it. The difficulty of machine learning is that you have to think about how to avoid this overfitting problem besides the feature engineering. These two problems, overfitting  and feature engineering, are partially related because poor feature engineering would fail into overfitting.</p><p>To avoid the problem of overfitting, there's not much to do except increase the amount of data or the number of tests. Generally, the amount of data is limited, so the methods of increasing the number of tests are often performed. The typical example is <span class="strong"><strong>K-fold cross-validation</strong></span>. In <a id="id97" class="indexterm"/>K-fold cross-validation, all the data is divided into K sets at the beginning. Then, one of the datasets is picked as a test dataset and the rest, K-1, are put as training datasets. Cross-validation performs the verification on each dataset divided into K for K times, and the precision is measured by calculating the average of these K results. The most worrying thing is that both a training dataset and a test dataset may happen to have good precision by chance; however, the probability of this accident can be decreased in K-fold cross-validation as it performs a test several times. You can never worry too much about overfitting, so it's necessary that you verify results carefully.</p><p>Well, you have now read through the flow of training and test sets and learned key points to be kept in mind. These two mainly focus on data analysis. So, for example, if your purpose is to pull out the meaningful information from the data you have and make good use of it, then you can go through this flow. On the other hand, if you need an application that can cope with a further new model, you need an additional process to make predictions with a model parameter obtained in a training and a test set. As an example, if you would like to find out some information from a dataset of stock prices and analyze and write a market report, the next step would be to perform  training and  test sets. Or, if you would like to predict future stock prices based on the data and utilize it as an investment system, then your purpose would be to build an application using a model obtained in a training and a test set and to predict a price based on the data you can get anew every day, or from every period you set. In the second case, if you would like to renew the model with the data that is newly added, you need to be careful to complete the calculation of the model building by the time the next model arrives.</p></div>
<div class="section" title="Theories and algorithms of neural networks"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec16"/>Theories and algorithms of neural networks</h1></div></div></div><p>In the <a id="id98" class="indexterm"/>previous section, you saw the general flow of when we perform data analysis with machine learning. In this section, theories and algorithms of neural networks, one of the methods of machine learning, are introduced as a preparation toward deep learning.</p><p>Although we simply say "neural networks", their history is long. The first published algorithm <a id="id99" class="indexterm"/>of neural networks was called <span class="strong"><strong>perceptron</strong></span>, and the paper released in 1957 by Frank Rosenblatt was named <span class="emphasis"><em>The Perceptron: A Perceiving and Recognizing Automaton (Project Para)</em></span>. From then on, many methods were researched, developed, and released, and now neural networks are one of the elements of deep learning. Although we simply say "neural networks," there are various types and we'll look at the representative methods in order now.</p><div class="section" title="Perceptrons (single-layer neural networks)"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec15"/>Perceptrons (single-layer neural networks)</h2></div></div></div><p>The perceptron algorithm is the model that has the simplest structure in the algorithms of neural <a id="id100" class="indexterm"/>networks and it can perform linear classification<a id="id101" class="indexterm"/> for two classes. We can say that it's the prototype of neural networks. It is the algorithm that models human neurons in the simplest way.</p><p>The following figure is a schematic drawing of the general model:</p><div class="mediaobject"><img src="graphics/B04779_02_51.jpg" alt="Perceptrons (single-layer neural networks)"/></div><p>Here, <span class="inlinemediaobject"><img src="graphics/B04779_02_61.jpg" alt="Perceptrons (single-layer neural networks)"/></span> shows the input signal, <span class="inlinemediaobject"><img src="graphics/B04779_02_62.jpg" alt="Perceptrons (single-layer neural networks)"/></span> shows the weight corresponding to each input signal, and <span class="inlinemediaobject"><img src="graphics/B04779_02_63.jpg" alt="Perceptrons (single-layer neural networks)"/></span> shows the output signal. <span class="inlinemediaobject"><img src="graphics/B04779_02_64.jpg" alt="Perceptrons (single-layer neural networks)"/></span> is the activation function. <span class="inlinemediaobject"><img src="graphics/B04779_02_65.jpg" alt="Perceptrons (single-layer neural networks)"/></span> shows, literally, the meaning of calculating the sum of data coming from the input. Please bear in mind that <span class="inlinemediaobject"><img src="graphics/B04779_02_61.jpg" alt="Perceptrons (single-layer neural networks)"/></span> applies <a id="id102" class="indexterm"/>a processing of nonlinear conversion<a id="id103" class="indexterm"/> with feature engineering in advance, that is, <span class="inlinemediaobject"><img src="graphics/B04779_02_61.jpg" alt="Perceptrons (single-layer neural networks)"/></span>is an engineered feature.</p><p>Then, the output of perceptron can be represented as follows: </p><div class="mediaobject"><img src="graphics/B04779_02_01.jpg" alt="Perceptrons (single-layer neural networks)"/></div><div class="mediaobject"><img src="graphics/B04779_02_02.jpg" alt="Perceptrons (single-layer neural networks)"/></div><p> <span class="inlinemediaobject"><img src="graphics/B04779_02_66.jpg" alt="Perceptrons (single-layer neural networks)"/></span> is called the step function. As shown in the equation, Perceptron returns the output by multiplying each factor of the feature vector by weight, calculating the sum of them, and then activating the sum with the step function. The output is the result estimated by Perceptron. During the training, you will compare this result with the correct data and feed back the error.</p><p>Let <span class="inlinemediaobject"><img src="graphics/B04779_02_67.jpg" alt="Perceptrons (single-layer neural networks)"/></span> be the value of the labeled data. Then, the formula can be represented as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_03.jpg" alt="Perceptrons (single-layer neural networks)"/></div><p>If<a id="id104" class="indexterm"/> some labeled data belongs to class 1, <span class="inlinemediaobject"><img src="graphics/B04779_02_68.jpg" alt="Perceptrons (single-layer neural networks)"/></span>, we have <span class="inlinemediaobject"><img src="graphics/B04779_02_69.jpg" alt="Perceptrons (single-layer neural networks)"/></span>. If it <a id="id105" class="indexterm"/>belongs to class 2, <span class="inlinemediaobject"><img src="graphics/B04779_02_70.jpg" alt="Perceptrons (single-layer neural networks)"/></span>, we have <span class="inlinemediaobject"><img src="graphics/B04779_02_71.jpg" alt="Perceptrons (single-layer neural networks)"/></span>. Also, if the input data is classified correctly, we get:</p><div class="mediaobject"><img src="graphics/B04779_02_04.jpg" alt="Perceptrons (single-layer neural networks)"/></div><p>So, putting these equations together, we have the following equation of properly classified data:</p><div class="mediaobject"><img src="graphics/B04779_02_05.jpg" alt="Perceptrons (single-layer neural networks)"/></div><p>Therefore, you can increase the predictability of Perceptron by minimizing the following function:</p><div class="mediaobject"><img src="graphics/B04779_02_06.jpg" alt="Perceptrons (single-layer neural networks)"/></div><p>Here, <span class="inlinemediaobject"><img src="graphics/B04779_02_72.jpg" alt="Perceptrons (single-layer neural networks)"/></span> is called the error function. <span class="inlinemediaobject"><img src="graphics/B04779_02_73.jpg" alt="Perceptrons (single-layer neural networks)"/></span> shows the set of misclassification. To minimize the error<a id="id106" class="indexterm"/> function, gradient descent, or steepest <a id="id107" class="indexterm"/>descent, an optimization algorithm is used to find a local minimum of a function using gradient descent. The equation can be described as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_07.jpg" alt="Perceptrons (single-layer neural networks)"/></div><p>Here, <span class="inlinemediaobject"><img src="graphics/B04779_02_74.jpg" alt="Perceptrons (single-layer neural networks)"/></span> is the learning rate, a common parameter of the optimization algorithm that adjusts the learning speed, and <span class="inlinemediaobject"><img src="graphics/B04779_02_75.jpg" alt="Perceptrons (single-layer neural networks)"/></span> shows the number of steps of the algorithm. In general, the smaller the value of the learning rate, the more probable it is that the algorithm falls into a local minimum because the model can't override the old value much. If the value is too big, however, the model parameters can't converge because the values fluctuate too widely. Therefore, practically, the learning rate is set to be big at the beginning and then dwindle with each iteration. On the other hand, with perceptrons, it is proved that the algorithm converges irrespective of the value of the learning rate when the data set is linearly separable, and thus the value is set to be 1.</p><p>Now, let's look at an implementation. The package structure is as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_52.jpg" alt="Perceptrons (single-layer neural networks)"/></div><p>Let's have <a id="id108" class="indexterm"/>a look at the content of <code class="literal">Perceptrons.java</code> as<a id="id109" class="indexterm"/> shown in the previous image. We will look into the main methods one by one.</p><p>First, we define the parameters and constants that are needed for learning. As explained earlier, the learning rate (defined as <code class="literal">learningRate</code> in the code) can be 1:</p><div class="informalexample"><pre class="programlisting">final int train_N = 1000;  // number of training data
final int test_N = 200;   // number of test data
final int nIn = 2;        // dimensions of input data

double[][] train_X = new double[train_N][nIn];  // input data for training
int[] train_T = new int[train_N];               // output data (label) for training

double[][] test_X = new double[test_N][nIn];  // input data for test
int[] test_T = new int[test_N];               // label of inputs
int[] predicted_T = new int[test_N];          // output data predicted by the model

final int epochs = 2000;   // maximum training epochs
final double learningRate = 1.;  // learning rate can be 1 in perceptrons</pre></div><p>Needless to say, machine learning and deep learning need a dataset to be learned and classified. Here, since we would like to focus on implementations deeply related to the theory of perceptrons, a sample dataset is generated within the source code and is used for the training and test sets, the class called <code class="literal">GaussianDistribution</code> is defined, and it returns a value following the normal distribution or Gaussian distribution. As for the source code itself, we don't mention it here as you can see it in <code class="literal">GaussianDistribution.java</code>. We set the dimensions of the learning data in <code class="literal">nIn = 2</code> and define two types of instances as follows:</p><div class="informalexample"><pre class="programlisting">GaussianDistribution g1 = new GaussianDistribution(-2.0, 1.0, rng);
GaussianDistribution g2 = new GaussianDistribution(2.0, 1.0, rng);</pre></div><p>You can get the values that follow the normal distributions with a mean of <code class="literal">-2.0</code> and a variance of <code class="literal">1.0</code> by <code class="literal">g1.random()</code> and a mean of <code class="literal">2.0</code> and a variance of <code class="literal">1.0</code> by <code class="literal">g2.random()</code>.</p><p>With these<a id="id110" class="indexterm"/> values, 500 data attributes are generated in<a id="id111" class="indexterm"/> class 1 obtained by <code class="literal">[ g1.random(), g2.random() ]</code> and another 500 generated in class 2 obtained by <code class="literal">[ g2.random(), g1.random() ]</code>. Also, please bear in mind that each value of the class 1 label is <code class="literal">1</code> and of the class 2 label is <code class="literal">-1</code>. Almost all the data turns out to be a value around <code class="literal">[-2.0, 2.0]</code> for class 1 and <code class="literal">[2.0, -2.0]</code> for class 2; hence, they can be linearly separated, but some data can be blended near the other class as noise.</p><p>Now we have prepared the data, we can move on to building the model. The number of units in the input layer, <code class="literal">nIn</code>, is the argument used here to decide the model outline:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Perceptrons classifier = new Perceptrons(nIn);</strong></span>
</pre></div><p>Let's look at the actual <code class="literal">Perceptrons</code> constructor. The parameter of the perceptrons model is only the weight, <code class="literal">w</code>, of the network—very simple —as follows:</p><div class="informalexample"><pre class="programlisting">public Perceptrons(int nIn) {

   this.nIn = nIn;
   w = new double[nIn];

}</pre></div><p>The next step is finally the training. The iteration of learning continues until it reaches enough numbers of the learning set in advance or classifies all the training data correctly:</p><div class="informalexample"><pre class="programlisting">while (true) {
   int classified_ = 0;

   for (int i=0; i &lt; train_N; i++) {
       classified_ += classifier.train(train_X[i], train_T[i], learningRate);
   }

   if (classified_ == train_N) break;  // when all data classified correctly

   epoch++;
   if (epoch &gt; epochs) break;
}</pre></div><p>In the <code class="literal">train</code> method, you <a id="id112" class="indexterm"/>can write down the gradient<a id="id113" class="indexterm"/> descent algorithm as we just explained. Here, the <code class="literal">w</code> parameter of the network is updated:</p><div class="informalexample"><pre class="programlisting">public int train(double[] x, int t, double learningRate) {

   int classified = 0;
   double c = 0.;

   // check whether the data is classified correctly
   for (int i = 0; i &lt; nIn; i++) {
       c += w[i] * x[i] * t;
   }

   // apply gradient descent method if the data is wrongly classified
   if (c &gt; 0) {
       classified = 1;
   } else {
       for (int i = 0; i &lt; nIn; i++) {
           w[i] += learningRate * x[i] * t;
       }
   }

   return classified;
}</pre></div><p>Once you have done enough numbers of learning and finish, the next step is to perform the test. First, let's check which class the test data is classified by in the well-trained model:</p><div class="informalexample"><pre class="programlisting">for (int i = 0; i &lt; test_N; i++) {
   predicted_T[i] = classifier.predict(test_X[i]);
}</pre></div><p>In the <code class="literal">predict</code> method, simply activate the input through the network. The step function used here is defined in <code class="literal">ActivationFunction.java</code>:</p><div class="informalexample"><pre class="programlisting">public int predict (double[] x) {

   double preActivation = 0.;

   for (int i = 0; i &lt; nIn; i++) {
       preActivation += w[i] * x[i];
   }

   return step(preActivation);
}</pre></div><p>Subsequently, we evaluate the model using the test data. You might need more explanation to perform this part.</p><p>Generally, the<a id="id114" class="indexterm"/> performance of the method of machine learning <a id="id115" class="indexterm"/>is measured by the indicator of accuracy, precision, and recall based on the confusion matrix. The confusion matrix summarizes the results of a comparison of the predicted class and the correct class in the matrix and is shown as the following table:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom"> </th><th style="text-align: left" valign="bottom">
<p>p_predicted</p>
</th><th style="text-align: left" valign="bottom">
<p>n_predicted</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>p_actual</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>True positive (TP)</p>
</td><td style="text-align: left" valign="top">
<p>False negative (FN)</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>n_actual</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>False positive (FP)</p>
</td><td style="text-align: left" valign="top">
<p>True negative (TN)</p>
</td></tr></tbody></table></div><p>The three indicators are shown below:</p><div class="mediaobject"><img src="graphics/B04779_02_08.jpg" alt="Perceptrons (single-layer neural networks)"/></div><div class="mediaobject"><img src="graphics/B04779_02_09.jpg" alt="Perceptrons (single-layer neural networks)"/></div><div class="mediaobject"><img src="graphics/B04779_02_10.jpg" alt="Perceptrons (single-layer neural networks)"/></div><p>Accuracy shows the proportion of the data that is correctly classified for all the data, while precision shows the proportion of the actual correct data to the data predicted as positive, and recall is the proportion of the data predicted as positive to the actual positive data. Here is<a id="id116" class="indexterm"/> the code for this:</p><div class="informalexample"><pre class="programlisting">int[][] confusionMatrix = new int[2][2];
double accuracy = 0.;
double precision = 0.;
double recall = 0.;

for (int i = 0; i &lt; test_N; i++) {

   if (predicted_T[i] &gt; 0) {
       if (test_T[i] &gt; 0) {
           accuracy += 1;
           precision += 1;
           recall += 1;
           confusionMatrix[0][0] += 1;
       } else {
           confusionMatrix[1][0] += 1;
       }
   } else {
       if (test_T[i] &gt; 0) {
           confusionMatrix[0][1] += 1;
       } else {
           accuracy += 1;
           confusionMatrix[1][1] += 1;
       }
   }

}

accuracy /= test_N;
precision /= confusionMatrix[0][0] + confusionMatrix[1][0];
recall /= confusionMatrix[0][0] + confusionMatrix[0][1];

System.out.println("----------------------------");
System.out.println("Perceptrons model evaluation");
System.out.println("----------------------------");
System.out.printf("Accuracy:  %.1f %%\n", accuracy * 100);
System.out.printf("Precision: %.1f %%\n", precision * 100);
System.out.printf("Recall:    %.1f %%\n", recall * 100);</pre></div><p>When <a id="id117" class="indexterm"/>you compile <code class="literal">Perceptron.java</code> and run it, you can get 99.0% for accuracy, 98.0% for precision, and 100% for recall. This means that actual positive data is classified correctly but that there has been some data wrongly predicted as positive when it is actually negative. In this source code, since the data set is for demonstration, K-fold cross-validation is not included. The dataset in the example above is programmatically generated and has little noise data. Therefore, accuracy, precision, and recall are all high because the data can be well classified. However, as mentioned above, you<a id="id118" class="indexterm"/> have to look carefully at results, especially <a id="id119" class="indexterm"/>when you have great results.</p></div><div class="section" title="Logistic regression"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec16"/>Logistic regression</h2></div></div></div><p>Logistic<a id="id120" class="indexterm"/> regression is, as you can assume from the <a id="id121" class="indexterm"/>name, the regression model. But when you look at the formula, you can see that logistic regression is the linear separation model that generalizes perceptrons.</p><p>Logistic regression can be regarded as one of the neural networks. With perceptrons, the step function is used for the activation function, but in logistic regression, the (logistic) sigmoid function is used. The equation of the sigmoid function can be represented as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_11.jpg" alt="Logistic regression"/></div><p>The graph of this function can be illustrated as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_58.jpg" alt="Logistic regression"/></div><p>The <code class="literal">sigmoid</code> function maps any values of a real number to a value from 0 to 1. Therefore, the output of the logistic regression can be regarded as the posterior probability <a id="id122" class="indexterm"/>for each class. The equations can be<a id="id123" class="indexterm"/> described as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_12.jpg" alt="Logistic regression"/></div><div class="mediaobject"><img src="graphics/B04779_02_13.jpg" alt="Logistic regression"/></div><p>These equations can be combined to make:</p><div class="mediaobject"><img src="graphics/B04779_02_14.jpg" alt="Logistic regression"/></div><p>Here, <span class="inlinemediaobject"><img src="graphics/B04779_02_15.jpg" alt="Logistic regression"/></span> is the correct data. You may have noticed that the range of the data is different from the one of perceptrons.</p><p>With the <a id="id124" class="indexterm"/>previous equation, the <code class="literal">likelihood</code> function, which estimates the maximum likelihood of the model parameters, can be expressed as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_16.jpg" alt="Logistic regression"/></div><p>Where:</p><div class="mediaobject"><img src="graphics/B04779_02_17.jpg" alt="Logistic regression"/></div><p>As you can see, not only the weight of the network but the bias <span class="inlinemediaobject"><img src="graphics/B04779_02_76.jpg" alt="Logistic regression"/></span> are also parameters that need to be optimized.</p><p>What we<a id="id125" class="indexterm"/> need to do now is maximize the likelihood function, but the calculation is worrying because the function has a mathematical product. To make the calculation easier, we take the logarithm (log) of the likelihood function. Additionally, we substitute the sign to turn the object to minimizing the negative log <code class="literal">likelihood</code> function. Since the log is the monotonic increase, the magnitude correlation doesn't change. The equation can be represented as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_18.jpg" alt="Logistic regression"/></div><p>You can see the error function at the same time. This type of function is called a cross-entropy error function.</p><p>Similar to perceptrons, we can optimize the model by computing the gradients of the model parameters, <span class="inlinemediaobject"><img src="graphics/B04779_02_57.jpg" alt="Logistic regression"/></span> and <span class="inlinemediaobject"><img src="graphics/B04779_02_76.jpg" alt="Logistic regression"/></span>. The gradients can be described as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_19.jpg" alt="Logistic regression"/></div><div class="mediaobject"><img src="graphics/B04779_02_20.jpg" alt="Logistic regression"/></div><p>With these <a id="id126" class="indexterm"/>equations, we can update the model parameters as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_21.jpg" alt="Logistic regression"/></div><div class="mediaobject"><img src="graphics/B04779_02_22.jpg" alt="Logistic regression"/></div><p>Theoretically, we <a id="id127" class="indexterm"/>have no problem using the equations just mentioned and implementing them. As you can see, however, you have to calculate the sum of all the data to compute the gradients for each iteration. This will hugely increase the calculation cost once the size of a dataset becomes big.</p><p>Therefore, another method is usually applied that partially picks up some data from the dataset, computes the gradients by calculating the sum only with picked data, and renews the parameters. This<a id="id128" class="indexterm"/> is called <span class="strong"><strong>stochastic gradient descent</strong></span> (<span class="strong"><strong>SGD</strong></span>) because <a id="id129" class="indexterm"/>it stochastically chooses a subset of the data. This subset of the dataset <a id="id130" class="indexterm"/>used <a id="id131" class="indexterm"/>for one renewal is called a <span class="strong"><strong>mini-batch</strong></span>.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip02"/>Tip</h3><p>SGD using a mini-batch is sometimes called <span class="strong"><strong>mini-batch stochastic gradient descent</strong></span> (<span class="strong"><strong>MSGD</strong></span>). Online<a id="id132" class="indexterm"/> training that learns to randomly choose one data from the dataset is called SGD to distinguish one from the other. In this book, however, both MSGD and SGD are called SGD, as both become the same when the size of the mini-batch is 1. Since learning by each data does increase the calculation cost, it's better to use mini-batches.</p></div></div><p>In terms of the implementation of logistic regression, since it can be covered with multi-class logistic regression introduced in the next section, we won't write the code here. You can refer to the code of multi-class logistic regression in this section.</p></div><div class="section" title="Multi-class logistic regression"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec17"/>Multi-class logistic regression</h2></div></div></div><p>Logistic<a id="id133" class="indexterm"/> regression can also be applied to<a id="id134" class="indexterm"/> multi-class classification. In two-class classification, the activation function is the sigmoid function, and you can classify the data by evaluating the output value shifting from 0 to 1. How, then, can we classify data when the number of classes is K? Fortunately, it is not difficult. We can classify multi-class data by changing the equation for the output to the K-dimensional class-membership probability vector, and we use the <code class="literal">softmax</code> function to do so, which is the multivariate version of the sigmoid function. The posterior probability of each class can be represented as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_23.jpg" alt="Multi-class logistic regression"/></div><p>With this, the same as two-class cases, you can get the likelihood function and the negative log likelihood function as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_24.jpg" alt="Multi-class logistic regression"/></div><div class="mediaobject"><img src="graphics/B04779_02_25.jpg" alt="Multi-class logistic regression"/></div><p>Here, <span class="inlinemediaobject"><img src="graphics/B04779_02_26.jpg" alt="Multi-class logistic regression"/></span> , <span class="inlinemediaobject"><img src="graphics/B04779_02_27.jpg" alt="Multi-class logistic regression"/></span>. Also, <span class="inlinemediaobject"><img src="graphics/B04779_02_28.jpg" alt="Multi-class logistic regression"/></span> is the Kth element of the correct data vector, <span class="inlinemediaobject"><img src="graphics/B04779_02_29.jpg" alt="Multi-class logistic regression"/></span>, which corresponds to the <span class="emphasis"><em>n</em></span>
<span class="emphasis"><em>th</em></span> training data. If an input data belongs to the class <span class="emphasis"><em>k</em></span>, the value of <span class="inlinemediaobject"><img src="graphics/B04779_02_28.jpg" alt="Multi-class logistic regression"/></span> is 1; the value is 0 otherwise.</p><p>Gradients<a id="id135" class="indexterm"/> of the loss function against <a id="id136" class="indexterm"/>the model parameters, the weight vector, and the bias, can be described as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_30.jpg" alt="Multi-class logistic regression"/></div><div class="mediaobject"><img src="graphics/B04779_02_31.jpg" alt="Multi-class logistic regression"/></div><p>Now let's look through the source code to better understand the theory. You can see some variables related to mini-batches besides the ones necessary for the model:</p><div class="informalexample"><pre class="programlisting">int minibatchSize = 50;  //  number of data in each minibatch
int minibatch_N = train_N / minibatchSize; //  number of minibatches

double[][][] train_X_minibatch = new double[minibatch_N][minibatchSize][nIn];  // minibatches of training data
int[][][] train_T_minibatch = new int[minibatch_N][minibatchSize][nOut];       // minibatches of output data for training</pre></div><p>The following code is the process to shuffle training data so the data of each mini-batch is to be applied randomly to SGD:</p><div class="informalexample"><pre class="programlisting">List&lt;Integer&gt; minibatchIndex = new ArrayList&lt;&gt;();  // data index for minibatch to apply SGD
for (int i = 0; i &lt; train_N; i++) minibatchIndex.add(i);
Collections.shuffle(minibatchIndex, rng);  // shuffle data index for SGD</pre></div><p>Since<a id="id137" class="indexterm"/> we can see the multi-class classification <a id="id138" class="indexterm"/>problem, we generate a sample dataset with three classes. In addition to mean values and variances used in perceptrons, we also use the dataset according to normal distribution with the mean of <code class="literal">0.0</code> and the variance of 1.0 for the training data and the test data for class 3. In other words, each class's data follows normal distributions with the mean of <code class="literal">[-2.0, 2.0]</code>, <code class="literal">[2.0, -1.0]</code> and <code class="literal">[0.0, 0.0]</code> and the variance of <code class="literal">1.0</code>. We defined the training data as the <code class="literal">int</code> type and the test data as the Integer type for the labeled data. This is to process the test data easier when evaluating the model. Also, each piece of labeled data is defined as an array because it follows multi-class classification:</p><div class="informalexample"><pre class="programlisting">train_T[i] = new int[]{1, 0, 0};
test_T[i] = new Integer[]{1, 0, 0};</pre></div><p>Then we classify the training data into a mini-batch using <code class="literal">minibatchIndex</code>, which was defined earlier:</p><div class="informalexample"><pre class="programlisting">for (int i = 0; i &lt; minibatch_N; i++) {
   for (int j = 0; j &lt; minibatchSize; j++) {
       train_X_minibatch[i][j] = train_X[minibatchIndex.get(i * minibatchSize + j)];
       train_T_minibatch[i][j] = train_T[minibatchIndex.get(i * minibatchSize + j)];
   }
}</pre></div><p>Now we have <a id="id139" class="indexterm"/>prepared the data, let's practically build a model:</p><div class="informalexample"><pre class="programlisting">LogisticRegression classifier = new LogisticRegression(nIn, nOut);</pre></div><p>The model parameters of logistic regression are <code class="literal">W</code>, weight of the network, and bias <code class="literal">b</code>:</p><div class="informalexample"><pre class="programlisting">public LogisticRegression(int nIn, int nOut) {

   this.nIn = nIn;
   this.nOut = nOut;

   W = new double[nOut][nIn];
   b = new double[nOut];

}</pre></div><p>The training is done with each mini-batch. If you set <code class="literal">minibatchSize = 1</code>, you can make the training so-called online training:</p><div class="informalexample"><pre class="programlisting">for (int epoch = 0; epoch &lt; epochs; epoch++) {
   for (int batch = 0; batch &lt; minibatch_N; batch++) {
       classifier.train(train_X_minibatch[batch], train_T_minibatch[batch], minibatchSize, learningRate);
   }
   learningRate *= 0.95;
}</pre></div><p>Here, the <a id="id140" class="indexterm"/>learning rate gradually decreases so that the model can converge. Now, for the actual training <code class="literal">train</code> method, you can briefly divide it into two parts, as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Calculate the gradient of <code class="literal">W</code> and <code class="literal">b</code> using the data from the mini-batch.</li><li class="listitem">Update <code class="literal">W</code> and <code class="literal">b</code> with the gradients:<div class="informalexample"><pre class="programlisting">// 1. calculate gradient of W, b
for (int n = 0; n &lt; minibatchSize; n++) {

   double[] predicted_Y_ = output(X[n]);

   for (int j = 0; j &lt; nOut; j++) {
       dY[n][j] = predicted_Y_[j] - T[n][j];

       for (int i = 0; i &lt; nIn; i++) {
           grad_W[j][i] += dY[n][j] * X[n][i];
       }

       grad_b[j] += dY[n][j];
   }
}

// 2. update params
for (int j = 0; j &lt; nOut; j++) {
   for (int i = 0; i &lt; nIn; i++) {
       W[j][i] -= learningRate * grad_W[j][i] / minibatchSize;
   }
   b[j] -= learningRate * grad_b[j] / minibatchSize;
}

return dY;</pre></div></li></ol></div><p>At the<a id="id141" class="indexterm"/> end of the <code class="literal">train</code> method, <code class="literal">return dY</code>, the error value of the predicted data and the correct data is returned. This is not mandatory for logistic regression itself but it is necessary in the machine learning and the deep learning algorithms introduced later.</p><p>Next up for the training is the test. The process of performing the test doesn't really change from the one for perceptrons.</p><p>First, with the <code class="literal">predict</code> method, let's predict the input data using the trained model:</p><div class="informalexample"><pre class="programlisting">for (int i = 0; i &lt; test_N; i++) {
   predicted_T[i] = classifier.predict(test_X[i]);
}</pre></div><p>The<code class="literal"> predict</code> method <a id="id142" class="indexterm"/>and the <code class="literal">output</code> method called are written as follows:</p><div class="informalexample"><pre class="programlisting">public Integer[] predict(double[] x) {

   double[] y = output(x);  // activate input data through learned networks
   Integer[] t = new Integer[nOut]; // output is the probability, so cast it to label

   int argmax = -1;
   double max = 0.;

   for (int i = 0; i &lt; nOut; i++) {
       if (max &lt; y[i]) {
           max = y[i];
           argmax = i;
       }
   }

   for (int i = 0; i &lt; nOut; i++) {
       if (i == argmax) {
           t[i] = 1;
       } else {
           t[i] = 0;
       }
   }

   return t;
}


public double[] output(double[] x) {

   double[] preActivation = new double[nOut];

   for (int j = 0; j &lt; nOut; j++) {

       for (int i = 0; i &lt; nIn; i++) {
           preActivation[j] += W[j][i] * x[i];
       }

       preActivation[j] += b[j];  // linear output
   }

   return softmax(preActivation, nOut);
}</pre></div><p>First, input data is activated with the <code class="literal">output</code> method. As you can see from the bottom of the output, the activation function uses the <code class="literal">softmax</code> function. <code class="literal">softmax</code> is defined in <code class="literal">ActivationFunction.java</code>, and with this function the array showing the probability of each class <a id="id143" class="indexterm"/>is returned, hence you just need <a id="id144" class="indexterm"/>to get the index within the array of the element that has the highest probability. The index represents the predicted class.</p><p>Finally, let's evaluate the model. Again, the confusion matrix is introduced for model evaluation, but be careful as you need to find the precision or recall for each class this time because we have multi-class classification here:</p><div class="informalexample"><pre class="programlisting">int[][] confusionMatrix = new int[patterns][patterns];
double accuracy = 0.;
double[] precision = new double[patterns];
double[] recall = new double[patterns];

for (int i = 0; i &lt; test_N; i++) {
   int predicted_ = Arrays.asList(predicted_T[i]).indexOf(1);
   int actual_ = Arrays.asList(test_T[i]).indexOf(1);

   confusionMatrix[actual_][predicted_] += 1;
}

for (int i = 0; i &lt; patterns; i++) {
   double col_ = 0.;
   double row_ = 0.;

   for (int j = 0; j &lt; patterns; j++) {

       if (i == j) {
           accuracy += confusionMatrix[i][j];
           precision[i] += confusionMatrix[j][i];
           recall[i] += confusionMatrix[i][j];
       }

       col_ += confusionMatrix[j][i];
       row_ += confusionMatrix[i][j];
   }
   precision[i] /= col_;
   recall[i] /= row_;
}

accuracy /= test_N;

System.out.println("------------------------------------");
System.out.println("Logistic Regression model evaluation");
System.out.println("------------------------------------");
System.out.printf("Accuracy: %.1f %%\n", accuracy * 100);
System.out.println("Precision:");
for (int i = 0; i &lt; patterns; i++) {
   System.out.printf(" class %d: %.1f %%\n", i+1, precision[i] * 100);
}
System.out.println("Recall:");
for (int i = 0; i &lt; patterns; i++) {
   System.out.printf(" class %d: %.1f %%\n", i+1, recall[i] * 100);</pre></div></div><div class="section" title="Multi-layer perceptrons (multi-layer neural networks)"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec18"/>Multi-layer perceptrons (multi-layer neural networks)</h2></div></div></div><p>Single-layer<a id="id145" class="indexterm"/> neural networks have a huge<a id="id146" class="indexterm"/> problem. Perceptrons or logistic regressions are efficient for problems that can be linearly classified but they can't solve nonlinear problems at all. For example, they can't even solve the simplest XOR problem seen in the figure here:</p><div class="mediaobject"><img src="graphics/B04779_02_53.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><p>Since most of the problems in the real world are nonlinear, perceptrons and logistic regression aren't applicable for practical uses. Hence, the algorithm was improved to correspond to nonlinear problems. These are multi-layer perceptrons (or <span class="strong"><strong>multi-layer neural networks</strong></span>, <span class="strong"><strong>MLPs</strong></span>). As you can see from the name, by adding another layer, called a hidden<a id="id147" class="indexterm"/> layer, between the input layer and the output layer, the networks have the ability to express various patterns. This is the graphical model of an MLP:</p><div class="mediaobject"><img src="graphics/B04779_02_54.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><p>What is most important here is not to introduce the skip-layer connection. In neural networks, it is better for both theory and implementation to keep the model as having a feed-forward network structure. By sticking to these rules, and by increasing the number of hidden layers, you can approximate arbitrary functions without making the model too complicated<a id="id148" class="indexterm"/> mathematically.</p><p>Now, let's see how we compute the output. It looks complicated at first glance but it accumulates the layers and the scheme of the network's weight or activation in the same way, so you simply have to combine the equation of each layer. Each output can be shown as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_32.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><p>Here, <span class="inlinemediaobject"><img src="graphics/B04779_02_77.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></span> is the<a id="id149" class="indexterm"/> activation function of the hidden layer and <span class="inlinemediaobject"><img src="graphics/B04779_02_78.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></span> is the output layer.</p><p>As has <a id="id150" class="indexterm"/>already been introduced, in the case of multi-class classification, the activation function of the output layer can be calculated efficiently by using the <code class="literal">softmax</code> function, and the error function is given as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_33.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><p>As for a single layer, it's fine just to reflect this error in the input layer, but for the multi-layer, neural networks cannot learn as a whole unless you reflect the error in both the hidden layer and input layer.</p><p>Fortunately, in feed-forward networks, there is an algorithm known as <code class="literal">backpropagation</code>, which enables the model to propagate this error efficiently by tracing the network forward and backward. Let's look at the mechanism of this algorithm. To make the equation more readable, we'll think about the valuation of an error function in the online training, shown as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_34.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><p>We can now think about just the gradient of this, <span class="inlinemediaobject"><img src="graphics/B04779_02_79.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></span>. Since all the data in a dataset in most cases of practical application is independent and identically distributed, we have no problem defining it as we just mentioned.</p><p>Each unit in the feed-forward network is shown as the sum of the weight of the network connected to the unit, hence the generalized term can be represented as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_35.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><div class="mediaobject"><img src="graphics/B04779_02_36.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><p>Be careful, as <span class="inlinemediaobject"><img src="graphics/B04779_02_61.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></span> here is not only the value of the input layer (of course, this can be the value <a id="id151" class="indexterm"/>of the input layer). Also, <span class="inlinemediaobject"><img src="graphics/B04779_02_77.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></span> is the nonlinear activation function. The gradient of weights and the gradient of the bias can be shown as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_37.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><div class="mediaobject"><img src="graphics/B04779_02_38.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><p>Now, let the<a id="id152" class="indexterm"/> notation defined in the next equation be introduced:</p><div class="mediaobject"><img src="graphics/B04779_02_39.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><p>Then, we get:</p><div class="mediaobject"><img src="graphics/B04779_02_40.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><div class="mediaobject"><img src="graphics/B04779_02_41.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><p>Therefore, when<a id="id153" class="indexterm"/> we compare the equations, the output unit can be described as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_42.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><p>Also, each unit of the hidden layer is:</p><div class="mediaobject"><img src="graphics/B04779_02_43.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><div class="mediaobject"><img src="graphics/B04779_02_44.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><p>Thus, the <span class="strong"><strong>backpropagation formula </strong></span>is introduced. As such, delta is called the <span class="strong"><strong>backpropagated</strong></span> error. By <a id="id154" class="indexterm"/>computing the <code class="literal">backpropagated</code> error, the weights and bias can be calculated. It may seem difficult when you look <a id="id155" class="indexterm"/>at the formula, but what it basically does is receive feedback on errors from<a id="id156" class="indexterm"/> a connected<a id="id157" class="indexterm"/> unit and renew the weight, so it's not that difficult.</p><p>Now, let's look at an implementation with a simple XOR problem as an example. You will have better understanding when you read the source code. The structure of the package is as follows:</p><div class="mediaobject"><img src="graphics/B04779_02_55.jpg" alt="Multi-layer perceptrons (multi-layer neural networks)"/></div><p>The basic flow of the algorithm is written in <code class="literal">MultiLayerPerceptrons.java</code>, but the actual part of backpropagation is written in <code class="literal">HiddenLayer.java</code>. We use multi-class logistic regression for the output layer. Since there is no change in <code class="literal">LogisticRegression.java</code>, the code is not shown in this section. In <code class="literal">ActivationFunction.java</code>, derivatives of the sigmoid function and hyperbolic tangent are added. The hyperbolic tangent is also the activation function that is often used as an alternative to the sigmoid. Also, in <code class="literal">RandomGenerator.java</code>, the method to generate random numbers with a uniform distribution is written. This is to randomly initialize the weight of the hidden layer, and it is quite an important part because a model often falls into a local optimum and fails to classify the data depending on these initial values.</p><p>Let's have a look at the content of <code class="literal">MultiLayerPerceptrons.java</code>. In <code class="literal">MultiLayerPereptrons.java</code>, differently defined classes are defined respectively for each layer: <code class="literal">HiddenLayer</code> class is used for the hidden layer and <code class="literal">LogisticRegression</code> class for the output layer. Instances of these classes are defined as <code class="literal">hiddenLayer</code> and <code class="literal">logisticLayer</code>, respectively:</p><div class="informalexample"><pre class="programlisting">public MultiLayerPerceptrons(int nIn, int nHidden, int nOut, Random rng) {

   this.nIn = nIn;
   this.nHidden = nHidden;
   this.nOut = nOut;

   if (rng == null) rng = new Random(1234);
   this.rng = rng;

   // construct hidden layer with tanh as activation function
   hiddenLayer = new HiddenLayer(nIn, nHidden, null, null, rng, "tanh");  // sigmoid or tanh

   // construct output layer i.e. multi-class logistic layer
   logisticLayer = new LogisticRegression(nHidden, nOut);

}</pre></div><p>The parameters <a id="id158" class="indexterm"/>of the MLP are the weights <code class="literal">W</code> and bias <code class="literal">b</code> of the <a id="id159" class="indexterm"/>hidden layer, <code class="literal">HiddenLayer</code>, and the output layer, <code class="literal">LogisticRegression</code>. Since the output layer is the same as the one previously introduced, we won't look at the code here. The constructor of <code class="literal">HiddenLayer</code> is as follows:</p><div class="informalexample"><pre class="programlisting">public HiddenLayer(int nIn, int nOut, double[][] W, double[] b, Random rng, String activation) {

   if (rng == null) rng = new Random(1234);  // seed random

   if (W == null) {

       W = new double[nOut][nIn];
       double w_ = 1. / nIn;

       for(int j = 0; j &lt; nOut; j++) {
           for(int i = 0; i &lt; nIn; i++) {
               W[j][i] = uniform(-w_, w_, rng);  // initialize W with uniform distribution
           }
       }

   }

   if (b == null) b = new double[nOut];

   this.nIn = nIn;
   this.nOut = nOut;
   this.W = W;
   this.b = b;
   this.rng = rng;

   if (activation == "sigmoid" || activation == null) {

       this.activation = (double x) -&gt; sigmoid(x);
       this.dactivation = (double x) -&gt; dsigmoid(x);

   } else if (activation == "tanh") {

       this.activation = (double x) -&gt; tanh(x);
       this.dactivation = (double x) -&gt; dtanh(x);

   }  else {
       throw new IllegalArgumentException("activation function not supported");
   }

}</pre></div><p>
<code class="literal">W</code> is initialized, randomly <a id="id160" class="indexterm"/>matching the number <a id="id161" class="indexterm"/>of the units. This initialization is actually tricky as it makes you face the local minima problem more often if the initial values are not well distributed. Therefore, in a practical scene, it often happens that the model is tested with some random seeds. The activation function can be applied to either the sigmoid function or the hyperbolic tangent function.</p><p>The training of the MLP can be given by forward propagation and backward propagation through the neural networks in order:</p><div class="informalexample"><pre class="programlisting">public void train(double[][] X, int T[][], int minibatchSize, double learningRate) {

   double[][] Z = new double[minibatchSize][nIn];  // outputs of hidden layer (= inputs of output layer)
   double[][] dY;

   // forward hidden layer
   for (int n = 0; n &lt; minibatchSize; n++) {
       Z[n] = hiddenLayer.forward(X[n]);  // activate input units
   }

   // forward &amp; backward output layer
   dY = logisticLayer.train(Z, T, minibatchSize, learningRate);

   // backward hidden layer (backpropagate)
   hiddenLayer.backward(X, Z, dY, logisticLayer.W, minibatchSize, learningRate);
}</pre></div><p>The part <a id="id162" class="indexterm"/>of <code class="literal">hiddenLayer.backward</code> gives the <a id="id163" class="indexterm"/>hidden layer backpropagation of the prediction error, <code class="literal">dY</code>, from a logistic regression. Be careful, as the input data of a logistic regression is also necessary for the backpropagation:</p><div class="informalexample"><pre class="programlisting">public double[][] backward(double[][] X, double[][] Z, double[][] dY, double[][] Wprev, int minibatchSize, double learningRate) {

   double[][] dZ = new double[minibatchSize][nOut];  // backpropagation error

   double[][] grad_W = new double[nOut][nIn];
   double[] grad_b = new double[nOut];

   // train with SGD
   // calculate backpropagation error to get gradient of W, b
   for (int n = 0; n &lt; minibatchSize; n++) {

       for (int j = 0; j &lt; nOut; j++) {

           for (int k = 0; k &lt; dY[0].length; k++) {  // k &lt; ( nOut of previous layer )
               dZ[n][j] += Wprev[k][j] * dY[n][k];
           }
           dZ[n][j] *= dactivation.apply(Z[n][j]);


           for (int i = 0; i &lt; nIn; i++) {
               grad_W[j][i] += dZ[n][j] * X[n][i];
           }

           grad_b[j] += dZ[n][j];
       }
   }

   // update params
   for (int j = 0; j &lt; nOut; j++) {
       for(int i = 0; i &lt; nIn; i++) {
           W[j][i] -= learningRate * grad_W[j][i] / minibatchSize;
       }
       b[j] -= learningRate * grad_b[j] / minibatchSize;
   }

   return dZ;
}</pre></div><p>You might <a id="id164" class="indexterm"/>think the algorithm is complex and difficult because the arguments seem complicated, but what we do here is almost the<a id="id165" class="indexterm"/> same as what we do with the <code class="literal">train</code> method of logistic regression: we calculate the gradients of <code class="literal">W</code> and <code class="literal">b</code> with the unit of the mini-batch and update the model parameters. That's it. So, can an MLP learn the XOR problem? Check the result by running <code class="literal">MultiLayerPerceptrons.java</code>.</p><p>The result only outputs the percentages of the accuracy, precision, and recall of the model, but for example, if you dump the prediction data with the <code class="literal">predict</code> method of <code class="literal">LogisticRegression</code>, you can see how much it actually predicts the probability, as follows:</p><div class="informalexample"><pre class="programlisting">double[] y = output(x);  // activate input data through learned networks
Integer[] t = new Integer[nOut]; // output is the probability, so cast it to label

System.out.println(  Arrays.toString(y) );</pre></div><p>We've just shown that MLPs can approximate the function of XOR. Moreover, it is proven that MLPs can approximate any functions. We don't follow the math details here, but you can easily imagine that the more units MLPs have, the more complicated functions they could express and approximate.</p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec17"/>Summary</h1></div></div></div><p>In this chapter, as  preparation for deep learning, we dug into neural networks, which are one of the algorithms of machine learning. You learned about three representative algorithms of single-layer neural networks: perceptrons, logistic regression, and multi-class logistic regression. We see that single-layer neural networks can't solve nonlinear problems, but this problem can be solved with multi-layer neural networks—the networks with a hidden layer(s) between the input layer and output layer. An intuitive understanding of why MLPs can solve nonlinear problems says that the networks can learn more complicated logical operations by adding layers and increasing the number of units, and thus having the ability to express more complicated functions. The key to letting the model have this ability is the backpropagation algorithm. By backpropagating the error of the output to the whole network, the model is updated and adjusted to fit in the training data with each iteration, and finally optimized to approximate the function for the data.</p><p>In the next chapter, you'll learn the concepts and algorithms of deep learning. Since you've now acquired a foundational understanding of machine learning algorithms, you'll have no difficulty learning about deep learning.</p></div></body></html>