<html><head></head><body>
		<div id="_idContainer699">
			<h1 class="chapterNumber sigil_not_in_toc">Chapter 13</h1>
			<h1 class="chapterTitle" xml:lang="en-GB" id="sigil_toc_id_209" lang="en-GB"><a id="_idTextAnchor293"/>AI for Games – Become the Master at Snake</h1>
</div>

			<p class="normal">This is the last practical chapter; congratulations
 on finishing the previous ones! I hope you really enjoyed them. Now, 
let's leave aside business problems and self-driving cars. Let's have 
some fun by playing a popular game called Snake and making an AI that 
teaches itself to play this game!</p>
			<p class="normal">That's exactly what we'll do in this chapter. The model we'll implement is called deep convolutional Q-learning, using a <strong class="bold">Convolutional Neural Network</strong> (<strong class="bold">CNN</strong>).</p>
			<p class="normal">Our AI won't be perfect, and it won't fill in the 
entire map, but after some training it will start playing at a level 
comparable with humans.</p>
			<p class="normal">Let's start tackling this problem by looking at what the game looks like and what the target is.</p>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_210" lang="en-GB"><a id="_idTextAnchor294"/>Problem to solve</h2>
			<p class="normal">First, let's have a<a id="_idIndexMarker570"/> look at the game itself:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_01.png" alt=""/></figure>
			<p class="packt_figref">Figure 1: The Snake game</p>
			<p class="normal">Does that look<a id="_idIndexMarker571"/> somewhat familiar to you?</p>
			<p class="normal">I'm pretty convinced that it will; everyone's played Snake at least once in their life.</p>
			<p class="normal">The game is pretty simple; it consists of a snake 
and an apple. We control the snake and our aim is to eat as many apples 
as possible.</p>
			<p class="normal">Sounds easy? Well, there's a small catch. Every 
time our snake eats an apple, our snake gets larger by one tile. This 
means that the game is unbelievably simple at the beginning, but it gets
 gradually harder, to the point where it becomes a strategic game.</p>
			<p class="normal">Also, when controlling our snake, we can't hit 
ourselves, nor the borders of the board. This rather predictably results
 in us losing.</p>
			<p class="normal">Now that we understand the problem, we can progress to the first step when creating an AI – building the environment!</p>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_211" lang="en-GB"><a id="_idTextAnchor295"/>Building the environment</h2>
			<p class="normal">This time, as opposed to <a id="_idIndexMarker572"/>some
 of the other practical sections in this book, we don't have to specify 
any variables or make any assumptions. We can just go<a id="_idIndexMarker573"/> straight to the three crucial steps present in every deep Q-learning project:</p>
			<ol>
				<li class="list">Defining the states</li>
				<li class="list">Defining the actions</li>
				<li class="list">Defining the rewards</li>
			</ol>
			<p class="normal">Let's begin!</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_212" lang="en-GB"><a id="_idTextAnchor296"/>Defining the states</h3>
			<p class="normal">In every previous example, our<a id="_idIndexMarker574"/>
 states were a 1D vector that represented some values that define the 
environment. For example, for our self-driving car we had 
the information gathered from the three sensors around the car and the 
car's position. All of these were put into a single 1D array.</p>
			<p class="normal">But what if we want to make something slightly more
 realistic? What if we want the AI to see and gather information from 
the same source as we do? Well, that's what we'll do in this chapter. 
Our AI will see exactly the same board as we see when playing Snake!</p>
			<p class="normal">The state of the game should be a 2D array representing the board of the game, exactly the same thing that we can see.</p>
			<p class="normal">There's just one problem with this solution. Take a
 look at the following image, and see if you can answer the question: 
which way is our snake moving right now?</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_02.png" alt=""/></figure>
			<p class="packt_figref">Figure 2: The Snake game</p>
			<p class="normal">If you said "I don't know," then<a id="_idIndexMarker575"/> you're exactly right.</p>
			<p class="normal">Based on a single frame, we can't tell which way 
our snake is going. Therefore, we'll need to stack multiple images, and 
then input all of them at once to a Convolutional Neural Network. This 
will result in us having 3D states rather than 2D ones.</p>
			<p class="normal">So, just to recap:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_03.png" alt=""/></figure>
			<p class="packt_figref">Figure 3: The AI vision</p>
			<p class="normal">We'll have a 3D array, containing next game frames stacked on top of each other, where the top one is the<a id="_idIndexMarker576"/>
 latest frame obtained from our game. Now, we can clearly see which way 
our AI is moving; in this case it's going up, toward the apple.</p>
			<p class="normal">Now that we have defined states, we can go the next step: defining the actions!</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_213" lang="en-GB"><a id="_idTextAnchor297"/>Defining the actions</h3>
			<p class="normal">When we play Snake on a phone or <a id="_idIndexMarker577"/>a website, there are four actions available for us to take:</p>
			<ol>
				<li class="list" value="1">Go up</li>
				<li class="list">Go down</li>
				<li class="list">Go right</li>
				<li class="list">Go left</li>
			</ol>
			<p class="normal">However, if the action we take would require the 
snake to make a 180° turn directly back on itself, then the game blocks 
this action and the snake continues going in its current direction.</p>
			<p class="normal">In the preceding <a id="_idIndexMarker578"/>example,
 if we were to select action 2 – go down–our snake would still continue 
going up, because going down is impossible as the snake can't make 
a 180° turn directly back on itself.</p>
			<p class="normal">It's worth noting that all of these actions are 
relative to the board, not the snake; they're not affected by the 
current movement of the snake. Going up, down, right, or left always 
means going up, down, right, or left with respect to the board, not to 
the snake's current direction of movement.</p>
			<p class="normal">Alright, so right now you might be in one of these two groups when it comes to deciding what actions we model in our AI:</p>
			<ol>
				<li class="list" value="1">We can use these four same actions for our AI.</li>
				<li class="list">We can't use these same actions, because blocking 
certain moves will be confusing for our AI. Instead, we should invent a 
way to tell the snake to go left, go right, or keep going.</li>
			</ol>
			<p class="normal">We actually can use these same actions for our AI!</p>
			<p class="normal">Why won't it be confusing for our agent? That's 
because as long as our AI agent gets rewards for the actions it chose, 
and not for the action ultimately performed by the snake, then deep 
Q-learning will work and our AI will understand that in the example 
above choosing either <em class="italics">go up</em> or <em class="italics">go down</em> results in the same outcome.</p>
			<p class="normal">For example, let's say that the AI-controlled snake
 is currently going left. It chooses action 3, go right; and because 
that would cause the snake to make a 180° turn back on itself, instead 
the snake continues going left. Let's say that action means the snake 
crashes into the wall and, as a result, dies. In order for this not to 
be confusing for our agent, all we need to do is tell it that the action
 of <em class="italics">go right</em> caused it to crash, even though the snake kept moving left.</p>
			<p class="normal">Think of it as teaching an AI to play with the 
actual buttons on a phone. If you keep trying to make your snake double 
back on itself when it's moving left, by pressing the go right button 
over and over again, the game will keep ignoring the impossible move you
 keep telling it to do, keep going left, and eventually crash. That's 
all the AI needs to learn.</p>
			<p class="normal">This is because, remember, in deep Q-learning we 
only update the Q-values of the action that the AI takes. If our snake 
is going left, and the AI decides to go right and the snake dies, it 
needs to understand that the action of <em class="italics">go right</em> caused it to get the negative reward, not the fact that the snake moved left; even though choosing the action <em class="italics">go left</em> would cause the same outcome.</p>
			<p class="normal">I hope you<a id="_idIndexMarker579"/> understand
 that the AI can use the same actions as we use when we play. We can 
continue to the next, final step – defining the rewards!</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_214" lang="en-GB"><a id="_idTextAnchor298"/>Defining the rewards</h3>
			<p class="normal">This last step is pretty <a id="_idIndexMarker580"/>simple; we just need three rewards:</p>
			<ol>
				<li class="list" value="1">Reward for eating an apple</li>
				<li class="list">Reward for dying</li>
				<li class="list">The living penalty</li>
			</ol>
			<p class="normal">The first two are hopefully easy to understand. 
After all, we want to encourage our agent to eat as many apples as 
possible and therefore we will set its reward to be positive. To be 
precise: <strong class="bold">eating an apple = +2</strong></p>
			<p class="normal">Meanwhile, we want to discourage our snake from dying. That's why we set that reward to be a negative one. To be precise: <strong class="bold">dying = -1</strong></p>
			<p class="normal">Then comes the final reward: the living penalty.</p>
			<p class="normal">What is that, and why is it necessary? We have to 
convince our agent that collecting apples as quickly as possible, 
without dying, is a good idea. If we were to only have the two rewards 
we've already defined, our agent would simply travel around the entire 
map, hoping that at some point it finds an apple. It wouldn't understand
 that it needs to collect apples as quickly as it can.</p>
			<p class="normal">That's why we introduce the living penalty. It will
 slightly punish our AI for every action it takes, unless this action 
leads to dying or collecting an apple. This will show our agent that it 
needs to collect apples quickly, as only moves that collect an apple 
lead to gaining a positive reward. So, how big this reward should be? 
Well, we don't want to punish it too much. To be precise: <strong class="bold">living penalty =-0.03</strong></p>
			<p class="normal">If you want to tinker with these rewards, the 
absolute value of this reward should always be relatively small compared
 to the other rewards, for dying (-1) and collecting an apple (+2).</p>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_215" lang="en-GB"><a id="_idTextAnchor299"/>AI solution</h2>
			<p class="normal">As always, the AI solution<a id="_idIndexMarker581"/> for deep Q-learning consists of two parts:</p>
			<ol>
				<li class="list" value="1"><strong class="bold">Brain</strong> – the neural network that will learn and take actions</li>
				<li class="list"><strong class="bold">Experience replay memory</strong> – the memory that will store our experience; the neural network will learn from this memory</li>
			</ol>
			<p class="normal">Let's tackle those now!</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_216" lang="en-GB"><a id="_idTextAnchor300"/>The brain</h3>
			<p class="normal">This part of the AI<a id="_idIndexMarker582"/> solution will be responsible for teaching, storing, and evaluating our neural network. To build it, we're going to use a CNN!</p>
			<p class="normal">Why a CNN? When explaining the theory behind them, I
 mentioned that they're often used when "our environment as state 
returns images," and that's exactly what we're dealing with here. We've 
already established that the game state is going to be a stacked 3D 
array containing the last few game frames.</p>
			<p class="normal">In the previous chapter, we discussed that a CNN 
takes a 2D image as input, not a stacked 3D array of images; but do you 
remember this graphic?</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_04.png" alt="https://lh5.googleusercontent.com/qjfDY_d7Dvn92gkZ2KDpPAoy-SM_7AO8RExLTjtj-FYCQcCDVIrfSjvgslPBBT5kAneqJMRbJKAOikeslS-1T5TQaPDDxX338ko4DWQxi5xPggLbosb-p3tR8y5DDGp-blxs1aqj"/></figure>
			<p class="packt_figref">Figure 4: RGB images</p>
			<p class="normal">Here, I informed you that the RGB images are 
represented by 3D arrays that contain every single 2D channel of this 
image. Does that sound familiar? We can use the very same method for our
 problem. Just like each color in the RGB structure, we'll simply input 
every game frame<a id="_idIndexMarker583"/> as a new channel, which will give us a 3D array, which we will be able to input into a CNN. </p>
			<p class="normal">In reality, CNNs usually only support 3D arrays as 
inputs. In order to input a 2D array, you need to create a fake single 
channel that transforms a 2D array into a 3D one.</p>
			<p class="normal">When it comes to the CNN architecture, we'll have 
two convolution layers separated by a pooling layer. One convolution 
layer will have 32 3x3 filters, and the other one will have 64 2x2 
filters. The pooling layer will shrink the size by 2, as the pooling 
window size will be 2x2. Why such an architecture? It's a classic one, 
found in many research papers, which I arbitrarily chose as common 
practice and which turned out to work brilliantly.</p>
			<p class="normal">Our neural network will have one hidden layer with 
256 neurons, and an output layer with 4 neurons; one for each of our 
possible outcome actions.</p>
			<p class="normal">We also need to set two last parameters for our CNN – learning rate and input shape.</p>
			<p class="normal">Learning rate, which was used in the previous 
examples, is a parameter that specifies by how much we update the 
weights in the neural network. Too small and it won't learn, too big and
 it won't learn for a different reason; the changes will be too big for 
any optimization. I found through experimentation that a good learning 
rate for this example is 0.0001.</p>
			<p class="normal">We've already agreed that the input should be a 3D 
array containing last frames obtained from our game. To be exact, we 
will not be reading pixels from our screen. Instead, we'll read the 
direct 2D array that represents our game's screen at a particular time.</p>
			<p class="normal">As you've probably noticed, our game is built on a 
grid. In the example we are using, the grid is 10x10. Then, inside the 
environment is an array with the same size (10x10), telling us 
mathematically what the board looks like. For example, if we have part 
of the snake in one cell, then we place the value 0.5 in the 
corresponding cell in our 2D array, which we will read. An apple is 
described as value 1 in this array.</p>
			<p class="normal">Now that we know how we'll see one frame, we need 
to decide how many previous frames we'll use when we describe the 
current game state. 2 should be enough, since we can discern from that 
which way the snake is going, but to make sure, we'll have 4.</p>
			<p class="normal">Can you tell me exactly what shape our input to the CNN will be?</p>
			<p class="normal">It'll be 10x10x4, which gives us a 3D array!</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_217" lang="en-GB"><a id="_idTextAnchor301"/>The experience replay memory</h3>
			<p class="normal">As defined in the<a id="_idIndexMarker584"/> theoretical chapter of deep Q-learning, we need to have a memory that stores experience gathered during training.</p>
			<p class="normal">We'll store the following data:</p>
			<ul>
				<li class="list">Current state – The game state the AI was in when it performed an action (what we inputted to our CNN)</li>
				<li class="list">Action – Which action was undertaken</li>
				<li class="list">Reward – The reward gained by performing this action on the current state</li>
				<li class="list">Next state – What happened (how the state looked) after performing the action</li>
				<li class="list">Game over – Information about whether we have lost or not</li>
			</ul>
			<p class="normal">Also, we always have to specify two parameters for every experience replay memory:</p>
			<ul>
				<li class="list">Memory size – The maximum size of our memory</li>
				<li class="list">Gamma – The discount factor, existent in the Bellman equation</li>
			</ul>
			<p class="normal">We'll set the memory size to 60,000 and the gamma parameter to 0.9.</p>
			<p class="normal">There's one last thing to specify here.</p>
			<p class="normal">I told you that our AI will learn from this memory,
 and that's true; but the AI won't be learning from the entire memory. 
Rather, it will learn from a small batch taken from it. The parameter 
that specifies this size will be called batch size, and in this example,
 we'll set its value to 32. That means that our AI will learn every 
iteration from a batch of this size taken from experience replay memory.</p>
			<p class="normal">Now that you understand everything you have to code, you can get started!</p>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_218" lang="en-GB"><a id="_idTextAnchor302"/>Implementation</h2>
			<p class="normal">You'll implement the entire AI code <a id="_idIndexMarker585"/>and the Snake game in five files:</p>
			<ol>
				<li class="list" value="1"><code class="Code-In-Text--PACKT-">environment.py</code> file – The file containing the environment (Snake game)</li>
				<li class="list"><code class="Code-In-Text--PACKT-">brain.py</code> file – The file in which we build our CNN</li>
				<li class="list"><code class="Code-In-Text--PACKT-">DQN.py</code> – The file that builds the Experience Replay Memory</li>
				<li class="list"><code class="Code-In-Text--PACKT-">train.py</code> – The file where we will train our AI to play Snake</li>
				<li class="list"><code class="Code-In-Text--PACKT-">test.py</code> – The file where we will test our AI to see how well it performs</li>
			</ol>
			<p class="normal">You can find all of them on the GitHub page along with a pre-trained model. To get there, select <code class="Code-In-Text--PACKT-">Chapter 13</code> folder on the main page.</p>
			<p class="normal">We'll go through each<a id="_idIndexMarker586"/> file in the same order. Let's start building the environment!</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_219" lang="en-GB"><a id="_idTextAnchor303"/>Step 1 – Building the environment</h3>
			<p class="normal">Start this first, important step by<a id="_idIndexMarker587"/> importing the libraries you'll need. Like this:</p>
			<pre class="programlisting language-markup"><code class="hljs clean"># Importing the libraries   #<span class="hljs-number">4</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np   #<span class="hljs-number">5</span>
<span class="hljs-keyword">import</span> pygame <span class="hljs-keyword">as</span> pg   #<span class="hljs-number">6</span>
</code></pre>
			
			
			<p class="normal">You'll only use two libraries: NumPy and PyGame. 
The former is really useful when dealing with lists or arrays, and the 
latter will be used to build the entire game – to draw the snake and the
 apple, and update the screen.</p>
			<p class="normal">Now, let's create the <code class="Code-In-Text--PACKT-">Environment</code>
 class which will contain all the information, variables and methods 
that you need for your game. Why a class? This is because it makes 
things easier for you later on. You'll be able to call specific methods 
or variables from the object of this class.</p>
			<p class="normal">The first method that you always have to have is the <code class="Code-In-Text--PACKT-">__init__</code> method, always called when a new object of this class is created in the main code. To create this class along with this <code class="Code-In-Text--PACKT-">__init__</code> method, you need to write:</p>
			<pre class="programlisting language-markup"><code class="hljs ruby"><span class="hljs-comment"># Initializing the Environment class   #8</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Environment</span>():   <span class="hljs-comment">#9</span></span>
    <span class="hljs-comment">#10</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, waitTime)</span></span>:   <span class="hljs-comment">#11</span>
        <span class="hljs-comment">#12</span>
        <span class="hljs-comment"># Defining the parameters   #13</span>
        <span class="hljs-keyword">self</span>.width = <span class="hljs-number">880</span>            <span class="hljs-comment"># width of the game window   #14</span>
        <span class="hljs-keyword">self</span>.height = <span class="hljs-number">880</span>           <span class="hljs-comment"># height of the game window   #15</span>
        <span class="hljs-keyword">self</span>.nRows = <span class="hljs-number">10</span>             <span class="hljs-comment"># number of rows in our board   #16</span>
        <span class="hljs-keyword">self</span>.nColumns = <span class="hljs-number">10</span>          <span class="hljs-comment"># number of columns in our board   #17</span>
        <span class="hljs-keyword">self</span>.initSnakeLen = <span class="hljs-number">2</span>       <span class="hljs-comment"># initial length of the snake   #18</span>
        <span class="hljs-keyword">self</span>.defReward = -<span class="hljs-number">0</span>.<span class="hljs-number">03</span>      <span class="hljs-comment"># reward for taking an action - The Living Penalty   #19</span>
        <span class="hljs-keyword">self</span>.negReward = -<span class="hljs-number">1</span>.        <span class="hljs-comment"># reward for dying   #20</span>
        <span class="hljs-keyword">self</span>.posReward = <span class="hljs-number">2</span>.         <span class="hljs-comment"># reward for collecting an apple   #21</span>
        <span class="hljs-keyword">self</span>.waitTime = waitTime    <span class="hljs-comment"># slowdown after taking an action   #22</span>
        <span class="hljs-comment">#23</span>
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.initSnakeLen &gt; <span class="hljs-keyword">self</span>.nRows / <span class="hljs-number">2</span>:   <span class="hljs-comment">#24</span>
            <span class="hljs-keyword">self</span>.initSnakeLen = int(<span class="hljs-keyword">self</span>.nRows / <span class="hljs-number">2</span>)   <span class="hljs-comment">#25</span>
        <span class="hljs-comment">#26</span>
        <span class="hljs-keyword">self</span>.screen = pg.display.set_mode((<span class="hljs-keyword">self</span>.width, <span class="hljs-keyword">self</span>.height))   <span class="hljs-comment">#27</span>
        <span class="hljs-comment">#28</span>
        <span class="hljs-keyword">self</span>.snakePos = list()   <span class="hljs-comment">#29</span>
        <span class="hljs-comment">#30</span>
        <span class="hljs-comment"># Creating the array that contains mathematical representation of the game's board   #31</span>
        <span class="hljs-keyword">self</span>.screenMap = np.zeros((<span class="hljs-keyword">self</span>.nRows, <span class="hljs-keyword">self</span>.nColumns))   <span class="hljs-comment">#32</span>
        <span class="hljs-comment">#33</span>
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-keyword">self</span>.initSnakeLen):   <span class="hljs-comment">#34</span>
            <span class="hljs-keyword">self</span>.snakePos.append((int(<span class="hljs-keyword">self</span>.nRows / <span class="hljs-number">2</span>) + i, int(<span class="hljs-keyword">self</span>.nColumns / <span class="hljs-number">2</span>)))   <span class="hljs-comment">#35</span>
            <span class="hljs-keyword">self</span>.screenMap[int(<span class="hljs-keyword">self</span>.nRows / <span class="hljs-number">2</span>) + i][int(<span class="hljs-keyword">self</span>.nColumns / <span class="hljs-number">2</span>)] = <span class="hljs-number">0</span>.<span class="hljs-number">5</span>   <span class="hljs-comment">#36</span>
            <span class="hljs-comment">#37</span>
        <span class="hljs-keyword">self</span>.applePos = <span class="hljs-keyword">self</span>.placeApple()   <span class="hljs-comment">#38</span>
        <span class="hljs-comment">#39</span>
        <span class="hljs-keyword">self</span>.drawScreen()   <span class="hljs-comment">#40</span>
        <span class="hljs-comment">#41</span>
        <span class="hljs-keyword">self</span>.collected = False   <span class="hljs-comment">#42</span>
        <span class="hljs-keyword">self</span>.lastMove = <span class="hljs-number">0</span>   <span class="hljs-comment">#43</span>
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">You create a new class, the <code class="Code-In-Text--PACKT-">Environment()</code> class, along with its <code class="Code-In-Text--PACKT-">__init__</code> method. This method only takes one argument, which is <code class="Code-In-Text--PACKT-">waitTime</code>. Then after defining the method, create a list of <a id="_idIndexMarker588"/>constants,
 each of which is explained in the inline comments. After that, you 
perform some initialization. You make sure the snake is half the length 
of the screen or less on lines 24 and 25, and set the screen up on line 
27. One important thing to note is that you create the <code class="Code-In-Text--PACKT-">screenMap</code>
 array on line 32, which represents the board more mathematically. 0.5 
in a cell means that this cell is taken by the snake, and 1 in a cell 
means that this cell is taken by the apple.</p>
			<p class="normal">On lines 34 to 36, you place the snake in the middle of the screen, facing upward, and then in the remaining lines<a id="_idIndexMarker589"/> you place an apple using the <code class="Code-In-Text--PACKT-">placeapple()</code>
 method (which we are about to define), draw the screen, set that the 
apple hasn't been collected, and set that there's no last move.</p>
			<p class="normal">That's the very first method completed. Now you can proceed to the next one:</p>
			<pre class="programlisting language-markup"><code class="hljs oxygene">    # Building a <span class="hljs-function"><span class="hljs-keyword">method</span> <span class="hljs-title">that</span> <span class="hljs-title">gets</span> <span class="hljs-title">new</span>, <span class="hljs-title">random</span> <span class="hljs-title">position</span> <span class="hljs-title">of</span> <span class="hljs-title">an</span> <span class="hljs-title">apple</span>
    <span class="hljs-title">def</span> <span class="hljs-title">placeApple</span><span class="hljs-params">(<span class="hljs-keyword">self</span>)</span>:</span>
        posx = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-keyword">self</span>.nColumns)
        posy = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-keyword">self</span>.nRows)
        <span class="hljs-keyword">while</span> <span class="hljs-keyword">self</span>.screenMap[posy][posx] == <span class="hljs-number">0.5</span>:
            posx = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-keyword">self</span>.nColumns)
            posy = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-keyword">self</span>.nRows)
        
        <span class="hljs-keyword">self</span>.screenMap[posy][posx] = <span class="hljs-number">1</span>
        
        return (posy, posx)
</code></pre>
			
			
			
			
			
			
			
			
			
			
			<p class="normal">This short method places an apple in a new, random spot in your <code class="Code-In-Text--PACKT-">screenMap</code>
 array. You'll need this method when our snake collects the apple and a 
new apple needs to be placed. It also returns the random position of the
 new apple.</p>
			<p class="normal">Then, you'll need a function that draws everything for you to see:</p>
			<pre class="programlisting language-markup"><code class="hljs yaml">    <span class="hljs-comment"># Making a function that draws everything for us to see</span>
    <span class="hljs-string">def</span> <span class="hljs-string">drawScreen(self):</span>
        
        <span class="hljs-string">self.screen.fill((0,</span> <span class="hljs-number">0</span><span class="hljs-string">,</span> <span class="hljs-number">0</span><span class="hljs-string">))</span>
        
        <span class="hljs-string">cellWidth</span> <span class="hljs-string">=</span> <span class="hljs-string">self.width</span> <span class="hljs-string">/</span> <span class="hljs-string">self.nColumns</span>
        <span class="hljs-string">cellHeight</span> <span class="hljs-string">=</span> <span class="hljs-string">self.height</span> <span class="hljs-string">/</span> <span class="hljs-string">self.nRows</span>
        
        <span class="hljs-string">for</span> <span class="hljs-string">i</span> <span class="hljs-string">in</span> <span class="hljs-string">range(self.nRows):</span>
            <span class="hljs-string">for</span> <span class="hljs-string">j</span> <span class="hljs-string">in</span> <span class="hljs-string">range(self.nColumns):</span>
                <span class="hljs-string">if</span> <span class="hljs-string">self.screenMap[i][j]</span> <span class="hljs-string">==</span> <span class="hljs-attr">0.5:</span>
                    <span class="hljs-string">pg.draw.rect(self.screen,</span> <span class="hljs-string">(255,</span> <span class="hljs-number">255</span><span class="hljs-string">,</span> <span class="hljs-number">255</span><span class="hljs-string">),</span> <span class="hljs-string">(j*cellWidth</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">,</span> <span class="hljs-string">i*cellHeight</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">,</span> <span class="hljs-string">cellWidth</span> <span class="hljs-bullet">-</span> <span class="hljs-number">2</span><span class="hljs-string">,</span> <span class="hljs-string">cellHeight</span> <span class="hljs-bullet">-</span> <span class="hljs-number">2</span><span class="hljs-string">))</span>
                <span class="hljs-string">elif</span> <span class="hljs-string">self.screenMap[i][j]</span> <span class="hljs-string">==</span> <span class="hljs-attr">1:</span>
                    <span class="hljs-string">pg.draw.rect(self.screen,</span> <span class="hljs-string">(255,</span> <span class="hljs-number">0</span><span class="hljs-string">,</span> <span class="hljs-number">0</span><span class="hljs-string">),</span> <span class="hljs-string">(j*cellWidth</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">,</span> <span class="hljs-string">i*cellHeight</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">,</span> <span class="hljs-string">cellWidth</span> <span class="hljs-bullet">-</span> <span class="hljs-number">2</span><span class="hljs-string">,</span> <span class="hljs-string">cellHeight</span> <span class="hljs-bullet">-</span> <span class="hljs-number">2</span><span class="hljs-string">))</span>
                    
        <span class="hljs-string">pg.display.flip()</span>
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">As you can see, the name of this method is <code class="Code-In-Text--PACKT-">drawScreen</code> and it doesn't take any arguments. Here you<a id="_idIndexMarker590"/>
 simply empty the entire screen, then fill it in with white tiles where 
the snake is and with a red tile where the apple is. At the end, you 
update the screen with <code class="Code-In-Text--PACKT-">pg.display.flip()</code>.</p>
			<p class="normal">Now, you need a function that will update the snake's position and not the entire environment:</p>
			<pre class="programlisting language-markup"><code class="hljs pf">    <span class="hljs-comment"># A method that updates the snake's position</span>
    def moveSnake(<span class="hljs-literal">self</span>, nextP<span class="hljs-keyword">os</span>, col):
        
        <span class="hljs-literal">self</span>.snakeP<span class="hljs-keyword">os</span>.insert(<span class="hljs-number">0</span>, nextP<span class="hljs-keyword">os</span>)
        
        if not col:
            <span class="hljs-literal">self</span>.snakeP<span class="hljs-keyword">os</span>.pop(len(<span class="hljs-literal">self</span>.snakeP<span class="hljs-keyword">os</span>) - <span class="hljs-number">1</span>)
        
        <span class="hljs-literal">self</span>.screenMap = np.zeros((<span class="hljs-literal">self</span>.nRows, <span class="hljs-literal">self</span>.nColumns))
        
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(<span class="hljs-literal">self</span>.snakeP<span class="hljs-keyword">os</span>)):
            <span class="hljs-literal">self</span>.screenMap[<span class="hljs-literal">self</span>.snakeP<span class="hljs-keyword">os</span>[i][<span class="hljs-number">0</span>]][<span class="hljs-literal">self</span>.snakeP<span class="hljs-keyword">os</span>[i][<span class="hljs-number">1</span>]] = <span class="hljs-number">0.5</span>
        
        if col:
            <span class="hljs-literal">self</span>.appleP<span class="hljs-keyword">os</span> = <span class="hljs-literal">self</span>.placeApple()
            <span class="hljs-literal">self</span>.collected = True
            
        <span class="hljs-literal">self</span>.screenMap[<span class="hljs-literal">self</span>.appleP<span class="hljs-keyword">os</span>[<span class="hljs-number">0</span>]][<span class="hljs-literal">self</span>.appleP<span class="hljs-keyword">os</span>[<span class="hljs-number">1</span>]] = <span class="hljs-number">1</span>
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">You can see that this new method takes two arguments: <code class="Code-In-Text--PACKT-">nextPos</code> and <code class="Code-In-Text--PACKT-">col</code>.
 The former tells you where the head of the snake will be after 
performing a certain action. The latter will inform you whether the 
snake has collected an apple by taking this action, or not. Remember 
that if the snake has collected an apple, then the length of the snake 
increases by 1. If you go deep into this code, you can see that, but we 
won't go into detail here since it's not so relevant for the AI. You can
 also see that if the snake has collected an apple, a new one is spawned
 in a new spot.</p>
			<p class="normal">Now, let's move on to the most important part of 
this code. You define a function that will update the entire 
environment. It will move your snake, calculate the reward, check if you
 lost, and return a new game frame. This is how it starts:</p>
			<pre class="programlisting language-markup"><code class="hljs nix">    <span class="hljs-comment"># The main method that updates the environment</span>
    def step(self, action):
        <span class="hljs-comment"># action = 0 -&gt; up</span>
        <span class="hljs-comment"># action = 1 -&gt; down</span>
        <span class="hljs-comment"># action = 2 -&gt; right</span>
        <span class="hljs-comment"># action = 3 -&gt; left</span>
        
        <span class="hljs-comment"># Resetting these parameters and setting the reward to the living penalty</span>
        <span class="hljs-attr">gameOver</span> = False
        <span class="hljs-attr">reward</span> = self.defReward
        self.<span class="hljs-attr">collected</span> = False
        
        for event <span class="hljs-keyword">in</span> pg.event.get():
            <span class="hljs-keyword">if</span> event.<span class="hljs-attr">type</span> == pg.QUIT:
                return
        
        <span class="hljs-attr">snakeX</span> = self.snakePos[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]
        <span class="hljs-attr">snakeY</span> = self.snakePos[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]
        
        <span class="hljs-comment"># Checking if an action is playable and if not then it is changed to the playable one</span>
        <span class="hljs-keyword">if</span> <span class="hljs-attr">action</span> == <span class="hljs-number">1</span> <span class="hljs-literal">and</span> self.<span class="hljs-attr">lastMove</span> == <span class="hljs-number">0</span>:
            <span class="hljs-attr">action</span> = <span class="hljs-number">0</span>
        <span class="hljs-keyword">if</span> <span class="hljs-attr">action</span> == <span class="hljs-number">0</span> <span class="hljs-literal">and</span> self.<span class="hljs-attr">lastMove</span> == <span class="hljs-number">1</span>:
            <span class="hljs-attr">action</span> = <span class="hljs-number">1</span>
        <span class="hljs-keyword">if</span> <span class="hljs-attr">action</span> == <span class="hljs-number">3</span> <span class="hljs-literal">and</span> self.<span class="hljs-attr">lastMove</span> == <span class="hljs-number">2</span>:
            <span class="hljs-attr">action</span> = <span class="hljs-number">2</span>
        <span class="hljs-keyword">if</span> <span class="hljs-attr">action</span> == <span class="hljs-number">2</span> <span class="hljs-literal">and</span> self.<span class="hljs-attr">lastMove</span> == <span class="hljs-number">3</span>:
            <span class="hljs-attr">action</span> = <span class="hljs-number">3</span>
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">As you can see, this method is called <code class="Code-In-Text--PACKT-">step</code> and it takes one argument: the action that tells you which way you <a id="_idIndexMarker591"/>want
 the snake to be going. Just beneath the method's definition, in the 
comments, you can see which action means which direction.</p>
			<p class="normal">Then you reset some variables. You set <code class="Code-In-Text--PACKT-">gameOver</code> to <code class="Code-In-Text--PACKT-">False</code> as this bool variable will tell you if you lost after performing this action. You set <code class="Code-In-Text--PACKT-">reward</code> to <code class="Code-In-Text--PACKT-">defReward</code>, as this is the living penalty; it can change if we collect an apple or die later.</p>
			<p class="normal">Then there's a <code class="Code-In-Text--PACKT-">for</code>
 loop. It's there to make sure the PyGame window doesn't freeze; this is
 a requirement of the PyGame library. It just has to be there.</p>
			<p class="normal"><code class="Code-In-Text--PACKT-">snakeX</code> and <code class="Code-In-Text--PACKT-">snakeY</code>
 tell you what the head position of the snake is. It'll be used by the 
algorithm later, to determine what happens after the head moves.</p>
			<p class="normal">In the last few lines, you can see the algorithm 
that blocks impossible actions. Just to recap, an impossible action is 
the one that requires the snake to make a 180° turn in place. <code class="Code-In-Text--PACKT-">lastMove</code> tells you which way the snake is going right now, and is compared with <code class="Code-In-Text--PACKT-">action</code>. If these lead to a contradiction, then <code class="Code-In-Text--PACKT-">action</code> is set to <code class="Code-In-Text--PACKT-">lastMove</code>.</p>
			<p class="normal">Still inside this method, you update the snake position, check for game over, and calculate the reward, like so:</p>
			<pre class="programlisting language-markup"><code class="hljs yaml">        <span class="hljs-comment"># Checking what happens when we take this action</span>
        <span class="hljs-string">if</span> <span class="hljs-string">action</span> <span class="hljs-string">==</span> <span class="hljs-attr">0:</span>
            <span class="hljs-string">if</span> <span class="hljs-string">snakeY</span> <span class="hljs-string">&gt;</span> <span class="hljs-attr">0:</span>
                <span class="hljs-string">if</span> <span class="hljs-string">self.screenMap[snakeY</span> <span class="hljs-bullet">-</span> <span class="hljs-number">1</span><span class="hljs-string">][snakeX]</span> <span class="hljs-string">==</span> <span class="hljs-attr">0.5:</span>
                    <span class="hljs-string">gameOver</span> <span class="hljs-string">=</span> <span class="hljs-literal">True</span>
                    <span class="hljs-string">reward</span> <span class="hljs-string">=</span> <span class="hljs-string">self.negReward</span>
                <span class="hljs-string">elif</span> <span class="hljs-string">self.screenMap[snakeY</span> <span class="hljs-bullet">-</span> <span class="hljs-number">1</span><span class="hljs-string">][snakeX]</span> <span class="hljs-string">==</span> <span class="hljs-attr">1:</span>
                    <span class="hljs-string">reward</span> <span class="hljs-string">=</span> <span class="hljs-string">self.posReward</span>
                    <span class="hljs-string">self.moveSnake((snakeY</span> <span class="hljs-bullet">-</span> <span class="hljs-number">1</span><span class="hljs-string">,</span> <span class="hljs-string">snakeX),</span> <span class="hljs-literal">True</span><span class="hljs-string">)</span>
                <span class="hljs-string">elif</span> <span class="hljs-string">self.screenMap[snakeY</span> <span class="hljs-bullet">-</span> <span class="hljs-number">1</span><span class="hljs-string">][snakeX]</span> <span class="hljs-string">==</span> <span class="hljs-attr">0:</span>
                    <span class="hljs-string">self.moveSnake((snakeY</span> <span class="hljs-bullet">-</span> <span class="hljs-number">1</span><span class="hljs-string">,</span> <span class="hljs-string">snakeX),</span> <span class="hljs-literal">False</span><span class="hljs-string">)</span>
            <span class="hljs-attr">else:</span>
                <span class="hljs-string">gameOver</span> <span class="hljs-string">=</span> <span class="hljs-literal">True</span>
                <span class="hljs-string">reward</span> <span class="hljs-string">=</span> <span class="hljs-string">self.negReward</span>
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">Here you check what happens if the snake goes up. If the head of the snake is already in the top row (row no. <code class="Code-In-Text--PACKT-">0</code>) then you've obviously lost, since the snake hits the wall. So, <code class="Code-In-Text--PACKT-">reward</code> is set to <code class="Code-In-Text--PACKT-">negReward</code> and <code class="Code-In-Text--PACKT-">gameOver</code> is set to <code class="Code-In-Text--PACKT-">True</code>. Otherwise, you check what lies ahead of the snake.</p>
			<p class="normal">If the cell ahead already <a id="_idIndexMarker592"/>contains part of the snake's body, then you've lost. You check that in the first <code class="Code-In-Text--PACKT-">if</code> statement, then set <code class="Code-In-Text--PACKT-">gameOver</code> to <code class="Code-In-Text--PACKT-">True</code> and <code class="Code-In-Text--PACKT-">reward</code> to <code class="Code-In-Text--PACKT-">negReward</code>.</p>
			<p class="normal">Else if the cell ahead is an apple, then you set <code class="Code-In-Text--PACKT-">reward</code> to <code class="Code-In-Text--PACKT-">posReward</code>. You also update the snake's position by calling the method you created just before this one.</p>
			<p class="normal">Else if the cell ahead is empty, then you don't update <code class="Code-In-Text--PACKT-">reward</code> in any way. You call the same method again, but this time with the <code class="Code-In-Text--PACKT-">col</code> argument set to <code class="Code-In-Text--PACKT-">False</code>,
 since the snake hasn't collected an apple. You go through the same 
process for every other action. I won't go through every line, but have a
 look at the code:</p>
			<pre class="programlisting language-markup"><code class="hljs yaml">        <span class="hljs-string">elif</span> <span class="hljs-string">action</span> <span class="hljs-string">==</span> <span class="hljs-attr">1:</span>
            <span class="hljs-string">if</span> <span class="hljs-string">snakeY</span> <span class="hljs-string">&lt;</span> <span class="hljs-attr">self.nRows - 1:</span>
                <span class="hljs-string">if</span> <span class="hljs-string">self.screenMap[snakeY</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">][snakeX]</span> <span class="hljs-string">==</span> <span class="hljs-attr">0.5:</span>
                    <span class="hljs-string">gameOver</span> <span class="hljs-string">=</span> <span class="hljs-literal">True</span>
                    <span class="hljs-string">reward</span> <span class="hljs-string">=</span> <span class="hljs-string">self.negReward</span>
                <span class="hljs-string">elif</span> <span class="hljs-string">self.screenMap[snakeY</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">][snakeX]</span> <span class="hljs-string">==</span> <span class="hljs-attr">1:</span>
                    <span class="hljs-string">reward</span> <span class="hljs-string">=</span> <span class="hljs-string">self.posReward</span>
                    <span class="hljs-string">self.moveSnake((snakeY</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">,</span> <span class="hljs-string">snakeX),</span> <span class="hljs-literal">True</span><span class="hljs-string">)</span>
                <span class="hljs-string">elif</span> <span class="hljs-string">self.screenMap[snakeY</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">][snakeX]</span> <span class="hljs-string">==</span> <span class="hljs-attr">0:</span>
                    <span class="hljs-string">self.moveSnake((snakeY</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">,</span> <span class="hljs-string">snakeX),</span> <span class="hljs-literal">False</span><span class="hljs-string">)</span>
            <span class="hljs-attr">else:</span>
                <span class="hljs-string">gameOver</span> <span class="hljs-string">=</span> <span class="hljs-literal">True</span>
                <span class="hljs-string">reward</span> <span class="hljs-string">=</span> <span class="hljs-string">self.negReward</span>
                
        <span class="hljs-string">elif</span> <span class="hljs-string">action</span> <span class="hljs-string">==</span> <span class="hljs-attr">2:</span>
            <span class="hljs-string">if</span> <span class="hljs-string">snakeX</span> <span class="hljs-string">&lt;</span> <span class="hljs-attr">self.nColumns - 1:</span>
                <span class="hljs-string">if</span> <span class="hljs-string">self.screenMap[snakeY][snakeX</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">]</span> <span class="hljs-string">==</span> <span class="hljs-attr">0.5:</span>
                    <span class="hljs-string">gameOver</span> <span class="hljs-string">=</span> <span class="hljs-literal">True</span>
                    <span class="hljs-string">reward</span> <span class="hljs-string">=</span> <span class="hljs-string">self.negReward</span>
                <span class="hljs-string">elif</span> <span class="hljs-string">self.screenMap[snakeY][snakeX</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">]</span> <span class="hljs-string">==</span> <span class="hljs-attr">1:</span>
                    <span class="hljs-string">reward</span> <span class="hljs-string">=</span> <span class="hljs-string">self.posReward</span>
                    <span class="hljs-string">self.moveSnake((snakeY,</span> <span class="hljs-string">snakeX</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">),</span> <span class="hljs-literal">True</span><span class="hljs-string">)</span>
                <span class="hljs-string">elif</span> <span class="hljs-string">self.screenMap[snakeY][snakeX</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">]</span> <span class="hljs-string">==</span> <span class="hljs-attr">0:</span>
                    <span class="hljs-string">self.moveSnake((snakeY,</span> <span class="hljs-string">snakeX</span> <span class="hljs-string">+</span> <span class="hljs-number">1</span><span class="hljs-string">),</span> <span class="hljs-literal">False</span><span class="hljs-string">)</span>
            <span class="hljs-attr">else:</span>
                <span class="hljs-string">gameOver</span> <span class="hljs-string">=</span> <span class="hljs-literal">True</span>
                <span class="hljs-string">reward</span> <span class="hljs-string">=</span> <span class="hljs-string">self.negReward</span> 
        
        <span class="hljs-string">elif</span> <span class="hljs-string">action</span> <span class="hljs-string">==</span> <span class="hljs-attr">3:</span>
            <span class="hljs-string">if</span> <span class="hljs-string">snakeX</span> <span class="hljs-string">&gt;</span> <span class="hljs-attr">0:</span>
                <span class="hljs-string">if</span> <span class="hljs-string">self.screenMap[snakeY][snakeX</span> <span class="hljs-bullet">-</span> <span class="hljs-number">1</span><span class="hljs-string">]</span> <span class="hljs-string">==</span> <span class="hljs-attr">0.5:</span>
                    <span class="hljs-string">gameOver</span> <span class="hljs-string">=</span> <span class="hljs-literal">True</span>
                    <span class="hljs-string">reward</span> <span class="hljs-string">=</span> <span class="hljs-string">self.negReward</span>
                <span class="hljs-string">elif</span> <span class="hljs-string">self.screenMap[snakeY][snakeX</span> <span class="hljs-bullet">-</span> <span class="hljs-number">1</span><span class="hljs-string">]</span> <span class="hljs-string">==</span> <span class="hljs-attr">1:</span>
                    <span class="hljs-string">reward</span> <span class="hljs-string">=</span> <span class="hljs-string">self.posReward</span>
                    <span class="hljs-string">self.moveSnake((snakeY,</span> <span class="hljs-string">snakeX</span> <span class="hljs-bullet">-</span> <span class="hljs-number">1</span><span class="hljs-string">),</span> <span class="hljs-literal">True</span><span class="hljs-string">)</span>
                <span class="hljs-string">elif</span> <span class="hljs-string">self.screenMap[snakeY][snakeX</span> <span class="hljs-bullet">-</span> <span class="hljs-number">1</span><span class="hljs-string">]</span> <span class="hljs-string">==</span> <span class="hljs-attr">0:</span>
                    <span class="hljs-string">self.moveSnake((snakeY,</span> <span class="hljs-string">snakeX</span> <span class="hljs-bullet">-</span> <span class="hljs-number">1</span><span class="hljs-string">),</span> <span class="hljs-literal">False</span><span class="hljs-string">)</span>
            <span class="hljs-attr">else:</span>
                <span class="hljs-string">gameOver</span> <span class="hljs-string">=</span> <span class="hljs-literal">True</span>
                <span class="hljs-string">reward</span> <span class="hljs-string">=</span> <span class="hljs-string">self.negReward</span>
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">Simply handle every <a id="_idIndexMarker593"/>single
 action in the same way you did with the action of going up. Check if 
the snake didn't hit the walls, check what lies ahead of the snake and 
update the snake's position, <code class="Code-In-Text--PACKT-">reward</code>, and <code class="Code-In-Text--PACKT-">gameOver</code> accordingly.</p>
			<p class="normal">There are two more steps in this method; let's jump straight into the first one:</p>
			<pre class="programlisting language-markup"><code class="hljs pf">        <span class="hljs-comment"># Drawing the screen, updating last move and waiting the wait time specified</span>
        <span class="hljs-literal">self</span>.drawScreen()
        
        <span class="hljs-literal">self</span>.lastMove = action
        
        pg.time.wait(<span class="hljs-literal">self</span>.waitTime)
</code></pre>
			
			
			
			
			
			<p class="normal">You update our screen by drawing the snake and the apple on it, then change <code class="Code-In-Text--PACKT-">lastMove</code> to <code class="Code-In-Text--PACKT-">action</code>, since your snake has already moved and now it's moving in the <code class="Code-In-Text--PACKT-">action</code> direction.</p>
			<p class="normal">The last step in this method is to return what the 
game looks like now, what the reward is that was obtained, and whether 
you've lost, like this:</p>
			<pre class="programlisting language-markup"><code class="hljs zephir">        <span class="hljs-comment"># Returning the new frame of the game, the reward obtained and whether the game has ended or not</span>
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">self</span>.screenMap, reward, gameOver
</code></pre>
			
			<p class="normal"><code class="Code-In-Text--PACKT-">screenMap</code> gives you the information you need about what the game looks like after performing an action, <code class="Code-In-Text--PACKT-">reward</code> gives you the collected reward from taking this action, and <code class="Code-In-Text--PACKT-">gameOver</code> tells you whether you lost or not.</p>
			<p class="normal">That's it for this<a id="_idIndexMarker594"/> method! To have a complete <code class="Code-In-Text--PACKT-">Environment</code> class, you only need to make a function that will reset the environment, like this <code class="Code-In-Text--PACKT-">reset</code> method:</p>
			<pre class="programlisting language-markup"><code class="hljs zephir">    <span class="hljs-comment"># Making a function that resets the environment</span>
    def reset(<span class="hljs-keyword">self</span>):
        <span class="hljs-keyword">self</span>.screenMap  = np.zeros((<span class="hljs-keyword">self</span>.nRows, <span class="hljs-keyword">self</span>.nColumns))
        <span class="hljs-keyword">self</span>.snakePos = <span class="hljs-keyword">list</span>()
        
        <span class="hljs-keyword">for</span> i in range(<span class="hljs-keyword">self</span>.initSnakeLen):
            <span class="hljs-keyword">self</span>.snakePos.append((<span class="hljs-keyword">int</span>(<span class="hljs-keyword">self</span>.nRows / <span class="hljs-number">2</span>) + i, <span class="hljs-keyword">int</span>(<span class="hljs-keyword">self</span>.nColumns / <span class="hljs-number">2</span>)))
            <span class="hljs-keyword">self</span>.screenMap[<span class="hljs-keyword">int</span>(<span class="hljs-keyword">self</span>.nRows / <span class="hljs-number">2</span>) + i][<span class="hljs-keyword">int</span>(<span class="hljs-keyword">self</span>.nColumns / <span class="hljs-number">2</span>)] = <span class="hljs-number">0.5</span>
        
        <span class="hljs-keyword">self</span>.screenMap[<span class="hljs-keyword">self</span>.applePos[<span class="hljs-number">0</span>]][<span class="hljs-keyword">self</span>.applePos[<span class="hljs-number">1</span>]] = <span class="hljs-number">1</span>
        
        <span class="hljs-keyword">self</span>.lastMove = <span class="hljs-number">0</span>
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">It simply resets the game board (<code class="Code-In-Text--PACKT-">screenMap</code>),
 as well as the snake's position, to the default, which is the middle of
 the board. It also sets the apple's position to the same as it was in 
the last round.</p>
			<p class="normal">Congratulations! You've just finished building the environment. Now, we'll proceed to the second step, building the brain.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_220" lang="en-GB"><a id="_idTextAnchor304"/>Step 2 – Building the brain</h3>
			<p class="normal">This is where you'll build our <a id="_idIndexMarker595"/>brain
 with a Convolutional Neural Network. You'll also set some parameters 
for its training and define a method that loads a pre-trained model for 
testing.</p>
			<p class="normal">Let's begin!</p>
			<p class="normal">As always, you start by importing the libraries that you'll use, like this:</p>
			<pre class="programlisting language-markup"><code class="hljs capnproto"><span class="hljs-comment"># Importing the libraries</span>
<span class="hljs-keyword">import</span> keras
<span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential, load_model
<span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Dense, Dropout, Conv2D, MaxPooling2D, Flatten
<span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> Adam
</code></pre>
			
			
			
			
			<p class="normal">As you've probably <a id="_idIndexMarker596"/>noticed, all of the classes are a part of the Keras library, which is the one you're going to use in this<a id="_idTextAnchor305"/>
 chapter. Keras is actually the only library that you'll use in this 
file. Let's go through each of these classes and methods right now:</p>
			<ol>
				<li class="list" value="1"><code class="Code-In-Text--PACKT-">Sequential</code> – A class that allows you to initialize a neural network, and defines the general structure of this network.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">load_model</code> – A function that loads a model from a file.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">Dense</code> – A class to create fully connected layers in an Artificial Neural Network (ANN).</li>
				<li class="list"><code class="Code-In-Text--PACKT-">Dropout</code> – A class that adds dropout to our network. You've seen it used already, in <em class="italics">Chapter 8</em>, <em class="italics">AI for Logistics – Robots in a Warehouse</em>.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">Conv2D</code> – A class that builds convolution layers.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">MaxPooling2D</code> – A class that builds max pooling layers.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">Flatten</code> – A class that performs flattening, so that you'll have an input for a classic ANN.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">Adam</code> – An optimizer, which will optimize your neural network. It's used when training the CNN.</li>
			</ol>
			<p class="normal">Now you've imported your library, you can continue by creating a class called <code class="Code-In-Text--PACKT-">Brain</code>, where all these classes and methods are used. Start by defining a class and the <code class="Code-In-Text--PACKT-">__init__</code> method, like this:</p>
			<pre class="programlisting language-markup"><code class="hljs ruby"><span class="hljs-comment"># Creating the Brain class</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Brain</span>():</span>
    
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, iS = (<span class="hljs-number">100</span>,<span class="hljs-number">100</span>,<span class="hljs-number">3</span>)</span></span>, lr = <span class="hljs-number">0</span>.<span class="hljs-number">0005</span>):
        
        <span class="hljs-keyword">self</span>.learningRate = lr
        <span class="hljs-keyword">self</span>.inputShape = iS
        <span class="hljs-keyword">self</span>.numOutputs = <span class="hljs-number">4</span>
        <span class="hljs-keyword">self</span>.model = Sequential()
</code></pre>
			
			
			
			
			
			
			
			
			<p class="normal">You can see that the <code class="Code-In-Text--PACKT-">__init__</code> method takes two arguments: <code class="Code-In-Text--PACKT-">iS</code> (input shape) and <code class="Code-In-Text--PACKT-">lr</code> (learning rate). Then <a id="_idIndexMarker597"/>you define some variables that will be associated with this class: <code class="Code-In-Text--PACKT-">learningRate</code>, <code class="Code-In-Text--PACKT-">inputShape</code>, <code class="Code-In-Text--PACKT-">numOutputs</code>. Set <code class="Code-In-Text--PACKT-">numOutputs</code> to <code class="Code-In-Text--PACKT-">4</code>, as this is how many actions our AI can take. Then, in the last line, create an empty model. To do this, use the <code class="Code-In-Text--PACKT-">Sequential</code> class, which we imported earlier.</p>
			<p class="normal">Doing this will allow you to add all the layers that you need to the model. That's exactly what you do with these lines:</p>
			<pre class="programlisting language-markup"><code class="hljs dockerfile">       <span class="hljs-comment"># Adding layers to the model   #20</span>
        self.model.<span class="hljs-keyword">add</span><span class="bash">(Conv2D(32, (3,3), activation = <span class="hljs-string">'relu'</span>, input_shape = self.inputShape))   <span class="hljs-comment">#21</span></span>
        <span class="hljs-comment">#22</span>
        self.model.<span class="hljs-keyword">add</span><span class="bash">(MaxPooling2D((2,2)))   <span class="hljs-comment">#23</span></span>
        <span class="hljs-comment">#24</span>
        self.model.<span class="hljs-keyword">add</span><span class="bash">(Conv2D(64, (2,2), activation = <span class="hljs-string">'relu'</span>))   <span class="hljs-comment">#25</span></span>
        <span class="hljs-comment">#26</span>
        self.model.<span class="hljs-keyword">add</span><span class="bash">(Flatten())   <span class="hljs-comment">#27</span></span>
        <span class="hljs-comment">#28</span>
        self.model.<span class="hljs-keyword">add</span><span class="bash">(Dense(units = 256, activation = <span class="hljs-string">'relu'</span>))   <span class="hljs-comment">#29</span></span>
        <span class="hljs-comment">#30</span>
        self.model.<span class="hljs-keyword">add</span><span class="bash">(Dense(units = self.numOutputs))   <span class="hljs-comment">#31</span></span>
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">Let's break this code down into lines:</p>
			<p class="normal"><strong class="bold">Line 21</strong>: You add a 
new convolution layer to your model. It has 32 3x3 filters with the ReLU
 activation function. You need to specify the input shape here as well. 
Remember that the input shape is one of the arguments of this function, 
and is saved under the <code class="Code-In-Text--PACKT-">inputShape</code> variable.</p>
			<p class="normal"><strong class="bold">Line 23</strong>: You add a max pooling layer. The window's size is 2x2, which will shrink our feature maps in size by <code class="Code-In-Text--PACKT-">2</code>.</p>
			<p class="normal"><strong class="bold">Line 25</strong>: You add the 
second convolution layer. This time it has 64 2x2 filters, with the same
 ReLU activation function. Why ReLU this time? I tried some other 
activation functions experimentally, and it turned out that for this AI 
ReLU worked the best.</p>
			<p class="normal"><strong class="bold">Line 27</strong>: Having 
applied convolution, you receive new feature maps, which you flatten to a
 1D vector. That's exactly what this line does – it flattens 2D images 
to a 1D vector, which you'll then be able to use as the input to your 
neural network.</p>
			<p class="normal"><strong class="bold">Line 29</strong>: Now, you're 
in the full connection step – you're building the traditional ANN. This 
specific line adds a new hidden layer with <code class="Code-In-Text--PACKT-">256</code> neurons and the ReLU activation function to our model.</p>
			<p class="normal"><strong class="bold">Line 31</strong>: You create 
the last layer in your neural network – the output layer. How big is it?
 Well, it has to have as many neurons as there are actions that you can 
take. You put that value under the <code class="Code-In-Text--PACKT-">numOutputs</code> variable earlier, and the value is equal to <code class="Code-In-Text--PACKT-">4</code>.
 You don't specify the activation function here, which means that the 
activation function will be linear as a default. It turns out that in 
this case, during training, using a linear output works better than a 
Softmax output; it makes the training more efficient.</p>
			<p class="normal">You also have to <code class="Code-In-Text--PACKT-">compile</code>
 your model. This will tell your code how to calculate the error, and 
which optimizer to use when training your model. You can do it with this
 single line:</p>
			<pre class="programlisting language-markup"><code class="hljs zephir">        <span class="hljs-comment"># Compiling the model</span>
        <span class="hljs-keyword">self</span>.model.compile(loss = <span class="hljs-string">'mean_squared_error'</span>, optimizer = Adam(lr = <span class="hljs-keyword">self</span>.learningRate))
</code></pre>
			
			<p class="normal">Here, you use a method<a id="_idIndexMarker598"/> that's a part of the <code class="Code-In-Text--PACKT-">Sequential</code> class (that's why you can use your model to call it) to do just that. The method is called <code class="Code-In-Text--PACKT-">compile</code> and, in this case, takes two arguments. <code class="Code-In-Text--PACKT-">loss</code> is a function that tells the AI how to calculate the error of your neural network; you'll use <code class="Code-In-Text--PACKT-">mean_squared_error</code>. The second parameter is the optimizer. You've already imported the <code class="Code-In-Text--PACKT-">Adam</code> optimizer, and you use it here. The learning rate for this optimizer was one of the arguments of the <code class="Code-In-Text--PACKT-">__init__</code> method of this class, and its value is represented by the <code class="Code-In-Text--PACKT-">learningRate</code> variable.</p>
			<p class="normal">There's only one step left to do in this class – make a function that will load a model from a file. You do it with this code:</p>
			<pre class="programlisting language-markup"><code class="hljs ruby">    <span class="hljs-comment"># Making a function that will load a model from a file</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loadModel</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, filepath)</span></span>:
        <span class="hljs-keyword">self</span>.model = load_model(filepath)
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">self</span>.model
</code></pre>
			
			
			
			<p class="normal">You can see that you've created a new function called <code class="Code-In-Text--PACKT-">loadModel</code>, which takes one argument – <code class="Code-In-Text--PACKT-">filepath</code>.
 This parameter is the file path to the pre-trained model. Once you've 
defined the function, you can actually load the model from this file 
path. To do so, you use the <code class="Code-In-Text--PACKT-">load_model</code> method, which you imported earlier. This function takes the same argument – <code class="Code-In-Text--PACKT-">filepath</code>. Then in the final line, you return the loaded model. </p>
			<p class="normal">Congratulations! You've just finished building the brain. </p>
			<p class="normal">Let's advance on our path, and build the experience replay memory.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_221" lang="en-GB"><a id="_idTextAnchor306"/>Step 3 – Building the experience replay memory</h3>
			<p class="normal">You'll build this memory <a id="_idIndexMarker599"/>now,
 and later, you'll train your model from small batches of this memory. 
The memory will contain information about the game state before taking 
the action, the action that was taken, the reward gained, and the game 
state after performing the action.</p>
			<p class="normal">I have some excellent news for you – do you remember this code?</p>
			<pre class="programlisting language-markup"><code class="hljs oxygene"># AI <span class="hljs-keyword">for</span> Games - Beat the Snake game
# Implementing Deep Q-Learning <span class="hljs-keyword">with</span> Experience Replay

# Importing the libraries
import numpy <span class="hljs-keyword">as</span> np

# IMPLEMENTING DEEP Q-LEARNING <span class="hljs-keyword">WITH</span> EXPERIENCE REPLAY

<span class="hljs-keyword">class</span> Dqn(object):
    
    # INTRODUCING <span class="hljs-keyword">AND</span> INITIALIZING ALL THE PARAMETERS <span class="hljs-keyword">AND</span> VARIABLES <span class="hljs-keyword">OF</span> THE DQN
    def __init__(<span class="hljs-keyword">self</span>, max_memory = <span class="hljs-number">100</span>, discount = <span class="hljs-number">0.9</span>):
        <span class="hljs-keyword">self</span>.memory = list()
        <span class="hljs-keyword">self</span>.max_memory = max_memory
        <span class="hljs-keyword">self</span>.discount = discount

    # MAKING A <span class="hljs-function"><span class="hljs-keyword">METHOD</span> <span class="hljs-title">THAT</span> <span class="hljs-title">BUILDS</span> <span class="hljs-title">THE</span> <span class="hljs-title">MEMORY</span> <span class="hljs-title">IN</span> <span class="hljs-title">EXPERIENCE</span> <span class="hljs-title">REPLAY</span>
    <span class="hljs-title">def</span> <span class="hljs-title">remember</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, transition, game_over)</span>:</span>
        <span class="hljs-keyword">self</span>.memory.append([transition, game_over])
        <span class="hljs-keyword">if</span> len(<span class="hljs-keyword">self</span>.memory) &gt; <span class="hljs-keyword">self</span>.max_memory:
            del <span class="hljs-keyword">self</span>.memory[<span class="hljs-number">0</span>]

    # MAKING A <span class="hljs-function"><span class="hljs-keyword">METHOD</span> <span class="hljs-title">THAT</span> <span class="hljs-title">BUILDS</span> <span class="hljs-title">TWO</span> <span class="hljs-title">BATCHES</span> <span class="hljs-title">OF</span> <span class="hljs-title">INPUTS</span> <span class="hljs-title">AND</span> <span class="hljs-title">TARGETS</span> <span class="hljs-title">BY</span> <span class="hljs-title">EXTRACTING</span> <span class="hljs-title">TRANSITIONS</span> <span class="hljs-title">FROM</span> <span class="hljs-title">THE</span> <span class="hljs-title">MEMORY</span>
    <span class="hljs-title">def</span> <span class="hljs-title">get_batch</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, model, batch_size = 10)</span>:</span>
        len_memory = len(<span class="hljs-keyword">self</span>.memory)
        num_inputs = <span class="hljs-keyword">self</span>.memory[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].shape[<span class="hljs-number">1</span>]
        num_outputs = model.output_shape[-<span class="hljs-number">1</span>]
        inputs = np.zeros((min(len_memory, batch_size), num_inputs))
        targets = np.zeros((min(len_memory, batch_size), num_outputs))
        <span class="hljs-keyword">for</span> i, idx <span class="hljs-keyword">in</span> enumerate(np.random.randint(<span class="hljs-number">0</span>, len_memory, size = min(len_memory, batch_size))):
            current_state, action, reward, next_state = <span class="hljs-keyword">self</span>.memory[idx][<span class="hljs-number">0</span>]
            game_over = <span class="hljs-keyword">self</span>.memory[idx][<span class="hljs-number">1</span>]
            inputs[i] = current_state
            targets[i] = model.predict(current_state)[<span class="hljs-number">0</span>]
            Q_sa = np.max(model.predict(next_state)[<span class="hljs-number">0</span>])
            <span class="hljs-keyword">if</span> game_over:
                targets[i, action] = reward
            <span class="hljs-keyword">else</span>:
                targets[i, action] = reward + <span class="hljs-keyword">self</span>.discount * Q_sa
        return inputs, targets
</code></pre>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<p class="normal">You'll use almost the same code, with only two small changes.</p>
			<p class="normal">First, you get rid of this line:</p>
			<pre class="programlisting language-markup"><code class="hljs lsl">        num_inputs = self.memory[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].shape[<span class="hljs-number">1</span>]
</code></pre>
			<p class="normal">And then change this line:</p>
			<pre class="programlisting language-markup"><code class="hljs scilab">        inputs = np.<span class="hljs-built_in">zeros</span>((<span class="hljs-built_in">min</span>(len_memory, batch_size), num_inputs))
</code></pre>
			<p class="normal">To this one:</p>
			<pre class="programlisting language-markup"><code class="hljs lsl">        inputs = np.zeros((min(len_memory, batch_size), self.memory[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].shape[<span class="hljs-number">1</span>],self.memory[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].shape[<span class="hljs-number">2</span>],self.memory[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].shape[<span class="hljs-number">3</span>]))
</code></pre>
			<p class="normal">Why did you have<a id="_idIndexMarker600"/> to do this? Well, you got rid of the first line since you no longer have a 1D vector of inputs. Now you have a 3D array.</p>
			<p class="normal">Then, if you look closely, you'll see that you didn't actually change <code class="Code-In-Text--PACKT-">inputs</code>.
 Before, you had a 2D array, one dimension of which was batch size and 
the other of which was number of inputs. Now, things are very similar; 
the first dimension is once again the batch size, and the last three 
correspond to the size of the input as well!</p>
			<p class="normal">Since our input is now a 3D array, you wrote <code class="Code-In-Text--PACKT-">.shape[1]</code>, <code class="Code-In-Text--PACKT-">.shape[2]</code>, and <code class="Code-In-Text--PACKT-">.shape[3]</code>. What exactly are those shapes?</p>
			<p class="normal"><code class="Code-In-Text--PACKT-">.shape[1]</code> is the number of rows in the game (in your case 10). <code class="Code-In-Text--PACKT-">.shape[2]</code> is the number of columns in the game (in your case 10). <code class="Code-In-Text--PACKT-">.shape[3]</code> is the number of last frames stacked onto each other (in your case 4).</p>
			<p class="normal">As you can see, you didn't really change anything. You just made the code work for our 3D inputs.</p>
			<p class="normal">I also renamed this <code class="Code-In-Text--PACKT-">dqn.py</code> file to <code class="Code-In-Text--PACKT-">DQN.py</code> and renamed the class <code class="Code-In-Text--PACKT-">DQN</code> to <code class="Code-In-Text--PACKT-">Dqn</code>.</p>
			<p class="normal">That's that! That was probably much simpler than most of you expected it to be.</p>
			<p class="normal">You can finally start training your model. We'll do that in the next section – training the AI.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_222" lang="en-GB"><a id="_idTextAnchor307"/>Step 4 – Training the AI</h3>
			<p class="normal">This is, by far, the<a id="_idIndexMarker601"/> most important step. Here we finally teach our AI to play Snake!</p>
			<p class="normal">As always, start by importing the libraries you need:</p>
			<pre class="programlisting language-markup"><code class="hljs haskell"><span class="hljs-meta"># Importing the libraries</span>
<span class="hljs-title">from</span> environment <span class="hljs-keyword">import</span> Environment
<span class="hljs-title">from</span> brain <span class="hljs-keyword">import</span> Brain
<span class="hljs-title">from</span> <span class="hljs-type">DQN</span> <span class="hljs-keyword">import</span> Dqn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
</code></pre>
			
			
			
			
			
			<p class="normal">In the first three lines you import the tools that you created earlier, including the <code class="Code-In-Text--PACKT-">Brain</code>, the <code class="Code-In-Text--PACKT-">Environment</code>, and the experience replay memory.</p>
			<p class="normal">Then, in the following two lines, you import the 
libraries that you'll use. These include NumPy and Matplotlib. You'll 
already recognize the former; the latter will be used to display your 
model's performance. To be specific, it will help you display a graph 
that, every 100 games, will show you the average number of 
apples collected.</p>
			<p class="normal">That's all for this step. Now, define some hyperparameters for your code:</p>
			<pre class="programlisting language-markup"><code class="hljs ini"><span class="hljs-comment"># Defining the parameters</span>
<span class="hljs-attr">memSize</span> = <span class="hljs-number">60000</span>
<span class="hljs-attr">batchSize</span> = <span class="hljs-number">32</span>
<span class="hljs-attr">learningRate</span> = <span class="hljs-number">0.0001</span>
<span class="hljs-attr">gamma</span> = <span class="hljs-number">0.9</span>
<span class="hljs-attr">nLastStates</span> = <span class="hljs-number">4</span>

<span class="hljs-attr">epsilon</span> = <span class="hljs-number">1</span>.
<span class="hljs-attr">epsilonDecayRate</span> = <span class="hljs-number">0.0002</span>
<span class="hljs-attr">minEpsilon</span> = <span class="hljs-number">0.05</span>

<span class="hljs-attr">filepathToSave</span> = <span class="hljs-string">'model2.h5'</span>
</code></pre>
			
			
			
			
			
			
			
			
			
			<p class="normal">I'll explain them in this list:</p>
			<ol>
				<li class="list" value="1"> <code class="Code-In-Text--PACKT-">memSize</code> – The maximum size of your experience replay memory.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">batchSize</code>
 – The size of the batch of inputs and targets that you get at each 
iteration from your experience replay memory for your model to train on.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">learningRate</code> – The learning rate for your <code class="Code-In-Text--PACKT-">Adam</code> optimizer in the <code class="Code-In-Text--PACKT-">Brain</code>.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">gamma</code> – The discount factor for your experience replay memory.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">nLastStates</code> – How many last frames you save as your current state of the game. Remember, you'll input a 3D array of size <code class="Code-In-Text--PACKT-">nRows</code> x <code class="Code-In-Text--PACKT-">nColumns</code> x <code class="Code-In-Text--PACKT-">nLastStates</code> to your CNN in the <code class="Code-In-Text--PACKT-">Brain</code>.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">epsilon</code> – The initial epsilon, the chance of taking a random action.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">epsilonDecayRate</code> – By how much you decrease <code class="Code-In-Text--PACKT-">epsilon</code> after every single game/epoch.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">minEpsilon</code> – The lowest possible epsilon, after which it can't be adjusted any lower.</li>
				<li class="list"><code class="Code-In-Text--PACKT-">filepathToSave</code> – Where you want to save your model.</li>
			</ol>
			<p class="normal">There you go – you've<a id="_idIndexMarker602"/>
 defined the hyperparameters. You'll use them later when you write the 
rest of the code. Now, you have to create an environment, a brain, and 
an experience replay memory:</p>
			<pre class="programlisting language-markup"><code class="hljs ini"><span class="hljs-comment"># Creating the Environment, the Brain and the Experience Replay Memory</span>
<span class="hljs-attr">env</span> = Environment(<span class="hljs-number">0</span>)
<span class="hljs-attr">brain</span> = Brain((env.nRows, env.nColumns, nLastStates), learningRate)
<span class="hljs-attr">model</span> = brain.model
<span class="hljs-attr">dqn</span> = Dqn(memSize, gamma)
</code></pre>
			
			
			
			
			<p class="normal">You can see that in the first line you create an object of the <code class="Code-In-Text--PACKT-">Environment</code>
 class. You need to specify one variable here, which is the slowdown of 
your environment (wait time between moves). You don't want any slowdown 
during the training, so you input <code class="Code-In-Text--PACKT-">0</code> here.</p>
			<p class="normal">In the next line you create an object of the <code class="Code-In-Text--PACKT-">Brain</code>
 class. It takes two arguments – the input shape and the learning rate. 
As I've mentioned multiple times, the input shape will be a 3D array of 
size <code class="Code-In-Text--PACKT-">nRows</code> x <code class="Code-In-Text--PACKT-">nColumns</code> x <code class="Code-In-Text--PACKT-">nLastStates</code>,
 so that's what you type in here. The second argument is the learning 
rate, and since you've created a variable for that, you simply input the
 name of this variable – <code class="Code-In-Text--PACKT-">learningRate</code>. After this line you take the model of this <code class="Code-In-Text--PACKT-">Brain</code> class and create an instance of this model in your code. Keep things simple, and call it <code class="Code-In-Text--PACKT-">model</code>.</p>
			<p class="normal">In the last line you create an object of the <code class="Code-In-Text--PACKT-">Dqn</code>
 class. It takes two arguments – the maximum size of the memory, and the
 discount factor for the memory. You've specified two variables, <code class="Code-In-Text--PACKT-">memSize</code> and <code class="Code-In-Text--PACKT-">gamma</code>, for just that, so you use them here.</p>
			<p class="normal">Now, you need to write a function that will reset 
the states for your AI. You need it because the states are quite 
complicated, and resetting them in the main code would mess it up a lot.
 Here's what it looks like:</p>
			<pre class="programlisting language-markup"><code class="hljs ruby"><span class="hljs-comment"># Making a function that will initialize game states   #30</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">resetStates</span><span class="hljs-params">()</span></span>:   <span class="hljs-comment">#31</span>
    currentState = np.zeros((<span class="hljs-number">1</span>, env.nRows, env.nColumns, nLastStates))   <span class="hljs-comment">#32</span>
    <span class="hljs-comment">#33</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(nLastStates):   <span class="hljs-comment">#34</span>
        currentState[<span class="hljs-symbol">:</span>,<span class="hljs-symbol">:</span>,<span class="hljs-symbol">:</span>,i] = env.screenMap   <span class="hljs-comment">#35</span>
    <span class="hljs-comment">#36</span>
    <span class="hljs-keyword">return</span> currentState, currentState   <span class="hljs-comment">#37</span>
</code></pre>
			
			
			
			
			
			
			
			<p class="normal">Let's break it down into separate lines:</p>
			<p class="normal"><strong class="bold">Line 31</strong>: You define a new function called <code class="Code-In-Text--PACKT-">resetStates</code>. It doesn't take any arguments.</p>
			<p class="normal"><strong class="bold">Line 32</strong>: You create a new array called <code class="Code-In-Text--PACKT-">currentState</code>.
 It's full of zeros, but you may ask why it's 4D; shouldn't the input be
 3D as we said? You're absolutely right, and it will be. The first 
dimension is called batch size and simply says how many inputs you input
 to your neural network at once. You'll only input one array at a time, 
so the first size is <code class="Code-In-Text--PACKT-">1</code>. The next three sizes<a id="_idIndexMarker603"/> correspond to the size of the input.</p>
			<p class="normal"><strong class="bold">Lines 34-35</strong>: In a <code class="Code-In-Text--PACKT-">for</code> loop, which will be executed <code class="Code-In-Text--PACKT-">nLastStates</code>
 times, you set the board for each layer in your 3D state to the 
current, initial look of the game board from your environment. Every 
frame in your state will look the same initially, the same way the board
 of the game looks when you start a game.</p>
			<p class="normal"><strong class="bold">Line 37</strong>: This function will return two <code class="Code-In-Text--PACKT-">currentStates</code>.
 Why? This is because you need two game state arrays. One to represent 
the board before you've taken an action, and one to represent the board 
after you've taken an action.</p>
			<p class="normal">Now you can start writing the code for the entire training. First, create a couple of useful variables, like this:</p>
			<pre class="programlisting language-markup"><code class="hljs ini"><span class="hljs-comment"># Starting the main loop</span>
<span class="hljs-attr">epoch</span> = <span class="hljs-number">0</span>
<span class="hljs-attr">scores</span> = list()
<span class="hljs-attr">maxNCollected</span> = <span class="hljs-number">0</span>
<span class="hljs-attr">nCollected</span> = <span class="hljs-number">0</span>.
<span class="hljs-attr">totNCollected</span> = <span class="hljs-number">0</span>
</code></pre>
			
			
			
			
			
			<p class="normal"><code class="Code-In-Text--PACKT-">epoch</code> will tell you which epoch/game you're in right now. <code class="Code-In-Text--PACKT-">scores</code> is a list in which you save the average scores per game after every 100 games/epochs. <code class="Code-In-Text--PACKT-">maxNCollected</code> tells you the highest score obtained so far in the training, while <code class="Code-In-Text--PACKT-">nCollected</code> is the score in each game/epoch. The last variable, <code class="Code-In-Text--PACKT-">totNCollected</code>, tells you how many apples you've collected over 100 epochs/games.</p>
			<p class="normal">Now you start an important, infinite <code class="Code-In-Text--PACKT-">while</code> loop, like this:</p>
			<pre class="programlisting language-markup"><code class="hljs yaml"><span class="hljs-attr">while True:</span>
    <span class="hljs-comment"># Resetting the environment and game states</span>
    <span class="hljs-string">env.reset()</span>
    <span class="hljs-string">currentState,</span> <span class="hljs-string">nextState</span> <span class="hljs-string">=</span> <span class="hljs-string">resetStates()</span>
    <span class="hljs-string">epoch</span> <span class="hljs-string">+=</span> <span class="hljs-number">1</span>
    <span class="hljs-string">gameOver</span> <span class="hljs-string">=</span> <span class="hljs-literal">False</span>
</code></pre>
			
			
			
			
			
			<p class="normal">Here, you iterate through every game, every epoch. That's why you restart the environment in the first line, create new <code class="Code-In-Text--PACKT-">currentState</code> and <code class="Code-In-Text--PACKT-">nextState</code> in the next line, increase <code class="Code-In-Text--PACKT-">epoch</code> by one, and set <code class="Code-In-Text--PACKT-">gameOver</code> to <code class="Code-In-Text--PACKT-">False</code> as you obviously haven't lost yet.</p>
			<p class="normal">Note that this loop <a id="_idIndexMarker604"/>doesn't
 end; therefore, the training never stops. We do it this way because we 
don't have a set goal for when to stop the training, since we haven't 
defined what a satisfactory result for our AI would be. We could 
calculate the average result, or a similar metric, but then training 
might take too long. I prefer to keep the training going and you can 
just stop the training whenever you want. A good time to stop is when 
the AI reaches an average of six apples per game, or you can even go up 
to 12 apples per game if you want better performance.</p>
			<p class="normal">You've started the first loop that will iterate 
through every epoch. Now you need to create the second loop, where the 
AI performs actions, updates the environment, and trains your CNN. Start
 it with these lines:</p>
			<pre class="programlisting language-markup"><code class="hljs properties"><span class="hljs-comment">    # Starting the second loop in which we play the game and teach our AI</span>
    <span class="hljs-attr">while</span> <span class="hljs-string">not gameOver: </span>
<span class="hljs-comment">        
        # Choosing an action to play</span>
        <span class="hljs-attr">if</span> <span class="hljs-string">np.random.rand() &lt; epsilon:</span>
            <span class="hljs-attr">action</span> = <span class="hljs-string">np.random.randint(0, 4)</span>
        <span class="hljs-attr">else</span>:<span class="hljs-string"/>
            <span class="hljs-attr">qvalues</span> = <span class="hljs-string">model.predict(currentState)[0]</span>
            <span class="hljs-attr">action</span> = <span class="hljs-string">np.argmax(qvalues)</span>
</code></pre>
			
			
			
			
			
			
			
			
			<p class="normal">As I mentioned, this is the loop in which your AI 
makes decisions, moves, and updates the environment. You start off by 
initializing a <code class="Code-In-Text--PACKT-">while</code> loop that will be executed as long as you haven't lost; that is, as long as <code class="Code-In-Text--PACKT-">gameOver</code> is set to <code class="Code-In-Text--PACKT-">False</code>.</p>
			<p class="normal">Then, you can see <code class="Code-In-Text--PACKT-">if</code>
 conditions. This is where your AI will make decisions. If a random 
value from range (0,1) is lower than the epsilon, then a random action 
will be performed. Otherwise, you predict the Q-values based on the 
current state of the game and from these Q-values you take the index 
with the highest Q-value. This will be the action performed by your AI.</p>
			<p class="normal">Then, you have to update your environment:</p>
			<pre class="programlisting language-markup"><code class="hljs pf">        <span class="hljs-comment"># Updating the environment</span>
        <span class="hljs-keyword">state</span>, reward, gameOver = env.step(action)
</code></pre>
			
			<p class="normal">You use the <code class="Code-In-Text--PACKT-">step</code> method from your <code class="Code-In-Text--PACKT-">Environment</code> class object. It takes one argument, which is the action<a id="_idIndexMarker605"/>
 that you perform. It also returns the new frame obtained from your game
 after performing this action along with the reward obtained and the 
game over information. You'll use these variables soon.</p>
			<p class="normal">Keep in mind, that this method returns a single 2D frame from your game. This means that you have to add this new frame to your <code class="Code-In-Text--PACKT-">nextState</code> and remove the last one. You do this with these lines:</p>
			<pre class="programlisting language-markup"><code class="hljs pf">        <span class="hljs-comment"># Adding new game frame to the next state and deleting the oldest frame from next state</span>
        <span class="hljs-keyword">state</span> = np.reshape(<span class="hljs-keyword">state</span>, (<span class="hljs-number">1</span>, env.nRows, env.nColumns, <span class="hljs-number">1</span>))
        nextState = np.append(nextState, <span class="hljs-keyword">state</span>, axis = <span class="hljs-number">3</span>)
        nextState = np.delete(nextState, <span class="hljs-number">0</span>, axis = <span class="hljs-number">3</span>)
</code></pre>
			
			
			
			<p class="normal">As you can see, first you reshape <code class="Code-In-Text--PACKT-">state</code> because it is 2D, while both <code class="Code-In-Text--PACKT-">currentState</code> and <code class="Code-In-Text--PACKT-">nextState</code> are 4D. Then you add this new, reshaped frame to <code class="Code-In-Text--PACKT-">nextState</code>
 along the 3rd axis. Why 3rd? That's because the 3rd index refers to the
 4th dimension of this array, which keeps the 2D frames inside. In the 
last line you simply delete the first frame from <code class="Code-In-Text--PACKT-">nextState</code>, which has index 0 (the oldest frames are kept on the lowest indexes).</p>
			<p class="normal">Now, you can <code class="Code-In-Text--PACKT-">remember</code>
 this transition in your experience replay memory, and train your model 
from a random batch of this memory. You do that with these lines:</p>
			<pre class="programlisting language-markup"><code class="hljs reasonml">        # Remembering the transition <span class="hljs-keyword">and</span> training our AI
        dqn.remember(<span class="hljs-literal">[<span class="hljs-identifier">currentState</span>, <span class="hljs-identifier">action</span>, <span class="hljs-identifier">reward</span>, <span class="hljs-identifier">nextState</span>]</span>, gameOver)
        inputs, targets = dqn.get<span class="hljs-constructor">_batch(<span class="hljs-params">model</span>, <span class="hljs-params">batchSize</span>)</span>
        model.train<span class="hljs-constructor">_on_batch(<span class="hljs-params">inputs</span>, <span class="hljs-params">targets</span>)</span>
</code></pre>
			
			
			
			<p class="normal">In the first line, you append this transition to 
the memory. It contains information about the game state before taking 
the action (<code class="Code-In-Text--PACKT-">currentState</code>), the action that was taken (<code class="Code-In-Text--PACKT-">action</code>), the reward gained (<code class="Code-In-Text--PACKT-">reward</code>), and the game state after taking this action (<code class="Code-In-Text--PACKT-">nextState</code>). You also remember the <code class="Code-In-Text--PACKT-">gameOver</code>
 status. In the following two lines, you take a random batch of inputs 
and targets from your memory, and train your model on them.</p>
			<p class="normal">Having done that, you can check if your snake has collected an apple and update <code class="Code-In-Text--PACKT-">currentState</code>. You can do that with these lines:</p>
			<pre class="programlisting language-markup"><code class="hljs properties"><span class="hljs-comment">        # Checking whether we have collected an apple and updating the current state</span>
        <span class="hljs-attr">if</span> <span class="hljs-string">env.collected:</span>
            <span class="hljs-attr">nCollected</span> <span class="hljs-string">+= 1</span>
        
        <span class="hljs-attr">currentState</span> = <span class="hljs-string">nextState</span>
</code></pre>
			
			
			
			
			<p class="normal">In the first two lines, you check whether the snake has collected an apple and if it has, you increase <code class="Code-In-Text--PACKT-">nCollected</code>. Then you update <code class="Code-In-Text--PACKT-">currentState</code> by setting its values to the ones of <code class="Code-In-Text--PACKT-">nextState</code>.</p>
			<p class="normal">Now, you can quit this loop. You still have a couple of things to do:</p>
			<pre class="programlisting language-markup"><code class="hljs properties"><span class="hljs-comment">    # Checking if a record of apples eaten in a around was beaten and if yes then saving the model</span>
    <span class="hljs-attr">if</span> <span class="hljs-string">nCollected &gt; maxNCollected and nCollected &gt; 2:</span>
        <span class="hljs-attr">maxNCollected</span> = <span class="hljs-string">nCollected</span>
        <span class="hljs-attr">model.save(filepathToSave)</span>
    
    <span class="hljs-attr">totNCollected</span> <span class="hljs-string">+= nCollected</span>
    <span class="hljs-attr">nCollected</span> = <span class="hljs-string">0</span>
</code></pre>
			
			
			
			
			
			
			<p class="normal">You check if you've beaten<a id="_idIndexMarker606"/>
 the record for the number of apples eaten in a round (this number has 
to be bigger than 2) and if you did, you update the record and save your
 current model to the file path you specified before. You also increase <code class="Code-In-Text--PACKT-">totNCollected</code> and reset <code class="Code-In-Text--PACKT-">nCollected</code> to 0 for the next game.</p>
			<p class="normal">Then, after 100 games, you show the average score, like this:</p>
			<pre class="programlisting language-markup"><code class="hljs yaml">    <span class="hljs-comment"># Showing the results each 100 games</span>
    <span class="hljs-string">if</span> <span class="hljs-string">epoch</span> <span class="hljs-string">%</span> <span class="hljs-number">100</span> <span class="hljs-string">==</span> <span class="hljs-number">0</span> <span class="hljs-string">and</span> <span class="hljs-string">epoch</span> <span class="hljs-string">!=</span> <span class="hljs-attr">0:</span>
        <span class="hljs-string">scores.append(totNCollected</span> <span class="hljs-string">/</span> <span class="hljs-number">100</span><span class="hljs-string">)</span>
        <span class="hljs-string">totNCollected</span> <span class="hljs-string">=</span> <span class="hljs-number">0</span>
        <span class="hljs-string">plt.plot(scores)</span>
        <span class="hljs-string">plt.xlabel('Epoch</span> <span class="hljs-string">/</span> <span class="hljs-number">100</span><span class="hljs-string">')
        plt.ylabel('</span><span class="hljs-string">Average</span> <span class="hljs-string">Score')</span>
        <span class="hljs-string">plt.savefig('stats.png')</span>
        <span class="hljs-string">plt.close()</span>
</code></pre>
			
			
			
			
			
			
			
			
			<p class="normal">You have a list called <code class="Code-In-Text--PACKT-">scores</code>, where you store the average score after 100 games. You append a new value to it and then reset this value. Then you show <code class="Code-In-Text--PACKT-">scores</code> on a graph, using the Matplotlib library that you imported before. This graph is saved in <code class="Code-In-Text--PACKT-">stats.png</code> every 100 games/epochs.</p>
			<p class="normal">Then you lower the epsilon, like so:</p>
			<pre class="programlisting language-markup"><code class="hljs properties"><span class="hljs-comment">    # Lowering the epsilon</span>
    <span class="hljs-attr">if</span> <span class="hljs-string">epsilon &gt; minEpsilon:</span>
        <span class="hljs-attr">epsilon</span> <span class="hljs-string">-= epsilonDecayRate</span>
</code></pre>
			
			
			<p class="normal">With the <code class="Code-In-Text--PACKT-">if</code> condition, you make sure that the epsilon doesn't go lower than the minimum threshold.</p>
			<p class="normal">In the last line, you display some additional information about every single game, like this:</p>
			<pre class="programlisting language-markup"><code class="hljs lisp">    # Showing the results each game
    print('Epoch: ' + str(<span class="hljs-name">epoch</span>) + ' Current Best: ' + str(<span class="hljs-name">maxNCollected</span>) + ' Epsilon: {:.<span class="hljs-number">5</span>f}'.format(<span class="hljs-name">epsilon</span>))
</code></pre>
			
			<p class="normal">You display the current epoch (game), the current record for the number of apples collected in one <a id="_idIndexMarker607"/>game, and the current epsilon.</p>
			<p class="normal">That's it! Congratulations! You've just built a 
function that will train your model. Remember that this training goes on
 infinitely until you decide it's finished. When you're satisfied with 
it, you'll want to test it. For that, you need a short file to test your
 model. Let's do it!</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_223" lang="en-GB"><a id="_idTextAnchor308"/>Step 5 – Testing the AI</h3>
			<p class="normal">This will be a very short section, so don't<a id="_idIndexMarker608"/> worry. You'll be running this code in just a moment!</p>
			<p class="normal">As always, you start by importing the libraries you need:</p>
			<pre class="programlisting language-markup"><code class="hljs capnproto"><span class="hljs-comment"># Importing the libraries</span>
<span class="hljs-keyword">from</span> environment <span class="hljs-keyword">import</span> Environment
<span class="hljs-keyword">from</span> brain <span class="hljs-keyword">import</span> Brain
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
</code></pre>
			
			
			
			<p class="normal">This time you won't be using the DQN memory nor the Matplotlib library, and therefore you don't import them.</p>
			<p class="normal">You also need to specify some hyperparameters, like this:</p>
			<pre class="programlisting language-markup"><code class="hljs ini"><span class="hljs-comment"># Defining the parameters</span>
<span class="hljs-attr">nLastStates</span> = <span class="hljs-number">4</span>
<span class="hljs-attr">filepathToOpen</span> = <span class="hljs-string">'model.h5'</span>
<span class="hljs-attr">slowdown</span> = <span class="hljs-number">75</span>
</code></pre>
			
			
			
			<p class="normal">You'll need <code class="Code-In-Text--PACKT-">nLastStates</code>
 later in this code. You also created a file path to the model that 
you'll test. Finally, there's also a variable that you'll use to specify
 the wait time after every move, so that you can clearly see how your AI
 performs.</p>
			<p class="normal">Once again, you create some useful objects, like an <code class="Code-In-Text--PACKT-">Environment</code> and a <code class="Code-In-Text--PACKT-">Brain</code>:</p>
			<pre class="programlisting language-markup"><code class="hljs reasonml"># Creating the Environment <span class="hljs-keyword">and</span> the Brain
env = <span class="hljs-constructor">Environment(<span class="hljs-params">slowdown</span>)</span>
brain = <span class="hljs-constructor">Brain((<span class="hljs-params">env</span>.<span class="hljs-params">nRows</span>, <span class="hljs-params">env</span>.<span class="hljs-params">nColumns</span>, <span class="hljs-params">nLastStates</span>)</span>)
model = brain.load<span class="hljs-constructor">Model(<span class="hljs-params">filepathToOpen</span>)</span>
</code></pre>
			
			
			
			<p class="normal">Into the brackets of the <code class="Code-In-Text--PACKT-">Environment</code>, you input the <code class="Code-In-Text--PACKT-">slowdown</code>, because that's the argument that this class takes. You also create an object of the <code class="Code-In-Text--PACKT-">Brain</code> class, but this time, you don't specify the learning rate, since you won't be training your model. In the final line you load <a id="_idIndexMarker609"/>a pre-trained model using the <code class="Code-In-Text--PACKT-">loadModel</code> method from the <code class="Code-In-Text--PACKT-">Brain</code> class. This method takes one argument, which is the file path from which you load the model.</p>
			<p class="normal">Once again, you need a function to reset states. You can use the same one as before, so just copy and paste these lines:</p>
			<pre class="programlisting language-markup"><code class="hljs ruby"><span class="hljs-comment"># Making a function that will reset game states</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">resetStates</span><span class="hljs-params">()</span></span>:
    currentState = np.zeros((<span class="hljs-number">1</span>, env.nRows, env.nColumns, nLastStates))
    
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(nLastStates):
        currentState[<span class="hljs-symbol">:</span>,<span class="hljs-symbol">:</span>,<span class="hljs-symbol">:</span>,i] = env.screenMap
   
    <span class="hljs-keyword">return</span> currentState, currentState
</code></pre>
			
			
			
			
			
			
			
			<p class="normal">Now, you can enter the main <code class="Code-In-Text--PACKT-">while</code> loop like before. This time, however, you won't define any variables, since you don't need any:</p>
			<pre class="programlisting language-markup"><code class="hljs zephir"><span class="hljs-comment"># Starting the main loop</span>
<span class="hljs-keyword">while</span> <span class="hljs-keyword">True</span>:
    <span class="hljs-comment"># Resetting the game and the game states</span>
    env.reset()
    currentState, nextState = resetStates()
    gameOver = <span class="hljs-keyword">False</span>
</code></pre>
			
			
			
			
			
			<p class="normal">As you can see, you've started this infinite <code class="Code-In-Text--PACKT-">while</code> loop. Once again, you have to restart the environment, the states, and the game over, every iteration.</p>
			<p class="normal">Now, you can enter the game's <code class="Code-In-Text--PACKT-">while</code> loop, where you take actions, update the environment, and so on:</p>
			<pre class="programlisting language-markup"><code class="hljs properties"><span class="hljs-comment">    # Playing the game</span>
    <span class="hljs-attr">while</span> <span class="hljs-string">not gameOver: </span>
<span class="hljs-comment">        
        # Choosing an action to play</span>
        <span class="hljs-attr">qvalues</span> = <span class="hljs-string">model.predict(currentState)[0]</span>
        <span class="hljs-attr">action</span> = <span class="hljs-string">np.argmax(qvalues)</span>
</code></pre>
			
			
			
			
			
			<p class="normal">This time, you don't need any <code class="Code-In-Text--PACKT-">if</code> statements. After all, you're testing your AI, so you mustn't have any random actions here.</p>
			<p class="normal">Once again, you update the environment:</p>
			<pre class="programlisting language-markup"><code class="hljs pf">        <span class="hljs-comment"># Updating the environment</span>
        <span class="hljs-keyword">state</span>, _, gameOver = env.step(action)
</code></pre>
			
			<p class="normal">You don't really care about the reward, so just place "<code class="Code-In-Text--PACKT-">_</code>" instead of <code class="Code-In-Text--PACKT-">reward</code>. The environment still returns the frame after taking an action, along with the information about game over.</p>
			<p class="normal">Due to this fact, you<a id="_idIndexMarker610"/> need to reshape your <code class="Code-In-Text--PACKT-">state</code> and update <code class="Code-In-Text--PACKT-">nextState</code> in the same way as before:</p>
			<pre class="programlisting language-markup"><code class="hljs pf">        <span class="hljs-comment"># Adding new game frame to next state and deleting the oldest one from next state</span>
        <span class="hljs-keyword">state</span> = np.reshape(<span class="hljs-keyword">state</span>, (<span class="hljs-number">1</span>, env.nRows, env.nColumns, <span class="hljs-number">1</span>))
        nextState = np.append(nextState, <span class="hljs-keyword">state</span>, axis = <span class="hljs-number">3</span>)
        nextState = np.delete(nextState, <span class="hljs-number">0</span>, axis = <span class="hljs-number">3</span>)
</code></pre>
			
			
			
			<p class="normal">In the final line, you need to update <code class="Code-In-Text--PACKT-">currentState</code> as you did in the other file:</p>
			<pre class="programlisting language-markup"><code class="hljs nginx">        <span class="hljs-comment"># Updating current state</span>
        <span class="hljs-attribute">currentState</span> = nextState
</code></pre>
			
			<p class="normal">That's the end of coding for this section! This isn't, however, the end of this chapter. You still have to run the code.</p>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_224" lang="en-GB"><a id="_idTextAnchor309"/>The demo</h2>
			<p class="normal">Unfortunately, due<a id="_idIndexMarker611"/> to PyGame not being supported by Google Colab, you'll need to use Anaconda.</p>
			<p class="normal">Thankfully, you should have it installed after <em class="italics">Chapter 10</em>, <em class="italics">AI for Autonomous Vehicles – Build a Self-Driving Car</em>, so it'll be easier to install the required packages and libraries.</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_225" lang="en-GB"><a id="_idTextAnchor310"/>Installation</h3>
			<p class="normal">First, create a new virtual environment inside 
Anaconda. This time, I'll walk you through the installation on the 
Anaconda Prompt from a PC, so that you can all see how it's done from 
any system.</p>
			<p class="normal">Windows users, please <a id="_idIndexMarker612"/>open the Anaconda Prompt on your PC, and Mac/Linux users, please open your Terminal on Mac/Linux. Then type:</p>
			<pre class="programlisting language-markup"><code class="hljs routeros">conda create -n snake <span class="hljs-attribute">python</span>=3.6
</code></pre>
			<p class="normal">Just like so:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_05.png" alt=""/></figure>
			<p class="normal">Then, hit <kbd class="Key--PACKT-">Enter</kbd> on your<a id="_idIndexMarker613"/> keyboard. You should get something more or less like this:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_06.png" alt=""/></figure>
			<p class="normal">Type <code class="Code-In-Text--PACKT-">y</code> on your keyboard and hit <kbd class="Key--PACKT-">Enter</kbd> once again. After everything gets installed, type this in your Anaconda Prompt:</p>
			<pre class="programlisting language-markup"><code class="hljs nginx"><span class="hljs-attribute">conda</span> activate snake
</code></pre>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_07.png" alt=""/></figure>
			<p class="normal">And hit <kbd class="Key--PACKT-">Enter</kbd> once <a id="_idIndexMarker614"/>again. Now on the left, you should see <strong class="screen-text">snake</strong> written instead of <strong class="screen-text">base</strong>. This means that you're in the newly created Anaconda environment.</p>
			<p class="normal">Now you need to install the required libraries. The first one i<a id="_idTextAnchor311"/>s Keras:</p>
			<pre class="programlisting language-markup"><code class="hljs llvm">conda install -<span class="hljs-keyword">c</span> conda-forge keras
</code></pre>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_08.png" alt=""/></figure>
			<p class="normal">After writing that, hit <kbd class="Key--PACKT-">Enter</kbd>. When you get this:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_09.png" alt=""/></figure>
			<p class="normal">Type <code class="Code-In-Text--PACKT-">y</code> once again and hit <kbd class="Key--PACKT-">Enter</kbd> once again. Once you have it installed, you need to install PyGame and Matplotlib.</p>
			<p class="normal">The first one can be<a id="_idIndexMarker615"/> installed by entering <code class="Code-In-Text--PACKT-">pip install pygame</code>, while the second one can be installed by entering <code class="Code-In-Text--PACKT-">pip install matplotlib</code>. The installation follows the same procedure as you just took to install Keras.</p>
			<p class="normal">Ok, now you can run your code!</p>
			<p class="normal">If you've accidentally closed your Anaconda Prompt/Terminal for any reason, re-open it and type in this to activate the <code class="Code-In-Text--PACKT-">snake</code> environment that we have just created:</p>
			<pre class="programlisting language-markup"><code class="hljs nginx"><span class="hljs-attribute">conda</span> activate snake
</code></pre>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_10.png" alt=""/></figure>
			<p class="normal">And then hit <kbd class="Key--PACKT-">Enter</kbd>. I got<a id="_idIndexMarker616"/> a bunch of warnings after doing this, and you may see similar warnings as well, but don't worry about them:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_11.png" alt=""/></figure>
			<p class="normal">Now, you need to navigate this console to the folder that contains the file you want to run, in this case <code class="Code-In-Text--PACKT-">train.py</code>. I recommend that you put all the code of <code class="Code-In-Text--PACKT-">Chapter 13</code> in one folder called <code class="Code-In-Text--PACKT-">Snake</code>
 on your desktop. Then you'll be able to follow the exact instructions 
that I'll give you now. To navigate to this folder, you'll need to use <code class="Code-In-Text--PACKT-">cd</code> commands.</p>
			<p class="normal">First, navigate to the desktop by running <code class="Code-In-Text--PACKT-">cd Desktop</code>, like this:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_12.png" alt=""/></figure>
			<p class="normal">And then enter<a id="_idIndexMarker617"/> the <code class="Code-In-Text--PACKT-">Snake</code> folder that you created. Just as with the previous command, run <code class="Code-In-Text--PACKT-">cd Snake</code>, like this:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_13.png" alt=""/></figure>
			<p class="normal">You're getting super close. To train a new model, you need to type:</p>
			<pre class="programlisting language-markup"><code class="hljs vim"><span class="hljs-keyword">python</span> train.<span class="hljs-keyword">py</span>
</code></pre>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_14.png" alt=""/></figure>
			<p class="normal">And hit <kbd class="Key--PACKT-">Enter</kbd>. This is more or less what you should see:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_15.png" alt=""/></figure>
			<p class="normal">You have both a <a id="_idIndexMarker618"/>window on the left with the game, and one on the right with the terminal informing you about every game (every epoch).</p>
			<p class="normal">Congratulations! You just smashed the code of this 
chapter and built an AI for Snake. Be patient with it though! Training 
it may take up a couple of hours.</p>
			<p class="normal">So, what kind of results can you expect?</p>
			<h3 class="title" xml:lang="en-GB" id="sigil_toc_id_226" lang="en-GB"><a id="_idTextAnchor312"/>The results</h3>
			<p class="normal">Firstly, make sure to<a id="_idIndexMarker619"/>
 follow the results also on your Anaconda Prompt/Terminal, epoch by 
epoch. An epoch is one game played. After thousands of games (epochs), 
you'll see the score increase, as well as the snake size increase.</p>
			<p class="normal">After thousands of epochs of training, while the 
snake doesn't fill in the entire map, your AI plays on a level 
comparable with humans. Here are some pictures after 25,000 epochs.</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_16.png" alt=""/></figure>
			<p class="packt_figref">Figure 5: Results example 1</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_17.png" alt=""/></figure>
			<p class="packt_figref">Figure 6: Results example 2</p>
			<p class="normal">You'll also get a graph<a id="_idIndexMarker620"/> created in the folder (<code class="Code-In-Text--PACKT-">stats.png</code>) showing the average score over the epochs. Here is the graph I got when training our AI over 25,000 epochs:</p>
			<figure class="mediaobject" xml:lang="en-GB" lang="en-GB"><img src="../Images/B14110_13_18.png" alt=""/></figure>
			<p class="packt_figref">Figure 7: Average score over 25,000 epochs</p>
			<p class="normal">You can see that our AI reached an average score of
 10-11 per game. This isn't bad considering that before training it knew
 absolutely nothing about the game.</p>
			<p class="normal">You can also see the <a id="_idIndexMarker621"/>same results if you run the <code class="Code-In-Text--PACKT-">test.py</code> file using the pre-trained model <code class="Code-In-Text--PACKT-">model.h5</code> attached to this chapter in GitHub. To do this, you simply need to enter in your Anaconda Prompt/Terminal (still in the same <code class="Code-In-Text--PACKT-">Snake</code> folder on your desktop that contains all the code of <code class="Code-In-Text--PACKT-">Chapter 13</code>, and still inside the <code class="Code-In-Text--PACKT-">snake</code> virtual environment):</p>
			<pre class="programlisting language-markup"><code class="hljs vim"><span class="hljs-keyword">python</span> test.<span class="hljs-keyword">py</span>
</code></pre>
			<p class="normal">If you want to test your model after training, you simply need to replace <code class="Code-In-Text--PACKT-">model.h5</code> with <code class="Code-In-Text--PACKT-">model2.h5</code> in the <code class="Code-In-Text--PACKT-">test.py</code> file. That's because during the training the weights of your AI's neural network will be saved into a file named <code class="Code-In-Text--PACKT-">model2.h5</code>. Then re-enter <code class="Code-In-Text--PACKT-">python test.py</code> in your Anaconda Prompt/Terminal, and enjoy your own results.</p>
			<h2 class="title" xml:lang="en-GB" id="sigil_toc_id_227" lang="en-GB"><a id="_idTextAnchor313"/>Summary</h2>
			<p class="normal">In this last practical chapter of the book, we 
built a deep convolutional Q-Learning model for Snake. Before we built 
anything, we had to define what our AI would see. We established that we
 needed to stack multiple frames, so that our AI would see the 
continuity of its moves. This was the input to our Convolutional Neural 
Network. The outputs were the Q-values corresponding to each of the four
 possible moves: going up, going down, going left, and going right. We 
rewarded our AI for eating an apple, punished it for losing, and 
punished it slightly for performing any action (the living penalty). 
Having run 25,000 games, we can see that our AI is able to eat 10-11 
apples per game.</p>
			<p class="normal">I hope you enjoyed it!</p>
</body></html>