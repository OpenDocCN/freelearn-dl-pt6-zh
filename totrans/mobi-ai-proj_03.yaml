- en: Implementing Deep Net Architectures to Recognize Handwritten Digits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we have been through the essential concepts and have
    set up tools that are required for us to get our journey into **Artificial Intelligence**
    (**AI**) started. We also built a small prediction app to get our feet wet with
    the tools we will be using.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to cover a more interesting and popular application
    of AI – Computer Vision, or Machine Vision. We will start by continuing from the
    previous chapter and ease into building **convolutional neural networks** (**CNN**),
    the most popular neural network type for Computer Vision. This chapter will also
    cover the essential concepts that were promised in [Chapter 1](1bfa8853-a79e-4b4a-aa9f-254392b158bb.xhtml), *Artificial
    Intelligence Concepts and Fundamentals*, but, in contrast, this chapter will have
    a very hands-on approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be covering the following topics in the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Building a feedforward neural network to recognize handwritten digits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remaining concepts of neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a deeper neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to computer vision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a feedforward neural network to recognize handwritten digits, version
    one
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will use the knowledge that we gained from the last two
    chapters to tackle a problem that has unstructured data – image classification.
    The idea is to take a dive into solving a Computer Vision task with the current
    setup and the basics of neural networks that we are familiar with. We have seen
    that feedforward neural networks can be used for prediction using structured data;
    let's try that on images to classify handwritten digits.
  prefs: []
  type: TYPE_NORMAL
- en: To solve this task, we are going to leverage the **MNSIT** database and use
    the handwritten digits dataset. MNSIT stands for **Modified National Institute
    of Standards and Technology**. It is a large database that's commonly used for
    training, testing, and benchmarking image-related tasks in Computer Vision.
  prefs: []
  type: TYPE_NORMAL
- en: The MNSIT digits dataset contains 60,000 images of handwritten digits, which
    are used for training the model, and 10,000 images of handwritten digits, which
    are used for testing the model.
  prefs: []
  type: TYPE_NORMAL
- en: From here out, we will be using Jupyter Notebook to understand and execute this
    task. So, please start your Jupyter Notebook and create a new Python Notebook
    if you have not already done so.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have your notebook ready, the first thing to do, as always, is to
    import all the necessary modules for the task at hand:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `numpy` and set the `seed` for reproducibility:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the Keras dependencies and the built-in MNSIT digits dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the data into the training and test sets, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the number of training images, along with the size of each image. In
    this case, the size of each image is 28 x 28 pixels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the dependent variable, in this case, 60,000 cases with the right label:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the labels for the first 100 training samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the number of test images, along with the size of each image. In this
    case, the size of each image is 28 x 28 pixels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the samples in the test data, which are basically 2D arrays of size 28
    x 28:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the dependent variable, in this case, 10,000 cases with the right label:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The right label for the previous first sample in the test set is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we need to pre-process the data by converting it from a 28 x 28 2D array
    into a normalized 1D array of 784 elements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the first sample of the pre-processed dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to one-hot code the labels; in other words, we need to convert
    the data type of the labels (zero to nine) from numeric into categorical:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'View the first sample of the label that has been one-hot coded. In this case,
    the number was seven:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we need to design our simple feedforward neural network with an input
    layer using the `sigmoid` activation function and 64 neurons. We will add a `softmax`
    function to the output layer, which does the classification by giving probabilities
    of the classified label:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We can look at the structure of the neural network we just designed using the
    `summary()` function, which is a simple network with an input layer of 64 neurons
    and an output layer with 10 neurons. The output layer has 10 neurons we have 10
    class labels to predict/classify (zero to nine):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to configure the model to use an optimizer, a cost function,
    and a metric to determine accuracy. Here, the optimizer that''s being used is
    **Scalar Gradient Descent (SGD)** with a learning rate of 0.01\. The loss function
    that''s being used is the algebraic **Mean Squared Error** (**MSE**), and the
    metric to measure the correctness of the model is `accuracy`, which is the probability
    score:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are ready to train the model. We want it to use 128 samples for every
    iteration of learning through the network, indicated by `batch_size`. We want
    each sample to iterate at least 200 times throughout the network, which is indicated
    by `epochs`. Also, we indicate the training and validation sets to be used. `Verbose`
    controls the output prints on the console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Train on 60,000 samples, and then validate on 10,000 samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can evaluate the model and how well the model predicts on the test
    dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This can be interpreted as having an error rate (MSE) of 0.027 and an accuracy
    of 0.865, which means it predicted the right label 86% of the time on the test
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Building a feedforward neural network to recognize handwritten digits, version
    two
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous section, we built a very simple neural network with just an
    input and output layer. This simple neural network gave us an accuracy of 86%.
    Let''s see if we can improve this accuracy further by building a neural network
    that is a little deeper than the previous version:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s do this on a new notebook. Loading the dataset and data pre-processing
    will be the same as in the previous section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The design of the neural network is slightly different from the previous version.
    We will add a hidden layer with 64 neurons to the network, along with the input
    and output layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Also, we will use the `relu` activation function for the input and hidden layer
    instead of the `sigmoid` function we used previously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can inspect the model design and architecture as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will configure the model to use the derivative `categorical_crossentropy` cost
    function rather than MSE. Also, the learning rate is increased from 0.01 to 0.1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will train the model, like we did in the previous examples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Train on 60,000 samples and validate on 10,000 samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, there is an increase in accuracy compared to the model we built
    in the first version.
  prefs: []
  type: TYPE_NORMAL
- en: Building a deeper neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will use the concepts we learned about in this chapter
    to build a deeper neural network to classify handwritten digits:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start with a new notebook and then load the required dependencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now load and pre-process the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will design a deeper neural architecture with measures to take care
    of overfitting and to provide better generalization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, we will configure the model using an `adam` optimizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will post that we will train the model for `200` epochs at a batch
    size of `128`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Train on 60,000 samples and validate on 10,000 samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Introduction to Computer Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Computer Vision can be defined as the subset of AI where we can teach a computer
    to *see*. We cannot just add a camera to a machine in order for it to *see*. For
    a machine to actually view the world like people or animals do, it relies on Computer
    Vision and image recognition techniques. Reading barcodes and face recognition
    are examples of Computer Vision. Computer Vision can be described as that part
    of the human brain that processes the information that's perceived by the eyes,
    nothing else.
  prefs: []
  type: TYPE_NORMAL
- en: Image recognition is one of the interesting uses of Computer Vision from an
    AI standpoint. The input that is received through Computer Vision on the machine
    is interpreted by the image recognition system, and based on what it sees, the
    output is classified.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, we use our eyes to capture the objects around us, and those
    objects/images are processed in our brain, which allows us to visualize the world
    around us. This capability is given by Computer Vision to machines. Computer Vision
    is responsible for automatically extracting, analyzing, and understanding the
    required information from the videos or images that are fed in as input.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are various Computer Vision application, and they are used in the following
    scenerios:'
  prefs: []
  type: TYPE_NORMAL
- en: Augmented reality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robotics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Biometrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pollution monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agriculture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Medical image analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forensics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geoscience
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autonomous vehicles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image restoration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Process control
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Character recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remote sensing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gesture analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security and surveillance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Face recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transport
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retail
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Industrial quality inspection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning for Computer Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's important to use the appropriate ML theories and tools, which will be very
    helpful when we need to develop various applications that involve classifying
    images, detecting objects, and so on. Utilizing  these theories to create computer
    vision applications requires an understanding of some basic machine learning concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Conferences help on Computer Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some of the conferences to look for latest research and applications are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Conference on Computer Vision and Pattern Recognition** (**CVPR**) is held
    every year and is one of the popular conferences with research papers ranging
    from both theory and application across a wide domain'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**International Conference on Computer Vision **(**ICCV**)is another major
    conference held every other year attracting one of the best research papers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Special Interest Group on Computer Graphics** (**SIGGRAPH**) and interactive
    techniques though more on computer graphics domain has several applications papers
    that utilizes computer vision techniques.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other notable conferences include **Neural Information Processing Systems** (**NIPS**), **International
    Conference on Machine Learning** (**ICML**), **Asian Conference on Computer Vision** (**ACCV**), **European
    Conference on Computer Vision** (**ECCV**), and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we built a feedforward neural network to recognize handwritten
    digits in two versions. Then, we built a neural network to classify handwritten
    digits, and, finally we gave a short introduction to Computer Vision.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will build a Machine Vision mobile app to classify flower
    species and retrieve the necessary information.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For in-depth knowledge on computer vision, do refer the following Packt books:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Deep Learning for Computer Vision* by Rajalingappaa Shanmugamani'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Practical Computer Vision* by Abhinav Dadhich'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
