["```py\nimport tensorflow as tf\nimport keras\nimport numpy as np\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\n```", "```py\n(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n```", "```py\nX_train = X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])\nX_train = X_train/255\nX_test = X_test/255\n```", "```py\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=784, activation='relu'))\nmodel.add(Dense(784, activation='relu'))\nmodel.summary()\n```", "```py\nmodel.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\nmodel.fit(X_train, X_train, validation_data=(X_test, X_test),epochs=10, batch_size=1024, verbose=1)\n```", "```py\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.subplot(221)\nplt.imshow(model.predict(X_test[0,:].reshape(1,784)).reshape(28,28), cmap=plt.get_cmap('gray'))\nplt.axis('off')\nplt.subplot(222)\nplt.imshow(model.predict(X_test[1,:].reshape(1,784)).reshape(28,28), cmap=plt.get_cmap('gray'))\nplt.axis('off')\nplt.subplot(223)\nplt.imshow(model.predict(X_test[2,:].reshape(1,784)).reshape(28,28), cmap=plt.get_cmap('gray'))\nplt.axis('off')\nplt.subplot(224)\nplt.imshow(model.predict(X_test[3,:].reshape(1,784)).reshape(28,28), cmap=plt.get_cmap('gray'))\nplt.axis('off')\nplt.show()\n```", "```py\nmodel = Sequential()\nmodel.add(Dense(100, input_dim=784, activation='relu'))\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dense(100,activation='relu'))\nmodel.add(Dense(784, activation='relu'))\nmodel.summary()\n```", "```py\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(X_train, X_train, validation_data=(X_test, X_test),epochs=25, batch_size=1024, verbose=1)\n```", "```py\n(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n\nX_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\nX_train = X_train/255\nX_test = X_test/255\n```", "```py\nmodel = Sequential()\nmodel.add(Conv2D(32, (3,3), input_shape=(28, 28,1), activation='relu',padding='same',name='conv1'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),name='pool1'))\nmodel.add(Conv2D(16, (3,3), activation='relu',padding='same',name='conv2'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),name='pool2'))\nmodel.add(Conv2D(8, (3,3), activation='relu',padding='same',name='conv3'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),name='pool3'))\nmodel.add(Conv2D(32, (3,3), activation='relu',padding='same',name='conv4'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),name='pool4'))\nmodel.add(Flatten(name='flatten'))\nmodel.add(Reshape((1,1,32)))\nmodel.add(Conv2DTranspose(8, kernel_size = (3,3), activation='relu'))\nmodel.add(Conv2DTranspose(16, kernel_size = (5,5), activation='relu'))\nmodel.add(Conv2DTranspose(32, kernel_size = (8,8), activation='relu'))\nmodel.add(Conv2DTranspose(32, kernel_size = (15,15), activation='relu'))\nmodel.add(Conv2D(1, (3, 3), activation='relu',padding='same'))\nmodel.summary()\n```", "```py\nfrom keras.optimizers import Adam\nadam = Adam(lr=0.001)\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(X_train, X_train, validation_data=(X_test, X_test),epochs=10, batch_size=1024, verbose=1)\n```", "```py\nfrom keras.models import Model\nlayer_name = 'flatten'\nintermediate_layer_model = Model(inputs=model.input,outputs=model.get_layer(layer_name).output)\nintermediate_output = intermediate_layer_model.predict(X_test)\n```", "```py\nfrom sklearn.manifold import TSNE\ntsne_model = TSNE(n_components=2, verbose=1, random_state=0)\ntsne_img_label = tsne_model.fit_transform(intermediate_output)\ntsne_df = pd.DataFrame(tsne_img_label, columns=['x', 'y'])\ntsne_df['image_label'] = y_test\n```", "```py\nfrom ggplot import *\nchart = ggplot(tsne_df, aes(x='x', y='y', color='factor(image_label)'))+ geom_point(size=70,alpha=0.5)\nchart\n```", "```py\nimport numpy as np\nimport pandas as pd\nfrom keras.layers import Input, Embedding, Dense, Dropout, merge, Flatten, dot\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nratings = pd.read_csv('...') # Path to the user-movie-ratings file\n```", "```py\nratings['User2']=ratings['User'].astype('category')\nratings['Movies2']=ratings['Movies'].astype('category')\n```", "```py\nusers = ratings.User.unique()\nmovies = ratings.Movies.unique()\nuserid2idx = {o:i for i,o in enumerate(users)}\nmoviesid2idx = {o:i for i,o in enumerate(movies)}\nidx2userid = {i:o for i,o in enumerate(users)}\nidx2moviesid = {i:o for i,o in enumerate(movies)}\n```", "```py\nratings['Movies2'] = ratings.Movies.apply(lambda x: moviesid2idx[x])\nratings['User2'] = ratings.User.apply(lambda x: userid2idx[x])\n```", "```py\nn_users = ratings.User.nunique()\nn_movies = ratings.Movies.nunique()\n```", "```py\ndef embedding_input(name,n_in,n_out):\n  inp = Input(shape=(1,),dtype='int64',name=name)\n  return inp, Embedding(n_in,n_out,input_length=1)(inp)\n```", "```py\nn_factors = 100\nuser_in, u = embedding_input('user_in', n_users, n_factors)\narticle_in, a = embedding_input('article_in', n_movies, n_factors)\n```", "```py\nx = dot([u,a], axes=1)\nx=Flatten()(x)\nx = Dense(500, activation='relu')(x)\nx = Dense(1)(x)\nmodel = Model([user_in,article_in],x)\nadam = Adam(lr=0.01)\nmodel.compile(adam,loss='mse')\nmodel.summary()\n```", "```py\nmodel.fit([ratings.User2,ratings.Movies2], ratings.rating, epochs=50,batch_size=128)\n```", "```py\n# Extracting user vectors\nmodel.get_weights()[0]\n\n# Extracting movie vectors\nmodel.get_weights()[1]\n```", "```py\nfrom sklearn.metrics.pairwise import cosine_similarity\nnp.argmax(cosine_similarity(model.get_weights()[1][574].reshape(1,-1),model.get_weights()[1][:574].reshape(574,100)))\n```"]