<html><head></head><body>
		<div class="Content" id="_idContainer118">
			<h1 id="_idParaDest-122"><em class="italics"><a id="_idTextAnchor134"/>Chapter 5</em></h1>
		</div>
		<div class="Content" id="_idContainer119">
			<h1 id="_idParaDest-123"><a id="_idTextAnchor135"/>Recurrent Neural Networks</h1>
		</div>
		<div class="Content" id="_idContainer120">
			<h2>Learning Objectives</h2>
			<p>By the end of this chapter, you will be able to:</p>
			<ul>
				<li class="bullets">Describe classical feedforward networks</li>
				<li class="bullets">Differentiate between feedforward neural networks and recurrent neural networks</li>
				<li class="bullets">Evaluate the application of backpropagation through time for recurrent neural networks</li>
				<li class="bullets">Describe the drawbacks of recurrent neural networks</li>
				<li class="bullets">Use recurrent neural networks with keras to solve the author attribution problem</li>
			</ul>
			<p><a id="_idTextAnchor136"/>This chapter aims to introduce you to recurrent neural networks and their applications, as well as their drawbacks.</p>
		</div>
		<div class="Content" id="_idContainer156">
			<h2 id="_idParaDest-124"><a id="_idTextAnchor137"/>Introduction</h2>
			<p>We encounter different kinds of data in our day-to-day lives, and some of this data has temporal dependencies (dependencies over time) while some does not. For example, an image by itself contains the information it wants to convey. However, data forms such as audio and video have dependencies over time. They cannot convey information if a fixed point in time is taken into consideration. Based on the problem statement, the input that's needed in order to solve the problem can differ. If we have a model to detect a particular person in a frame, a single image can be used as input. However, if we need to detect their actions, we need a stream of images, contiguous in time, as the input. We can understand the person's actions by analyzing these images together, but not independently.</p>
			<p>While watching a movie, a particular scene makes sense because its context is known, and we remember all the information gathered before in the movie to understand the current scene. This is very important, and we, as humans, can do this because our brains can store memory, analyze past data, and retrieve useful information to understand the current scene.</p>
			<p>Networks such as multi-layered perceptron and convolutional neural networks lack this capability. Every input given to these networks is treated independently, and they don't store any information from past inputs to analyze the current inputs because they lack memory in their architecture. That being the case, maybe there is a way we can enable neural networks to have memory. We can try and make them store useful information from the past and make them retrieve information from the past that helps them to analyze the current input. This is indeed possible, and the architecture for it is called the <strong class="keyword">Recurrent</strong> <strong class="keyword">Neural</strong> <strong class="keyword">Network</strong> (<strong class="keyword">RNN</strong>).</p>
			<p>Before we delve deep into the theory of RNNs, let's take a look at their applications. Currently, RNNs are widely used. Some of the applications are as follows:</p>
			<ul>
				<li><em class="italics">Speech recognition</em>: Whether it's Amazon's Alexa, Apple's Siri, Google's voice assistant, or Microsoft's Cortana, all their speech recognition systems use RNNs.</li>
				<li><em class="italics">Time series predictions</em>: Any application with time series data, such as stock market data, website traffic, call center traffic, movie recommendations, Google Maps routes, and so on, uses RNNs to predict future data, the optimal path, optimal resource allocations, and so on.</li>
				<li><em class="italics">Natural language processing</em>: Applications such as machine translation (for Google Translate, for instance), chatbots (such as those for Slack and <a id="_idTextAnchor138"/>Google), and question answering all use RNNs to model dependencies.</li>
			</ul>
			<h2 id="_idParaDest-125"><a id="_idTextAnchor139"/>Previous Versions of Neural Networks</h2>
			<p>Around 40 years ago, it became clear that <strong class="keyword">Feed</strong> <strong class="keyword">Forward</strong> <strong class="keyword">Neural</strong> <strong class="keyword">Networks</strong> (<strong class="keyword">FFNNs</strong>) could not capture time-variable dependencies, which are essential for capturing the time-variable properties of a signal. Modeling time-variable dependencies is very important in many applications involving real-world data, such as speech and video, in which data has time-variable properties. Also, human biological neural networks have a recurrent relationship, so it is the most obvious direction to take. How could this recurrent relationship be added to existing feedforward networks?</p>
			<p>One of the first attempts to achieve this was done by adding delay elements, and the network was called the <strong class="keyword">Time-Delay</strong> <strong class="keyword">Neural</strong> <strong class="keyword">Network</strong>, or <strong class="keyword">TDNN</strong> for short.</p>
			<p>In this network, as the following figure shows, the delay elements are added to the network and the past inputs are given to the network along with the current timestep as the input to the network. This definitely has an advantage over the traditional feed forward networks but has the disadvantage of having only so many inputs from the past as the window allows. If the window is too large, the network grows with increasing parameters and computational complexities.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer121">
					<img alt="Figure 5.1: TDNN structure&#13;&#10;" src="image/C13783_5_01.jpg"/>
				</div>
			</div>
			<h6>Figure 5.1: TDNN structure</h6>
			<p>Then came Elman networks, or simple RNNs. Elman networks are very similar to feedforward networks, except that the hidden layer of output is stored and used for the next input. This way, information from the previous timesteps can be captured in these hidden states.</p>
			<p>One way of looking at Elman networks is that at each input, we append the previous hidden layers' outputs along with the inputs and send them all as the inputs to the network. So, if the input size is <strong class="bold">m</strong> and the hidden layer size is <strong class="bold">n</strong>, the effective input layer size becomes <strong class="bold">m+n</strong>.</p>
			<p>The following figure shows a simple three-layer network, where the previous state is fed back to the network to store the context, and therefore it is called <strong class="bold">SimpleRNN</strong>. There are other variations to this architecture, such as Jordan networks, which we will not study in this chapter. For those are interested in the early history of RNNs, reading more on Elman networks and Jordan networks might be the best place to start.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer122">
					<img alt="Figure 5.2: SimpleRNN structure&#13;&#10;" src="image/C13783_5_02.jpg"/>
				</div>
			</div>
			<h6>Figure 5.2: SimpleRNN structure</h6>
			<p>And then came the <strong class="bold">RNN</strong>, which is the topic of this chapter. We will look into RNNs in detail in the coming sections It is important to note that in recurrent networks, since there are memory units and weights associated to these units, they need to be learned during backpropagation. Since these gradients are also backpropagated through time, we call it <strong class="keyword">Back</strong> <strong class="keyword">Propagation</strong> <strong class="keyword">Through</strong> <strong class="keyword">Time</strong>, or <strong class="keyword">BPTT</strong>. We will discuss BPTT in detail in the upcoming sections. However, TDNN, Elman networks, and RNNs have a major drawback due to BPTT, and it is called vanishing gradients. Vanishing gradients is a problem where gradients get smaller and smaller as they backpropagate, and in these networks, as timesteps increase, back-propagated gradients get smaller and smaller, resulting in vanishing gradients. It's almost impossible to capture time dependencies greater than 20 timesteps. </p>
			<p>To address this issue, an architecture called the <strong class="keyword">Long</strong> <strong class="keyword">Short-Term</strong> <strong class="keyword">Memory</strong> (<strong class="keyword">LSTM</strong>) architecture was introduced. The key idea here is to hold some cell states constant and introduce them as needed in future timesteps. These decisions are made by gates, including forget gates and output gates. Another commonly used variant of the LSTM is called the <strong class="keyword">Gated</strong> <strong class="keyword">Recurrent</strong> <strong class="keyword">Unit</strong>, or <strong class="keyword">GRU</strong> for short. Don't worry much if you didn't understand this completely. There are two chapters following that are dedicated to making these concepts clear.</p>
			<h2 id="_idParaDest-126"><a id="_idTextAnchor140"/>RNNs</h2>
			<p>Recurrent often means occurring repeatedly. The recurrent part of RNNs simply means that the same task is done over all the inputs in the input sequence (for RNNs, we give a sequence of timesteps as the input sequence). One main difference between feed forward networks and RNNs is that RNNs have memory elements called states that capture the information from the previous inputs. So, in this architecture, the current output not only depends on the current input, but also on the current state, which takes into account past inputs.</p>
			<p>RNNs are trained by sequences of inputs rather than a single input; similarly, we can consider each input to an RNN as a sequence of timesteps. The state elements in RNNs contain information about past inputs to process the current input sequence.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer123">
					<img alt="Figure 5.3: RNN structure&#13;&#10;" src="image/C13783_5_03.jpg"/>
				</div>
			</div>
			<h6>Figure 5.3: RNN structure</h6>
			<p>For each input in the input sequence, the RNN gets a state, calculates its output, and sends its state to the next input in the sequence. The same set of tasks is repeated for all the elements in the sequence.</p>
			<p>It's easy to understand RNNs and their operations by comparing them to feedforward networks. Let's do that now.</p>
			<p>By now, it's very clear that the inputs are independent of each other in feedforward neural networks, so we train the network by randomly drawing pairs of inputs and outputs. There is no significance to the sequence. At any given time, the output is a function of input and weights.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer124">
					<img alt="Figure 5.4: Expression for the output of an RNN&#13;&#10;" src="image/C13783_05_04.jpg"/>
				</div>
			</div>
			<h6>Figure 5.4: Expression for the output of an RNN</h6>
			<p>In RNNs, our output at time <strong class="bold">t</strong> depends not only on the current input and the weight, but also on previous inputs. In this case, the output at time <strong class="bold">t</strong> will be defined as shown:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer125">
					<img alt="Figure 5.5: Expression for the output of an RNN at time t&#13;&#10;" src="image/C13783_05_05.jpg"/>
				</div>
			</div>
			<h6>Figure 5.5: Expression for the output of an RNN at time t</h6>
			<p>Let's look at a simple structure of an RNN that is called a folded model. In the following figure, the <strong class="bold">S</strong><strong class="bold">t</strong> state vector is fed back into the network from the previous timestep. One important takeaway from this representation is that RNNs share the same weight matrices across timesteps. By increasing the timesteps, we are not learning more parameters, but we are looking at a bigger sequence.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer126">
					<img alt="Figure 5.6: Folded model of an RNN&#13;&#10;" src="image/C13783_5_06.jpg"/>
				</div>
			</div>
			<h6>Figure 5.6: Folded model of an RNN</h6>
			<p>This is a folded model of an RNN:</p>
			<p><strong class="bold">Xt </strong>: Current input vector in the input sequence</p>
			<p><strong class="bold">Yt</strong>: Current output vector in the output sequence</p>
			<p><strong class="bold">St</strong>: Current state vector</p>
			<p><strong class="bold">Wx</strong>: Weight matrix connecting the input vector to the state vector</p>
			<p><strong class="bold">Wy</strong>: Weight matrix connecting the state vector to the output vector</p>
			<p><strong class="bold">Ws</strong>: Weight matrix connecting the state vector of previous timestep to the next one</p>
			<p>Since the input, <strong class="bold">x</strong> is a sequence of timesteps and we perform the same task for elements in this sequence, we can unfold this model.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer127">
					<img alt="Figure 5.7: Unfolding of an RNN&#13;&#10;" src="image/C13783_5_07.jpg"/>
				</div>
			</div>
			<h6>Figure 5.7: Unfolding of an RNN</h6>
			<p>For example, the output at time <strong class="bold">t+1</strong>,<strong class="bold">y</strong><strong class="bold">t+1</strong> depends on input at time <strong class="bold">t+1</strong>, weight matrices, and all the inputs before it.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer128">
					<img alt="Figure 5.8: Unfolded RNN&#13;&#10;" src="image/C13783_5_08.jpg"/>
				</div>
			</div>
			<h6>Figure 5.8: Unfolded RNN</h6>
			<p>Since RNNs are extensions of FFNNs, it's best to understand the differences between these architectures. </p>
			<div>
				<div class="IMG---Figure" id="_idContainer129">
					<img alt="Figure 5.9: Differences between FFNNs and RNNs&#13;&#10;" src="image/C13783_5_09.jpg"/>
				</div>
			</div>
			<h6>Figure 5.9: Differences between FFNNs and RNNs</h6>
			<p>The output expressions for FFNNs and RNNs are as follows:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer130">
					<img alt="Figure 5.10: Output expressions for FFNNs and RNNs&#13;&#10;" src="image/C13783_5_10.jpg"/>
				</div>
			</div>
			<h6>Figure 5.10: Output expressions for FFNNs and RNNs</h6>
			<p>From the previous figure and equations, it is very evident that there are a lot of similarities between these two architectures. In fact, they are the same if <strong class="bold">Ws=0</strong>. This is obviously the case since <strong class="bold">Ws</strong> is the weight associated with the state that is fed back to the network. Without <strong class="bold">Ws</strong>, there is no feedback, which is the basis of the RNN.</p>
			<p>In FFNNs, the output at <strong class="bold">t</strong> depends on the input at <strong class="bold">t</strong> and weight matrices. In RNNs, the output at <strong class="bold">t</strong> depends on input at <strong class="bold">t</strong>, <strong class="bold">t-1</strong>, <strong class="bold">t-2</strong>, and so on, as well as the weight matrices. This is explained with the further calculation of hidden vector <strong class="bold">h</strong> in the case of an FFNN and <strong class="bold">s</strong> in the case of an RNN. At first glance, it might look like the state at <strong class="bold">t</strong> depends on the input at <strong class="bold">t</strong>, the state at <strong class="bold">t-1</strong>, and the weight matrices; and the state at <strong class="bold">t-1</strong> depends on the input at <strong class="bold">t-1</strong>, the state at <strong class="bold">t-2</strong>, and so on; creating a chain that goes back all the way to the first timestep considered. The output calculations of both FFNNs and RNNs are same, though.</p>
			<h3 id="_idParaDest-127"><a id="_idTextAnchor141"/>RNN Architectures</h3>
			<p>RNNs can come in many forms, and the appropriate architecture needs to be chosen depending on the problem we are solving.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer131">
					<img alt="Figure 5.11 Different architectures of RNNs&#13;&#10;" src="image/C13783_05_11.jpg"/>
				</div>
			</div>
			<h6>Figure 5.11 Different architectures of RNNs</h6>
			<p><em class="italics">One to many</em>: In this architecture, a single input is given, and the output is a sequence. An example of this is image captioning, where the input is a single image, and the output is a sequence of words explaining the image.</p>
			<p><em class="italics">Many to one</em>: In this architecture, a sequence of inputs is given, but a single output is expected. An example is any time series prediction where the next timestep in the sequence needs to be predicted, given the previous timesteps.</p>
			<p><em class="italics">Many to many</em>: In this architecture, an input sequence is given to the network, and the network outputs a sequence. In this case, the sequence can be either synced or not synced. For example, in machine translation, the whole sentence needs to be fed in before the networks starts to translate it. Sometimes, the input and output are not in sync; for example, in the case of speech enhancement, where an audio frame is given as input and a cleaner version of the input frame is the output expected. In such cases, the input and output are in sync.</p>
			<p>RNNs can also be stacked on top of each other. It is important to note that each RNN in the stack has its own weight matrices. So, the weight matrices are shared on the horizontal axis (the time axis) and not on the vertical axis (the number of RNNs).</p>
			<div>
				<div class="IMG---Figure" id="_idContainer132">
					<img alt="Figure 5.12: Stacked RNNs&#13;&#10;" src="image/C13783_5_11.jpg"/>
				</div>
			</div>
			<h6>Figure 5.12: Stacked RNNs</h6>
			<h3 id="_idParaDest-128"><a id="_idTextAnchor142"/>BPTT</h3>
			<p>RNNs can deal with varying sequence lengths, can be used in different forms, and can be stacked on top of each other. Previously, you have come across the back propagation technique to backpropagate loss values to adjust weights. In the case of RNNs, something similar can be done, with a bit of a twist, which is a gate loss through time. It's called <strong class="bold">BPTT</strong>.</p>
			<p>From the basic theory of back propagation, we know the following:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer133">
					<img alt="Figure 5.13: Expression for weight update&#13;&#10;" src="image/C13783_05_13.jpg"/>
				</div>
			</div>
			<h6>Figure 5.13: Expression for weight update</h6>
			<p>The update value is calculated through gradient calculations using the chain rule:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer134">
					<img alt="Figure 5.14 Partial derivative of error with regards to weight&#13;&#10;" src="image/C13783_05_14.jpg"/>
				</div>
			</div>
			<h6>Figure 5.14 Partial derivative of error with regards to weight</h6>
			<p>Here, <strong class="bold">α</strong> is the learning rate. The partial derivative of <strong class="bold">Error</strong> (<strong class="bold">loss</strong>) with respect to the weight matrix is the main calculation. Once this new matrix is obtained, adjusting the weight matrices is simply adding this new matrix, scaled by a learning factor, to itself.</p>
			<p>When calculating the update values for RNNs, we will use BPTT.</p>
			<p>Let's look at an example to understand this better. Consider a loss function, such as the mean squared error (which is commonly used for regression problems):</p>
			<div>
				<div class="IMG---Figure" id="_idContainer135">
					<img alt="Figure 5.15: Loss function&#13;&#10;" src="image/C13783_5_15.jpg"/>
				</div>
			</div>
			<h6>Figure 5.15: Loss function</h6>
			<p>At timestep <strong class="bold">t = 3</strong>, the loss calculated is as shown:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer136">
					<img alt="Figure 5.16 Loss at time t=3&#13;&#10;" src="image/C13783_05_16.jpg"/>
				</div>
			</div>
			<h6>Figure 5.16 Loss at time t=3</h6>
			<p>This loss needs to be backpropagated, and the <strong class="bold">Wy</strong>, <strong class="bold">Wx</strong>, and <strong class="bold">Ws</strong> weights need to be updated.</p>
			<p>As seen previously, we need to calculate the update value to adjust these weights, and this update value can be calculated using partial derivatives and the chain rule.</p>
			<p>There are three parts to doing this:</p>
			<ul>
				<li>Update Weight <strong class="bold">Wy</strong> by calculating the partial derivative of the error with respect to <strong class="bold">Wy</strong></li>
				<li>Update Weight <strong class="bold">Ws</strong> by calculating the partial derivative of the error with respect to <strong class="bold">Ws</strong></li>
				<li>Update Weight <strong class="bold">Wx</strong> by calculating the partial derivative of the error with respect to <strong class="bold">Wx</strong></li>
			</ul>
			<p>Before we look at these updates, let's unroll the model and keep the part of the network that's actually relevant for our calculations.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer137">
					<img alt="Figure 5.17 Unfolded RNN with loss at time t=3&#13;&#10;" src="image/C13783_5_18.jpg"/>
				</div>
			</div>
			<h6>Figure 5.17 Unfolded RNN with loss at time t=3</h6>
			<p>Since we are looking at how loss at <strong class="bold">t=3 </strong>affects the weight matrices, the loss values at and previous to <strong class="bold">t=2</strong> are not relevant. Now, we need to understand how to backpropagate this loss through the network.</p>
			<p>Let's look at each of these updates and show the gradient flow for each of the updates shown in the preceding figure.</p>
			<h2 id="_idParaDest-129"><a id="_idTextAnchor143"/>Updates and Gradient Flow</h2>
			<p>The updates can be listed as follows:</p>
			<ul>
				<li>Adjusting weight matrix <strong class="bold">Wy</strong></li>
				<li>Adjusting weight matrix<strong class="bold"> Ws</strong></li>
				<li>For updating <strong class="bold">Wx</strong></li>
			</ul>
			<h3 id="_idParaDest-130"><a id="_idTextAnchor144"/>Adjusting Weight Matrix <strong class="bold">Wy</strong></h3>
			<p>The model can be visualized as follows:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer138">
					<img alt="Figure 5.18: Back propagation of loss through weight matrix Wy&#13;&#10;" src="image/C13783_5_19.jpg"/>
				</div>
			</div>
			<h6>Figure 5.18: Back propagation of loss through weight matrix Wy</h6>
			<p>For Wy, the update is very simple since there are no additional paths or variables between Wy and the error. The matrix can be realized as follows:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer139">
					<img alt="Figure 5.19: Expression for weight matrix Wy&#13;&#10;" src="image/C13783_05_19.jpg"/>
				</div>
			</div>
			<h6>Figure 5.19: Expression for weight matrix Wy</h6>
			<h3 id="_idParaDest-131"><a id="_idTextAnchor145"/>Adjusting Weight Matrix <strong class="bold">Ws</strong></h3>
			<div>
				<div class="IMG---Figure" id="_idContainer140">
					<img alt="Figure 5.20: Back propagation of loss through weight matrix Ws with respect to S3&#13;&#10;" src="image/C13783_5_20.jpg"/>
				</div>
			</div>
			<h6>Figure 5.20: Back propagation of loss through weight matrix Ws with respect to S3</h6>
			<p>We can calculate the partial derivate of error with respect to <strong class="bold">Ws</strong> using the chain rule, as shown in the previous figure. It looks like that is what is needed, but it's important to remember that <strong class="bold">S</strong><strong class="bold">t</strong><strong class="bold"> </strong>is dependent on <strong class="bold">S</strong><strong class="bold">t-1</strong>, and therefore <strong class="bold">S</strong><strong class="bold">3</strong> is dependent on <strong class="bold">S</strong><strong class="bold">2</strong>, so we need to consider <strong class="bold">S</strong><strong class="bold">2</strong> also, as shown here:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer141">
					<img alt="Figure 5.21: Back propagation of loss through weight matrix Ws with respect to S2&#13;&#10;" src="image/C13783_5_21.jpg"/>
				</div>
			</div>
			<h6>Figure 5.21: Back propagation of loss through weight matrix Ws with respect to S2</h6>
			<p>Again, <strong class="bold">S</strong><strong class="bold">2</strong> in turn depends on <strong class="bold">S</strong><strong class="bold">1</strong>, and therefore <strong class="bold">S</strong><strong class="bold">1</strong> needs to be considered, too, as shown here: </p>
			<div>
				<div class="IMG---Figure" id="_idContainer142">
					<img alt="Figure 5.22: Back propagation of loss through weight matrix Ws with respect to S1&#13;&#10;" src="image/C13783_5_22.jpg"/>
				</div>
			</div>
			<h6>Figure 5.22: Back propagation of loss through weight matrix Ws with respect to S1</h6>
			<p>At <strong class="bold">t=3</strong>, we must consider the contribution of state <strong class="bold">S</strong><strong class="bold">3</strong> to the error, the contribution of state <strong class="bold">S</strong><strong class="bold">2</strong> to the error, and the contribution of state <strong class="bold">S</strong><strong class="bold">1</strong> to the error, <strong class="bold">E</strong><strong class="bold">3</strong>. The final value looks like this:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer143">
					<img alt="Figure 5.23: Sum of all derivatives of error with respect to Ws at t=3&#13;&#10;" src="image/C13783_5_23.jpg"/>
				</div>
			</div>
			<h6>Figure 5.23: Sum of all derivatives of error with respect to Ws at t=3</h6>
			<p>In general, for timestep <strong class="bold">N</strong>, all the contributions of the previous timesteps need to be considered. So, the general formula looks like this:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer144">
					<img alt="Figure 5.24: General expression for the derivative of error with respect to Ws&#13;&#10;" src="image/C13783_5_24.jpg"/>
				</div>
			</div>
			<h6>Figure 5.24: General expression for the derivative of error with respect to Ws</h6>
			<h3 id="_idParaDest-132"><a id="_idTextAnchor146"/>For Updating <strong class="bold">Wx</strong></h3>
			<p>We can calculate the partial derivate of error with respect to <strong class="bold">Wx</strong> using the chain rule, as shown in the next few figures. With the same reasoning that <strong class="bold">S</strong><strong class="bold">t</strong> is dependent on <strong class="bold">S</strong><strong class="bold">t-1</strong>, the calculation of partial derivative of error with respect to <strong class="bold">Wx</strong> can be divided into three stages at <strong class="bold">t=3</strong>.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer145">
					<img alt="Figure 5.25: Back propagation of loss through weight matrix Wx with respect to S2&#13;&#10;" src="image/C13783_5_25.jpg"/>
				</div>
			</div>
			<h6>Figure 5.25: Back propagation of loss through weight matrix Wx with respect to S2</h6>
			<p>Back propagation of loss through weight matrix Wx with respect to S2:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer146">
					<img alt="Figure 5.26: Back propagation of loss through weight matrix Wx with respect to S2&#13;&#10;" src="image/C13783_5_26.jpg"/>
				</div>
			</div>
			<h6>Figure 5.26: Back propagation of loss through weight matrix Wx with respect to S2</h6>
			<p>Back propagation of loss through weight matrix Wx with respect to S1:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer147">
					<img alt="Figure 5.27: Back propagation of loss through weight matrix Wx with respect to S1&#13;&#10;" src="image/C13783_5_27.jpg"/>
				</div>
			</div>
			<h6>Figure 5.27: Back propagation of loss through weight matrix Wx with respect to S1</h6>
			<p>Similar to the previous discussion, at <strong class="bold">t=3</strong>, we must consider the contribution of state <strong class="bold">S</strong><strong class="bold">3</strong> to the error, the contribution of state <strong class="bold">S</strong><strong class="bold">2</strong> to the error, and the contribution of state <strong class="bold">S</strong><strong class="bold">1</strong> to the error, <strong class="bold">E</strong><strong class="bold">3</strong>. The final value looks like this:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer148">
					<img alt="Figure 5.28: Sum of all derivatives of error with respect to Wx at t=3&#13;&#10;" src="image/C13783_5_28.jpg"/>
				</div>
			</div>
			<h6>Figure 5.28: Sum of all derivatives of error with respect to Wx at t=3</h6>
			<p>In general, for timestep N, all the contributions of the previous timesteps need to be considered. So, the general formula looks as follows:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer149">
					<img alt="Figure 5.29: General expression of derivative of error with respect to Wx&#13;&#10;" src="image/C13783_5_29.jpg"/>
				</div>
			</div>
			<h6>Figure 5.29: General expression of derivative of error with respect to Wx</h6>
			<p>Since the chain of derivatives already has 5 multiplicative terms at <strong class="bold">t=3</strong>, this number grows to 22 multiplicative terms for timestep 20. It's possible that each of these derivatives could be either greater than 0 or less than 0. Due to consecutive multiplications with longer timesteps, the total derivative gets smaller or larger. This problem is either vanishing gradients or exploding gradients.</p>
			<h2 id="_idParaDest-133"><a id="_idTextAnchor147"/>Gradients</h2>
			<p>The two types of gradients that have been identified are:</p>
			<ul>
				<li>Exploding gradients</li>
				<li>Vanishing gradients</li>
			</ul>
			<h3 id="_idParaDest-134"><a id="_idTextAnchor148"/>Exploding Gradients</h3>
			<p>As the name indicates, this happens when gradients explode to much bigger values. This could be one of the problems that RNN architectures could encounter with larger timesteps. This could happen when each of the partial derivatives is larger than <strong class="bold">1</strong>, and multiplication of these partial derivatives leads to an even larger value. These larger gradient values cause a dramatic shift in the weight values each time they are adjusted using back propagation, leading to a network that doesn't learn well.</p>
			<p>There are some techniques used to mitigate this issue, such as gradient clipping, wherein the gradient is normalized once it exceeds a set threshold.</p>
			<h3 id="_idParaDest-135"><a id="_idTextAnchor149"/>Vanishing Gradients</h3>
			<p>Whether it is RNNs or CNNs, vanishing gradients could be a problem if calculated loss has to travel back a lot. In CNNs, this problem could occur when there are a lot of layers with activations such as sigmoid or tanh. The loss has to travel all the way back to the initial layers, and these activations generally dilute them by the time they reach the initial layers, which means there are almost no weight updates for the initial layers, resulting in underfitting. This is even common in RNNs, since even if a network has one RNN layer but a large number of timesteps, the loss has to travel all the way through the timesteps due to backpropagation through time. Since the gradients are multiplicative, as seen in the generalized derivative expressions earlier, these values tend to become low, and weights are not updated after a certain timestep. This means that even if more timesteps are shown to a network, the network can't benefit because the gradients cannot travel all the way back. This limitation in RNNs is due to vanishing gradients.</p>
			<p>As the name indicates, this happens when the gradients become too small. This could happen when each of partial derivatives is smaller than 1 and multiplication of these partial derivatives leads to a much smaller value. With this geometric decay of information, the network cannot learn properly. There are almost no changes in the weight values, which leads to underfitting.</p>
			<p>There must be a better mechanism to use to know what parts of the previous timesteps to remember, what to forget, and so on. To address this issue, architectures such as LSTM networks and GRUs were created.</p>
			<h3 id="_idParaDest-136"><a id="_idTextAnchor150"/>RNNs with Keras</h3>
			<p>So far, we have discussed the theory behind RNNs, but there are a lot of frameworks available that can abstract away the implementation details. As long as we know how to use these frameworks, we can successfully get our projects working. <strong class="bold">TensorFlow</strong>, <strong class="bold">Theano</strong>, <strong class="bold">Keras</strong>, <strong class="bold">PyTorch</strong>, and <strong class="bold">CNTK</strong> are some of these frameworks. In this chapter, let's take a closer look at the most commonly used framework, called <strong class="bold">Keras</strong>. It uses either Tensorflow or Theano as the backend, indicating that it creates an even higher level of abstraction than other frameworks. It is a tool best suited for beginners. Once comfortable with Keras, tools such as TensorFlow give much more power in implementing custom functions.</p>
			<p>There are many variants of RNNs that you will study in the next few chapters, but all of them use the same base class, called RNN:</p>
			<p class="snippet">keras.layers.RNN(cell, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)</p>
			<p>In this chapter, we have discussed the simple form of the RNN, which is called <strong class="bold">SimpleRNN</strong> in Keras:</p>
			<p class="snippet">keras.layers.SimpleRNN(units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)</p>
			<p>As you can see from the arguments here, there are two kinds: one for regular kernels, used to compute the outputs of a layer, and the other for recurrent kernels used to compute states. Don't worry too much about constraints, regularizers, initializers, and dropout. You can find more about them at <a href="">https://keras.io/layers/recurrent/</a>. They are mostly used to avoid overfitting. The role of activation here is the same as the role of activation with any other layer.</p>
			<p>The units are the number of recurrent units in a particular layer. The greater the number of units, the more parameters there are that need to be learned.</p>
			<p><strong class="inline">return_sequences</strong> is the argument that specifies whether the RNN layer should return the whole sequence or just the last timestep. If <strong class="inline">return_sequences</strong> is false, the output of the RNN layer is just the last timestep, so we cannot stack this with another RNN layer. In other words, if an RNN layer needs to be stacked by another RNN layer, <strong class="inline">return_sequences</strong> need to be true. If an RNN layer is connected to the Dense layer, this can argument can be either true or false, depending on the application.</p>
			<p>The <strong class="inline">return_state</strong> argument specifies whether the last state of the RNN needs to be returned along with the output. This can be set to either True or False, depending on the application.</p>
			<p><strong class="inline">go_backwards</strong> can be used if, for any reason, the input sequence needs to be processed backward. Keep a note that if this is set to True, even the returned sequence is reversed.</p>
			<p><strong class="inline">stateful</strong> is an argument that can be set to true if a state needs to be passed between batches. If this argument is set to true, the data needs to be handled carefully; we have a topic covering this in detail.</p>
			<p><strong class="inline">unroll</strong> is an argument that leads to the network being unrolled if set to true, which can speed up operations but can be very memory extensive depending on the timesteps. Generally, this argument is set to true for short sequences.</p>
			<p>The number of timesteps is not an argument for a particular layer since it stays the same for the whole network, which is represented in the input shape. This brings us to the important point of the shape of the network when using RNNs:</p>
			<p class="snippet">Input_shape </p>
			<p class="snippet">3D tensor with shape (batch_size, timesteps, input_dim)</p>
			<p class="snippet">Output_shape</p>
			<p class="snippet">If return_sequences is true, 3D tensor with shape (batch_size, timesteps, units)</p>
			<p class="snippet">If return_sequences is false, 2D tensor with shape (batch_size, units)</p>
			<p class="snippet">If return_state is True, a list of 2 tensors, 1 is output tensor same as above depending on return_sequences, the other is state tensor of shape (batch_size, units)</p>
			<h4>Note</h4>
			<p class="callout">If you start building a network with an RNN layer, <strong class="inline">input_shape</strong> must be specified.</p>
			<p>After a model is built, <strong class="inline">model.summary()</strong> can be used to see the shapes of each layer and the total number of parameters.</p>
			<h3 id="_idParaDest-137"><a id="_idTextAnchor151"/>Exercise 23: Building an RNN Model to Show the Stability of Parameters over Time</h3>
			<p>Let's build a simple RNN model to show that the parameters do not change with timesteps. Note that while mentioning the <strong class="inline">input_shape</strong> argument, <strong class="inline">batch_size</strong> need not be mentioned unless needed. It is needed for a stateful network, which we will discuss next. <strong class="inline">batch_size</strong> is mentioned while training the model with the fit() or <strong class="inline">fit_generator()</strong> functions.</p>
			<p>The following steps will help you with the solution:</p>
			<ol>
				<li>Import the necessary Python packages. We will be using Sequential, SimpleRNN, and Dense.<p class="snippet">from keras.models import Sequential</p><p class="snippet">from keras.layers import SimpleRNN, Dense</p></li>
				<li>Next, we define the model and its layers:<p class="snippet">model = Sequential()</p><p class="snippet"># Recurrent layer</p><p class="snippet">model.add(SimpleRNN(64, input_shape=(10,100), return_sequences=False))</p><p class="snippet"># Fully connected layer</p><p class="snippet">model.add(Dense(64, activation='relu'))</p><p class="snippet"># Output layer</p><p class="snippet">model.add(Dense(100, activation='softmax'))</p></li>
				<li>You can check the summary of the model:<p class="snippet">model.summary()</p><p><strong class="inline">model.summary()</strong> gives the following output:</p><div class="IMG---Figure" id="_idContainer150"><img alt="" src="image/C13783_05_30.jpg"/></div><h6>Figure 5.30: Model summary for model layers</h6><p>In this case, <strong class="bold">None</strong> is the <strong class="inline">batch_size</strong> parameter, which will be provided by the <strong class="inline">fit()</strong> function. The output of the RNN layer is <strong class="bold">(None, 64)</strong> since it is not returning the sequence.</p></li>
				<li>Let's look at the model that returns sequence:<p class="snippet">model = Sequential()</p><p class="snippet"># Recurrent layer</p><p class="snippet">model.add(SimpleRNN(64, input_shape=(10,100), return_sequences=True))</p><p class="snippet"># Fully connected layer</p><p class="snippet">model.add(Dense(64, activation='relu'))</p><p class="snippet"># Output layer</p><p class="snippet">model.add(Dense(100, activation='softmax'))</p><p class="snippet">model.summary()</p><p>The summary of the model that returns sequence looks like this:</p><div class="IMG---Figure" id="_idContainer151"><img alt="" src="image/C13783_05_31.jpg"/></div><h6>Figure 5.31: Model summary of sequence-returning model</h6><p>Now the RNN layer is returning a sequence, and therefore its output shape is 3D instead of 2D, as seen earlier. Also, note that the <strong class="bold">Dense</strong> layer is automatically adjusted to this change in its input. The <strong class="bold">Dense</strong> layer with the current Keras version has the capability of adjusting to time_steps from a previous RNN layer. In the previous versions of Keras, <strong class="bold">TimeDistributed</strong>(<strong class="bold">Dense</strong>) was used to achieve this.</p></li>
				<li>We have previously discussed how the RNN shares its parameters over timesteps. Let's see that in action and change the timesteps of the previous model from 10 to 1,000:<p class="snippet">model = Sequential()</p><p class="snippet"># Recurrent layer</p><p class="snippet">model.add(SimpleRNN(64, input_shape=(1000,100), return_sequences=True))</p><p class="snippet"># Fully connected layer</p><p class="snippet">model.add(Dense(64, activation='relu'))</p><p class="snippet"># Output layer</p><p class="snippet">model.add(Dense(100, activation='softmax'))</p><p class="snippet">model.summary()</p></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer152">
					<img alt="Figure 5.32: Model summary for timesteps&#13;&#10;" src="image/C13783_05_32.jpg"/>
				</div>
			</div>
			<h6>Figure 5.32: Model summary for timesteps</h6>
			<p>Clearly, the output shapes of the network changed to this new time_steps. However, there is no change in the parameters between the two models.</p>
			<p>This indicates that the parameters are shared over time and are not impacted by changing the number of timesteps. Note that the same is applicable to the <strong class="bold">Dense</strong> layer when operating on more than one timestep.</p>
			<h3 id="_idParaDest-138"><a id="_idTextAnchor152"/>Stateful versus Stateless</h3>
			<p>There are two modes of operation available with RNNs considering the states: the stateless and stateful modes. If the <strong class="bold">argument stateful=True</strong>, you are working with stateful mode, and <strong class="bold">False</strong> signifies stateless mode.</p>
			<p>Stateless mode is basically saying that one example in a batch is not related to any example in the next batch; that is, every example is independent in the given case. The state is reset after every example. Each example has a certain number of timesteps depending on the model architecture. For example, the last model we saw had 1,000 timesteps, and between these 1000 timesteps, the state vector was calculated and passed from one timestep to the next. However, at the end of the example or the beginning of the next example, there was no state passed. Each example was independent and therefore there was no consideration needed regarding the way the data was shuffled.</p>
			<p>In stateful mode, the state from example <strong class="bold">i</strong> of <strong class="bold">batch 1</strong> is passed to the <strong class="bold">i+1</strong> example of <strong class="bold">batch 2</strong>. This means that the state is passed from one example to the next among batches. For this reason, the examples must be contiguous across batches and cannot be random. The following figure explains this situation. The examples <strong class="bold">i</strong>, <strong class="bold">i+1</strong>, <strong class="bold">i+2</strong>, and so on are contiguous, and so are <strong class="bold">j</strong>, <strong class="bold">j+1</strong>, <strong class="bold">j+2</strong>, and so on, and <strong class="bold">k</strong>, <strong class="bold">k+1</strong>, <strong class="bold">k+2</strong>, and so on.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer153">
					<img alt="Figure 5.33 Batch formations for stateful RNN&#13;&#10;" src="image/C13783_5_33.jpg"/>
				</div>
			</div>
			<h6>Figure 5.33 Batch formations for stateful RNN</h6>
			<h3 id="_idParaDest-139"><a id="_idTextAnchor153"/>Exercise 24: Turning a Stateless Network into a Stateful Network by Only Changing Arguments</h3>
			<p>In order to turn a network from stateless to stateful by changing the arguments, the following steps should be taken.</p>
			<ol>
				<li value="1">First, we would need to import the required Python packages:<p class="snippet">from keras.models import Sequential</p><p class="snippet">from keras.layers import SimpleRNN, Dense</p></li>
				<li>Next, build the model using <strong class="inline">Sequential</strong> and define the layers:<p class="snippet">model = Sequential()</p><p class="snippet"># Recurrent layer</p><p class="snippet">model.add(SimpleRNN(64, input_shape=(1000,100), return_sequences=True, stateful=False))</p><p class="snippet"># Fully connected layer</p><p class="snippet">model.add(Dense(64, activation='relu'))</p><p class="snippet"># Output layer</p><p class="snippet">model.add(Dense(100, activation='softmax'))</p><p class="snippet">model.summary()</p></li>
				<li>Set the optimizer to <strong class="inline">Adam</strong>, set <strong class="inline">categorical</strong> <strong class="inline">crosstropy</strong> as the loss parameter, and set the metrics to fit the model. Compile the model and fit the model over 100 epochs:<p class="snippet">model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])</p><p class="snippet">model.fit(X, Y, batch_size=32, epochs=100, shuffle=True)</p></li>
				<li>Assume that <strong class="inline">X</strong> and <strong class="inline">Y</strong> are training data as contiguous examples. Turn this model into a stateful one:<p class="snippet">model = Sequential()</p><p class="snippet"># Recurrent layer</p><p class="snippet">model.add(SimpleRNN(64, input_shape=(1000,100), return_sequences=True, stateful=True))</p><p class="snippet"># Fully connected layer</p><p class="snippet">model.add(Dense(64, activation='relu'))</p><p class="snippet"># Output layer</p><p class="snippet">model.add(Dense(100, activation='softmax'))</p></li>
				<li>Set the optimizer to <strong class="inline">Adam</strong>, set <strong class="inline">categorical</strong> <strong class="inline">crossentropy</strong> as the loss parameter, and set the metrics to fit the model. Compile the model and fit the model over 100 epochs:<p class="snippet">model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])</p><p class="snippet">model.fit(X, Y, batch_size=1, epochs=100, shuffle=False)</p></li>
				<li>You can use a box and whisker plot to visualize the output.<p class="snippet">results.boxplot()</p><p class="snippet">pyplot.show()</p><p><strong class="bold">Expected output:</strong></p></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer154">
					<img alt="Figure 5.34: Box and whisker plot for stateful vs stateless&#13;&#10;" src="image/C13783_05_34.jpg"/>
				</div>
			</div>
			<h6>Figure 5.34: Box and whisker plot for stateful vs stateless</h6>
			<h4>Note</h4>
			<p class="callout">The output may vary depending on the data used.</p>
			<p>From the concept of stateful models, we understand that the data fed in batches need to be contiguous, so turn randomization <strong class="bold">OFF</strong>. However, even with <strong class="bold">batch_size &gt;1</strong>, the data across batches will not be contiguous, so make <strong class="bold">batch_size=1</strong>. By turning the network to <strong class="bold">stateful=True</strong> and fitting it with the mentioned parameters, we are essentially training the model correctly in a stateful manner.</p>
			<p>However, we are not using the concept of mini batch gradient descent, and nor are we shuffling the data. So, a generator needs to be implemented that can carefully train a stateful network, which is outside the scope of this chapter.</p>
			<p><strong class="inline">model.compile</strong> is a function where an optimizer and a loss function are assigned to the network, along with the metrics that we care about.</p>
			<p><strong class="inline">model.fit()</strong> is a function that is used to train a model by specifying its training data, validation data, the number of epochs, the batch size, the mode of shuffling, and more.</p>
			<h3 id="_idParaDest-140"><a id="_idTextAnchor154"/>Activity 6: Solving a Problem with an RNN – Author Attribution</h3>
			<p>Author attribution is a classic text classification problem that comes under the umbrella of natural language processing (NLP). Authorship attribution is a well-studied problem that led to the field of <strong class="bold">stylometry</strong>.</p>
			<p>In this problem, we are given a set of documents from certain authors. We need to train a model to understand the authors' styles and use the model to identify the authors of the unknown documents. As with many other NLP problems, it has benefited greatly from the increase in available computer power, data, and advanced machine learning techniques. This makes authorship attribution a natural candidate for the use of <strong class="bold">deep learning (DL</strong>). In particular, we can benefit from DL's ability to automatically extract the relevant features for a specific problem.</p>
			<p>In this activity, we will focus on the following:</p>
			<ol>
				<li value="1">Extracting character-level features from the text of each author (to get each author's style)</li>
				<li>Using those features to build a classification model for authorship attribution</li>
				<li>Applying the model for identifying the author of a set of unknown documents<h4>Note</h4><p class="callout">You can find the required data for the activity at <a href="">https://github.com/TrainingByPackt/Deep-Learning-for-Natural-Language-Processing/tree/master/Lesson%2005</a>.</p></li>
			</ol>
			<p>The following steps will help you with the solution.</p>
			<ol>
				<li value="1">Import the necessary Python packages.</li>
				<li>Upload the text document to be used. Then, pre-process the text file by converting all text into lowercase, converting all newlines and multiple whitespaces into single whitespaces, and removing any mention of the authors' names, otherwise we risk data leakage.</li>
				<li>To break the long texts into smaller sequences, we use the <strong class="inline">Tokenizer</strong> class from the Keras framework.</li>
				<li>Proceed to create the training and validation sets.</li>
				<li>We construct the model graph and perform the training procedure.</li>
				<li>Apply the model to the unknown papers. Do this for all the papers in the <strong class="bold">Unknown</strong> folder.<p><strong class="bold">Expected output:</strong></p></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer155">
					<img alt="Figure 5.35: Output for author attribution&#13;&#10;" src="image/C13783_05_35.jpg"/>
				</div>
			</div>
			<h6>Figure 5.35: Output for author attribution</h6>
			<h4>Note</h4>
			<p class="callout">The solution for the activity can be found on page 309.</p>
			<h2 id="_idParaDest-141"><a id="_idTextAnchor155"/>Summary</h2>
			<p>In this chapter, we were introduced to RNNs and covered the major differences between the architectures of RNNs and FFNNs. We looked at BPTT and how weight matrices are updated. We learned how to use RNNs using Keras and solved a problem of author attribution using RNNs in Keras. We looked at the shortcomings of RNNs by looking at vanishing gradients and exploding gradients. In the next chapters, we will look into architectures that will address these issues. </p>
		</div>
	</body></html>