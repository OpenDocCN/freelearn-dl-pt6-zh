["```py\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\ndf = pd.read_csv('D:/Advanced_Computing/Active_Experiments/LSTM/\n                  stock_market/all_stocks_5yr.csv')\n\ndf.head()\n```", "```py\nplt.figure(figsize = (18,9))\nplt.plot(range(aal.shape[0]),(aal['low']), color='r')\nplt.plot(range(aal.shape[0]),(aal['high']), color = 'b')\nplt.xticks(range(0,aal.shape[0],60),aal['date'].loc[::60],rotation=60)\nplt.xlabel('Date',fontsize=18)\nplt.ylabel('Price',fontsize=18)\nplt.show()\n```", "```py\nhigh_prices = aal.loc[:,'high'].values\nlow_prices = aal.loc[:,'low'].values\nmid_prices = (high_prices+low_prices)/2.0\n\nmid_prices.shape\n----------------------------------------------------\nOutput:\n(1259,) ----------------------------------------------------mid_prices\n----------------------------------------------------\nOutput:\narray([14.875, 14.635, 14.305, ..., 51.07 , 50.145, 51.435])\n```", "```py\ntrain_data = mid_prices[:1000]\ntest_data = mid_prices[1000:1251]\ntrain_data = train_data.reshape(-1,1)         #scaler.fit_transform\ntest_data = test_data.reshape(-1,1)           #scaler.fit_transform\n\nprint('%d training and %d total testing instances'%(len(train_data),    \n      len(test_data)))\n\n-----------------------------------------------------------------\nOutput:\n1000 training and 251 total testing instances \n```", "```py\n#Subplot with training data\nplt.subplot(1,2,1)\nplt.plot(range(train_data.shape[0]),train_data,color='r',label='Training split')\nplt.title('Train Data')\nplt.xlabel('time')\nplt.ylabel('Price')\nplt.legend()\n\n#Subplot with test data\nplt.subplot(1,2,2)\nplt.plot(range(test_data.shape[0]),test_data,color='b',label='Test Split')\nplt.title('Test Data')\nplt.xlabel('time')\nplt.ylabel('Price')\nplt.legend()\n\n#adjust layout and plot all\nplt.tight_layout()\nplt.show()\n```", "```py\n#Window size to normalize data in chunks \nnormalization_window = 250\n\n#Feature range for normalization\nscaler = MinMaxScaler(feature_range=(0, 1))\n\n# Loop over the training data in windows of 250 instances at a time\nfor i in range(0,1000,normalization_window):\n\n    # Fit the scaler object on the data in the current window\n    scaler.fit(train_data[i:i+normalization_window,:])\n\n    # Transform the data in the current window into values between the chosen feature range (0 and 1)\n    train_data[i:i+normalization_window,:] = scaler.transform(train_data[i:i+normalization_window,:])\n\n# normalize the the test data\ntest_data=scaler.fit_transform(test_data)\n```", "```py\nSmoothing = 0.0     #Initialize smoothing value as zero\n\ngamma = 0.1         #Define decay\n\nfor i in range(1000):\n\n    Smoothing = gamma*train_data[i] + (1-gamma)*Smoothing   # Update   \n                                                       smoothing value\n\n    train_data[i] = Smoothing # Replace datapoint with smoothened value\n```", "```py\nwindow_size = 26            # Define window size\nN = train_data.size         # and length of observations\n\nstd_avg_predictions = []    # Empty list to catch std\nmse_errors = []             # and mse\n\nfor i in range(window_size,N):\n    # Append the standard mean per window\n    std_avg_predictions.append(np.mean(train_data[i-window_size:i]))                                                                                                         \n\n    # Compute mean squared error per batch \n    mse_errors.append((std_avg_predictions[-1]-train_data[i])**2) \n\nprint('MSE error for standard averaging: %.5f'  \n      (0.5*np.mean(mse_errors)))\n\nMSE error for standard averaging: 0.00444\n```", "```py\nplt.figure(figsize = (19,6))\nplt.plot(range(train_data.shape[0]),train_data,color='darkblue',label='Actual')\nplt.plot(range(window_size,N),std_avg_predictions,color='orange',label='Predicted')\nplt.xticks(range(0,aal.shape[0]-len(test_data),50),aal['date'].loc[::50],rotation=45)\n\nplt.xlabel('Date')\nplt.ylabel('Mid Price')\nplt.legend(fontsize=18)\nplt.show()\n```", "```py\nema_avg_predictions = []\nmse_errors = []\n\nEMA = 0.0\nema_avg_predictions.append(EMA)\n\ngamma = 0.5\nwindow_size = 100\nN = len(train_data)\n\nfor i in range(1,N):\n    EMA = EMA*gamma + (1.0-gamma)*train_data[i-1]\n    ema_avg_predictions.append(EMA)\n    mse_errors.append((ema_avg_predictions[-1]-train_data[i])**2)\n\nprint('MSE error for EMA averaging: %.5f'%(0.5*np.mean(mse_errors)))\n\nMSE error for EMA averaging: 0.00018\n```", "```py\nplt.figure(figsize = (19,6))\nplt.plot(range(train_data.shape[0]),train_data,color='darkblue',label='True')\nplt.plot(range(0,N),ema_avg_predictions,color='orange', label='Prediction')\nplt.xticks(range(0,aal.shape[0]-len(test_data),50),aal['date'].loc[::50],rotation=45)\n\nplt.xlabel('Date')\nplt.ylabel('Mid Price')\nplt.legend(fontsize=18)\nplt.show()\n\n```", "```py\ndef create_dataset(dataset, look_back=7, foresight=3):   \n    X, Y = [], []\n    for i in range(len(dataset)-look_back-foresight): \n        obs = dataset[i:(i+look_back), 0] # Sequence of 7 stock prices  \n                                     as features forming an observation    \n       # Append sequence\n        X.append(obs)\n       # Append stock price value occurring 4 time-steps into future\n        Y.append(dataset[i + (look_back+foresight), 0]) \n    return np.array(X), np.array(Y)\n```", "```py\nx_train = np.reshape(x_train, (x_train.shape[0], 1,  x_train.shape[1]))\nx_test = np.reshape(x_test, (x_test.shape[0], 1,  x_test.shape[1]))\nx_train.shape\n\n(990, 1, 7)\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, GRU, Dense\nfrom keras.layers import Dropout, Flatten\n\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n```", "```py\ndef feed_forward():\n    model = Sequential()\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(1, activation='linear'))\n    model.compile(loss='mae', optimizer='adam')\n    return model\n```", "```py\ndef simple_gru():\n    model = Sequential()\n    model.add(GRU(32,  input_shape=(1, 7), dropout=0.1, recurrent_dropout=0.1))\n\n    model.add(Dense(1, activation='linear'))\n\n    model.compile(loss='mae', optimizer='adam', metrics = \n                  ['mean_absolute_error'])\n    return model\n```", "```py\ndef simple_lstm():\n    model = Sequential()\n    model.add(LSTM(32, input_shape=(1, 7)))\n\n    model.add(Dense(1, activation='linear'))\n\n    model.compile(loss='mae', optimizer='adam')\n    return model\n```", "```py\ndef lstm_stacked():\n    model = Sequential()\n    model.add(LSTM(16, input_shape=(1, 7), dropout=0.1, recurrent_dropout=0.2, return_sequences=True))\n    model.add(LSTM(16, dropout=0.1, recurrent_dropout=0.2))\n\n    model.add(Dense(1, activation='linear'))\n\n    model.compile(loss='mae', optimizer='adam')\n    return model\n```", "```py\ndef plot_losses(network):\n    plt.plot(network.history['loss'], label='loss')\n    plt.plot(network.history['val_loss'], label='val loss')\n    plt.legend()\n    plt.show()\n```", "```py\ndef plot_predictions(model, y_test=y_test):\n\n    preds = model.predict(x_test)\n    plt.figure(figsize = (12,6))\n    plt.plot(scaler.inverse_transform(preds.reshape(-1,1)), \n             label='generated', color='orange')\n    plt.plot(scaler.inverse_transform(y_test.reshape(-1,1)),   \n             label='Actual')\n    plt.legend()\n    plt.show()\n```", "```py\ndef train_network(list, x_train, y_train, epochs=5):\n    for net in list:               \n\n        network_name = str(net).split(' ')[1]\n        filepath = network_name + \"_epoch-{epoch:02d}-loss-\n                   {loss:.4f}-.hdf5\"\n        print('Training:', network_name)\n\n        checkpoint = ModelCheckpoint(filepath, monitor='loss', \n                     verbose=0, save_best_only=True, mode='min')\n        callbacks_list = [checkpoint] \n        model = net()                  \n\n        network = model.fit(x_train, y_train,\n                            validation_data=(x_test, y_test),\n                            epochs=epochs,\n                            batch_size=64,\n                            callbacks=callbacks_list)\n        model.summary()\n        plot_predictions(model, y_test)\n\n    return network, model\n\nall_networks = [feed_forward, simple_gru, simple_lstm, lstm_stacked]\ntrain_network(all_networks, x_train, y_train, epochs=50)\n```"]