- en: Discussion, Current Trends, and Outlook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep neural networks being at the core of **deep learning** (**DL**) allow computational
    models that are composed of multiple processing layers to learn representations
    of data with multiple levels of abstraction. These methods have dramatically improved
    the state-of-the-art stuff in speech recognition, multimedia (image/audio/video)
    analytics, NLP, image processing and segmentation, visual object recognition,
    object detection, and many other domains in life sciences, such as cancer genomics,
    drug discovery, personalized medicine, and biomedical imaging.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book, we have seen how to use JVM-based DL libraries to develop
    some applications covering these areas. I confess that some projects were not
    so comprehensive and cannot be deployed commercially but need some extra effort.
    Nonetheless, showing how to deploy such models was not within the scope of this
    book. However, at least these should provide us with some core insights.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we''ve come to the end of our little journey of deep learning with
    different Java libraries, it is time to wrap up everything. But before that, in
    this chapter, we''ll discuss the completed projects and some abstract takeaways.
    Then we''ll provide some suggestions for improvement. Additionally, we''ll cover
    some extension guidelines for other real-life deep learning projects. In summary,
    the following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Discussions on projects, outlook, future improvement, and extension
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Current trends on supervised and unsupervised deep learning algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequently asked questions (FAQs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discussion and outlook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this book, we have covered 10 end-to-end projects. We started our
    journey with an introduction to deep learning and finished at a factorization-machine
    based movie recommendation system project. In this section, we'll briefly review
    these projects, discuss potential limitations, and provide some future directions
    toward improvement and extension.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion on the completed projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In between, we tried to cover several real-life projects from diverse domains
    such as healthcare, sentiment analysis in NLP, transfer learning, image and video
    classification, distributed deep learning and training, reinforcement learning,
    online trading, and real-life object detection from video. These are outlined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Titanic survival prediction using MLP and LSTM networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cancer types prediction using recurrent type networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-label Image classification using convolutional neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis using Word2Vec and LSTM network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image classification using transfer learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-time object detection using YOLO, JavaCV, and DL4J
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stock price prediction using the LSTM network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed deep learning for video classification using convolutional LSTM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using deep reinforcement learning for a GridWorld game
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing a movie recommendation system using factorization machines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we will discuss the pros, cons, and future directions for improving these
    projects for possible extension.
  prefs: []
  type: TYPE_NORMAL
- en: Titanic survival prediction using MLP and LSTM networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this project, our main goal was to get familiar with Apache Spark ML library,
    followed by a basic introduction to machine learning, deep learning their types,
    architectures, and frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: We could not achieve higher accuracy. Then, in [Chapter 2](e27fb252-7892-4659-81e2-2289de8ce570.xhtml),
    *Cancer Types Prediction Using Recurrent Type Networks*, we revisited the same
    project but using a robust recurrent LSTM network, which shows higher accuracy.
    The takeaway was learning how to prepare the dataset by considering most of the
    features and feeding into Spark and a DL4J-based MLP classifier.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, this dataset is not so high dimensional, so applying DL methods
    is not a good idea. Therefore, I would recommend using other tree ensembles such
    as random forest and gradient-boosted trees for modeling and deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Cancer type prediction using recurrent type networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We solved an interesting project, where we successfully classified cancer patients
    based on cancer types. For this, we used the LSTM network. We used a very high-dimensional
    gene expression dataset. We converted the dataset into sequence format and trained
    the LSTM net for each sample per time step.
  prefs: []
  type: TYPE_NORMAL
- en: This project also shows the robustness of deep architecture such as LSTM, demonstrating
    that even without applying dimensionality reduction, the model can handle a very
    high-dimensional dataset.
  prefs: []
  type: TYPE_NORMAL
- en: One of the potential limitations of this approach was that we considered only
    a gene expression dataset, so it cannot be deployed for a real-life prognosis
    and diagnosis, whereas other datasets such as **Copy Number Variation** (**CNV**),
    DNA methylation, and survival-related clinical outcomes, have to be considered
    as well. Nonetheless, domain expertise from biomedical engineers and doctors is
    needed to come up with an integrated solution.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the takeaway is that at least it shows how to handle at least one type
    of cancer genomics dataset. Therefore, the same techniques can be applied to other
    data types too. Then, a multimodal network has to be developed by taking the input
    from domain experts before deploying, such as an AI expert system.
  prefs: []
  type: TYPE_NORMAL
- en: Image classification using convolutional neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this project, we saw how to solve a multi-label image classification problem.
    We used real Yelp images. Then we trained a CNN to predict the classes for each
    tagged image. In this project, the most challenging part was feature engineering,
    as we had to deal with not only images but also different tags and metadata. Unfortunately,
    we could not achieve very high accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: The takeaway would be that similar approaches can be applied to solve other
    image datasets having multi-labels. Yet, a multiclass classification problem can
    be solved with minimal effort as well. All you need is to prepare the dataset
    such that a CNN-based model can consume it. Apart from this outlook, the project
    in [Chapter 5](2d4fc6f2-3753-456c-8774-3f41dbe13cfb.xhtml), *Image Classification
    using Transfer Learning,* can be extended to solve similar problems.
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis using Word2Vec and the LSTM network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this project, we saw how to develop a sentiment analysis application using
    Word2Vec and LSTM. We also discussed how to convert unstructured texts into neural
    word embedding, and later on transform them into the sequence form required to
    train the LSTM network. Then we trained LSTM with the sequence of the corresponding
    texts at each time step.
  prefs: []
  type: TYPE_NORMAL
- en: This project also addressed a binary classification problem with very high accuracy.
    In the same line, this application can be extended for classifying other problems,
    such as spam versus ham for messages and email, and movie or product reviews.
    Finally, in the FAQ section, we discussed how to solve the same problem with CNN,
    which can achieve similar accuracy to LSTM.
  prefs: []
  type: TYPE_NORMAL
- en: Image classification using transfer learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we solved an interesting dog versus cat classification problem
    using the transfer learning technique. We used a pre-trained VGG16 model and its
    weights, and subsequently we fine-tuned the training with a real-life cat versus
    dog dataset from Kaggle.
  prefs: []
  type: TYPE_NORMAL
- en: Once the training was completed, we saved the trained model for model persistence
    and later reuse. We saw that the trained model could successfully detect and differentiate
    between cat and dog images with very different sizes, quality, and shapes.
  prefs: []
  type: TYPE_NORMAL
- en: The trained model/classifier can be used to solve cat versus dog problems in
    real life. Finally, the lesson was that this similar technique with minimal efforts,
    can be extended and used to solve similar image classification problems; this
    applies for both binary and multiclass classification problems.
  prefs: []
  type: TYPE_NORMAL
- en: Real-time object detection using YOLO, JavaCV, and DL4J
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this project, we again used the transfer learning technique to solve another
    interesting problem, which is real-time object detection from video clips. We
    used a pre-trained YOLOv2 model, JavaCV, and DL4J libraries to solve this problem.
  prefs: []
  type: TYPE_NORMAL
- en: As stated in the chapter, we extended the image recognition idea to solve this
    problem. That is, our technique generates video frames as images and then recognizes
    objects from the frame using the bounding box approach. The takeaway is that although
    we used a video clip to show the evaluation, it still showed very good accuracy.
    And from the provided demo, anyone can observe that most of the objects in the
    clip were accurately identified. Thus, a similar technique, can be extended for
    real-time object detection.
  prefs: []
  type: TYPE_NORMAL
- en: In this regard, we saw some tips to collect real-time videos from a webcam or
    video camera (or even a mobile phone) and feed them into our YOLOv2 model using
    the JavaCV library.
  prefs: []
  type: TYPE_NORMAL
- en: Stock price prediction using LSTM network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this project, we saw how to develop a demo project for predicting the stock
    prices for five categories: OPEN, CLOSE, LOW, HIGH, and VOLUME. However, this
    result also lacks the actual signal; all your network has to do is produce a value
    similar to the last input of the price.'
  prefs: []
  type: TYPE_NORMAL
- en: If we took your prediction as the input for the next prediction, we saw that
    the results were quite bad. I know there are some serious drawbacks of this approach.
    Nevertheless, we had not used enough data, which potentially limits the performance
    of such a model.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing the drawback of this project, the biggest takeaway is extending Bitcoin
    or another cryptocurrency price prediction. As suggested in the FAQ section, historical
    Bitcoin data can be downloaded from Kaggle. Then, similar feature engineering
    as we used in this project can be used to prepare the sequence dataset. Nevertheless,
    CNN-based approaches can be used too.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed deep learning â€“ video classification using a convolutional-LSTM
    network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this project, we developed a complete deep learning application that classifies
    a large collection of a video dataset from the UCF101 dataset. We applied a combined
    CNN-LSTM network with **deeplearning4j** (**DL4J**) that overcame the limitations
    of standalone CNN or RNN **Long Short-Term Memory** (**LSTM**) networks.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we saw how to perform training in both a parallel and distributed manner
    across multiple devices (CPUs and GPUs) on AWS EC2 AMI 9.0\. We performed parallel
    and distributed training on a `p2.8xlarge` instance with 8 GPUs, 32 computing
    cores, and 488 GB of RAM.
  prefs: []
  type: TYPE_NORMAL
- en: One of the greatest takeaways from this chapter was that this end-to-end project
    can be treated as a primer for human activity recognition from video. Secondly,
    we did not achieve high accuracy because we had not trained the model with all
    the available video clips.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, having the network trained with the a full video dataset and hyperparameter
    tuning definitely increases accuracy. In that case, deploying the improved model
    is commercially possible. Finally, if you want to make the training even faster,
    configuring a Hadoop cluster and distributing the training on both GPUs and Spark
    is possible.
  prefs: []
  type: TYPE_NORMAL
- en: Using deep reinforcement learning for GridWorld
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this project, we saw how to develop a demo GridWorld game using DL4J and
    Neural QLearning, which acts as the Q function. We also provided some basic theoretical
    background for developing DQN to play a GridWorld game. However, we did not develop
    a module for visualizing the moves of the agent for the entire episodes. I confess
    that it was the biggest drawback of this project. However, I discussed some improvements
    in the FAQ section.
  prefs: []
  type: TYPE_NORMAL
- en: The takeaway from this project is extending this application with a visualization
    model or even developing other RL-based games, such as Doom and ALE would be a
    good idea. Secondly and finally, we can also think of developing another interesting
    RL project for online trading.
  prefs: []
  type: TYPE_NORMAL
- en: Movie recommender system using factorization machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this project, we saw how to develop a movie recommendation system using factorization
    machines (FMs) that are a set of algorithms that enhance the performance of linear
    models by incorporating second-order feature interactions that are absent in matrix
    factorization algorithms in a supervised way.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, we saw some theoretical background of recommendation systems using
    matrix factorization and collaborative filtering before diving the project implementation
    using RankSys library-based FMs. This project not only covered movie-rating prediction
    by individual users but also discussed ranking predictions. Consequently, we used
    FM for predicting rankings for movies too.
  prefs: []
  type: TYPE_NORMAL
- en: However, the potential limitation is that this library is not scalable and well
    structured, I would say. Therefore, trying Python-based FM libraries would be
    a better idea. Finally, the biggest takeaway is extending this application with
    Python-based FM libraries for even larger movie datasets from MovieLens or IMDb,
    which is recommended.
  prefs: []
  type: TYPE_NORMAL
- en: Current trends and outlook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a researcher, I work as a **Program Committee** (**PC**) member for conferences
    such as WWW'2018, ISWC'2018, ESWC'2017/2018, and ESWC SemDeep'2018 international
    workshops. Apart from these, I am also a guest editor for International Semantic
    Web Journal, Journal of Cloud Computing, and Briefings in Bioinformatics.
  prefs: []
  type: TYPE_NORMAL
- en: While reviewing numerous papers for these conferences and journals, I found
    that researchers have not limited themselves to developing emerging use cases
    and analytical solutions using original RNN, CNN, DBN or autoencoders. They are
    coming up with ideas across new architectures by combining them for diverse domains.
  prefs: []
  type: TYPE_NORMAL
- en: Current trends
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As discussed in [Chapter 1](fba163f0-88c0-4278-a4a1-df5389cc3a10.xhtml), *Getting
    Started with Deep Learning*, researchers have recently proposed so many emergent
    DL architectures. These include not only improving CNN/RNN and their variants
    but also some other special types of architecture: **Deep SpatioTemporal Neural
    Networks** (**DST-NNs**), **Multi-Dimensional Recurrent Neural Networks** (**MD-RNNs**),
    **Convolutional AutoEncoders** (**CAEs**), deep embedding clustering, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, there are a few more emerging networks, such as CapsNets, which
    is an improved version of a CNN designed to remove the drawbacks of regular CNNs
    as proposed by Hinton et al. Then we have residual neural networks for image recognition
    and **Generative Adversarial Networks** (**GANs**) for simple image generation.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from these trends and use cases, different deep and emerging architectures
    are being used in multimedia analytics; computer vision (especially semantic image
    segmentation); anomaly detection from IoT, image, and network traffic; neural
    machine translation for NLP; and integration of knowledge graphs with neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Outlook on emergent DL architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this subsection, we'll discuss some emergent architectures and their variants,
    focusing on some use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Residual neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Because of the millions of billions of hyperparameters and other practical
    aspects associated with them, it is difficult to train deep neural networks. To
    overcome this limitation, Kaiming He et al. (see [https://arxiv.org/abs/1512.03385v1](https://arxiv.org/abs/1512.03385v1))
    proposed a **residual learning framework** (**RNN**) to ease the training of networks
    that are substantially deeper than those used previously. Now, according to the
    original paper:'
  prefs: []
  type: TYPE_NORMAL
- en: '"In this network setting, instead of hoping each stack of layers directly fits
    a desired underlying mapping, we explicitly let these layers fit a residual mapping.
    The original mapping is recast into F(x)+x. We hypothesize that it is easier to
    optimize the residual mapping than to optimize the original, unreferenced mapping.
    To the extreme, if an identity mapping were optimal, it would be easier to push
    the residual to zero than to fit an identity mapping by a stack of nonlinear layers."'
  prefs: []
  type: TYPE_NORMAL
- en: This way, RNNs are easier to optimize and can gain accuracy from considerably
    increased depth compared to other DNN architectures. The downside is that building
    a network by simply stacking residual blocks inevitably limits its optimization
    ability. To overcome this limitation, Ke Zhang et al. also proposed using a multilevel
    residual networks (see at [https://arxiv.org/abs/1608.02908](https://arxiv.org/abs/1608.02908)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Consequently, residual networks are in use to solve many emerging use cases,
    including:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Skeleton-Based Action Recognition with Spatial Reasoning and Temporal Stack
    Learning* (see more at [https://arxiv.org/pdf/1805.02335](https://arxiv.org/pdf/1805.02335)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recently, Yuan et al. proposed *Hyperspectral Image Denoising Employing a Spatial-Spectral
    Deep Residual Convolutional Neural Network* (see [https://arxiv.org/pdf/1806.00183](https://arxiv.org/pdf/1806.00183)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*A Dynamic Model for Traffic Flow Prediction Using Improved DRN* (see more
    at [https://arxiv.org/pdf/1805.00868](https://arxiv.org/pdf/1805.00868))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Classification of simulated radio signals using Wide Residual Networks for
    use in the search for extra-terrestrial intelligence* (see more at [https://arxiv.org/pdf/1803.08624](https://arxiv.org/pdf/1803.08624))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GANs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GANs are deep neural net architectures that consist of two networks pitted against
    each other (hence the name adversarial). Ian Goodfellow et al. introduced GANs
    in a paper (see more at [https://arxiv.org/abs/1406.2661v1](https://arxiv.org/abs/1406.2661v1)).
    GAN is one of the best research outcomes in AI that can learn to mimic any distribution
    of data. This is such that a trained GAN can be deployed to create worlds similar
    to our own, especially for images, music, speech, or prose.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although the original GAN paper targeted simple image generation such as DCGAN,
    BEGAN, and so on, people are extending the idea for font generation, anime character
    generation, interactive image generation, text-to-image generation, 2D object
    generation, human pose estimation, and so on. A few concrete research-oriented
    use cases as outlined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: For generating an image sequence from the description with LSTM (see more at
    [https://arxiv.org/pdf/1806.03027](https://arxiv.org/pdf/1806.03027))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative adversarial networks for **electroencephalographic** (**EEG**) brain
    signals (see more at [https://arxiv.org/pdf/1806.01875](https://arxiv.org/pdf/1806.01875))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For natural language generation for electronic health records (see more at [https://arxiv.org/pdf/1806.01353](https://arxiv.org/pdf/1806.01353))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For chest X-ray segmentation (see more at [https://arxiv.org/pdf/1806.00600](https://arxiv.org/pdf/1806.00600))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capsule networks (CapsNet)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in [Chapter 1](fba163f0-88c0-4278-a4a1-df5389cc3a10.xhtml), *Getting
    Started with Deep Learning*, CNNs perform well at classifying good quality images.
    However, if the images have rotation, tilt, or any other different orientation,
    CNNs give very poor performance. Even the pooling operation in CNNs cannot help
    much with positional invariance.
  prefs: []
  type: TYPE_NORMAL
- en: To overcome the this limitation of CNN, Geoffrey Hinton et al. come up with
    a ground breaking idea called **CapsuleNetworks (CapsNet)** that are particularly
    good at handling different types of visual stimulus and encoding things such as
    pose (position, size, and orientation), deformation, velocity, albedo, hue, texture.
  prefs: []
  type: TYPE_NORMAL
- en: In a regular DNN, we keep on adding layers (more layers means a deeper network).
    In CapsNet, the idea is to add more layers inside a single layer. This way, a
    CapsNet is a nested set of neural layers. In CapsNet, the limitation of max-pooling
    layer is overcome and replaced with **routing by agreement (RBA)** to capture
    low-level visual information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, the original paper is too theoretical. Therefore, researchers
    are trying to extend the idea of CapsNet for different AI and data science projects
    including image classification, GAN improvement and at improving RL-based gaming
    experience. A few example use cases are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Object Localization and Motion Transfer learning with Capsules* (see [https://arxiv.org/pdf/1805.07706](https://arxiv.org/pdf/1805.07706))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*An attention-based Bi-GRU-CapsNet model for hypernymy detection between compound
    entities* (see more at [https://arxiv.org/pdf/1805.04827](https://arxiv.org/pdf/1805.04827))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Brain Tumor Type Classification via Capsule Networks* (see more at [https://arxiv.org/pdf/1802.10200](https://arxiv.org/pdf/1802.10200))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*CapsuleGAN: Generative Adversarial Capsule Network* (see more at [https://arxiv.org/pdf/1802.06167](https://arxiv.org/pdf/1802.06167))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Deep Reinforcement Learning using Capsules in Advanced Game Environments*
    (see more at [https://arxiv.org/pdf/1801.09597](https://arxiv.org/pdf/1801.09597))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apart from these emerging architectures, people are trying to use GAN architectures
    for image synthesis using CapsNet (see [https://arxiv.org/pdf/1806.03796](https://arxiv.org/pdf/1806.03796)).
    Researchers have also used adversarial autoencoders for speech-based emotion recognition
    (see [https://arxiv.org/pdf/1806.02146](https://arxiv.org/pdf/1806.02146)). Finally,
    I would suggest readers to know the recent trends in artificial intelligence,
    machine learning, and deep learning from [https://arxiv.org/list/cs.AI/recent](https://arxiv.org/list/cs.AI/recent).
  prefs: []
  type: TYPE_NORMAL
- en: Semantic image segmentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image segmentation is the way to partition an image into several coherent parts,
    but *without* any attempt at understanding what these parts represent. Semantic
    segmentation, on the other hand, attempts to partition the image into semantically
    meaningful parts and to classify each part into one of the predetermined classes.
  prefs: []
  type: TYPE_NORMAL
- en: Such semantic segmentation of raw brain images into gray matter, white matter,
    and cerebrospinal fluid helps classify them based on the segmented areas. Deep-learning-based
    techniques are being in use and very successful such as **Stacked Denoising Autoencoders**
    (**SDAE**).
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, the recurrent-based fully convolutional network is being in use
    for semantic segmentation of high-resolution remote sensing images (see more at
    [https://arxiv.org/pdf/1805.02091](https://arxiv.org/pdf/1805.02091)). This types
    of image segmentation are being in use in emerging use cases such as Pelvic MRImage
    analysis, object detection for self-driving cars, geospatial image classification
    (see [http://www.semantic-web-journal.net/system/files/swj1862.pdf](http://www.semantic-web-journal.net/system/files/swj1862.pdf)),
    and many more.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning for clustering analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Clustering analysis is one of the most widely used data-driven task. To date,
    existing clustering analysis techniques use classical clustering algorithms such
    as k-means, bisecting k-means, or the Gaussian mixture model. In particular, the
    k-means clustering algorithm and its several variants have been proposed to address
    issues with higher-dimensional input spaces.
  prefs: []
  type: TYPE_NORMAL
- en: However, they are fundamentally limited to linear embedding. Hence, they cannot
    model nonlinear relationships. Nevertheless, fine-tuning in these approaches is
    based on only cluster assignment hardening loss. Therefore, a fine-grained clustering
    accuracy cannot be achieved.
  prefs: []
  type: TYPE_NORMAL
- en: In short, relatively less research has focused on deep-learning-based representation
    learning and clustering analysis. However, the quality of k-means is dependent
    on the data distribution. Deep architecture can help the model learn a mapping
    from the data space to a lower-dimensional feature space in which it iteratively
    optimizes a clustering objective.
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering these limitations and motivations, researchers have come up with
    deep-learning-based clustering techniques for clustering very-high-dimensional
    data and nonlinear objects. In these approaches, k-means is incorporated with
    deep architectures, where both the clustering-assignment-hardening loss (from
    k-means) and reconstruction loss (from DNN) are optimized simultaneously. These
    approaches include:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Unsupervised Deep Embedding for Clustering Analysis* by Xie et al. ( see [https://arxiv.org/pdf/1511.06335.pdf](https://arxiv.org/pdf/1511.06335.pdf))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Neural Networks-based Clustering using Pairwise Constraints* by Hsu et al.
    (see more at [https://arxiv.org/abs/1511.06321](https://arxiv.org/abs/1511.06321))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Discriminatively Boosted Clustering (DBC)* by Liu et al. (see more at [http://dataclustering.cse.msu.edu/papers/boost_cluster.pdf](http://dataclustering.cse.msu.edu/papers/boost_cluster.pdf))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Clustering with Deep Learning: Taxonomy and New Methods* by Elie et al. (see
    more at [https://arxiv.org/abs/1801.07648](https://arxiv.org/abs/1801.07648))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Recurrent Deep Embedding Networks for Genotype Clustering and Ethnicity Prediction*
    by Karim et al. (see more at [https://arxiv.org/pdf/1805.12218.pdf](https://arxiv.org/pdf/1805.12218.pdf))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequently asked questions (FAQs)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have analyzed the completed projects and looked at recent trends. Based
    on these, there might be several questions in your mind. In this section, I will
    try to devise some such questions and provide sample answers:'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we argued that using GAN, we could solve many research problems.
    Is there any GAN implementation in DL4J?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this chapter, we argued that using CapsNet is a better idea for handling
    images having different shapes and orientation. Is there any implementation for
    CapsNet in DL4J?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In [Chapter 1](fba163f0-88c0-4278-a4a1-df5389cc3a10.xhtml), *Getting Started
    with Deep Learning*, we discussed DBNs and restricted Boltzmann machines as their
    basic building blocks. However, we have not used DBNs in any of the completed
    projects. What is the reason for this?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this chapter, we argued that using unsupervised anomaly detection from IoT
    sensor data or images is an emerging research use case. Are there any examples
    of this in DL4J?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are there any examples of developing recommendation engines with DL4J?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Considering the fact that smartphones nowadays are very powerful, can we develop
    image/object detection applications on a smartphone?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How could I wrap-up a deep learning application as a web app?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I am having issues while running the projects. In addition, I am experiencing
    issues while configuring the development environment (for example, on Eclipse/IntelliJ
    IDEA and configuring CUDA/CuDNN). What can I do?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers to questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Answer** **to question 1**: There is an inactive issue on this. Interested
    readers can look at [https://github.com/deeplearning4j/deeplearning4j/issues/1737](https://github.com/deeplearning4j/deeplearning4j/issues/1737)
    to know the current update. However, the discussion loop is not very active.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question 2**: As far as I know, there is no CapsNet implementation
    in DL4J. Also, I didn''t see any open discussion/issues on this topic. I asked
    in the DL4j Gitter channel but nobody replied.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer to question 3**: Both unsupervised pre-training and supervised fine-tuning
    can be performed using DBN. That means this probabilistic network is an intelligent
    choice if we do not have enough labeled data but still want to perform NN-based
    training.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question 4**: Yes, there is an example of anomaly detection
    using a variational autoencoder with reconstruction probability for MNIST data.
    Take a look at DL4J examples at [https://github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/unsupervised/anomalydetection](https://github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/unsupervised/anomalydetection).
    However, this example can be extended for other datasets too.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer to question 5**: There is an example for well-dressed recommendation
    engine in this link [https://deeplearning4j.org/welldressed-recommendation-engine](https://deeplearning4j.org/welldressed-recommendation-engine).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer to question 6**: Deep learning and neural networks can be deployed
    in Android devices too. For more information, refer to [https://deeplearning4j.org/android](https://deeplearning4j.org/android).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer to question 7**: Once the NN is trained, the network can be used for
    inference, or making predictions about the data it sees. Inference happens to
    be a much less compute-intensive process. Then, Spring Boot or another framework
    can be used to wrap up the application as a web app. See some guidelines at [https://deeplearning4j.org/build_vgg_webapp](https://deeplearning4j.org/build_vgg_webapp).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer to question 8**: You should follow the instructions I provided in
    the chapters. In addition, the code of this book is available on GitHub, so feel
    free to PR or create new issues and I will try to fix them as soon as possible.
    About any new issues, you can ask through the DL4J Gitter live channel at [https://gitter.im/deeplearning4j/deeplearning4j](https://gitter.im/deeplearning4j/deeplearning4j).'
  prefs: []
  type: TYPE_NORMAL
