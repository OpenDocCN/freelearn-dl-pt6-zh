["```py\n    %matplotlib inline\n    import keras\n    import matplotlib.pyplot as plt\n    ```", "```py\n    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n    ```", "```py\n    sample_image = X_train[0]\n    plt.imshow(sample_image)\n    ```", "```py\n    print(sample_image[x][y]) \n    ```", "```py\n    print(sample_image[22][11])\n    print(sample_image[6][12])\n    print(sample_image[5][23])\n    print(sample_image[10][11])\n    ```", "```py\n    from matplotlib import pyplot\n    ```", "```py\n    def relu(x):\n        return max(0.0, x)\n    ```", "```py\n    inputs = [x for x in range(-15, 15)]\n    outputs = [relu(x) for x in inputs]\n    ```", "```py\n    pyplot.plot(inputs, outputs) #Plot the input against the output\n    pyplot.show()\n    ```", "```py\n    from keras.models import Sequential #For stacking layers\n    from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n    from keras.utils import plot_model\n    ```", "```py\n    num_classes = 10\n    ```", "```py\n    model = Sequential()\n    ```", "```py\n    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n    model.add(Conv2D(32, kernel_size=3, activation='relu'))\n    ```", "```py\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    ```", "```py\n    model.add(Flatten())\n    model.add(Dense(num_classes, activation='softmax'))\n    ```", "```py\n    model.summary()\n    ```", "```py\n    plot_model(model, to_file='model.png')\n    ```", "```py\n    epochs=12\n    ```", "```py\n    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n    ```", "```py\n    X_train = X_train.reshape(60000,28,28,1) #60,000 is the number of training examples\n    X_test = X_test.reshape(10000,28,28,1)\n    ```", "```py\n    #Demonstrating the to_categorical method\n    Import numpy as np\n    from keras.utils import to_categorical\n    example = [1,0,3,2]\n    to_categorical(example)\n    ```", "```py\n    from keras.utils import to_categorical\n    y_train = to_categorical(y_train)\n    y_test = to_categorical(y_test)\n    ```", "```py\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    ```", "```py\n    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs)\n    ```", "```py\n    score = model.evaluate(X_test, y_test, verbose=0)\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n    ```", "```py\n    import keras\n    from keras.datasets import reuters\n    from keras.preprocessing.text import Tokenizer\n    from keras.models import Sequential\n    from keras import layers\n    ```", "```py\n    batch_size = 32\n    epochs = 12\n    maxlen = 10000\n    batch_size = 32\n    embedding_dim = 128\n    num_filters = 64\n    kernel_size = 5\n    ```", "```py\n    (x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n    ```", "```py\n    word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n    num_classes = max(y_train) + 1 \n    index_to_word = {}\n    for key, value in word_index.items():\n        index_to_word[value] = key\n    ```", "```py\n    tokenizer = Tokenizer(num_words=maxlen)\n    x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n    x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n    y_train = keras.utils.to_categorical(y_train, num_classes)\n    y_test = keras.utils.to_categorical(y_test, num_classes)\n    ```", "```py\n    model = Sequential()\n    model.add(layers.Embedding(512, embedding_dim, input_length=maxlen))\n    model.add(layers.Conv1D(num_filters, kernel_size, activation='relu'))\n    model.add(layers.GlobalMaxPooling1D())\n    model.add(layers.Dense(10, activation='relu'))\n    model.add(layers.Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    ```", "```py\n    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1)\n    score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n    ```"]