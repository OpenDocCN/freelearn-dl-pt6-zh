["```py\n    git clone https://github.com/Kuntal-G/StackGAN.git\n    cd StackGAN\n\n    ```", "```py\n    sudo pip install prettytensor progressbar python-dateutil easydict pandas torchfile requests\n\n    ```", "```py\n    python google-drive-download.py 0B3y_msrWZaXLT1BZdVdycDY5TEE Data/ birds.zip\n\n    ```", "```py\n    unzip Data/birds.zip\n\n    ```", "```py\n    wget http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/\n    CUB_200_2011.tgz -O Data/birds/CUB_200_2011.tgz\n    tar -xzf CUB_200_2011.tgz\n\n    ```", "```py\n    python misc/preprocess_birds.py\n\n    ```", "```py\n    python google-drive-download.py 0B3y_msrWZaXLNUNKa3BaRjAyTzQ models/ birds_model_164000.ckpt\n\n    ```", "```py\n    python google-drive-download.py 0B0ywwgffWnLLU0F3UHA3NzFTNEE models/text_encoder/  lm_sje_nc4_cub_hybrid_gru18_a1_c512_0.00070_1_10_trainvalids.txt_iter30000.t7\n\n    ```", "```py\n    sh demo/birds_demo.sh\n\n    ```", "```py\nclass Generator(nn.Module):\n\n            self.main = nn.Sequential(\n            # Encoder\n                nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n                nn.LeakyReLU(0.2, inplace=True),\n                nn.Conv2d(64, 64 * 2, 4, 2, 1, bias=False),\n                nn.BatchNorm2d(64 * 2),\n                nn.LeakyReLU(0.2, inplace=True),\n                nn.Conv2d(64 * 2, 64 * 4, 4, 2, 1, bias=False),\n                nn.BatchNorm2d(64 * 4),\n                nn.LeakyReLU(0.2, inplace=True),\n                nn.Conv2d(64 * 4, 64 * 8, 4, 2, 1, bias=False),\n                nn.BatchNorm2d(64 * 8),\n                nn.LeakyReLU(0.2, inplace=True),\n                nn.Conv2d(64 * 8, 100, 4, 1, 0, bias=False),\n                nn.BatchNorm2d(100),\n                nn.LeakyReLU(0.2, inplace=True),\n\n             # Decoder\n                nn.ConvTranspose2d(100, 64 * 8, 4, 1, 0, bias=False),\n                nn.BatchNorm2d(64 * 8),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(64 * 8, 64 * 4, 4, 2, 1, bias=False),\n                nn.BatchNorm2d(64 * 4),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(64 * 4, 64 * 2, 4, 2, 1, bias=False),\n                nn.BatchNorm2d(64 * 2),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(64 * 2, 64, 4, 2, 1, bias=False),\n                nn.BatchNorm2d(64),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(64,3, 4, 2, 1, bias=False),\n                nn.Sigmoid()\n\n                . . . \n\n            )\n```", "```py\nclass Discriminator(nn.Module):\n\n        self.conv1 = nn.Conv2d(3, 64, 4, 2, 1, bias=False)\n        self.relu1 = nn.LeakyReLU(0.2, inplace=True)\n\n        self.conv2 = nn.Conv2d(64, 64 * 2, 4, 2, 1, bias=False)\n        self.bn2 = nn.BatchNorm2d(64 * 2)\n        self.relu2 = nn.LeakyReLU(0.2, inplace=True)\n\n        self.conv3 = nn.Conv2d(64 * 2, 64 * 4, 4, 2, 1, bias=False)\n        self.bn3 = nn.BatchNorm2d(64 * 4)\n        self.relu3 = nn.LeakyReLU(0.2, inplace=True)\n\n        self.conv4 = nn.Conv2d(64 * 4, 64 * 8, 4, 2, 1, bias=False)\n        self.bn4 = nn.BatchNorm2d(64 * 8)\n        self.relu4 = nn.LeakyReLU(0.2, inplace=True)\n\n        self.conv5 = nn.Conv2d(64 * 8, 1, 4, 1, 0, bias=False)\n\n        . . . .\n\n   return torch.sigmoid( conv5 ), [relu2, relu3, relu4]\n```", "```py\nrecon_criterion = nn.MSELoss()\ngan_criterion = nn.BCELoss()\n\noptim_gen = optim.Adam( gen_params, lr=args.learning_rate, betas=(0.5,0.999), weight_decay=0.00001)\noptim_dis = optim.Adam( dis_params, lr=args.learning_rate, betas=(0.5,0.999), weight_decay=0.00001)\n```", "```py\nAB = generator_B(A)\nBA = generator_A(B)\n\nABA = generator_A(AB)\nBAB = generator_B(BA)\n\n# Reconstruction Loss\nrecon_loss_A = recon_criterion( ABA, A )\nrecon_loss_B = recon_criterion( BAB, B )\n```", "```py\n# Real/Fake GAN Loss (A)\nA_dis_real, A_feats_real = discriminator_A( A )\nA_dis_fake, A_feats_fake = discriminator_A( BA )\n\ndis_loss_A, gen_loss_A = get_gan_loss( A_dis_real, A_dis_fake, gan_criterion, cuda )\nfm_loss_A = get_fm_loss(A_feats_real, A_feats_fake, feat_criterion)\n\n# Real/Fake GAN Loss (B)\nB_dis_real, B_feats_real = discriminator_B( B )\nB_dis_fake, B_feats_fake = discriminator_B( AB )\n\ndis_loss_B, gen_loss_B = get_gan_loss( B_dis_real, B_dis_fake, gan_criterion, cuda )\nfm_loss_B = get_fm_loss( B_feats_real, B_feats_fake, feat_criterion )\n\ngen_loss_A_total = (gen_loss_B*0.1 + fm_loss_B*0.9) * (1.-rate) + recon_loss_A * rate\ngen_loss_B_total = (gen_loss_A*0.1 + fm_loss_A*0.9) * (1.-rate) + recon_loss_B * rate\n```", "```py\nif args.model_arch == 'discogan':\n    gen_loss = gen_loss_A_total + gen_loss_B_total\n    dis_loss = dis_loss_A + dis_loss_B\n```", "```py\n    git clone https://github.com/SKTBrain/DiscoGAN.git\n    cd DiscoGAN\n\n    ```", "```py\n    python ./datasets/download.py edges2handbags\n\n    ```", "```py\n    python ./discogan/image_translation.py --task_name='edges2handbags'\n    ```", "```py\n    git clone https://github.com/SKTBrain/DiscoGAN.git\n    cd DiscoGAN\n\n    ```", "```py\n    python ./datasets/download.py facescrub\n\n    ```", "```py\n    python ./discogan/image_translation.py --task_name= facescrub\n\n    ```"]