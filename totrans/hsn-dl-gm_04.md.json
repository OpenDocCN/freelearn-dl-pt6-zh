["```py\nfrom __future__ import print_function, division\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport sys\nimport numpy as np\n```", "```py\nclass DCGAN():\n```", "```py\ndef build_generator(self):\n  model = Sequential()\n  model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n  model.add(Reshape((7, 7, 128)))\n  model.add(UpSampling2D())\n  model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n  model.add(BatchNormalization(momentum=0.8))\n  model.add(Activation(\"relu\"))\n  model.add(UpSampling2D())\n  model.add(Conv2D(64, kernel_size=3, padding=\"same\")) \n  model.add(BatchNormalization(momentum=0.8))\n  model.add(Activation(\"relu\"))\n  model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n  model.add(Activation(\"tanh\"))\n  model.summary()\n\n  noise = Input(shape=(self.latent_dim,))\n  img = model(noise)\n  return Model(noise, img)\n```", "```py\ndef build_discriminator(self):\n  model = Sequential()\n  model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n  model.add(LeakyReLU(alpha=0.2))\n  model.add(Dropout(0.25))\n  model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n  model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n  model.add(BatchNormalization(momentum=0.8))\n  model.add(LeakyReLU(alpha=0.2))\n  model.add(Dropout(0.25))\n  model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n  model.add(BatchNormalization(momentum=0.8))\n  model.add(LeakyReLU(alpha=0.2))\n  model.add(Dropout(0.25))\n  model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n  model.add(BatchNormalization(momentum=0.8))\n  model.add(LeakyReLU(alpha=0.2))\n  model.add(Dropout(0.25))\n  model.add(Flatten())\n  model.add(Dense(1, activation='sigmoid'))\n  model.summary()\n\n  img = Input(shape=self.img_shape)\n  validity = model(img)\n  return Model(img, validity)\n```", "```py\ndef __init__(self):\n  self.img_rows = 28\n  self.img_cols = 28\n  self.channels = 1\n  self.img_shape = (self.img_rows, self.img_cols, self.channels)\n  self.latent_dim = 100\n  optimizer = Adam(0.0002, 0.5)\n\n  self.discriminator = self.build_discriminator()\n  self.discriminator.compile(loss='binary_crossentropy',    \n  optimizer=optimizer, metrics=['accuracy'])\n\n  self.generator = self.build_generator() \n  z = Input(shape=(self.latent_dim,))\n  img = self.generator(z)\n\n  self.discriminator.trainable = False\n  valid = self.discriminator(img)\n\n  self.combined = Model(z, valid)\n  self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n```", "```py\ndef train(self, epochs, batch_size=128, save_interval=50):  \n  (X_train, _), (_, _) = mnist.load_data()\n  X_train = X_train / 127.5 - 1.\n  X_train = np.expand_dims(X_train, axis=3)\n\n  valid = np.ones((batch_size, 1))\n  fake = np.zeros((batch_size, 1))\n```", "```py\nfor epoch in range(epochs):\n```", "```py\nidx = np.random.randint(0, X_train.shape[0], batch_size)\nimgs = X_train[idx]\n```", "```py\nnoise = np.random.normal(0, 1, (batch_size, self.latent_dim))\ngen_imgs = self.generator.predict(noise)\n```", "```py\nd_loss_real = self.discriminator.train_on_batch(imgs, valid)\nd_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\nd_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n```", "```py\ng_loss = self.combined.train_on_batch(noise, valid)\n\nprint (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\nif epoch % save_interval == 0:\n  self.save_imgs(epoch)\n```", "```py\ndef train(self, epochs, batch_size=128, sample_interval=50):\n  (X_train, _), (_, _) = mnist.load_data()\n\n  X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n  X_train = np.expand_dims(X_train, axis=3)\n\n  valid = -np.ones((batch_size, 1))\n  fake = np.ones((batch_size, 1))\n\n  for epoch in range(epochs):\n    for _ in range(self.n_critic):\n      idx = np.random.randint(0, X_train.shape[0], batch_size)\n      imgs = X_train[idx]\n      noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n      gen_imgs = self.generator.predict(noise)\n\n      d_loss_real = self.critic.train_on_batch(imgs, valid)\n      d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n      d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n\n      for l in self.critic.layers:\n        weights = l.get_weights()\n        weights = [np.clip(w, -self.clip_value, self.clip_value) for \n        w in weights]\n        l.set_weights(weights)\n\n    g_loss = self.combined.train_on_batch(noise, valid)\n    print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 \n    - g_loss[0]))\\\n\n    if epoch % sample_interval == 0:\n      self.sample_images(epoch)\n```", "```py\nfrom keras.datasets import mnist  #remove or leave\nfrom keras.datasets import cifar100  #add\n```", "```py\nclass WGAN():\n  def __init__(self):\n    self.img_rows = 32\n    self.img_cols = 32\n    self.channels = 3\n```", "```py\n#(X_train, _), (_, _) = mnist.load_data() or delete me\n(X_train, y), (_, _) = cifar100.load_data(label_mode='fine')\nZ_train = []\ncnt = 0\nfor i in range(0,len(y)):\n  if y[i] == 33:  #forest images\n  cnt = cnt + 1 \n  z = X_train[i]\n  Z_train.append(z)\n#X_train = (X_train.astype(np.float32) - 127.5) / 127.5 or delete me\n#X_train = np.expand_dims(X_train, axis=3)\nZ_train = np.reshape(Z_train, [500, 32, 32, 3])\nZ_train = (Z_train.astype(np.float32) - 127.5) / 127.5\n\n#X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n#X_train = np.expand_dims(X_train, axis=3)\n```", "```py\ndef build_generator(self):\n  model = Sequential()\n  model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n  model.add(Reshape((8, 8, 128)))\n  model.add(UpSampling2D())\n  model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n  model.add(BatchNormalization(momentum=0.8))\n  model.add(Activation(\"relu\"))\n  model.add(UpSampling2D())\n  model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n  model.add(BatchNormalization(momentum=0.8))\n  model.add(Activation(\"relu\"))\n  model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n  model.add(Activation(\"tanh\"))\n  model.summary()\n  noise = Input(shape=(self.latent_dim,))\n  img = model(noise)\n  return Model(noise, img)\n```", "```py\ndef save_images(self, imgs, epoch):\n  r, c = 5, 5 \n  gen_imgs = 0.5 * imgs + 1\n  fig, axs = plt.subplots(r, c)\n  cnt = 0\n  for i in range(r):\n    for j in range(c):\n      axs[i,j].imshow(gen_imgs[cnt, :,:,0],cmap='gray')\n      axs[i,j].axis('off')\n      cnt += 1\n\n  fig.savefig(\"images/cifar_%d.png\" % epoch)\n  plt.close()\n```", "```py\nidx = np.random.randint(0, Z_train.shape[0], batch_size)\nimgs = Z_train[idx] \nif epoch % sample_interval == 0:\n self.save_images(imgs, epoch)\n```", "```py\nmodel.add(BatchNormalization(momentum=0.8))\n```", "```py\npip install music21\npip install h5py\n```", "```py\ncd musegen\npython musegen.py or python3 musegen.py\n```", "```py\nprint('loading networks...')\ndir_path = os.path.dirname(os.path.realpath(__file__))\ngenerator = loadModelAndWeights(os.path.join(dir_path, note_generator_dir, 'model.json'),\n                               os.path.join(dir_path, note_generator_dir, 'weights-{:02d}.hdf5'.format(generator_epoch)))\n```", "```py\nx_p = Input(shape=(sequence_length, pitch_dim,), name='pitches_input')\nh = LSTM(256, return_sequences=True, name='h_lstm_p_1')(x_p)\nh = LSTM(512, return_sequences=True, name='h_lstm_p_2')(h)\nh = LSTM(256, return_sequences=True, name='h_lstm_p_3')(h)\n\n# VAE for pitches\nz_mean_p = TimeDistributed(Dense(latent_dim_p, kernel_initializer='uniform'))(h)\nz_log_var_p = TimeDistributed(Dense(latent_dim_p, kernel_initializer='uniform'))(h)\n\nz_p = Lambda(sampling)([z_mean_p, z_log_var_p])\nz_p = TimeDistributed(Dense(pitch_dim, kernel_initializer='uniform', activation='softmax'))(z_p)\n\nx_d = Input(shape=(sequence_length, duration_dim, ), name='durations_input')\nh = LSTM(128, return_sequences=True)(x_d)\nh = LSTM(256, return_sequences=True)(h)\nh = LSTM(128, return_sequences=True)(h)\n\n# VAE for durations\nz_mean_d = TimeDistributed(Dense(latent_dim_d, kernel_initializer='uniform'))(h)\nz_log_var_d = TimeDistributed(Dense(latent_dim_d, kernel_initializer='uniform'))(h)\n\nz_d = Lambda(sampling)([z_mean_d, z_log_var_d])\nz_d = TimeDistributed(Dense(duration_dim, kernel_initializer='uniform', activation='softmax'))(z_d)\nconc = Concatenate(axis=-1)([z_p, z_d])\nlatent = TimeDistributed(Dense(pitch_dim + duration_dim, kernel_initializer='uniform'))(conc)\nlatent = LSTM(256, return_sequences=False)(latent)\n\no_p = Dense(pitch_dim, activation='softmax', name='pitches_output', kernel_initializer='uniform')(latent)\no_d = Dense(duration_dim, activation='softmax', name='durations_output', kernel_initializer='uniform')(latent)\n```", "```py\npython note-generator.py \nor \npython3 note-generator.py\n```", "```py\ndef loadChorales():\n    notes = []\n    iterator = getChoralesIterator()\n\n    # load notes of chorales\n    for chorale in iterator[1:maxChorales]: # iterator is 1-based \n        transpose_to_C_A(chorale.parts[0])\n        notes = notes + parseToFlatArray(chorale.parts[0])\n        notes.append((['end'], 0.0)) # mark the end of the piece\n\n    return notes\n```", "```py\n# latent dimension of VAE (used in pitch-generator)\nlatent_dim = 512\n\n# latent dimensions for pitches and durations (used in note-generator)\nlatent_dim_p = 512\nlatent_dim_d = 256\n\n# directory for saving the note embedding network model --- not used anymore\nnote_embedding_dir = \"models/note-embedding\"\n\n# directory for saving the generator network model\npitch_generator_dir = 'models/pitch-generator'\n\n# directory for saving the note generator network model\nnote_generator_dir = 'models/note-generator'\n\n# directory for saving generated music samples\noutput_dir = 'samples'\n```", "```py\npython lstm.py \nor\npython3 lstm.py\n```", "```py\npython predict.py\nor\npython3 predict.py\n```"]