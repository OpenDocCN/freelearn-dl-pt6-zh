<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Caffe2 at the Edge and in the cloud</h1>
                </header>
            
            <article>
                
<p class="mce-root">In chapters 1-6 of this book, we have learned how to install and use Caffe2 to train DL neural networks and how to work with other popular DL frameworks. We have also learnt how to deploy our trained Caffe2 models on popular inference engines. In this last chapter, we will look at applications of Caffe2 that exploit its ability to scale from tiny edge devices such as the Raspberry Pi to running on containers in the cloud. We will also look at visualizing Caffe2 models.</p>
<p>The topics that will be covered in this chapter are as follows:</p>
<ul>
<li class="h1">Caffe2 at the edge on Raspberry Pi</li>
<li class="h1">Caffe2 in the cloud using containers</li>
<li class="h1">Caffe2 model visualization</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Caffe2 at the edge on Raspberry Pi</h1>
                </header>
            
            <article>
                
<p>There is a lot of interest in using deep learning at the edge. This is the application of deep learning to compute solutions on or near the devices that capture data using sensors and cameras. An alternative solution to deep learning at the edge is to capture edge data and send it to in the cloud for processing. But, deep learning at the edge has the advantage of lower latency and higher security. Devices at the edge are typically cheap, have a small form factor and use less power, and their processors or accelerators have less compute capability. One of the key advantages of Caffe2 is that it has been designed and developed from the beginning to scale: from multi-GPU, multi-CPU servers, down to tiny edge devices. In this section, we will use the Raspberry Pi as an example of an edge device and learn how to use Caffe2 on it.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Raspberry Pi</h1>
                </header>
            
            <article>
                
<p><span>The </span>Raspberry Pi<span> is a series of single-board general-purpose computers introduced by the </span>Raspberry Pi Foundation<span> from the UK. <em>Figure 7.1</em> shows the latest Rv3 board of the Raspberry Pi B+ unit, as follows:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-344 image-border" src="assets/fa3ebe16-1ea5-4f44-9649-bd767ed2c26b.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.1: A Raspberry Pi B+ Rev3 board, released in 2018</div>
<p>Since its introduction in 2012, the Pi has taken the world by storm, being used for teaching in schools, for hobby projects, and real-world deployments at the edge. Costing about $35 each, the Pi is affordable for all types of projects. What makes the Raspberry Pi computer so useful is its small form factor; it is about the size of a pack of cards. The Pi requires little power, running off a 5V micro-USB power supply. And the Pi is a fully general-purpose computer, with all common storage and I/O ports, such as SD/microSD card slots, USB ports, wireless connectivity, an Ethernet port, an HDMI out, and a composite video out. Probably the biggest advantage of the Pi over other devices in its form factor is the availability of Raspbian, a port of the popular Debian Linux distribution for the Pi. With Raspbian, Pi users get to use the same tools, compilers and programming libraries that are available on a mainstream Linux distribution.</p>
<p>Our Caffe2 experiment on the Raspberry Pi will involve the following steps:</p>
<ol>
<li>Installing Raspbian</li>
<li>Building and using Caffe2 on Raspbian</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing Raspbian</h1>
                </header>
            
            <article>
                
<p>Follow these steps to install Raspbian:</p>
<ol start="1">
<li>Download Raspbian releases from <a href="https://www.raspberrypi.org/downloads/raspbian/">https://www.raspberrypi.org/downloads/raspbian/</a>. There is a Raspbian release corresponding to every Debian release. The latest Debian version 9 is called <strong>Stretch</strong> and the corresponding Raspbian is called Raspbian 9 or Raspbian Stretch.</li>
<li>Choose a Raspbian bundle that is appropriate for you. To suit various applications, there are three type of Raspbian Stretch bundles that are available. For our purpose, the smallest bundle called <span class="packt_screen">Raspbian Stretch Lite</span> <span>is adequate. If you would like to use a desktop and GUI apps, then you can try the other bundles that ship with those features. Once your Raspbian is connected to your network, you can SSH into it and get full access to a Bash shell to run commands and console tools and editors. You could also choose to install other GUI applications later if you required them. Stretch Lite is sufficient for all these purposes.</span></li>
<li>Pick a tool to flash the Raspbian disk image to an SD card. A recommended easy-to-use tool for this purpose is <strong>Etcher</strong>. Download it from <a href="https://www.balena.io/etcher/">https://www.balena.io/etcher/</a>.</li>
<li>Once you have installed Etcher, plug in an SD card with a minimum of 4 GB capacity into your computer's SD card slot. Use Etcher to flash the Raspbian disk image to the SD card.</li>
</ol>
<div class="packt_infobox">The Raspberry Pi can be used as a headless computer by SSHing to it instead of working at it locally. If you would like this feature to be enabled from the very first boot up of Raspbian then put back the flashed SD card into your computer. Then, create an empty file named <kbd>ssh</kbd> in the root directory of the SD card.</div>
<ol start="5">
<li>Now we are done with flashing the SD card with Raspbian. Insert this SD card into the SD card slot on the Raspberry Pi board. Make sure your Pi is connected to your home wireless router with an Ethernet cable. Optionally, you can also connect your Pi to your TV or computer display with an HDMI cable to watch its boot messages.</li>
<li>Power on the Pi. You can see the boot messages of Raspbian on your TV or display. At the end of the boot-up sequence, it displays the IP address assigned to it by DHCP and asks you to log in locally. Alternatively, you can also figure out the IP address allocated to the Pi by checking the admin console of your wireless router. Now you can SSH into the Raspbian from any computer on the network using the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ ssh pi@&lt;IP address of Pi&gt;</strong></pre>
<ol start="7">
<li>Use the default password: <kbd>raspberry</kbd>. After your first successful login, Raspbian will remind you to change the default password. Please do so by typing the <kbd>passwd</kbd> <span>command </span>at the shell. You can use this new password from the next time you SSH into the Pi.</li>
<li>Finally, make sure to update the package repositories and update the installed packages using the following commands:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo apt update</strong><br/><strong>$ sudo apt upgrade</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building Caffe2 on Raspbian</h1>
                </header>
            
            <article>
                
<p>Caffe2 has been ported to Raspbian. But there is no easy way to cross-compile to the Raspberry Pi from your x86_64 computer, so Caffe2 has to be built on the diminutive Pi itself.</p>
<p>We could SSH to the Pi and clone the Caffe2 Git repository on it. However, the full PyTorch and Caffe2 repository, along with their submodules, is more than 400 MB, and that clone operation could take a long time to complete on the Pi. Also, note that it is fastest to clone to the SD card rather than a hard disk connected by USB to the Pi. The latter can be painfully slow because Pi only has USB 2.0 (which is slower than USB 3.0) and the USB ports and Ethernet ports share the same bus, further limiting the Git clone speed.</p>
<p>Let's get started with building Caffe 2 on Raspbian:</p>
<ol>
<li>Since it is easiest to clone on your local computer, let's do that first using the following commands:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ git clone --recursive https://github.com/pytorch/pytorch.git</strong><br/><strong>$ cd pytorch</strong><br/><strong>$ git submodule update --init</strong></pre>
<ol start="2">
<li>Once the clone is done, reduce the size of this directory by deleting the Git repository data, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ rm -rf .git</strong></pre>
<ol start="3">
<li>Now compress this into a <kbd>.tar.gz</kbd> archive and copy it over SSH to the Pi, as follows:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ cd ..</strong><br/><strong>$ tar zcvf pytorch.tar.gz pytorch</strong><br/><strong>$ scp pytorch.tar.gz pi@&lt;IP address of Pi&gt;:/home/pi</strong></pre>
<ol start="4">
<li> SSH to the Pi and decompress the copied archive there, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ tar xvf pytorch.tar.gz</strong><br/><strong>$ cd pytorch</strong></pre>
<ol start="5">
<li>The script to build Caffe2 on Raspbian is <kbd>scripts/build_raspbian.sh</kbd>. Note that this Raspbian build has not been maintained in recent times. So, before we run it, we need to install a few Python packages that are necessary for successful compilation, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo apt install python-future python-typing python-yaml</strong><br/><strong>$ sudo pip install -U protobuf</strong></pre>
<ol start="6">
<li>We are now ready to build by invoking the following script:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ cd scripts</strong><br/><strong>$ ./build_raspbian.sh</strong></pre>
<ol start="7">
<li>Just like the build process we used in <a href="5f3ecee9-fc6c-4a3f-bc8f-3bffb7cb2269.xhtml">Chapter 1</a>,<span> </span><span class="cdp-organizer-chapter-title"><span class="cdp-organize-title-label"><em>Introduction and Installation</em>,</span></span> this also uses CMake, first to configure the make process and then to invoke <kbd>make</kbd> to build the necessary components, placing the built artifacts in the <kbd>build</kbd> subdirectory.</li>
</ol>
<p>Note that the build process takes a long time and could take as much as half a day. The Raspberry Pi has 500 MB to 1 GB of RAM (depending on which variant of Pi you have) and Raspbian, by default, allocates only about 100 MB of swap space. So, the build can fail sometimes because it runs out of memory. If that happens, you can increase the swap space by opening the <kbd>/etc/dphys-swapfile</kbd> <span>file </span>and increasing the <kbd>CONF_SWAPSIZE</kbd> value. I found that increasing it from <kbd>100</kbd> to <kbd>1000</kbd> was sufficient for successful compilation.</p>
<p>After compilation, you can install and test Caffe2 just as we did in <a href="5f3ecee9-fc6c-4a3f-bc8f-3bffb7cb2269.xhtml">Chapter 1</a>, <em>Introduction and Installation</em>, as shown in the following example:</p>
<pre><strong>$ cd ../build</strong><br/><strong>$ sudo make install</strong><br/><strong>$ python -c "from caffe2.python import core"</strong></pre>
<p>You now have Caffe2 working on the Raspberry Pi. You can now attach sensors or camera modules to the Pi, read images and data from them, and run them through DL networks for classification, detection, and understanding.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Caffe2 in the cloud using containers</h1>
                </header>
            
            <article>
                
<p>Containers are now a ubiquitous and necessary tool for robustly deploying software in production, both locally and in the cloud. They enable developers to create the ideal software environment for the application and ensure that this software environment is exactly replicated on developer workstations, test computers, staging computers, and the final deployment to local servers or instances in the cloud. Containers also help create a sanitized software environment for every single application, enabling multiple software environments, one for each application, when multiple applications are running on the same server.</p>
<p>Among the many available container tools, <em>Docker</em> is the most popular. We will focus on using Docker in this section. Docker is available for all popular Linux distributions, macOS X, and Windows. With Docker, you can create an Ubuntu software environment from a specific Ubuntu version and run your Caffe2 application inside that on a RedHat host OS from a different version. Docker makes such varied deployments easy and doable in mere minutes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing Docker</h1>
                </header>
            
            <article>
                
<p>Follow these steps for installation:</p>
<ol>
<li>To install Docker using package repositories and packages specific to your OS or distribution, please follow the instructions here <a href="https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/">https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/</a>.</li>
<li>After the installation is successful, remember to add your username to the <kbd>docker</kbd> user group using a command like the one shown in the following example:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo adduser myusername docker</strong></pre>
<p style="padding-left: 60px">For this addition to the group to take full effect, you may need to log out and log back in again.</p>
<ol start="3">
<li>And, finally, to test if your Docker setup is working correctly, run the <kbd>hello-world</kbd> image. If successful, you will see a welcoming message similar to the following example:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ docker run hello-world</strong><br/><br/><strong>Hello from Docker!</strong><br/><strong>This message shows that your installation appears to be working correctly.</strong><br/><br/><strong>To generate this message, Docker took the following steps:</strong><br/><strong> 1. The Docker client contacted the Docker daemon.</strong><br/><strong> 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.</strong><br/><strong>   (amd64)</strong><br/><strong> 3. The Docker daemon created a new container from that image which <br/>    runs the </strong><strong>executable that produces the output you are currently <br/>    reading.</strong><br/><strong> 4. The Docker daemon streamed that output to the Docker client, <br/>    which sent it </strong><strong>to your terminal.</strong><br/><br/><strong>To try something more ambitious, you can run an Ubuntu container with:</strong><br/><strong> $ docker run -it ubuntu bash</strong><br/><br/><strong>Share images, automate workflows, and more with a free Docker ID:</strong><br/><strong> https://hub.docker.com/</strong><br/><br/><strong>For more examples and ideas, visit:</strong><br/><strong> https://docs.docker.com/get-started/</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>As a final experiment, you can get a Bash shell inside an Ubuntu container and explore inside that Ubuntu instance by using the following command:</p>
<pre><strong>$ docker run --rm -it ubuntu bash</strong></pre>
<p>Here we are launching an Ubuntu container. The <kbd>-it</kbd> option indicates that this is an interactive session. That is, we want to run the application (bash) and stay with it until we quit the container. This is opposed to the normal flow (such as in the <kbd>hello-world</kbd> container) where Docker executes an application and quits once it is completed. The <kbd>--rm</kbd> option indicates that Docker should tear down the container once we quit it. Normally, it would keep it around in the background, ready for use again.</p>
<p>You will notice that Docker logs you in as the <kbd>root</kbd> user and you get a root shell. You are placed at the root of the filesystem. The root privileges are only inside this Docker container. Any files you create or change inside the container are ephemeral. They are lost when you exit the container.</p>
<p>Once you are done exploring the Ubuntu container, you can quit by pressing <em>Ctrl + D</em> or typing <kbd>exit</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing nvidia-docker</h1>
                </header>
            
            <article>
                
<p>You can run Caffe2, Python, and C++ applications on the CPU in Docker after following the preceding steps. However, if you want to run Caffe2 applications on the GPU, then you need to install and use nvidia-docker.</p>
<p>NVIDIA-Docker provides full and unfettered access to the NVIDIA GPUs on your system to your applications running inside Docker. Note that this feature relies on the NVIDIA GPU driver installed on your host system. However, you do not need to install CUDA or cuDNN on your host system because you can spin up a container having any CUDA version you want installed inside it. This is a convenient way to build and test your applications against different CUDA versions.</p>
<p>The instructions for installing NVIDIA Docker can be found at <a href="https://github.com/NVIDIA/nvidia-docker">https://github.com/NVIDIA/nvidia-docker</a>. At the time of writing, nvidia-docker could be installed using the following steps:</p>
<ol>
<li>First, add the <kbd>nvidia-docker</kbd> repositories and update the package cache, as follows:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - distribution=$(. /etc/os-release;echo $ID$VERSION_ID)</strong><br/><strong>$ curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</strong><br/><strong>$ sudo apt-get update</strong></pre>
<ol start="2">
<li class="mce-root">Next, install the NVIDIA Docker runtime, as follows:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ sudo apt-get install -y nvidia-docker2</strong></pre>
<ol start="3">
<li class="mce-root">And, finally, restart the Docker daemon, as follows:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ sudo pkill -SIGHUP dockerd</strong></pre>
<p>We are now ready to test if our NVIDIA Docker is working and can access the NVIDIA GPU on our system. To do this we need to run the application <kbd>nvidia-smi</kbd> in the container, as follows:</p>
<pre><strong>$ docker run --runtime=nvidia --rm nvidia/cuda:9.0-base nvidia-smi</strong></pre>
<p><kbd>nvidia-smi</kbd> is a tool that talks to the NVIDIA GPU driver on your host system to print information about the GPUs available on your system. If your NVIDIA Docker installation is successful, you should be able to see the <kbd>nvidia-smi</kbd> list, the NVIDIA GPU driver version and the GPUs you have installed on it.</p>
<p>Note the Docker tag we used in this command: <kbd>nvidia/cuda:9.0-base</kbd>. This is a Docker image that has CUDA 9.0 installed inside it. The full list of available Docker images and tags can be seen here: <a href="https://hub.docker.com/r/nvidia/cuda/tags">https://hub.docker.com/r/nvidia/cuda/tags</a>. A table of CUDA versions and GPU driver versions compatible with each CUDA version can be found at <a href="https://github.com/NVIDIA/nvidia-docker/wiki/CUDA">https://github.com/NVIDIA/nvidia-docker/wiki/CUDA</a>.</p>
<p>In the preceding command, we specified that we wanted to use the NVIDIA Docker runtime using the <kbd>--runtime=nvidia</kbd> <span>option.</span> We can also run the same command without specifying the runtime by using the alias <kbd>nvidia-docker</kbd>, as follows:</p>
<pre><strong>$ nvidia-docker run --rm nvidia/cuda:9.0-base nvidia-smi</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running Caffe2 containers</h1>
                </header>
            
            <article>
                
<p class="mce-root">The Caffe2 project provides Docker images for different versions of Caffe2 and Ubuntu, both for CPU and GPU. The full list of available Docker images can be found at <a href="https://hub.docker.com/r/caffe2ai/caffe2/tags">https://hub.docker.com/r/caffe2ai/caffe2/tags</a>. The Caffe2 image Docker tag describes its capabilities succinctly. For example, the <kbd><span class="styles__name___3v6UY">c2v0.8.1.cpu.min.ubuntu16.04</span></kbd> <span>tag </span>indicates that the image has Caffe2 v0.8.1 for CPU on Ubuntu 16.04. The <kbd><span class="styles__name___3v6UY">c2v0.8.1.cuda8.cudnn7.ubuntu16.04</span></kbd> <span>tag </span>indicates that the image has Caffe2 v0.8.1 for GPU on Ubuntu 16.04 with CUDA 8.1 and cuDNN 7 installed.</p>
<p>We can spin up a Caffe2 CPU image and check whether Caffe2 works inside it in the following way:</p>
<pre><strong>$ docker run --rm -ti caffe2ai/caffe2:c2v0.8.1.cpu.min.ubuntu16.04</strong><br/><strong>root@13588569ad8f:/# python -c "from caffe2.python import core"</strong><br/><strong>WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.</strong></pre>
<p>We can spin up a Caffe2 GPU image and check whether Caffe2 works inside it in the following way:</p>
<pre><strong>$ nvidia-docker run --rm -ti caffe2ai/caffe2:c2v0.8.1.cuda8.cudnn7.ubuntu16.04</strong><br/><strong>root@9dd026974563:/# python -c "from caffe2.python import core"</strong></pre>
<p>Note how we need to use <kbd>nvidia-docker</kbd> instead of <kbd>docker</kbd> if we are using a Caffe2 GPU image.</p>
<p>Once your Caffe2 containers are working, you can mount your Caffe2 applications and data inside it and execute them. You can mount your host directories inside a Docker container using the <kbd>-v</kbd> option and indicating the guest directory to mount them to, as shown in the following example:</p>
<pre><strong>$ docker run --rm -ti -v /home/joe/caffe2_apps:/joe_caffe2_apps caffe2ai/caffe2:c2v0.8.1.cpu.min.ubuntu16.04</strong></pre>
<p>This mounts your <kbd>/home/joe/caffe2_apps</kbd> directory as <kbd>/joe_caffe2_apps</kbd> inside the container. You are now ready to build Caffe2 applications inside containers and deploy those applications to servers locally or in the cloud using containers.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Caffe2 model visualization</h1>
                </header>
            
            <article>
                
<p>DL models contain a high number of layers. Layers have many parameters, such as their name, type, weight dimensions, layer-type-specific parameters, input, and output tensor names. While typical feedforward network structures do not have cycles, the <strong>Recurrent Neural Network</strong> (<strong>RNN</strong>) and other network structures have cycles and other topologies. So, the ability to visualize the structure of a DL model is important, both for researchers devising new networks to solve problems, and for practitioners using new networks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Visualization using Caffe2 net_drawer</h1>
                </header>
            
            <article>
                
<p>Caffe2 ships with a simple visualization tool written in Python named <kbd>net_drawer</kbd>. This Python script can be found in your Caffe2 installation directory. For example, if you installed Caffe2 at <kbd>/usr/local</kbd>, then this tool is available at <kbd>/usr/local/lib/python2.7/dist-packages/caffe2/python/net_drawer.py</kbd> on your system. You can also find this tool in your Caffe2 source code at <kbd>caff2/python/net_drawer.py</kbd>.</p>
<p>We can visualize the AlexNet model from <a href="95863955-3504-48ab-a217-e95339a754d3.xhtml">Chapter 4</a>, <em>Working with Caffe</em>, using <kbd>net_drawer</kbd>, as follows:</p>
<pre><strong>$ python net_drawer.py --input /path/to/bvlc_alexnet/predict_net.pb --rankdir TB</strong></pre>
<p>We are indicating that we want to visualize the nodes of the graph in a top-to-bottom order using the option <kbd>--rankdir TB</kbd>. This command renders the AlexNet graph shown in <em>Figure 4.3</em> in <a href="95863955-3504-48ab-a217-e95339a754d3.xhtml">Chapter 4</a>, <em>Working with Caffe</em>.</p>
<p>This command writes two files. The first is a text file named <kbd>AlexNet.dot</kbd> that holds the graph structure in the human-readable GraphViz DOT format. The second is a PDF file named <kbd>AlexNet.pdf</kbd> with a graphical rendering of the structure.</p>
<p>Note that this tool provides other options to customize the visualization. You can find these by using the <kbd>--help</kbd> option, as follows:</p>
<pre><strong>$ python net_drawer.py --help</strong><br/><strong>usage: net_drawer.py [-h] --input INPUT [--output_prefix OUTPUT_PREFIX]</strong><br/><strong>                     [--minimal] [--minimal_dependency] [--<br/>                     append_output]</strong><br/><strong>                     [--rankdir RANKDIR]</strong><br/><br/><strong>Caffe2 net drawer.</strong><br/><br/><strong>optional arguments:</strong><br/><strong>  -h, --help            show this help message and exit</strong><br/><strong>  --input INPUT         The input protobuf file.</strong><br/><strong>  --output_prefix OUTPUT_PREFIX</strong><br/><strong>                        The prefix to be added to the output filename.</strong><br/><strong>  --minimal             If set, produce a minimal visualization.</strong><br/><strong>  --minimal_dependency  If set, only draw minimal dependency.</strong><br/><strong>  --append_output       If set, append the output blobs to the operator <br/>                        names.</strong><br/><strong>  --rankdir RANKDIR     The rank direction of the pydot graph.</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Visualization using Netron</h1>
                </header>
            
            <article>
                
<p><strong>Netron</strong> is a browser based DL model visualization written in Python. It is open source and available at <a href="https://github.com/lutzroeder/netron">https://github.com/lutzroeder/netron</a>.</p>
<p>Compared to <kbd>net_drawer</kbd>, Netron has a modern visualization style and allows a far better interaction with the graph nodes to view their parameters. Also, Netron's zoom capability makes it easier to use on larger networks. The biggest advantage of using Netron is that it supports the visualization of models from a large number of DL frameworks, such as Caffe2, Caffe, TensorFlow, and also the ONNX format.</p>
<p>Netron can be installed from PyPI repository using the following command:</p>
<pre><strong>$ pip3 install --user netron</strong></pre>
<p>We can visualize our Caffe2 AlexNet protobuf file using Netron, as follows:</p>
<pre><strong>$ netron -b /path/to/predict_net.pb</strong></pre>
<p>This opens a new tab in your browser at <kbd>http://localhost:8080</kbd> with a visualization of the AlexNet model. We can zoom in and out using the scroll feature of the mouse. Clicking on any layer in the model shows its parameters on the right. This can be seen in <em>Figure 7.2</em> for our AlexNet model, as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-345 image-border" src="assets/eba9a08d-39f8-4fb2-8434-6c8168e9e83e.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.2: Netron visualization of AlexNet with the parameters of the first Convolution layer shown on the right</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In the final chapter of this guide, we looked at two applications of Caffe2 that demonstrate its ability. As an application of Caffe2 to edge devices, we looked at how to build Caffe2 on the Raspberry Pi single-board computers and run Caffe2 applications on them. As an application of Caffe2 to the cloud, we looked at how to build and run Caffe2 applications inside Docker containers. As an aid to understanding the structure of DL models, we examined two tools that helped in the visualization of Caffe2 models.</p>


            </article>

            
        </section>
    </body></html>