["```py\nimport numpy as np np.random.seed(42)\n```", "```py\nimport keras from keras.datasets import mnist  \nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\n```", "```py\n(X_train, y_train), (X_test, y_test)= mnist.load_data()\n```", "```py\nX_train.shape\n(60000, 28, 28)\n```", "```py\ny_train.shape\n(60000,)\n```", "```py\ny_train [0 :99]  \narray([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9,\n       1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9,\n       8, 5, 9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0,\n       0, 1, 7, 1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7,\n       4, 6, 8, 0, 7, 8, 3], dtype=uint8)\n```", "```py\nX_test.shape\n(10000, 28, 28)\n```", "```py\nX_test[0]\narray([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,      \n          .\n          .\n,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n         18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0]], dtype=uint8)\n```", "```py\ny_test.shape\n(10000,)\n```", "```py\ny_test[0]\n7\n```", "```py\nX_train = X_train.reshape(60000, 784).astype('float32')\nX_test = X_test.reshape(10000, 784).astype('float32')\nX_train/=255\nX_test /=255\n```", "```py\nX_test[0]\narray([ 0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,\n        0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,\n        .\n        .\n        .\n        0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,\n        0.47450981,  0.99607843,  0.99607843,  0.85882354,  0.15686275,\n        0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,\n        0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,\n        0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,\n        0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,\n        0\\.        ,  0\\.        ,  0\\.        ,  0.47450981,  0.99607843,\n        0.81176472,  0.07058824,  0\\.        ,  0\\.        ,  0\\.        ,\n        0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,\n        0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,\n        0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,\n        0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ,\n        0\\.        ,  0\\.        ,  0\\.        ,  0\\.        ], dtype=float32)\n```", "```py\nn_classes=10\ny_train= keras.utils.to_categorical(y_train ,n_classes)\ny_test= keras.utils.to_categorical(y_test,n_classes)\n```", "```py\ny_test[0]\narray([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])\n```", "```py\nmodel=Sequential()\nmodel.add(Dense(64,activation='sigmoid', input_shape=(784,)))\nmodel.add(Dense(10,activation='softmax'))  \n```", "```py\nmodel.summary()\n_______________________________________________________________\nLayer (type)                 Output Shape              Param #\n=================================================================\ndense_1 (Dense)              (None, 64)                50240     \n_______________________________________________________________\ndense_2 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 50,890\nTrainable params: 50,890\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nmodel.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01),metrics['accuracy'])  \n```", "```py\nmodel.fit(X_train,y_train,batch_size=128,epochs=200,\nverbose=1,validation_data =(X_test,y_test))  \n```", "```py\nEpoch 1/200\n60000/60000 [==============================] - 1s - loss: 0.0915 - acc: 0.0895 - val_loss: 0.0911 - val_acc: 0.0955\nEpoch 2/200\n.\n.\n.\n60000/60000 [==============================] - 1s - loss: 0.0908 - acc: \n0.8579 - val_loss: 0.0274 - val_acc: 0.8649\nEpoch 199/200\n60000/60000 [==============================] - 1s - loss: 0.0283 - acc: 0.8585 - val_loss: 0.0273 - val_acc: 0.8656\nEpoch 200/200\n60000/60000 [==============================] - 1s - loss: 0.0282 - acc: 0.8587 - val_loss: 0.0272 - val_acc: 0.8658\n<keras.callbacks.History at 0x7f308e68be48>\n```", "```py\nmodel.evaluate(X_test,y_test)\n9472/10000 [===========================>..] - ETA: 0s\n[0.027176343995332718, 0.86580000000000001]\n```", "```py\nimport numpy as np np.random.seed(42)\nimport keras from keras.datasets import mnist \nfrom keras.models import Sequential \nfrom keras.layers import Dense\nfrom keras.optimizers import SG\n#loading and pre-processing data\n(X_train,y_train), (X_test,y_test)= mnist.load_data()\nX_train= X_train.reshape( 60000, 784). astype('float32')\nX_test =X_test.reshape(10000,784).astype('float32')\nX_train/=255\nX_test/=255\n```", "```py\nmodel=Sequential()\nmodel.add(Dense(64,activation='relu', input_shape=(784,)))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(10,activation='softmax'))\n\n```", "```py\nmodel.summary()\n_______________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 64)                50240     \n_______________________________________________________________\ndense_2 (Dense)              (None, 64)                4160      \n_______________________________________________________________\ndense_3 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 55,050\nTrainable params: 55,050\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nmodel.compile(loss='categorical_crossentropy',optimizer=SGD(lr=0.1), \nmetrics =['accuracy']) \n```", "```py\nmodel.fit(X_train,y_train,batch_size=128,epochs=200,verbose=1,validation_data =(X_test,y_test))\n```", "```py\nEpoch 1/200\n60000/60000 [==============================] - 1s - loss: 0.4785 - acc: 0.8642 - val_loss: 0.2507 - val_acc: 0.9255\nEpoch 2/200\n60000/60000 [==============================] - 1s - loss: 0.2245 - acc: 0.9354 - val_loss: 0.1930 - val_acc: 0.9436\n.\n.\n.\n60000/60000 [==============================] - 1s - loss: 4.8932e-04 - acc: 1.0000 - val_loss: 0.1241 - val_acc: 0.9774\n<keras.callbacks.History at 0x7f3096adadd8>\n```", "```py\nimport numpy as np np.random.seed(42)\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n*# new!*\nfrom\nkeras.layers.normalization *# new!*\nimport\nBatchNormalization\n*# new!*\nfrom keras import regularizers\n*# new!* \nfrom keras.optimizers\nimport SGD\n```", "```py\n(X_train,y_train),(X_test,y_test)= mnist.load_data()\nX_train= X_train.reshape(60000,784).\nastype('float32')\nX_test= X_test.reshape(10000,784).astype('float32')\nX_train/=255\nX_test/=255\nn_classes=10\ny_train=keras.utils.to_categorical(y_train,n_classes)\ny_test =keras.utils.to_categorical(y_test,n_classes)\n\n```", "```py\nmodel=Sequential()\nmodel.add(Dense(64,activation='relu',input_shape=(784,)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10,activation='softmax'))\nmodel.summary()\n_______________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 64)                50240     \n_______________________________________________________________\nbatch_normalization_1 (Batch (None, 64)                256       \n_______________________________________________________________\ndropout_1 (Dropout)          (None, 64)                0         \n_______________________________________________________________\ndense_2 (Dense)              (None, 64)                4160      \n_______________________________________________________________\nbatch_normalization_2 (Batch (None, 64)                256       \n_______________________________________________________________\ndropout_2 (Dropout)          (None, 64)                0         \n_______________________________________________________________\ndense_3 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 55,562\nTrainable params: 55,306\nNon-trainable params: 256_______________________________________________________________\n```", "```py\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n```", "```py\nmodel.fit(X_train, y_train, batch_size= 128, epochs= 200, verbose= 1, validation_data= (X_test,y_test))\n```", "```py\nEpoch 1/200\n60000/60000 [==============================] - 3s - loss: 0.8586 - acc: 0.7308 - val_loss: 0.2594 - val_acc: 0.9230\nEpoch 2/200\n60000/60000 [==============================] - 2s - loss: 0.4370 - acc: 0.8721 - val_loss: 0.2086 - val_acc: 0.9363\n.\n.\n.\nEpoch 200/200\n60000/60000 [==============================] - 2s - loss: 0.1323 - acc: 0.9589 - val_loss: 0.1136 - val_acc: 0.9690\n<keras.callbacks.History at 0x7f321175a748>\n```"]