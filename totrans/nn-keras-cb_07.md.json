["```py\n$ wget http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Training_Images.zip\n$ unzip GTSRB_Final_Training_Images.zip\n```", "```py\nfrom skimage import io\nimport os\nimport glob\n\nroot_dir = '/content/GTSRB/Final_Training/Images/'\nall_img_paths = glob.glob(os.path.join(root_dir, '*/*.ppm'))\n```", "```py\nimport numpy as np\nfrom skimage import color, exposure, transform\n\nNUM_CLASSES = 43\nIMG_SIZE = 48\n\ndef preprocess_img(img):\n     hsv = color.rgb2hsv(img)\n     hsv[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n     img = color.hsv2rgb(hsv)\n     img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n     return img\n```", "```py\ncount = 0\nimgs = []\nlabels = []\nfor img_path in all_img_paths:\n     img = preprocess_img(io.imread(img_path))\n     label = img_path.split('/')[-2]\n     imgs.append(img)\n     labels.append(label)\n\nX = np.array(imgs)\nY = to_categorical(labels, num_classes = NUM_CLASSES)\n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state= 42)\n```", "```py\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same',input_shape=(IMG_SIZE, IMG_SIZE, 3), activation='relu'))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(128, (3, 3), padding='same',activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(NUM_CLASSES, activation='softmax'))\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy']\n```", "```py\nmodel.fit(X_train, y_train,batch_size=32,epochs=5,validation_data = (X_test, y_test))\n```", "```py\n$ pip install PyDrive \n\nfrom pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nfrom google.colab import auth\nfrom oauth2client.client import GoogleCredentials\n\nauth.authenticate_user()\ngauth = GoogleAuth()\ngauth.credentials = GoogleCredentials.get_application_default()\ndrive = GoogleDrive(gauth)\n\nfile_id = '0B-KJCaaF7elleG1RbzVPZWV4Tlk' # URL id. \ndownloaded = drive.CreateFile({'id': file_id})\ndownloaded.GetContentFile('steering_angle.zip')\n\n$ unzip steering_angle.zip\n```", "```py\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import pi\nimport cv2\nimport scipy.misc\nimport tensorflow as tf\n```", "```py\nDATA_FOLDER = \"/content/driving_dataset/\"\nDATA_FILE = os.path.join(DATA_FOLDER, \"data.txt\")\nx = []\ny = []\n\ntrain_batch_pointer = 0\ntest_batch_pointer = 0\n\nwith open(DATA_FILE) as f:\n     for line in f:\n         image_name, angle = line.split() \n         image_path = os.path.join(DATA_FOLDER, image_name)\n         x.append(image_path) \n         angle_radians = float(angle) * (pi / 180) #converting angle into radians\n         y.append(angle_radians)\ny = np.array(y)\n```", "```py\nsplit_ratio = int(len(x) * 0.8)\ntrain_x = x[:split_ratio]\ntrain_y = y[:split_ratio]\ntest_x = x[split_ratio:]\ntest_y = y[split_ratio:]\n```", "```py\nfig = plt.figure(figsize = (10, 7))\nplt.hist(train_y, bins = 50, histtype = \"step\",color='r')\nplt.hist(test_y, bins = 50, histtype = \"step\",color='b')\nplt.title(\"Steering Wheel angle in train and test\")\nplt.xlabel(\"Angle\")\nplt.ylabel(\"Bin count\")\nplt.grid('off')\nplt.show()\n```", "```py\nx = []\ny = []\nfor i in range(10000):\n     im = cv2.imread(train_x[i])\n     im = im[100:,:,:]/255\n     vgg_im = vgg16_model.predict(im.reshape(1,im.shape[0],im.shape[1],3))\n     x.append(vgg_im)\n     y.append(train_y[i])\nx1 = np.array(x)\nx1 = x1.reshape(x1.shape[0],4,14,512)\ny1 = np.array(y)\n```", "```py\nmodel = Sequential()\nmodel.add(Flatten(input_shape=(4,14,512)))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(100, activation='linear'))\nmodel.add(Dropout(.2))\nmodel.add(Dense(50, activation='linear'))\nmodel.add(Dropout(.1))\nmodel.add(Dense(10, activation='linear'))\nmodel.add(Dense(1, activation='linear'))\nmodel.summary()\n```", "```py\nmodel.compile(loss='mean_squared_error',optimizer='adam')\n```", "```py\nmodel.fit(x1/11, y1,batch_size=32,epochs=10, validation_split = 0.1, verbose = 1)\n```", "```py\n$ wget https://www.dropbox.com/s/0pigmmmynbf9xwq/dataset1.zip\n$ unzip dataset1.zip\ndir_data = \"/content/dataset1\"\ndir_seg = dir_data + \"/annotations_prepped_train/\"\ndir_img = dir_data + \"/images_prepped_train/\"\nimport glob, os\nall_img_paths = glob.glob(os.path.join(dir_img, '*.png'))\nall_mask_paths = glob.glob(os.path.join(dir_seg, '*.png'))\n```", "```py\nimport cv2\nfrom scipy import ndimage\nx = []\ny = []\nfor i in range(len(all_img_paths)):\n  img = cv2.imread(all_img_paths[i])\n  img = cv2.resize(img,(224,224))\n  mask_path = dir_seg+all_img_paths[i].split('/')[4]\n  img_mask = ndimage.imread(mask_path)\n  img_mask = cv2.resize(img_mask,(224,224))\n  x.append(img)\n  y.append(img_mask)\n\nx = np.array(x)/255\ny = np.array(y)/255\ny2 = np.where(y==8,1,0)\n```", "```py\nx = np.array(x)\nx = x/255\ny2 = np.array(y2)\ny2 = y2.reshape(y2.shape[0],y2.shape[1],y2.shape[2],1)\n```", "```py\nfrom keras.applications.vgg16 import VGG16 as PTModel\nfrom keras.layers import Input, Conv2D, concatenate, UpSampling2D, BatchNormalization, Activation, Cropping2D, ZeroPadding2D\nfrom keras.layers import Input, merge, Conv2D, MaxPooling2D,UpSampling2D, Dropout, Cropping2D, merge, concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras import backend as K\nfrom keras.models import Model\n```", "```py\nbase_pretrained_model = PTModel(input_shape = (224,224,3), include_top = False, weights = 'imagenet')\nbase_pretrained_model.trainable = False\n```", "```py\nconv1 = Model(inputs=base_pretrained_model.input,outputs=base_pretrained_model.get_layer('block1_conv2').output).output\nconv2 = Model(inputs=base_pretrained_model.input,outputs=base_pretrained_model.get_layer('block2_conv2').output).output\nconv3 = Model(inputs=base_pretrained_model.input,outputs=base_pretrained_model.get_layer('block3_conv3').output).output\nconv4 = Model(inputs=base_pretrained_model.input,outputs=base_pretrained_model.get_layer('block4_conv3').output).output\ndrop4 = Dropout(0.5)(conv4)\nconv5 = Model(inputs=base_pretrained_model.input,outputs=base_pretrained_model.get_layer('block5_conv3').output).output\ndrop5 = Dropout(0.5)(conv5)\n```", "```py\nup6 = Conv2D(512, 2, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(UpSampling2D(size =(2,2))(drop5))\nmerge6 = concatenate([drop4,up6], axis = 3) \n\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(merge6)\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv6)\nconv6 = BatchNormalization()(conv6)\nup7 = Conv2D(256, 2, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(UpSampling2D(size =(2,2))(conv6))\nmerge7 = concatenate([conv3,up7], axis = 3)\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(merge7)\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv7)\nconv7 = BatchNormalization()(conv7)\nup8 = Conv2D(128, 2, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(UpSampling2D(size =(2,2))(conv7))\nmerge8 = concatenate([conv2,up8],axis = 3)\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(merge8)\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv8)\nconv8 = BatchNormalization()(conv8)\nup9 = Conv2D(64, 2, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(UpSampling2D(size =(2,2))(conv8))\nmerge9 = concatenate([conv1,up9], axis = 3)\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(merge9)\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv9)\nconv9 = Conv2D(2, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv9)\nconv9 = BatchNormalization()(conv9)\nconv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n```", "```py\nmodel = Model(input = base_pretrained_model.input, output = conv10)\n```", "```py\nfor layer in model.layers[:18]:\n     layer.trainable = False\n```", "```py\nfrom keras import optimizers\nadam = optimizers.Adam(1e-3, decay = 1e-6)\nmodel.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\nhistory = model.fit(x,y,validation_split = 0.1,batch_size=1,epochs=5,verbose=1)\n```", "```py\ny_pred = model.predict(x[-2:].reshape(2,224,224,3))\n```", "```py\n!wget https://www.dropbox.com/s/0pigmmmynbf9xwq/dataset1.zip\n!unzip dataset1.zip\ndir_data = \"/content/dataset1\"\ndir_seg = dir_data + \"/annotations_prepped_train/\"\ndir_img = dir_data + \"/images_prepped_train/\"\nimport glob, os\nall_img_paths = glob.glob(os.path.join(dir_img, '*.png'))\nall_mask_paths = glob.glob(os.path.join(dir_seg, '*.png'))\n```", "```py\nimport cv2\nfrom scipy import ndimage\nfor i in range(len(all_img_paths)):\n     img = cv2.imread(all_img_paths[i])\n     img = cv2.resize(img,(224,224))\n     mask_path = dir_seg+all_img_paths[i].split('/')[4]\n     img_mask = ndimage.imread(mask_path)\n     img_mask = cv2.resize(img_mask,(224,224))\n     x.append(img)\n     y.append(img_mask)\n```", "```py\nn_classes = len(set(np.array(y).flatten()))\n```", "```py\ndef getSegmentationArr(img):\n      seg_labels = np.zeros(( 224, 224, n_classes ))\n      for c in range(n_classes):\n            seg_labels[: , : , c ] = (img == c ).astype(int)\n      return seg_labels\n\ny2 = []\nfor i in range(len(y)):\n     y2.append(getSegmentationArr(y[i]))\n\ny2 = np.array(y2)\nx = x/255\n```", "```py\nfrom keras.applications.vgg16 import VGG16 as PTModel\nbase_pretrained_model = PTModel(input_shape = (224,224,3), include_top = False, weights = 'imagenet')\nbase_pretrained_model.trainable = False\n```", "```py\nconv1 = Model(inputs=base_pretrained_model.input,outputs=base_pretrained_model.get_layer('block1_conv2').output).output\nconv2 = Model(inputs=base_pretrained_model.input,outputs=base_pretrained_model.get_layer('block2_conv2').output).output\nconv3 = Model(inputs=base_pretrained_model.input,outputs=base_pretrained_model.get_layer('block3_conv3').output).output\nconv4 = Model(inputs=base_pretrained_model.input,outputs=base_pretrained_model.get_layer('block4_conv3').output).output\ndrop4 = Dropout(0.5)(conv4)\nconv5 = Model(inputs=base_pretrained_model.input,outputs=base_pretrained_model.get_layer('block5_conv3').output).output\ndrop5 = Dropout(0.5)(conv5)\n```", "```py\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(merge6)\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv6)\nconv6 = BatchNormalization()(conv6)\nup7 = Conv2D(256, 2, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(UpSampling2D(size =(2,2))(conv6))\nmerge7 = concatenate([conv3,up7], axis = 3)\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(merge7)\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv7)\nconv7 = BatchNormalization()(conv7)\nup8 = Conv2D(128, 2, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(UpSampling2D(size =(2,2))(conv7))\nmerge8 = concatenate([conv2,up8],axis = 3)\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(merge8)\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv8)\nconv8 = BatchNormalization()(conv8)\nup9 = Conv2D(64, 2, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(UpSampling2D(size =(2,2))(conv8))\nmerge9 = concatenate([conv1,up9], axis = 3)\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(merge9)\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv9)\nconv9 = Conv2D(2, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv9)\nconv9 = BatchNormalization()(conv9)\nconv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n\nmodel = Model(input = base_pretrained_model.input, output = conv10)\n```", "```py\nfor layer in model.layers[:18]:\n     layer.trainable = False\n```", "```py\nmodel.compile(optimizer=Adam(1e-3, decay = 1e-6), \n loss='categorical_crossentropy', metrics = ['accuracy'])\n\nhistory = model.fit(x,y2,epochs=15,batch_size=1,validation_split=0.1)\n```", "```py\ny_pred = model.predict(x[-2:].reshape(2,224,224,3))\ny_predi = np.argmax(y_pred, axis=3)\ny_testi = np.argmax(y2[-2:].reshape(2,224,224,12), axis=3)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.subplot(231)\nplt.imshow(x[-1])\nplt.axis('off')\nplt.title('Original image')\nplt.grid('off')\nplt.subplot(232)\nplt.imshow(y[-1])\nplt.axis('off')\nplt.title('Masked image')\nplt.grid('off')\nplt.subplot(233)\nplt.imshow(y_predi[-1])\nplt.axis('off')\nplt.title('Predicted masked image')\nplt.grid('off')\nplt.subplot(234)\nplt.imshow(x[-2])\nplt.axis('off')\nplt.grid('off')\nplt.subplot(235)\nplt.imshow(y[-2])\nplt.axis('off')\nplt.grid('off')\nplt.subplot(236)\nplt.imshow(y_predi[-2])\nplt.axis('off')\nplt.grid('off')\nplt.show()\n```"]