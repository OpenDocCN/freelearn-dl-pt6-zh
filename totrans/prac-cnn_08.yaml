- en: 'GAN: Generating New Images with CNN'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Generally, a neural network needs labeled examples to learn effectively. Unsupervised
    learning approaches to learn from unlabeled data have not worked very well. A **generative
    adversarial network**, or simply a **GAN**, is part of an unsupervised learning
    approach but based on differentiable generator networks. GANs were first invented
    by Ian Goodfellow and others in 2014\. Since then they have become extremely popular.
    This is based on game theory and has two players or networks: a generator network
    and b) a discriminator network, both competing against each other. This dual network
    game theory-based approach vastly improved the process of learning from unlabeled
    data. The generator network produces fake data and passes it to a discriminator.
    The discriminator network also sees real data and predicts whether the data it
    receives is fake or real. So, the generator is trained so that it can easily produce
    data that is very close to real data in order to fool the discriminator network.
    The discriminator network is trained to classify which data is real and which
    data is fake. So, eventually, a generator network learns to produce data that
    is very, very close to real data. GANs are going to be widely popular in the music
    and arts domains.'
  prefs: []
  type: TYPE_NORMAL
- en: According to Goodfellow, "*You can think of generative models as giving Artificial
    Intelligence a form of imagination*."
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are a couple of examples of GANs:'
  prefs: []
  type: TYPE_NORMAL
- en: Pix2pix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CycleGAN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pix2pix - Image-to-Image translation GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This network uses a **conditional generative adversarial network** (**cGAN**)
    to learn mapping from the input and output of an image. Some of the examples that
    can be done from the original paper are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5bd742bd-4360-4fb0-acaf-595d92808a92.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Pix2pix examples of cGANs
  prefs: []
  type: TYPE_NORMAL
- en: In the handbags example, the network learns how to color a black and white image.
    Here, the training dataset has the input image in black and white and the target
    image is the color version.
  prefs: []
  type: TYPE_NORMAL
- en: CycleGAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CycleGAN is also an image-to-image translator but without input/output pairs.
    For example, to generate photos from paintings, convert a horse image into a zebra
    image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/60b9b3b9-a03d-4a53-acbf-49563705690e.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In a discriminator network, use of dropout is important. Otherwise, it may produce
    a poor result.
  prefs: []
  type: TYPE_NORMAL
- en: The generator network takes random noise as input and produces a realistic image
    as output. Running a generator network for different kinds of random noise produces
    different types of realistic images. The second network, which is known as the **discriminator
    network**, is very similar to a regular neural net classifier. This network is
    trained on real images, although training a GAN is quite different from a supervised
    training method. In supervised training, each image is labeled first before being
    shown to the model. For example, if the input is a dog image, we tell the model
    this is a dog. In case of a generative model, we show the model a lot of images
    and ask it to make more such similar images from the same probability distribution.
    Actually, the second discriminator network helps the generator network to achieve
    this.
  prefs: []
  type: TYPE_NORMAL
- en: 'The discriminator outputs the probability that the image is real or fake from
    the generator network. In other words, it tries to assign a probability close
    to 1 for a real image and a probability close to 0 for fake images. Meanwhile,
    the generator does the opposite. It is trained to output images that will have
    a probability close to 1 by the discriminator. Over time, the generator produces
    more realistic images and fools the discriminator:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/31c3ec0c-b8e9-407f-9e05-9764f2b33178.png)'
  prefs: []
  type: TYPE_IMG
- en: Training a GAN model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Most machine learning models explained in earlier chapters are based on optimization,
    that is, we minimize the cost function over its parameter space. GANs are different
    because of two networks: the generator G and the discriminator D. Each has its
    own cost. An easy way to visualize GAN is the cost of the discriminator is the
    negative of the cost of the generator. In GAN, we can define a value function
    that the generator has to minimize and the discriminator has to maximize. The
    training process for a generative model is quite different from the supervised
    training method. GAN is sensitive to the initial weights. So we need to use batch
    normalization. Batch normalization makes the model stable, besides improving performance.
    Here, we train two models, the generative model and the discriminative model,
    simultaneously. Generative model G captures data distribution and discriminative
    model D estimates the probability of a sample that came from training data rather
    than G.'
  prefs: []
  type: TYPE_NORMAL
- en: GAN – code example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following example, we build and train a GAN model using an MNIST dataset
    and using TensorFlow. Here, we will use a special version of the ReLU activation
    function known as **Leaky ReLU**. The output is a new type of handwritten digit:'
  prefs: []
  type: TYPE_NORMAL
- en: Leaky ReLU is a variation of the ReLU activation function given by the formula *f(x) = max(α∗x, x**)*.
    So the output for the negative value for *x* is *alpha * x *and the output for
    positive *x* is *x*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to build this network, we need two inputs, one for the generator and
    one for the discriminator. In the following code, we create placeholders for `real_input`
    for the discriminator and `z_input` for the generator, with the input sizes as
    `dim_real` and `dim_z`, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, input `z` is a random vector to the generator which turns this vector
    into an image. Then we add a hidden layer, which is a leaky ReLU layer, to allow
    gradients to flow backwards. Leaky ReLU is just like a normal ReLU (for negative
    values emitting zero) except that there is a small non-zero output for negative
    input values. The generator performs better with the `tanh``sigmoid` function.
    Generator output is `tanh` output. So, we''ll have to rescale the MNIST images
    to be between -1 and 1, instead of 0 and 1\. With this knowledge, we can build
    the generator network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The discriminator network is the same as the generator except that output layer
    is a `sigmoid` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To build the network, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We want to share weights between real and fake data, so we need to reuse the
    variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Calculating loss
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the discriminator, the total loss is the sum of the losses for real and
    fake images. The losses will be sigmoid cross-entropyies, which we can get using
    the TensorFlow `tf.nn.sigmoid_cross_entropy_with_logits`. Then we compute the
    mean for all the images in the batch. So the losses will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: To help the discriminator generalize better, the `labels` can be reduced a bit
    from 1.0 to 0.9, by for example, using the parameter `smooth`*. *This is known
    as **label smoothing**, and is typically used with classifiers to improve performance. The
    discriminator loss for the fake data is similar. The `logits` are `d_logits_fake`,
    which we got from passing the generator output to the discriminator. These fake
    `logits` are used with `labels` of all zeros. Remember that we want the discriminator
    to output 1 for real images and 0 for fake images, so we need to set up the losses
    to reflect that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the generator losses are using `d_logits_fake`*, *the fake image `logits`.
    But now the `labels` are all 1s. The generator is trying to fool the discriminator,
    so it wants the discriminator to output ones for fake images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Adding the optimizer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need to update the generator and discriminator variables separately. So,
    first get all the variables of the graph and then, as we explained earlier, we
    can get only generator variables from the generator scope and, similarly, discriminator
    variables from the discriminator scope:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'To train the network, use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Once the model is trained and saved, you can visualize the generated digits
    (the code is not here, but it can be downloaded).
  prefs: []
  type: TYPE_NORMAL
- en: Semi-supervised learning and GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So for, we have seen how GAN can be used to generate realistic images. In this
    section, we will see how GAN can be used for classification tasks where we have
    less labeled data but still want to improve the accuracy of the classifier. Here
    we will also use the same **Street View House Number** or **SVHN** dataset to
    classify images. As previously, here we also have two networks, the generator
    G and discriminator D. In this case, the discriminator is trained to become a
    classifier. Another change is that the output of the discriminator goes to a softmax
    function instead of a `sigmoid` function, as seen earlier. The softmax function
    returns the probability distribution over labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8f617d78-0c02-4e22-9e9c-1e99923915dc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we model the network as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*total cost = cost of labeled data + cost of unlabeled data*'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get the cost of labeled data, we can use the `cross_entropy` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can calculate the sum of all classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Normal classifiers work on labeled data. However, semi-supervised GAN-based
    classifiers work on labeled data, real unlabeled data, and fake images. This works
    very well, that is, there are less classification errors even though we have less
    labeled data in the training process.
  prefs: []
  type: TYPE_NORMAL
- en: Feature matching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The idea of feature matching is to add an extra variable to the cost function
    of the generator in order to penalize the difference between absolute errors in
    the test data and training data.
  prefs: []
  type: TYPE_NORMAL
- en: Semi-supervised classification using a GAN example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we explain how to use GAN to build a classifier with the semi-supervised
    learning approach.
  prefs: []
  type: TYPE_NORMAL
- en: In supervised learning, we have a training set of inputs `X` and class labels `y`.
    We train a model that takes `X` as input and gives `y` as output.
  prefs: []
  type: TYPE_NORMAL
- en: In semi-supervised learning, our goal is still to train a model that takes `X` as
    input and generates `y` as output. However, not all of our training examples have
    a label `y`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the SVHN dataset. We''ll turn the GAN discriminator into an 11 class
    discriminator (0 to 9 and one label for the fake image). It will recognize the
    10 different classes of real SVHN digits, as well as an eleventh class of fake
    images that come from the generator. The discriminator will get to train on real
    labeled images, real unlabeled images, and fake images. By drawing on three sources
    of data instead of just one, it will generalize to the test set much better than
    a traditional classifier trained on only one source of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the discriminator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate the loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the optimizers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Build the network model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Train and persist the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Deep convolutional GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Deep convolutional GAN**, also called **DCGAN**, is used to generate color
    images. Here we use a convolutional layer in the generator and discriminator.
    We''ll also need to use batch normalization to get the GAN to train appropriately.
    We will discuss batch normalization in detail in the performance improvement of
    deep neural networks chapter. We''ll be training GAN on the SVHN dataset; a small
    example is shown in the following figure. After training, the generator will be
    able to create images that are nearly identical to these images. You can download
    the code for this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ca8ff0f4-19fc-465c-9b3e-aab5e4b9f1d7.png)'
  prefs: []
  type: TYPE_IMG
- en: Google Street View house numbers view
  prefs: []
  type: TYPE_NORMAL
- en: Batch normalization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Batch normalization is a technique for improving the performance and stability
    of neural networks. The idea is to normalize the layer inputs so that they have
    a mean of zero and variance of 1\. Batch normalization was introduced in Sergey
    Ioffe's and Christian Szegedy's 2015 paper, *Batch Normalization is Necessary
    to Make DCGANs Work*. The idea is that instead of just normalizing the inputs
    to the network, we normalize the inputs to layers within the network. It's called
    **batch** **normalization** because during training, we normalize each layer's
    input by using the mean and variance of the values in the current mini-batch.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen how the GAN model truly displays the power of
    CNN. We learned how to train our own generative model and saw a practical example
    of GAN that can generate photos from paintings and turn horses into zebras.
  prefs: []
  type: TYPE_NORMAL
- en: We understood how GAN differs from other discriminative models and learned why
    generative models are preferred.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about deep learning software comparison from
    scratch.
  prefs: []
  type: TYPE_NORMAL
