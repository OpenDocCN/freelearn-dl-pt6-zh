- en: '*Chapter 2*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction to Computer Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Explain the impact of artificial intelligence and computer vision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy some of the basic computer vision algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Develop some of the basic machine learning algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Construct your first neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter covers an introduction to computer vision followed by a few important
    basic computer vision and machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Artificial Intelligence** (**AI**) is changing everything. It tries to mimic
    human intelligence in order to achieve different tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: The section of AI that deals with images is called computer vision. Computer
    vision is an interdisciplinary scientific field that tries to mimic human eyes.
    It not only makes sense out of the pixels that are extracted from an image, but
    also gains a higher level of understanding from that specific image by performing
    automated tasks and using algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Some of these algorithms are better at object recognition, recognizing faces,
    classifying images, editing images, and even generating images.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will begin with an introduction to computer vision, starting with
    some of the most basic algorithms and an exercise to put them into practice. Later,
    an introduction to machine learning will be given, starting from the most basic
    algorithms to neural networks, involving several exercises to strengthen the knowledge
    acquired.
  prefs: []
  type: TYPE_NORMAL
- en: Basic Algorithms in Computer Vision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this topic, we will be addressing how images are formed. We will introduce
    a library that is very useful for performing computer vision tasks and we will
    learn about the workings of some of these tasks and algorithms and how to code
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Image Terminology
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To understand computer vision, we first need to know how images work and how
    a computer interprets them.
  prefs: []
  type: TYPE_NORMAL
- en: 'A computer understands an image as a set of numbers grouped together. To be
    more specific, the image is seen as a two-dimensional array, a matrix that contains
    values from 0 to 255 (0 being for black and 255 for white in grayscale images)
    representing the values of the pixels of an image (**pixel values**), as shown
    in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1: Image representation without and with pixel values](img/C13550_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: Image representation without and with pixel values'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the image on the left-hand side, the number 3 is shown in a low resolution.
    On the right-hand side, the same image is shown along with the value of every
    pixel. As this value rises, a brighter color is shown, and if the value decreases,
    the color gets darker.
  prefs: []
  type: TYPE_NORMAL
- en: This particular image is in grayscale, which means it is only a two-dimensional
    array of values from 0 to 255, but what about colored images? Colored images (or
    red/green/blue (RGB) images) have three layers of two-dimensional arrays stacked
    together. Every layer represents one color each and putting them all together
    forms a colored image.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding image has 14x14 pixels in its matrix. In grayscale, it is represented
    as 14x14x1, as it only has one matrix, and one channel. For the RGB format, the
    representation is 14x14x3 as it has 3 channels. From this, all that computers
    need to understand is that the images come from these pixels.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OpenCV is an open source computer vision library that has C++, Python, and Java
    interfaces and supports Windows, Linux, macOS, iOS, and Android.
  prefs: []
  type: TYPE_NORMAL
- en: For all the algorithms mentioned in this chapter, we will be using OpenCV. OpenCV
    helps us perform these algorithms using Python. If you want to practice one of
    these algorithms, we recommend using Google Colab. You will need to install Python
    3.5 or above, OpenCV, and NumPy to carry on with this chapter. To display them
    on our screens, we will use Matplotlib. Both of these are great libraries for
    AI.
  prefs: []
  type: TYPE_NORMAL
- en: Basic Image Processing Algorithms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order for a computer to understand an image, the image has to be processed
    first. There are many algorithms that can be used to process images and the output
    depends on the task at hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the most basic algorithms are:'
  prefs: []
  type: TYPE_NORMAL
- en: Thresholding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Morphological transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blurring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thresholding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Thresholding** is commonly used to simplify how an image is visualized by
    both the computer and the user in order to make analysis easier. It is based on
    a value that the user sets and every pixel is converted to white or black depending
    on whether the value of every pixel is higher or lower than the set value. If
    the image is in grayscale, the output image will be white and black, but if you
    choose to keep the RGB format for your image, the threshold will be applied for
    every channel, which means it will still output a colored image.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different methods for thresholding, and these are some of the most
    used ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Simple Thresholding:** If the pixel value is lower than the threshold set
    by the user, this pixel will be assigned a 0 value (black), or 255 (white). There
    are also different styles of thresholding within simple thresholding:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Threshold binary
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Threshold binary inverted
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Truncate
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Threshold to zero
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Threshold to zero inverted
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The different types of thresholds are shown in figure 2.2
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.2: Different types of thresholds](img/C13550_02_02.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.2: Different types of thresholds'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Threshold binary inverted works like binary but the pixels that were black are
    white and vice versa. Global thresholding is another name given to binary thresholding
    under simple thresholding.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Truncate shows the exact value of the threshold if the pixel is above the threshold
    and the pixel value.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Threshold to zero outputs the pixel value (which is the actual value of the
    pixel) if the pixel value is above the threshold value, otherwise it will output
    a black image, whereas threshold to zero inverted does the exact opposite.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The threshold value can be modified depending on the image or what the user
    wants to achieve.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Adaptive Thresholding**: Simple thresholding uses a global value as the threshold.
    If the image has different lighting conditions in some parts, the algorithm does
    not perform that well. In such cases, adaptive thresholding automatically guesses
    different threshold values for different regions within the image, giving us a
    better overall result with varying lighting conditions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'There are two types of adaptive thresholding:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Adaptive mean thresholding
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Adaptive Gaussian thresholding
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The difference between the adaptive thresholding and simple thresholding is
    shown in figure 2.3
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.3: Difference between adaptive thresholding and simple thresholding](img/C13550_02_03.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.3: Difference between adaptive thresholding and simple thresholding'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: In adaptive mean thresholding, the threshold value is the mean of the neighborhood
    area, while in adaptive Gaussian thresholding, the threshold value is the weighted
    sum of the neighborhood values where weights are a Gaussian window.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Otsu''s Binarization:** In global thresholding, we used an arbitrary value
    to assign a threshold value. Consider a bimodal image (an image where the pixels
    are distributed over two dominant regions). How would you choose the correct value?
    Otsu''s binarization automatically calculates a threshold value from the image
    histogram for a bimodal image. An **image histogram** is a type of [histogram](https://en.wikipedia.org/wiki/Histogram)
    that acts as a [graphical representation](https://en.wikipedia.org/wiki/Graphical_representation)
    of the [tonal](https://en.wikipedia.org/wiki/Lightness_(color)) distribution in
    a [digital image](https://en.wikipedia.org/wiki/Digital_image):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.4: Otsu’s thresholding](img/C13550_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Otsu''s thresholding'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 4: Applying Various Thresholds to an Image'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As we are training artificial neural networks on Google Colab, we should use
    the GPU that Google Colab provides us. In order to do that, we would have to go
    to `runtime > Change runtime type > Hardware accelerator: GPU > Save`.'
  prefs: []
  type: TYPE_NORMAL
- en: All the exercises and activities will be primarily developed in Google Colab.
    It is recommended to keep a separate folder for different assignments, unless
    advised not to.
  prefs: []
  type: TYPE_NORMAL
- en: The `Dataset` folder is available on GitHub in the Lesson02 | Activity02 folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this exercise, we will be loading an image of a subway, to which we will
    apply thresholding:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up your Google Colab interface.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a folder for the book, download the `Dataset` folder from GitHub, and
    upload it in the folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the drive and mount it as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: Every time you use a new collaborator, mount the drive to the desired folder.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once you have mounted your drive for the first time, you will have to enter
    the authorization code that you would get by clicking on the URL given by Google
    and pressing the **Enter** key on your keyboard:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.5: Image displaying the Google Colab authorization step](img/C13550_02_05.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.5: Image displaying the Google Colab authorization step'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now that you have mounted the drive, you need to set the path of the directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The path mentioned in step 5 may change as per your folder setup on Google Drive.
    The path will always begin with `cd /content/drive/My Drive/`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `Dataset` folder must be present in the path you are setting up.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now you need to import the corresponding dependencies: OpenCV `cv2` and Matplotlib:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now type the code to load the `subway.jpg` image, which we are going to process
    in grayscale using OpenCV and show using Matplotlib:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.6: Result of plotting the loaded subway image](img/C13550_02_06.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.6: Result of plotting the loaded subway image'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Let's apply simple thresholding by using OpenCV methods.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The method for doing so in OpenCV is called **cv2.threshold** and it takes
    three parameters: **image** (grayscale), **threshold value** (used to classify
    the pixel values), and **maxVal**, which represents the value to be given if the
    pixel value is more than (sometimes less than) the threshold value:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.7: Simple thresholding using OpenCV](img/C13550_02_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.7: Simple thresholding using OpenCV'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: We are going to do the same with adaptive thresholding.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The method for doing so is **cv2.adaptiveThreshold** and it has three special
    input parameters and only one output argument. Adaptive method, block size (the
    size of the neighborhood area), and C (a constant that is subtracted from the
    mean or weighted mean calculated) are the inputs, whereas you only obtain the
    thresholded image as the output. This is unlike global thresholding, where there
    are two outputs:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.8: Adaptive thresholding using OpenCV](img/C13550_02_08.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.8: Adaptive thresholding using OpenCV'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Finally, let's put Otsu's binarization into practice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The method is the same as for simple thresholding, **cv2.threshold**, but with
    an extra flag, **cv2.THRESH_OTU**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.9: Otsu’s binarization using OpenCV](img/C13550_02_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.9: Otsu''s binarization using OpenCV'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now you are able to apply different thresholding transformations to any image.
  prefs: []
  type: TYPE_NORMAL
- en: Morphological Transformations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A morphological transformation consists of a set of simple image operations
    based on an image shape, and they are usually used on binary images. They are
    commonly used to differentiate text from the background or any other shapes. They
    need two inputs, one being the original image, and the other is called the **structuring
    element** or **kernel**, which decides the nature of the operation. The **kernel**
    is usually a matrix that slides through the image, multiplying its values by the
    values of the pixels of the image. Two basic morphological operators are erosion
    and dilation. Their variant forms are opening and closing. The one that should
    be used depends on the task at hand:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Erosion**: When given a binary image, it shrinks the thickness by one pixel
    both on the interior and the exterior of the image, which is represented by white
    pixels. This method can be applied several times. It can be used for different
    reasons, depending on what you want to achieve, but normally it is used with dilation
    (which is explained in figure 2.10) in order to get rid of holes or noise. An
    example of erosion is shown here with the same digit, 3:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 2.10: Example of erosion](img/C13550_02_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.10: Example of erosion'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Dilation**: This method does the opposite of erosion. It increases the thickness
    of the object in a binary image by one pixel both on the interior and the exterior.
    It can also be applied to an image several times. This method can be used for
    different reasons, depending on what you want to achieve, but normally it is implemented
    along with erosion in order to get rid of holes in an image or noise. An example
    of dilation is shown here (we have implemented dilation on the image several times):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 2.11: Example of dilation](img/C13550_02_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.11: Example of dilation'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Opening**: This method performs erosion first, followed by dilation, and
    it is usually used for removing noise from an image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Closing**: This algorithm does the opposite of opening, as it performs dilation
    first before erosion. It is usually used for removing holes within an object:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 2.12: Examples of opening and closing](img/C13550_02_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.12: Examples of opening and closing'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, the opening method removes random noise from the image and the
    closing method works perfectly in fixing the small random holes within the image.
    In order to get rid of the holes of the output image from the opening method,
    a closing method could be applied.
  prefs: []
  type: TYPE_NORMAL
- en: There are more binary operations, but these are the basic ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 5: Applying the Various Morphological Transformations to an Image'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will be loading an image of a number, on which we will
    apply the morphological transformations that we have just learned about:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up your Google Colab interface.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set the path of the directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The path mentioned in step 2 may change, as per your folder setup on Google
    Drive.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import the OpenCV, Matplotlib, and NumPy libraries. NumPy here is the fundamental
    package for scientific computing with Python and will help us create the kernels
    applied:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now type the code to load the `Dataset/three.png` image, which we are going
    to process in grayscale using OpenCV and show using Matplotlib:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.13: Result of plotting the loaded image](img/C13550_02_13.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.13: Result of plotting the loaded image'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Let's apply erosion by using OpenCV methods.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The method used here is **cv2.erode**, and it takes three parameters: the image,
    a kernel that slides through the image, and the number of iterations, which is
    the number of times that it is executed:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.14: Output of the erosion method using OpenCV](img/C13550_02_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.14: Output of the erosion method using OpenCV'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: As we can see, the thickness of the figure has decreased.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We are going to do the same with dilation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The method used here is **cv2.dilate**, and it takes three parameters: the
    image, the kernel, and the number of iterations:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.15: Output of the dilation method using OpenCV](img/C13550_02_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.15: Output of the dilation method using OpenCV'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: As we can see, the thickness of the figure has increased.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Finally, let's put opening and closing into practice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The method used here is **cv2.morphologyEx**, and it takes three parameters:
    the image, the method applied, and the kernel:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.16: Output of the opening method (left) and closing method (right)
    using OpenCV](img/C13550_02_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.16: Output of the opening method (left) and closing method (right)
    using OpenCV'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The entire code file can be found on GitHub in the Lesson02 | Exercise05 folder.
  prefs: []
  type: TYPE_NORMAL
- en: Blurring (Smoothing)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Image blurring performs convolution over an image with a filter kernel, which
    in simpler terms is multiplying a matrix of specific values on every part of the
    image, in order to smooth it. It is useful for removing noise and edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Averaging**: In this method, we consider a box filter or kernel that takes
    the average of the pixels within the area of the kernel, replacing the central
    element by using convolution over the entire image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gaussian Blurring**: The kernel applied here is Gaussian, instead of the
    box filter. It is used for removing Gaussian noise in a particular image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Median Blurring**: Similar to averaging, but this one replaces the central
    element with the median value of the pixels of the kernel. It actually has a very
    good effect on salt-and-pepper noise (that is, visible black or white spots in
    an image).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In Figure 2.17, we have applied the aforementioned methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.17: Result of comparing different blurring methods](img/C13550_02_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.17: Result of comparing different blurring methods'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: There are many more algorithms that could be applied, but these are the most
    important ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 6: Applying the Various Blurring Methods to an Image'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will be loading an image of a subway, to which we will
    apply the blurring method:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up your Google Colab interface.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set the path of the directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The path mentioned in step 2 may be different according to your folder setup
    on Google Drive.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import the OpenCV, Matplotlib, and NumPy libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Type the code to load the `Dataset/subway.png` image that we are going to process
    in grayscale using OpenCV and show it using Matplotlib:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.18: Result of plotting the loaded subway image in RGB](img/C13550_02_18.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.18: Result of plotting the loaded subway image in RGB'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let''s apply all the blurring methods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The methods applied are **cv2.blur**, **cv2.GaussianBlur**, and **cv2.medianBlur**.
    All of them take an image as the first parameter. The first method takes only
    one argument, that is, the kernel. The second method takes the kernel and the
    standard deviation (sigmaX and sigmaY), and if both are given as zeros, they are
    calculated from the kernel size. The method mentioned last only takes one more
    argument, which is the kernel size:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.19: Blurring methods with OpenCV](img/C13550_02_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.19: Blurring methods with OpenCV'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now you know how to apply several blurring techniques to any image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7: Loading an Image and Applying the Learned Methods'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will be loading an image of a number and we will apply
    the methods that we have learned so far.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The entire code is available on GitHub in the Lesson02 | Exercise07-09 folder.
  prefs: []
  type: TYPE_NORMAL
- en: Open up a new Google Colab interface, and mount your drive as mentioned in *Exercise
    4*, *Applying the Various Thresholds to an Image*, of this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set the path of the directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The path mentioned in step 2 may be different according to your folder setup
    on Google Drive.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import the corresponding dependencies: NumPy, OpenCV, and Matplotlib:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Type the code to load the `Dataset/number.jpg` image, which we are going to
    process in grayscale using OpenCV and show using Matplotlib:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.20: Result of loading the image with the number](img/C13550_02_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.20: Result of loading the image with the number'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: If you want to recognize those digits using machine learning or any other algorithm,
    you need to simplify the visualization of them. Using thresholding seems to be
    the first logical step to proceed with this exercise. We have learned some thresholding
    methods, but the most commonly used one is Otsu's binarization, as it automatically
    calculates the threshold value without the user providing the details manually.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Apply Otsu''s binarization to the grayscale image and show it using Matplotlib:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.21: Using Otsu’s binarization thresholding on the image](img/C13550_02_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.21: Using Otsu''s binarization thresholding on the image'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In order to get rid of the lines in the background, we need to do some morphological
    transformations. First, start by applying the closing method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.22: Applying the closing method](img/C13550_02_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.22: Applying the closing method'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The lines in the background have been removed completely. Now a number prediction
    will be much easier.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In order to fill the holes that are visible in these digits, we need to apply
    the opening method. Apply the opening method to the preceding image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.23: Applying the opening method](img/C13550_02_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.23: Applying the opening method'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'There are still leftovers and imperfections around the digits. In order to
    remove these, a closing method with a bigger kernel would be the best choice.
    Now apply the corresponding method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.24: Applying the closing method with a kernel of a bigger size](img/C13550_02_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.24: Applying the closing method with a kernel of a bigger size'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Depending on the classifier that you use to predict the digits or the conditions
    of the given image, some other algorithms would be applied.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you want to predict the numbers, you will need to predict them one by one.
    Thus, you should divide the numbers into smaller numbers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Thankfully, OpenCV has a method to do this, and it''s called **cv2.findContours**.
    In order to find contours, we need to invert blacks into whites. This piece of
    code is larger, but it is only required if you want to predict character by character:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The entire code with added comments is available on GitHub in the Lesson02 |
    Exercise07-09 folder.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.25: Extracted digits as the output](img/C13550_02_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.25: Extracted digits as the output'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the first part of the code, we are finding the **contours** of the image
    (the curve joining all the continuous points along the boundary and of the same
    color or intensity) to find every digit, which we then sort depending on the area
    of each contour (each digit).
  prefs: []
  type: TYPE_NORMAL
- en: After this, we loop over the contours, cropping the original image with the
    given contours, ending up with every number in a different image.
  prefs: []
  type: TYPE_NORMAL
- en: After this, we need to have all the images with the same shape, so we adapt
    the image to a given shape using NumPy and append the image to a list of images
    along with the X position.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we sort the list of images using the X position (from left to right,
    so they remain in order) and plot the results. We also save every single digit
    as an image so that we can use every digit separately afterward for any task we
    want.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have successfully processed an image with text in it, obtained
    the text, and extracted every single character, and now the magic of machine learning
    can begin.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Machine learning** (**ML**) is the science of making computers learn from
    data without stating any rules. ML is mostly based on models that are trained
    with a lot of data, such as images of digits or features of different objects,
    with their corresponding labels, such as the number of those digits or the type
    of the object. This is called **supervised learning**. There are other types of
    learning, such as **unsupervised learning** and **reinforcement learning**, but
    we will be focusing on supervised learning. The main difference between supervised
    learning and unsupervised learning is that the model learns clusters from the
    data (depending on how many clusters you specify), which are translated into classes.
    Reinforcement learning, on the other hand, is concerned with how software agents
    should take action in an environment in order to increase a reward that is given
    to the agent, which will be positive if the agent is performing the right actions
    and negative otherwise.'
  prefs: []
  type: TYPE_NORMAL
- en: In this part of the chapter, we will gain an understanding of machine learning
    and check a variety of models and algorithms, going from the most basic models
    to explaining artificial neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Decision Trees and Boosting Algorithms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will be explaining decision trees and boosting algorithms
    as some of the most basic machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bagging** (decision trees and random forests) and **boosting** (AdaBoost)
    will be explained in this topic.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bagging:'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Decision trees** are perhaps the most basic machine learning algorithms,
    and are used for classification and regression, but on a basic level, they are
    used for teaching and performing tests.'
  prefs: []
  type: TYPE_NORMAL
- en: In a decision tree, every node represents an attribute of the data that is being
    trained on (whether something is true or false), where every branch (line between
    nodes) represents a decision (if something is true, go this way; otherwise, the
    other way) and every leaf represents a final outcome (if all conditions are fulfilled,
    it's a sunflower or a daisy).
  prefs: []
  type: TYPE_NORMAL
- en: We are now going to use the Iris dataset. This dataset considers sepal width
    and length, along with petal width and length, in order to classify Iris flowers
    as setosa, versicolour, or virginica.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Iris dataset can be downloaded from scikit-learn using Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-learn is a library that provides useful tools for data mining and data
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following flowchart shows the learning representation of a decision tree
    trained on this dataset. X represents features from the dataset, X0 being sepal
    length, X1 being sepal width, X2 being petal length, and X3 petal width. The ''value''
    tag is how many samples of each category fall into each node. We can see that,
    in the first step, the decision tree already distinguishes setosa from the other
    two by only considering the X2 feature, petal length:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.26: Graph of a decision tree for the Iris dataset](img/C13550_02_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.26: Graph of a decision tree for the Iris dataset'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Decision trees can be implemented in Python using only a couple of lines thanks
    to scikit-learn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '`x` and `y` are the features and the labels of the training set, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: '`x`, apart from being only columns of data representing those lengths and widths,
    could also be every pixel of the image. In machine learning, when the input data
    is images, every pixel is treated as a feature.'
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees are trained for one specific task or dataset and cannot be transferred
    to another similar problem. Nevertheless, several decision trees can be combined
    in order to create bigger models and learn how to generalize. These are called
    **random forests**.
  prefs: []
  type: TYPE_NORMAL
- en: The name forest refers to an ensemble of many decision tree algorithms, following
    the **bagging** method, which states that the combination of several algorithms
    achieves the best result overall. The appearance of the word "random" refers to
    the randomness of the algorithm when selecting the features to take into account
    to split a node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks again to scikit-learn, we can implement the random forest algorithm
    with only a couple of lines, fairly similar to the previous lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '`n_estimators` stands for the number of underlying decision trees. If you test
    the results with this method, the results will improve for sure.'
  prefs: []
  type: TYPE_NORMAL
- en: There are other methods that follow the **boosting** methodology as well. Boosting
    consists of algorithms called **weak learners** that are put together into a weighted
    sum and generate a strong learner, which gives an output. These weak learners
    are trained sequentially, meaning each one of them tries to solve the mistakes
    made by its predecessor.
  prefs: []
  type: TYPE_NORMAL
- en: There are many algorithms that use this approach. The most famous ones are AdaBoost,
    gradient boosting, and XGBoost. We are only going to look at AdaBoost as it is
    the most well known and easy to understand.
  prefs: []
  type: TYPE_NORMAL
- en: Boosting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**AdaBoost** puts together weak learners in order to form a strong learner.
    The name AdaBoost stands for adaptive boosting, which means that this strategy
    would weigh differently at each point in time. Those examples that are incorrectly
    classified in a single iteration, get a higher weight than the next iteration,
    and vice versa.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this method is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '`n_estimators` is the maximum number of estimators once boosting is completed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This method is initialized with a decision tree underneath; thus, the performance
    might not be as good as the random forest. But in order to make a better classifier,
    the random forest algorithm should be used instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Exercise 8: Predicting Numbers Using the Decision Tree, Random Forest, and
    AdaBoost Algorithms'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we are going to use the digits obtained from the last exercise
    and the models that we have learned in this topic to correctly predict every number.
    To do that, we are going to extract several digits from some samples inside the
    `Dataset/numbers` folder, along with the MNIST dataset to have enough data, so
    the models learn properly. The MNIST dataset is a compound of handwritten digits,
    which go from 0 to 9 with a shape of 28 x 28 x 3, and it is mostly used for researchers
    to test their methods or to play around with. Nevertheless, it can help to predict
    some numbers even though they are not of the same kind. You can check out this
    dataset at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).
  prefs: []
  type: TYPE_NORMAL
- en: As the installation of Keras requires TensorFlow, we propose to use Google Colab,
    which is just like a Jupyter notebook but with the difference that your system
    is not being used. Instead, a remote virtual machine is used and everything for
    machine learning and Python is already installed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We will be continuing the code from Exercise 7, here in the same notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Head to the interface on Google Colab, where you executed the code for *Exercise
    7*, *Loading an Image and Applying the Learned Methods.*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We are setting the seed of the random method to 42, which is for reproducibility:
    all random steps have the same randomness and always give the same output. It
    could be set to any number that does not vary.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now we are going to import the MNIST dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the last line of the code, we are loading the data in `x_train`, which is
    the training set (60,000 examples of digits), `y_train`, which are the labels
    of those digits, `x_test`, which is the testing set, and `y_test`, which are the
    corresponding labels. These are in NumPy format.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s show some of those digits using Matplotlib:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.27: MNIST dataset](img/C13550_02_27.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.27: MNIST dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: These digits do not look like the ones that we extracted in the previous exercise.
    In order to make the models properly predict the digits from the image processed
    in the first exercise, we will need to add some of those digits to this dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here''s the process for adding new digits that look like the ones we want to
    predict:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Add a Dataset folder with subfolders numbered from 0 to 9 (already done).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Get the code from the previous exercise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Use the code to extract all the digits from the images that are stored in '`Dataset/numbers/`'
    (already done).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Paste the generated digits to the corresponding folders with the name that corresponds
    to the digit generated (already done).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Add those images to the original dataset (step 5 in this exercise).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To add those images to your training set, these two methods should be declared:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The first method, `list_files()`, lists all the files within a folder with the
    specified extension, which in this case is `jpg`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the main method, `load_images()`, we are loading the images from those folders,
    which are from the digit folder, with its corresponding label. If the maximum
    is different to –1, we establish a limit to the quantity that is loaded for every
    digit. We do this because there should be similar samples for every digit. Finally,
    we convert the lists to NumPy arrays.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now we need to add these arrays to the training set so that our models can
    learn how to recognize the extracted digits:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After adding those digits using the method declared in the preceding code,
    we concatenate those arrays to the sets created before the for loop mentioned:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After this, the `train_test_split` method from `sklearn` is used in order to
    separate those digits – 20% for testing and the rest for training:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once done, we concatenate those to the original training and testing sets. We
    have printed the shape of x_train and x_test before and after so those extra 60
    digits can be seen. It goes from shape (60,000, 28, and 28) and (10,000, 28, and
    28) to shape (60,072, 28, and 28) and (10,018, 28, and 28).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For the models imported from sklearn that we are going to use in this exercise,
    we need to format the arrays to the shape (n samples and array), and now we have
    (n samples, array_height, and array_width):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We multiply the height and the width of the array in order to get the total
    length of the array, but only in one dimension: (28*28) = (784).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now we are ready to feed the data into the models. We will start training a
    decision tree:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In order to see how well this model performs, metric accuracy is used. This
    represents the number of samples from `x_test` that have been predicted, which
    we have already imported from the `metrics` module and from sklearn. Now we will
    be using `accuracy_score()` from that module to calculate the accuracy of the
    model. We need to predict the results from `x_test` using the `predict()` function
    from the model and see whether the output matches the `y_test` labels:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: After that, the accuracy is calculated and printed. The resulting accuracy percentage
    is **87.92%**, which is not a bad result for a decision tree. It can be improved
    though.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s try the random forest algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Following the same methodology to calculate the accuracy, the accuracy obtained
    is **94.75%**, which is way better and could be classified as a good model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we will try AdaBoost initialized with random forest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The accuracy obtained using AdaBoost is **95.67%**. This algorithm takes much
    more time than the previous ones but gets better results.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We are now going to apply random forest to the digits that were obtained in
    the last exercise. We apply this algorithm because it takes much less time than
    AdaBoost and gives better results. Before checking the following code, you need
    to run the code from the exercise one for the image stored in the `Dataset/number.jpg`
    folder, which is the one used in the first exercise, and for the other two images
    that are extracted for testing in the `Dataset/testing/` folder. Once you have
    done that, you should have five images of digits in your directory for every image,
    ready to be loaded. Here''s the code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.28: Random forest prediction for the digits 1, 6, 2, 1, and 6](img/C13550_02_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.28: Random forest prediction for the digits 1, 6, 2, 1, and 6'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here, we are applying the `predict()` function of the random forest model,
    passing every image to it. Random forest seems to perform pretty well, as it has
    predicted all of the numbers correctly. Let''s try another number that has not
    been used (there is a folder with some images for testing inside the `Dataset`
    folder):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.29: Random forest prediction for the digits 1, 5, 8, 3, and 4](img/C13550_02_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.29: Random forest prediction for the digits 1, 5, 8, 3, and 4'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'It is still performing well with the rest of the digits. Let''s try another
    number:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.30: Random forest prediction for the digits 1, 9, 4, 7, and 9](img/C13550_02_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.30: Random forest prediction for the digits 1, 9, 4, 7, and 9'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: With the number 7, it seems to be having problems. It is probably because we
    have not introduced enough samples, and due to the simplicity of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The entire code for this exercise is available on GitHub in the Lesson02 | Exercise07-09
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: Now, in the next topic, we are going to explore the world of artificial neural
    networks, which are far more capable of achieving these tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial Neural Networks (ANNs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Artificial neural networks** **(ANNs)** are information processing systems
    that are modeled on and inspired by the human brain, which they try to mimic by
    learning how to recognize patterns in data. They accomplish tasks by having a
    well structured architecture. This architecture is composed of several small processing
    units called neurons, which are interconnected in order to solve major problems.'
  prefs: []
  type: TYPE_NORMAL
- en: ANNs learn by having enough examples in the dataset that they are processing,
    and enough examples means thousands of examples, or even millions. The amount
    of data here can be a disadvantage, since if you do not have this data, you will
    have to create it yourself, and that means that you will probably need a lot of
    money to gather sufficient data.
  prefs: []
  type: TYPE_NORMAL
- en: Another disadvantage of these algorithms is that they need to be trained on
    specific hardware and software. They are well trained on high-performance GPUs,
    which are expensive. You can still do certain things using a GPU that does not
    cost that much, but the data will take much longer to be trained. You also need
    to have specific software, such as **TensorFlow**, **Keras**, **PyTorch**, or
    **Fast.AI**. For this book, we will be using TensorFlow and Keras, which runs
    on top of TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'These algorithms work by taking all of the data as input, in which the first
    layer of neurons acts as the input. After that, every entry is passed to the next
    layer of neurons, where these are multiplied by some value and processed by an
    activation function, which makes "decisions" and passes those values to the next
    layer. The layers in the middle of the network are called hidden layers. This
    process keeps going until the last layer, where the output is given. When introducing
    the MNIST images as input to the neural network, the end of the network should
    have 10 neurons, each neuron representing each digit, and if the neural network
    guesses that an image is a specific digit, then the corresponding neuron will
    be activated. The ANN checks whether it has succeeded for the decision, and if
    not, it performs a correction process called **backpropagation**, where every
    pass of the network is checked and corrected, adjusting the weights of the neurons.
    In Figure 2.31, backpropagation is shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.31: Backpropagation process](img/C13550_02_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.31: Backpropagation process'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here is a graphical representation of an ANN:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.32: ANN architecture](img/C13550_02_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.32: ANN architecture'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the preceding diagram, we can see the neurons, which is where all the processing
    occurs, and the connections between them, which are the weights of the network.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to gain an understanding of how to create one of these neural networks,
    but first, we need to take a look at the data that we have.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous exercise, we had the shapes (60,072 and 784) and (10,018 and
    784) as integer types, and 0 to 255 as pixel values, for training and testing,
    respectively. ANNs perform better and faster with **normalized data**, but what
    is that?
  prefs: []
  type: TYPE_NORMAL
- en: 'Having normalized data means converting that 0-255 range of values to a range
    of 0-1\. The values must be adapted to fit between 0 and 1, which means they will
    be float numbers, because there is no other way to fit a higher range of numbers
    into a shorter range So, first we need to convert the data to a float and then
    normalize it. Here''s the code for doing so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: For the labels, we also need to change the format to one-hot encoding.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to do that, we need to use a function from Keras, from its `utils`
    package (the name has changed to `np_utils`), called `to_categorical()`, which
    transforms the number of the digit of every label to **one-hot encoding**. Here''s
    the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: If we print the first label of `y_train`, 5, and then we print the first value
    of `y_train` after the conversion, it will output [0\. 0\. 0\. 0\. 0\. 1\. 0\.
    0\. 0\. 0.]. This format puts a 1 in the sixth place of an array of 10 positions
    (because there are 10 numbers) for the number 5 (in the sixth place because the
    first one is for the 0, and not for the 1). Now we are ready to go ahead with
    the architecture of the neural network.
  prefs: []
  type: TYPE_NORMAL
- en: For a basic neural network, dense layers (or **fully connected layers**) are
    employed. These neural networks are also called **fully connected neural networks**.
    These contain a series of neurons that represent the neurons of the human brain.
    They need an activation function to be specified. An activation function is a
    function that takes the input and calculates a weighted sum of it, adding a bias
    and deciding whether it should be activated or not (outputs 1 and 0, respectively).
  prefs: []
  type: TYPE_NORMAL
- en: 'The two most used activation functions are sigmoid and ReLU, but ReLU has demonstrated
    better performance overall. They are represented on the following chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.33: The sigmoid and ReLU functions](img/C13550_02_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.33: The sigmoid and ReLU functions'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The sigmoid and ReLU functions calculate the weighted sum and add the bias.
    They then output a value depending on the value of that calculation. The sigmoid
    function will give different values depending on the value of the calculation,
    from 0 to 1\. But ReLU will give 0 for negative values or return the value of
    the calculation for positive values.
  prefs: []
  type: TYPE_NORMAL
- en: Toward the end of a neural network, normally the **softmax** activation function
    takes place, which will output a non-probabilistic number for every class, which
    is higher for the class that has the highest chance of corresponding to the input
    image. There are other activation functions, but this one is the best for the
    output of a network for multi-classification problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'In **Keras**, a neural network could be coded as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The model is created as `Sequential()` as the layers are created sequentially.
    First, we add a dense layer with 16 neurons and the shape of the input is passed
    so that the neural network knows the shape of the input. After which, the `ReLU`
    activation function is applied. We use this function because it generally gives
    good results. We stack another layer with eight neurons and the same activation
    function.
  prefs: []
  type: TYPE_NORMAL
- en: At the end, we use the `Flatten` function to convert the array to one dimension
    and then the last dense layer is stacked, where the number of classes should represent
    the number of neurons (in this case, there would be 10 classes for the MNIST dataset).
    The softmax function is applied in order to get the results as a one-hot encoder,
    as we have mentioned before.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we have to compile the model. In order to do that, we use the `compile`
    method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: We pass the loss function, which is used to calculate the error for the backpropagation
    process. For this problem, we will be using categorial cross-entropy as the loss
    function, as this is a categorical problem. The optimizer used is **Adadelta**,
    which performs very well in most situations. We establish accuracy as the main
    metric to be considered in the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to use what is called a callback in Keras. These are called in
    every epoch during training. We will be using the `Checkpoint` function in order
    to save our model with the best validation result on every epoch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The function to train this model is called `fit()` and is implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: We pass the training set with its labels, and we establish a batch size of 64
    (these are the images that are passed on every step of every epoch), out of which
    we choose to have 10 training epochs (on every epoch the data is processed). The
    validation set is also passed in order to see how the model performs on unseen
    data, and at the end, we set the callback that we created before.
  prefs: []
  type: TYPE_NORMAL
- en: All these parameters have to be adjusted according to the problem that we are
    facing. In order to put all of this into practice, we are going to perform an
    exercise – the same exercise that we did with decision trees, but with neural
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 9: Building Your First Neural Network'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We will be continuing the code from Exercise 8 here.
  prefs: []
  type: TYPE_NORMAL
- en: The entire code for this exercise can be found on GitHub in the Lesson02 | Exercise07-09
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: Head to the interface on Google Colab where you executed the code for *Exercise
    8*, *Predicting Numbers Using the Decision Tree, Random Forest, and AdaBoost Algorithms*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now import the packages from the Keras library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We normalize the data as we explained in this part of the chapter. We also
    declare the `input_shape` instance that will be passed to the neural network,
    and we print it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.34: Data output when passed for normalization using neural networks](img/C13550_02_34.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.34: Data output when passed for normalization using neural networks'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now we are going to declare the model. The model that we built before was never
    going to perform well enough on this problem, so we have created a deeper model
    with more neurons and with a couple of new methods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We have added a `BatchNormalization()` method, which helps the network converge
    faster and may give better results overall.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We have also added the `Dropout()` method, which helps the network to avoid
    **overfitting** (the accuracy of the training set is much higher than the accuracy
    of the validation set). It does that by disconnecting some neurons during training
    (0.2 -> 20% of neurons), which allows better generalization of the problem (better
    classification of unseen data).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Furthermore, the number of neurons has increased drastically. Also, the number
    of layers has increased. The more layers and neurons are added, the deeper the
    understanding is and more complex features are learned.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now we compile the model using categorical cross-entropy, as there are several
    classes, and we use Adadelta, which is great overall for these kinds of tasks.
    Also, we use accuracy as the main metric:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s create the `Checkpoint` callback, where the model will be stored in
    the `Models` folder with the name `model.h5`. We will be using validation loss
    as the main method to be tracked and the model will be saved in its entirety:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start to train the network with the `fit()` function, just like we explained
    before. We use 64 as the batch size, 10 epochs (which is enough as every epoch
    is going to last a very long time and between epochs it will not improve that
    much), and we will introduce the Checkpoint callback:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is going to take a while.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output should look like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.35: Neural network output](img/C13550_02_35.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2.35: Neural network output'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: The final accuracy of the model corresponds to the last `val_acc`, which is
    **97.83%.** This is a better result than we got using AdaBoost or random forest.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now let''s make some predictions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The code looks similar to the code used in the last exercise but has some minor
    differences. One is that, as we changed the input format, we have to change the
    format of the input image too (float and normalize). The other is that the prediction
    is in one-hot encoding, so we use the `argmax()` NumPy function in order to get
    the position of the maximum value of the one-hot output vector, which would be
    the predicted digit.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s see the output of the last number that we tried using random forest:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.36: Prediction of numbers using neural networks](img/C13550_02_36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.36: Prediction of numbers using neural networks'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The output has been successful – even the 7 that the random forest model struggled
    with.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The entire code can be found on GitHub in the Lesson02 | Exercise07-09 folder.
  prefs: []
  type: TYPE_NORMAL
- en: If you try the other numbers, it will classify them all very well – it has learned
    how to.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have built your first neural network and you have applied
    it to a real-world problem! Now you are ready to go through the activity for this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 2: Classify 10 Types of Clothes from the Fashion-MNIST Database'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now you are going to face a similar problem to the previous one but with types
    of clothes. This database is very similar to the original MNIST. It has 60,000
    images – 28x28 in grayscale – for training and 10,000 for testing. You will have
    to follow the steps mentioned in the first exercise as this activity is not focused
    on the real world. You will have to put into practice the abilities learned in
    the last exercise by building a neural network on your own. For this, you will
    have to open a Google Colab notebook. The following steps will guide you in the
    right direction:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the dataset from Keras:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The data is preprocessed like MNIST, so the next steps should be similar to
    *Exercise 5*, *Applying the Various Morphological Transformations to an Image*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Import `random` and set the seed to 42\. Import `matplotlib` and plot five random
    samples of the dataset, just as we did in the last exercise.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now normalize the data and reshape it to fit properly into the neural network
    and convert the labels to one-hot encoder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start to build the architecture of the neural network by using dense layers.
    You have to build it inside a method that will return the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: We recommend starting off by building a very small, easy architecture and improving
    it by testing it with the given dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Compile the model with the appropriate parameters and start training the neural
    network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once trained, we should make some predictions in order to test the model. We
    have uploaded some images into the same `testing` folder inside the `Dataset`
    folder of the last exercise. Make predictions using those images, just as we did
    in the last exercise.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You have to consider that the images that were fed into the neural network
    had a black background and the clothes were white, so you should make corresponding
    adjustments to make the image look like those. If needed, you should invert white
    as black and vice versa. NumPy has a method that does that: `image = np.invert(image)`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Check the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.37: The output of the prediction is the index of the position in
    this list](img/C13550_02_37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.37: The output of the prediction is the index of the position in this
    list'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity is available on page 302.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Computer vision is a big field within AI. By understanding this field, you can
    achieve results such as extracting information from an image or generating images
    that look just like they do in real life, for example. This chapter has covered
    image preprocessing for feature extraction using the OpenCV library, which allows
    easy training and prediction for machine learning models. Some basic machine learning
    models have also been covered, such as decision trees and boosting algorithms.
    These served as an introduction to machine learning and were mostly used to play
    around. Finally, neural networks were introduced and coded using Keras and TensorFlow
    as a backend. Normalization was explained and put into practice, along with dense
    layers, though convolutional layers are known to work better with images than
    dense layers do, and they will be explained later in the book.
  prefs: []
  type: TYPE_NORMAL
- en: Concepts for avoiding overfitting were also covered, and toward the end, we
    used the model to make predictions and put it into practice using real-world images.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, the fundamentals of **natural language processing** (**NLP**)
    will be introduced, along with the most widely used techniques for extracting
    information from a corpus in order to create basic models for language prediction.
  prefs: []
  type: TYPE_NORMAL
