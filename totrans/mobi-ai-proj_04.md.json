["```py\n//the jquery  is pulled down in the JavaScript console\nvar script = document.createElement('script');\nscript.src = \"https://ajax.googleapis.com/ajax/libs/jquery/2.2.0/jquery.min.js\";\ndocument.getElementsByTagName('head')[0].appendChild(script);\n//Let us get the URLs\nvar urls = $('.rg_di .rg_meta').map(function() { return JSON.parse($(this).text()).ou; });\n// Now, we will write the URls one per line to file\nvar textToSave = urls.toArray().join('\\n');\nvar hiddenElement = document.createElement('a');\nhiddenElement.href = 'data:attachment/text,' + encodeURI(textToSave);\nhiddenElement.target = '_blank';\nhiddenElement.download = 'urls.txt';\nhiddenElement.click();\n```", "```py\n# We will start by importing the required pacages\nfrom imutils import paths\nimport argparse\nimport requests\nimport cv2\nimport os\n```", "```py\nap = argparse.ArgumentParser()\nap.add_argument(\"-u\", \"--urls\", required=True,\nhelp=\"path to file containing image URLs\")\nap.add_argument(\"-o\", \"--output\", required=True,\nhelp=\"path to output directory of images\")\nargs = vars(ap.parse_args())\n```", "```py\nrows = open(args[\"urls\"]).read().strip().split(\"\\n\")\ntotal = 0\n# URLs are looped in\nfor url in rows:\ntry:\n# Try downloading the image\nr = requests.get(url, timeout=60)\n#The image is then saved to the disk\np = os.path.sep.join([args[\"output\"], \"{}.jpg\".format(\nstr(total).zfill(8))])\nf = open(p, \"wb\")\nf.write(r.content)\nf.close()\n#The counter is updated\nprint(\"[INFO] downloaded: {}\".format(p))\ntotal += 1\n```", "```py\nprint(\"[INFO] error downloading {}...skipping\".format(p))\n```", "```py\nfor imagePath in paths.list_images(args[\"output\"])\n```", "```py\ndelete = False\n```", "```py\nimage = cv2.imread(imagePath)\n```", "```py\nif image is None:\ndelete = True\n```", "```py\nexcept:\nprint(\"Except\")\ndelete = True\n```", "```py\nif delete:\nprint(\"[INFO] deleting {}\".format(imagePath))\nos.remove(imagePath)\n```", "```py\nImage_download.py --urls urls.txt --output Doberman\n```", "```py\nimport sys\nimport argparse\nimport os\nimport cv2\nimport numpy as np\nprint(cv2.__version__)\n```", "```py\ndef extractImages(pathIn, pathOut):\ncount = 0\nvidcap = cv2.VideoCapture(pathIn)\nsuccess,image = vidcap.read()\nsuccess = True\nwhile success:\nvidcap.set(cv2.CAP_PROP_POS_MSEC,(count*10)) # Adjust frequency of frames here\nsuccess,image = vidcap.read()\nprint ('Read a new frame: ', success)\n#Once we identify the last frame, stop there\nimage_last = cv2.imread(\"frame{}.png\".format(count-1))\nif np.array_equal(image,image_last):\nbreak\ncv2.imwrite( os.path.join(\"frames\",\"frame{:d}.jpg\".format(count)), image) # save frame as JPEG file\ncount = count + 1\npathIn = \"myvideo.mp4\"\npathOut = \"\"\nextractImages(pathIn, pathOut)\n```", "```py\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport argparse\nimport collections\nfrom datetime import datetime\nimport hashlib\nimport os.path\nimport random\nimport re\nimport sys\nimport tarfile\nimport numpy as np\nfrom six.moves import urllib\nimport tensorflow as tf\nfrom tensorflow.python.framework import graph_util\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.python.util import compat\nFLAGS = None\nMAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1 # ~134M\n```", "```py\nresult = collections.OrderedDict()\nsub_dirs = [\nos.path.join(image_dir,item)\nfor item in gfile.ListDirectory(image_dir)]\nsub_dirs = sorted(item for item in sub_dirs\nif gfile.IsDirectory(item))\nfor sub_dir in sub_dirs:\n```", "```py\ndef create_model_info(architecture):\narchitecture = architecture.lower()\nif architecture == 'inception_v3':\n# pylint: disable=line-too-long\ndata_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n# pylint: enable=line-too-long\nbottleneck_tensor_name = 'pool_3/_reshape:0'\nbottleneck_tensor_size = 2048\ninput_width = 299\ninput_height = 299\ninput_depth = 3\nresized_input_tensor_name = 'Mul:0'\nmodel_file_name = 'classify_image_graph_def.pb'\ninput_mean = 128\ninput_std = 128\nelif architecture.startswith('mobilenet_'):\nparts = architecture.split('_')\nif len(parts) != 3 and len(parts) != 4:\ntf.logging.error(\"Couldn't understand architecture name '%s'\",\narchitecture)\nreturn None\nversion_string = parts[1]\nif (version_string != '1.0' and version_string != '0.75' and\nversion_string != '0.50' and version_string != '0.25'):\ntf.logging.error(\n\"\"\"\"The Mobilenet version should be '1.0', '0.75', '0.50', or '0.25',\nbut found '%s' for architecture '%s'\"\"\",\nversion_string, architecture)\nreturn None\nsize_string = parts[2]\nif (size_string != '224' and size_string != '192' and\nsize_string != '160' and size_string != '128'):\ntf.logging.error(\n\"\"\"The Mobilenet input size should be '224', '192', '160', or '128',\nbut found '%s' for architecture '%s'\"\"\",\nsize_string, architecture)\nreturn None\nif len(parts) == 3:\nis_quantized = False\n```", "```py\nelse:\nif parts[3] != 'quantized':\ntf.logging.error(\n\"Couldn't understand architecture suffix '%s' for '%s'\", parts[3],\narchitecture)\nreturn None\nis_quantized = True\ndata_url = 'http://download.tensorflow.org/models/mobilenet_v1_'\ndata_url += version_string + '_' + size_string + '_frozen.tgz'\nbottleneck_tensor_name = 'MobilenetV1/Predictions/Reshape:0'\nbottleneck_tensor_size = 1001\ninput_width = int(size_string)\ninput_height = int(size_string)\ninput_depth = 3\nresized_input_tensor_name = 'input:0'\nif is_quantized:\nmodel_base_name = 'quantized_graph.pb'\nelse:\nmodel_base_name = 'frozen_graph.pb'\nmodel_dir_name = 'mobilenet_v1_' + version_string + '_' + size_string\nmodel_file_name = os.path.join(model_dir_name, model_base_name)\ninput_mean = 127.5\ninput_std = 127.5\nelse:\ntf.logging.error(\"Couldn't understand architecture name '%s'\", architecture)\nraise ValueError('Unknown architecture', architecture)\nreturn {\n'data_url': data_url,\n'bottleneck_tensor_name': bottleneck_tensor_name,\n'bottleneck_tensor_size': bottleneck_tensor_size,\n'input_width': input_width,\n'input_height': input_height,\n'input_depth': input_depth,\n'resized_input_tensor_name': resized_input_tensor_name,\n'model_file_name': model_file_name,\n'input_mean': input_mean,\n'input_std': input_std,\n}\n==============================================================\n```", "```py\ndef add_jpeg_decoding(input_width, input_height, input_depth, input_mean,\ninput_std):\njpeg_data = tf.placeholder(tf.string, name='DecodeJPGInput')\ndecoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)\ndecoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)\ndecoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\nresize_shape = tf.stack([input_height, input_width])\nresize_shape_as_int = tf.cast(resize_shape, dtype=tf.int32)\nresized_image = tf.image.resize_bilinear(decoded_image_4d,\nresize_shape_as_int)\noffset_image = tf.subtract(resized_image, input_mean)\nmul_image = tf.multiply(offset_image, 1.0 / input_std)\nreturn jpeg_data, mul_image\n```", "```py\ndef main(_):\ntf.logging.set_verbosity(tf.logging.INFO)\nprepare_file_system()\nmodel_info = create_model_info(FLAGS.architecture)\nif not model_info:\ntf.logging.error('Did not recognize architecture flag')\nreturn -1\nmaybe_download_and_extract(model_info['data_url'])\ngraph, bottleneck_tensor, resized_image_tensor = (\ncreate_model_graph(model_info))\nimage_lists = create_image_lists(FLAGS.image_dir, FLAGS.testing_percentage,\nFLAGS.validation_percentage)\n```", "```py\ntensorboard --logdir=path/to/log-directory\n```"]