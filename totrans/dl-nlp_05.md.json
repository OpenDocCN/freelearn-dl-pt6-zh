["```py\nkeras.layers.RNN(cell, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)\n```", "```py\nkeras.layers.SimpleRNN(units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)\n```", "```py\nInput_shape \n3D tensor with shape (batch_size, timesteps, input_dim)\nOutput_shape\nIf return_sequences is true, 3D tensor with shape (batch_size, timesteps, units)\nIf return_sequences is false, 2D tensor with shape (batch_size, units)\nIf return_state is True, a list of 2 tensors, 1 is output tensor same as above depending on return_sequences, the other is state tensor of shape (batch_size, units)\n```", "```py\n    from keras.models import Sequential\n    from keras.layers import SimpleRNN, Dense\n    ```", "```py\n    model = Sequential()\n    # Recurrent layer\n    model.add(SimpleRNN(64, input_shape=(10,100), return_sequences=False))\n    # Fully connected layer\n    model.add(Dense(64, activation='relu'))\n    # Output layer\n    model.add(Dense(100, activation='softmax'))\n    ```", "```py\n    model.summary()\n    ```", "```py\n    model = Sequential()\n    # Recurrent layer\n    model.add(SimpleRNN(64, input_shape=(10,100), return_sequences=True))\n    # Fully connected layer\n    model.add(Dense(64, activation='relu'))\n    # Output layer\n    model.add(Dense(100, activation='softmax'))\n    model.summary()\n    ```", "```py\n    model = Sequential()\n    # Recurrent layer\n    model.add(SimpleRNN(64, input_shape=(1000,100), return_sequences=True))\n    # Fully connected layer\n    model.add(Dense(64, activation='relu'))\n    # Output layer\n    model.add(Dense(100, activation='softmax'))\n    model.summary()\n    ```", "```py\n    from keras.models import Sequential\n    from keras.layers import SimpleRNN, Dense\n    ```", "```py\n    model = Sequential()\n    # Recurrent layer\n    model.add(SimpleRNN(64, input_shape=(1000,100), return_sequences=True, stateful=False))\n    # Fully connected layer\n    model.add(Dense(64, activation='relu'))\n    # Output layer\n    model.add(Dense(100, activation='softmax'))\n    model.summary()\n    ```", "```py\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    model.fit(X, Y, batch_size=32, epochs=100, shuffle=True)\n    ```", "```py\n    model = Sequential()\n    # Recurrent layer\n    model.add(SimpleRNN(64, input_shape=(1000,100), return_sequences=True, stateful=True))\n    # Fully connected layer\n    model.add(Dense(64, activation='relu'))\n    # Output layer\n    model.add(Dense(100, activation='softmax'))\n    ```", "```py\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    model.fit(X, Y, batch_size=1, epochs=100, shuffle=False)\n    ```", "```py\n    results.boxplot()\n    pyplot.show()\n    ```"]