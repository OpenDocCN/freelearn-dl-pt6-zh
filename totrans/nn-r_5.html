<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Training and Visualizing a Neural Network in R</h1>
                
            
            <article>
                
<p class="calibre2">As seen in <a target="_blank" href="part0021.html#K0RQ0-263fb608a19f4bb5955f37a7741ba5c4" class="calibre4">Chapters 1</a>, <em class="calibre14"><span>Neural Network and Artificial Intelligence Concepts</span></em>, and <a target="_blank" href="part0056.html#1LCVG0-263fb608a19f4bb5955f37a7741ba5c4" class="calibre4">Chapter 2</a>, <em class="calibre14"><span>Learning Process in Neural Networks</span></em>, training a neural network model forms the basis for building a neural network.</p>
<p class="calibre2">Feed-forward and backpropagation are the techniques used to determine the weights and biases of the model. The weights can never be zero but the biases can be zero. To start with, the weights are initialized a random number, and by gradient descent, the errors are minimized; we get a set of best possible weights and biases for the model.</p>
<p class="calibre2">Once the model is trained using any of the R functions, we can pass on the independent variables to predict the target or unknown variable. In this chapter, we will use a publicly available dataset to train, test, and visualize a neural network model. The following items will be covered:</p>
<ul class="calibre16">
<li class="calibre17">Training, testing, and evaluating a dataset using NN model</li>
<li class="calibre17">Visualizing the NN model</li>
<li class="calibre17">Early stopping</li>
<li class="calibre17">Avoiding overfitting</li>
<li class="calibre17">Generalization of NN</li>
<li class="calibre17">Scaling of NN parameters</li>
<li class="calibre17">Ensemble models</li>
</ul>
<p class="calibre2"><span>By the end of the chapter, we will understand how to train, test, and evaluate a dataset using NN model. We will learn how to visualize the NN model in R environment. We will cover the concepts like early stopping, avoiding overfitting, generalization of NN, and scaling of NN parameters.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Data fitting with neural network</h1>
                
            
            <article>
                
<p class="calibre2">Data fitting is the process of building a curve or a mathematical function that has the best match with a set of previously collected points. The curve fitting can relate to both interpolations, where exact data points are required, and smoothing, where a flat function is built that approximates the data. The approximate curves obtained from the data fitting can be used to help display data, to predict the values of a function where no data is available, and to summarize the relationship between two or more variables. In the following figure is shown a linear interpolation of collected data:</p>
<div class="cdpaligncenter"><img class="image-border4" src="../images/00097.jpeg"/></div>
<p class="calibre2">Data fitting is the process of training a neural network on a set of inputs in order to produce an associated set of target outputs. Once the neural network has fit the data, it forms a generalization of the input-output relationship and can be used to generate outputs for inputs it was not trained on.</p>
<p class="calibre2">The fuel consumption of vehicles has always been studied by the major manufacturers of the entire planet. In an era characterized by oil refueling problems and even greater air pollution problems, fuel consumption by vehicles has become a key factor. In this example, we will build a neural network with the purpose of predicting the fuel consumption of the vehicles according to certain characteristics.</p>
<p class="calibre2">To do this, use the <kbd class="calibre13">Auto</kbd> dataset contained in the <kbd class="calibre13">ISLR</kbd> package that we have already used in an example in <a href="part0081.html#2D7TI0-263fb608a19f4bb5955f37a7741ba5c4" class="calibre4">Chapter 3</a>, <em class="calibre14">Deep Learning Using Multilayer Neural Networks</em>. The <kbd class="calibre13">Auto</kbd> dataset contain gas mileage, horsepower, and other information for 392 vehicles. It is a data frame with 392 observations on the following nine variables:</p>
<ul class="calibre16">
<li class="calibre17"><kbd class="calibre13">mpg</kbd>: Miles per gallon</li>
<li class="calibre17"><kbd class="calibre13">cylinders</kbd>: Number of cylinders between 4 and 8</li>
<li class="calibre17"><kbd class="calibre13">displacement</kbd>: Engine displacement (cubic inches)</li>
<li class="calibre17"><kbd class="calibre13">horsepower</kbd>: Engine horsepower</li>
<li class="calibre17"><kbd class="calibre13">weight</kbd>: Vehicle weight (lbs)</li>
<li class="calibre17"><kbd class="calibre13">acceleration</kbd>: Time to accelerate from 0 to 60 mph (sec)</li>
<li class="calibre17"><kbd class="calibre13">year</kbd>: Model year (modulo 100)</li>
<li class="calibre17"><kbd class="calibre13">origin</kbd>: Origin of car (American, European, Japanese)</li>
<li class="calibre17"><kbd class="calibre13">name</kbd>: Vehicle name</li>
</ul>
<p class="calibre2">The following is the code that we will use in this example:</p>
<pre class="calibre24"><strong class="calibre1">###########################################################################</strong><br class="title-page-name"/><strong class="calibre1">########Chapter 5 - Introduction to Neural Networks - using R##############         </strong><br class="title-page-name"/><strong class="calibre1">##########R program to build, train and test neural networks############### </strong><br class="title-page-name"/><strong class="calibre1">###########################################################################</strong><br class="title-page-name"/><strong class="calibre1">library("neuralnet")</strong><br class="title-page-name"/><strong class="calibre1">library("ISLR")</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">data = Auto</strong><br class="title-page-name"/><strong class="calibre1">View(data)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">plot(data$weight, data$mpg, pch=data$origin,cex=2)</strong><br class="title-page-name"/><strong class="calibre1">par(mfrow=c(2,2))</strong><br class="title-page-name"/><strong class="calibre1">plot(data$cylinders, data$mpg, pch=data$origin,cex=1)</strong><br class="title-page-name"/><strong class="calibre1">plot(data$displacement, data$mpg, pch=data$origin,cex=1)</strong><br class="title-page-name"/><strong class="calibre1">plot(data$horsepower, data$mpg, pch=data$origin,cex=1)</strong><br class="title-page-name"/><strong class="calibre1">plot(data$acceleration, data$mpg, pch=data$origin,cex=1)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">mean_data &lt;- apply(data[1:6], 2, mean)</strong><br class="title-page-name"/><strong class="calibre1">sd_data &lt;- apply(data[1:6], 2, sd)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">data_scaled &lt;- as.data.frame(scale(data[,1:6],center = mean_data, scale = sd_data))</strong><br class="title-page-name"/><strong class="calibre1">head(data_scaled, n=20)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">index = sample(1:nrow(data),round(0.70*nrow(data)))</strong><br class="title-page-name"/><strong class="calibre1">train_data &lt;- as.data.frame(data_scaled[index,])</strong><br class="title-page-name"/><strong class="calibre1">test_data &lt;- as.data.frame(data_scaled[-index,])</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">n = names(data_scaled)</strong><br class="title-page-name"/><strong class="calibre1">f = as.formula(paste("mpg ~", paste(n[!n %in% "mpg"], collapse = " + ")))</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">net = neuralnet(f,data=train_data,hidden=3,linear.output=TRUE)</strong><br class="title-page-name"/><strong class="calibre1">plot(net)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">predict_net_test &lt;- compute(net,test_data[,2:6])</strong><br class="title-page-name"/><strong class="calibre1">MSE.net &lt;- sum((test_data$mpg - predict_net_test$net.result)^2)/nrow(test_data)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">Lm_Mod &lt;- lm(mpg~., data=train_data)</strong><br class="title-page-name"/><strong class="calibre1">summary(Lm_Mod)</strong><br class="title-page-name"/><strong class="calibre1">predict_lm &lt;- predict(Lm_Mod,test_data)</strong><br class="title-page-name"/><strong class="calibre1">MSE.lm &lt;- sum((predict_lm - test_data$mpg)^2)/nrow(test_data)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">par(mfrow=c(1,2))</strong><br class="title-page-name"/><strong class="calibre1">plot(test_data$mpg,predict_net_test$net.result,col='black',main='Real vs predicted for neural network',pch=18,cex=4)</strong><br class="title-page-name"/><strong class="calibre1">abline(0,1,lwd=5)</strong><br class="title-page-name"/><strong class="calibre1">plot(test_data$mpg,predict_lm,col='black',main='Real vs predicted for linear regression',pch=18,cex=4)</strong><br class="title-page-name"/><strong class="calibre1">abline(0,1,lwd=5)</strong><br class="title-page-name"/><strong class="calibre1">###########################################################################</strong></pre>
<p class="calibre2">As usual, we will analyze the code line-by-line, by explaining in detail all the features applied to capture the results.</p>
<pre class="calibre24"><strong class="calibre1">library("neuralnet")</strong><br class="title-page-name"/><strong class="calibre1">library("ISLR")</strong></pre>
<p class="calibre2">The first two lines of the initial code are used to load the libraries needed to run the analysis.</p>
<div class="packt_tip">Remember, to install a library that is not present in the initial distribution of R, you must use the <kbd class="calibre61">install.package</kbd> function. <span class="calibre62">This is the main function to install packages. It takes a vector of names and a destination library, downloads the packages from the repositories and installs them.</span> This function should be used only once and not every time you run the code.</div>
<p class="calibre2">The <kbd class="calibre13">neuralnet</kbd> library is used to train neural networks using backpropagation, <strong class="calibre1">resilient backpropagation</strong> (<strong class="calibre1">RPROP</strong>) with or without weight backtracking, or the modified <strong class="calibre1">globally convergent version</strong> (<strong class="calibre1">GRPROP</strong>). The function allows flexible settings through custom-choice of error and activation function. Furthermore, the calculation of generalized weights is implemented.</p>
<p class="calibre2"><span>The <kbd class="calibre13">ISLR</kbd> library contains a set of datasets freely usable for our examples. This is a series of data collected during major studies conducted by research centers.</span></p>
<pre class="calibre24"><strong class="calibre1">data = Auto</strong><br class="title-page-name"/><strong class="calibre1">View(data)</strong></pre>
<p class="calibre2">This command loads the <kbd class="calibre13">Auto</kbd> dataset, which, as we anticipated, is contained in the <kbd class="calibre13">ISLR</kbd> library, and saves it in a given dataframe. Use the <kbd class="calibre13">View</kbd> function to view a compact display of the structure of an arbitrary R object. The following screenshot shows some of the data contained in the <kbd class="calibre13">Auto</kbd> dataset:</p>
<div class="cdpaligncenter"><img class="image-border4" src="../images/00098.jpeg"/></div>
<p class="calibre2">As you can see, the database consists of 392 rows and 9 columns. The rows represent 392 commercial vehicles from 1970 to 1982. The columns represent the 9 characteristics collected for each car, in order: <kbd class="calibre13">mpg</kbd>, <kbd class="calibre13">cylinders</kbd>, <kbd class="calibre13">displacement</kbd>, <kbd class="calibre13">horsepower</kbd>, <kbd class="calibre13">weight</kbd>, <kbd class="calibre13">acceleration</kbd>, <kbd class="calibre13">year</kbd>, <kbd class="calibre13">origin</kbd>, and <kbd class="calibre13">name</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Exploratory analysis</h1>
                
            
            <article>
                
<p class="calibre2">Before starting with data analysis through the building and training of a neural network, we conduct an exploratory analysis to understand how data is distributed and extract preliminary knowledge.</p>
<p class="calibre2">We can begin our explorative analysis by tracing a plot of predictors versus target. We recall in this respect that in our analysis, the predictors are the following variables: <kbd class="calibre13">cylinders</kbd>, <kbd class="calibre13">displacement</kbd>, <kbd class="calibre13">horsepower</kbd>, <kbd class="calibre13">weight</kbd>, <kbd class="calibre13">acceleration</kbd>, <kbd class="calibre13">year</kbd>, <kbd class="calibre13">origin</kbd>, and <kbd class="calibre13">name</kbd>. The target is the <kbd class="calibre13">mpg</kbd> variable that contains measurements of the miles per gallon of 392 sample cars.</p>
<p class="calibre2">Suppose we want to examine the weight and mileage of cars from three different origins, as shown <span>in the next graph, using the following code:</span></p>
<pre class="calibre24"><strong class="calibre1">plot(data$weight, data$mpg, pch=data$origin,cex=2)</strong></pre>
<p class="calibre2">To plot the chart, we used the <kbd class="calibre13">plot()</kbd> function, specifying what to point on the <em class="calibre14">x</em> axis (<kbd class="calibre13">weight</kbd>), what to point on the <em class="calibre14">y</em> axis (<kbd class="calibre13">mpg</kbd>), and finally, based on which variable to group the data (<kbd class="calibre13">origin</kbd>), as shown in the following graph:</p>
<div class="cdpaligncenter"><img class="image-border25" src="../images/00099.jpeg"/></div>
<p class="calibre2">Remember the number in the <kbd class="calibre13">origin</kbd> column correspond at the following zone: 1= America, 2=Europe, and 3=Japan). From the analysis of the previous graph, we can find that fuel consumption increases with weight gain. Let's remember that the target measures the miles per gallon, so how many miles are going with a gallon of fuel. It follows that the greater the value of mpg (miles per gallon), the lower the fuel consumption.</p>
<p class="calibre2">Another consideration that comes from plot analysis is that cars produced in America are heavier. In fact, in the right part of the chart (which corresponds to higher values of weight), there are only cars produced in that area.</p>
<p class="calibre2">Finally, if we focus our analysis on the left of the graph, in the upper part that corresponds to the lowest fuel consumption, we find in most cases Japanese and European cars. In conclusion, we can note that cars that have the lowest fuel consumption are Japanese.</p>
<p class="calibre2">Now, let's see the other graphs, that is, what we get if we plot the remaining numeric predictors (<kbd class="calibre13">cylinders</kbd>, <kbd class="calibre13">displacement</kbd>, <kbd class="calibre13">horsepower</kbd>, and <kbd class="calibre13">acceleration</kbd>) versus target (<kbd class="calibre13">mpg</kbd>).</p>
<pre class="calibre24"><strong class="calibre1">par(mfrow=c(2,2))</strong><br class="title-page-name"/><strong class="calibre1">plot(data$cylinders, data$mpg, pch=data$origin,cex=1)</strong><br class="title-page-name"/><strong class="calibre1">plot(data$displacement, data$mpg, pch=data$origin,cex=1)</strong><br class="title-page-name"/><strong class="calibre1">plot(data$horsepower, data$mpg, pch=data$origin,cex=1)</strong><br class="title-page-name"/><strong class="calibre1">plot(data$acceleration, data$mpg, pch=data$origin,cex=1)</strong></pre>
<p class="calibre2">For space reasons, we decided to place the four charts in one. R makes it easy to combine multiple plots into one general graph, using the <kbd class="calibre13">par()</kbd> function. Using the par( ) function, we can include the option mfrow=c(nrows, ncols) to create a matrix of nrows x ncols plots that are filled in by row. For example the option mfrow=c(3,2) creates a matrix plot with 3 rows and 2 columns. In addition, the option mfcol=c(nrows, ncols) fills in the matrix by columns.</p>
<p class="calibre2">In the following figure are shown 4 plot arranged in a matrix of 2 rows and two columns:</p>
<div class="cdpaligncenter"><img class="image-border4" src="../images/00100.jpeg"/></div>
<p class="calibre2">From the analysis of the previous figure, we find confirmation of what has already been mentioned earlier. We can note that cars with higher horsepower have higher fuel consumption. The same thing we can say about the engine displacement; also in this case, vehicles with higher displacement have higher fuel consumption. Again, cars with higher horsepower and displacement values are produced in America.</p>
<p class="calibre2">Conversely, cars with higher acceleration values have lower fuel consumption. This fact is due to the lesser weight that such cars have. Usually, heavy cars are slower in acceleration.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Neural network model</h1>
                
            
            <article>
                
<p class="calibre2">In <a target="_blank" href="part0056.html#1LCVG0-263fb608a19f4bb5955f37a7741ba5c4" class="calibre4">Chapter 2</a>, <em class="calibre14">Learning Process in Neural Networks</em>, we scaled the data before building the network. On that occasion, we pointed out that it is good practice to normalize the data before training a neural network. With normalization, data units are eliminated, allowing you to easily compare data from different locations.</p>
<p class="calibre2">It is not always necessary to normalize numeric data. However, it has been shown that when numeric values are normalized, neural network formation is often more efficient and leads to better prediction. In fact, if numeric data are not normalized and the sizes of two predictors are very distant, a change in the value of a neural network weight has much more relative influence on higher value.</p>
<p class="calibre2">There are several standardization techniques; in <a target="_blank" href="part0056.html#1LCVG0-263fb608a19f4bb5955f37a7741ba5c4" class="calibre4">Chapter 2</a>, <em class="calibre14">Learning Process in Neural Networks</em>, we adopted min-max standardization. In this case, we will adopt <em class="calibre14">Z</em>-scores normalization. This technique consists of subtracting the mean of the column to each value in a column, and then dividing the result for the standard deviation of the column. <span>The formula to achieve this is the following:</span></p>
<p class="calibre51"><img src="../images/00101.jpeg" class="calibre74"/></p>
<p class="calibre2"> </p>
<p class="calibre2">In summary, the <em class="calibre14">Z</em> score (also called standard score) represents the number of standard deviations with which the value of an observation point or data is greater than the mean value of what is observed or measured. Values above the mean have positive <em class="calibre14">Z</em>-scores, while values below the mean have negative <em class="calibre14">Z</em>-scores. The <em class="calibre14">Z</em>-score is a quantity without dimension, obtained by subtracting the population mean from a single rough score and then dividing the difference for the standard deviation of the population.</p>
<p class="calibre2"><span>Before applying the method chosen for</span> <span>normalization</span><span>, you must calculate the mean and standard deviation values of each database column. To do this, we use the <kbd class="calibre13">apply</kbd> function. This function returns a vector or an array or a list of values obtained by applying a function to margins of an array or matrix. Let's understand the meaning of the arguments used.</span></p>
<pre class="calibre24"><strong class="calibre1">mean_data &lt;- apply(data[1:6], 2, mean)</strong><br class="title-page-name"/><strong class="calibre1">sd_data &lt;- apply(data[1:6], 2, sd)</strong></pre>
<p class="calibre2">The first line allows us to calculate the mean of each variable going to the second line, allowing us to calculate the standard deviation of each variable. Let's see how we used the function <kbd class="calibre13">apply()</kbd>. The first argument of the <kbd class="calibre13">apply</kbd> function specifies the dataset to apply the function to, in our case, the dataset named data. In particular, we have only considered the first six numeric variables; the other ones we will use for other purposes. The second argument must contain a vector giving the subscripts which the function will be applied over. In our case, one indicates rows and two indicates columns. The third argument must contain the function to be applied; in our case, the <kbd class="calibre13">mean()</kbd> function in the first row and the <kbd class="calibre13">sd()</kbd> function in the second row. The results are shown as follows:</p>
<pre class="calibre24"><strong class="calibre1">&gt; mean_data</strong><br class="title-page-name"/><strong class="calibre1">         mpg    cylinders displacement   horsepower       weight </strong><br class="title-page-name"/><strong class="calibre1">   23.445918     5.471939   194.411990   104.469388  2977.584184   </strong><br class="title-page-name"/><strong class="calibre1">acceleration</strong><br class="title-page-name"/><strong class="calibre1">   15.541327</strong></pre>
<pre class="calibre24"><strong class="calibre1">&gt; sd_data</strong><br class="title-page-name"/><strong class="calibre1">         mpg    cylinders displacement    horsepower       weight </strong><br class="title-page-name"/><strong class="calibre1">    7.805007     1.705783    04.644004     38.491160   849.402560 </strong><br class="title-page-name"/><strong class="calibre1">acceleration</strong><br class="title-page-name"/><strong class="calibre1">    2.758864</strong></pre>
<p class="calibre2"><span>To normalize the data, we use the <kbd class="calibre13">scale()</kbd> function, which is a generic function whose default method centers and/or scales the columns of a numeric matrix:</span></p>
<pre class="calibre24"><strong class="calibre1">data_scaled &lt;- as.data.frame(scale(data[,1:6],center = mean_data, scale = sd_data))</strong></pre>
<p class="calibre2">Let's take a look at the data transformed by normalization:</p>
<pre class="calibre24"><strong class="calibre1">head(data_scaled, n=20)</strong></pre>
<p class="calibre2"><span>The results are as follows:</span></p>
<pre class="calibre24"><strong class="calibre1">&gt; head(data_scaled, n=20)</strong><br class="title-page-name"/><strong class="calibre1">           mpg  cylinders displacement horsepower     weight acceleration</strong><br class="title-page-name"/><strong class="calibre1">1  -0.69774672  1.4820530   1.07591459  0.6632851  0.6197483  -1.28361760</strong><br class="title-page-name"/><strong class="calibre1">2  -1.08211534  1.4820530   1.48683159  1.5725848  0.8422577  -1.46485160</strong><br class="title-page-name"/><strong class="calibre1">3  -0.69774672  1.4820530   1.18103289  1.1828849  0.5396921  -1.64608561</strong><br class="title-page-name"/><strong class="calibre1">4  -0.95399247  1.4820530   1.04724596  1.1828849  0.5361602  -1.28361760</strong><br class="title-page-name"/><strong class="calibre1">5  -0.82586959  1.4820530   1.02813354  0.9230850  0.5549969  -1.82731962</strong><br class="title-page-name"/><strong class="calibre1">6  -1.08211534  1.4820530   2.24177212  2.4299245  1.6051468  -2.00855363</strong><br class="title-page-name"/><strong class="calibre1">7  -1.21023822  1.4820530   2.48067735  3.0014843  1.6204517  -2.37102164</strong><br class="title-page-name"/><strong class="calibre1">8  -1.21023822  1.4820530   2.34689042  2.8715843  1.5710052  -2.55225565</strong><br class="title-page-name"/><strong class="calibre1">9  -1.21023822  1.4820530   2.49023356  3.1313843  1.7040399  -2.00855363</strong><br class="title-page-name"/><strong class="calibre1">10 -1.08211534  1.4820530   1.86907996  2.2220846  1.0270935  -2.55225565</strong><br class="title-page-name"/><strong class="calibre1">11 -1.08211534  1.4820530   1.80218649  1.7024847  0.6892089  -2.00855363</strong><br class="title-page-name"/><strong class="calibre1">12 -1.21023822  1.4820530   1.39126949  1.4426848  0.7433646  -2.73348966</strong><br class="title-page-name"/><strong class="calibre1">13 -1.08211534  1.4820530   1.96464205  1.1828849  0.9223139  -2.18978763</strong><br class="title-page-name"/><strong class="calibre1">14 -1.21023822  1.4820530   2.49023356  3.1313843  0.1276377  -2.00855363</strong><br class="title-page-name"/><strong class="calibre1">15  0.07099053 -0.8629108  -0.77799001 -0.2460146 -0.7129531  -0.19621355</strong><br class="title-page-name"/><strong class="calibre1">16 -0.18525522  0.3095711   0.03428778 -0.2460146 -0.1702187  -0.01497955</strong><br class="title-page-name"/><strong class="calibre1">17 -0.69774672  0.3095711   0.04384399 -0.1940546 -0.2396793  -0.01497955</strong><br class="title-page-name"/><strong class="calibre1">18 -0.31337809  0.3095711   0.05340019 -0.5058145 -0.4598340   0.16625446</strong><br class="title-page-name"/><strong class="calibre1">19  0.45535916 -0.8629108  -0.93088936 -0.4278746 -0.9978592  -0.37744756</strong><br class="title-page-name"/><strong class="calibre1">20  0.32723628 -0.8629108  -0.93088936 -1.5190342 -1.3451622   1.79736053</strong></pre>
<p class="calibre2">Let's now split the data for the training and the test:</p>
<pre class="calibre24"><strong class="calibre1">index = sample(1:nrow(data),round(0.70*nrow(data)))</strong><br class="title-page-name"/><strong class="calibre1">train_data &lt;- as.data.frame(data_scaled[index,])</strong><br class="title-page-name"/><strong class="calibre1">test_data &lt;- as.data.frame(data_scaled[-index,])</strong></pre>
<p class="calibre2">In the first line of the code just suggested, the dataset is split into 70:30, with the intention of using 70 percent of the data at our disposal to train the network and the remaining 30 percent to test the network. In the second and third lines, the data of the dataframe named data is subdivided into two new dataframes, called <kbd class="calibre13">train_data</kbd> and <kbd class="calibre13">test_data</kbd>. Now we have to build the function to be submitted to the network:</p>
<pre class="calibre24"><strong class="calibre1">n = names(data_scaled)</strong><br class="title-page-name"/><strong class="calibre1">f = as.formula(paste("mpg ~", paste(n[!n %in% "mpg"], collapse = " + ")))</strong></pre>
<p class="calibre2">In the first line, we recover all the variable names in the <kbd class="calibre13">data_scaled</kbd> dataframe, using the <kbd class="calibre13">names()</kbd> function. In the second line, we build formula that we will use to train the network. What does this formula represent?</p>
<p class="calibre2">The models fitted by the <kbd class="calibre13">neuralnet()</kbd> function are specified in a compact symbolic form. The ~ operator is basic in the formation of such models. An expression of the form <em class="calibre14">y</em> ~ model is interpreted as a specification that the response <em class="calibre14">y</em> is modelled by a predictor specified symbolically by model. Such a model consists of a series of terms separated by + operators. The terms themselves consist of variable and factor names separated by : operators. Such a term is interpreted as the interaction of all the variables and factors appearing in the term. Let's look at the formula we set:</p>
<pre class="calibre24"><strong class="calibre1">&gt; f</strong><br class="title-page-name"/><strong class="calibre1">mpg ~ cylinders + displacement + horsepower + weight + acceleration</strong></pre>
<p class="calibre2">Now we can build and train the network.</p>
<p class="calibre2">In <a target="_blank" href="part0081.html#2D7TI0-263fb608a19f4bb5955f37a7741ba5c4" class="calibre4">Chapter 3</a>, <em class="calibre14">Deep Learning Using Multilayer Neural Networks</em>, we said that to choose the optimal number of neurons, we need to know that:</p>
<ul class="calibre16">
<li class="calibre17">Small number of neurons will lead to high error for your system, as the predictive factors might be too complex for a small number of neurons to capture</li>
<li class="calibre17">Large number of neurons will overfit your training data and not generalize well</li>
<li class="calibre17">The number of neurons in each hidden layer should be somewhere between the size of the input and the output layer, potentially the mean</li>
<li class="calibre17">The number of neurons in each hidden layer shouldn't exceed twice the number of input neurons, as you are probably grossly overfit at this point</li>
</ul>
<p class="calibre2">In this case, we have five input variables (<kbd class="calibre13">cylinders</kbd>, <kbd class="calibre13">displacement</kbd>, <kbd class="calibre13">horsepower</kbd>, <kbd class="calibre13">weight</kbd>, and <kbd class="calibre13">acceleration</kbd>) and one variable output (<kbd class="calibre13">mpg</kbd>). We choose to set three neurons in the hidden layer.</p>
<pre class="calibre24"><strong class="calibre1">net = neuralnet(f,data=train_data,hidden=3,linear.output=TRUE)</strong></pre>
<p class="calibre2">The hidden argument accepts a vector with the number of neurons for each hidden layer, while the argument <kbd class="calibre13">linear.output</kbd> is used to specify whether we want to do regression (<kbd class="calibre13">linear.output=TRUE</kbd>) or classification (<kbd class="calibre13">linear.output=FALSE</kbd>).</p>
<p class="calibre2">The algorithm used in <kbd class="calibre13">neuralnet()</kbd>, by default, is based on the resilient backpropagation without weight backtracking and additionally modifies one learning rate, either the learning rate associated with the smallest absolute gradient (<kbd class="calibre13">sag</kbd>) or the smallest learning rate (<kbd class="calibre13">slr</kbd>) itself. The <kbd class="calibre13">neuralnet()</kbd> function returns an object of class <kbd class="calibre13">nn</kbd>. An object of class <kbd class="calibre13">nn</kbd> is a list containing at most the components shown in the following table:</p>
<table class="calibre40">
<tbody class="calibre6">
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Components</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Description</strong></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre13">call</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">The matched call.</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre13">response</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">Extracted from the <kbd class="calibre13">data</kbd> argument.</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre13">covariate</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">The variables extracted from the data argument.</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre13">model.list</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">A list containing the covariates and the <kbd class="calibre13">response</kbd> variables extracted from the <kbd class="calibre13">formula</kbd> argument.</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre13">err.fct</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">The error function.</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre13">act.fct</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">The activation function.</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre13">data</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">The data argument.</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre13">net.result</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">A list containing the overall result of the neural network for every repetition.</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre13">weights</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">A list containing the fitted weights of the neural network for every repetition.</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre13">generalized.weights</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">A list containing the generalized weights of the neural network for every repetition.</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre13">result.matrix</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">A matrix containing the reached threshold, needed steps, error, AIC and BIC (if computed), and weights for every repetition. Each column represents one repetition.</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre13">startweights</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">A list containing the startweights of the neural network for every repetition.</p>
</td>
</tr>
</tbody>
</table>
<p class="calibre2"> </p>
<p class="calibre2">To produce result summaries of the results of the model, we use the <kbd class="calibre13">summary()</kbd> function:</p>
<pre class="calibre24"><strong class="calibre1">&gt; summary(net)</strong><br class="title-page-name"/><strong class="calibre1">                    Length Class      Mode   </strong><br class="title-page-name"/><strong class="calibre1">call                   5   -none-     call  </strong><br class="title-page-name"/><strong class="calibre1">response             274   -none-     numeric</strong><br class="title-page-name"/><strong class="calibre1">covariate           1370   -none-     numeric</strong><br class="title-page-name"/><strong class="calibre1">model.list             2   -none-     list   </strong><br class="title-page-name"/><strong class="calibre1">err.fct                1   -none-     function</strong><br class="title-page-name"/><strong class="calibre1">act.fct                1   -none-     function</strong><br class="title-page-name"/><strong class="calibre1">linear.output          1   -none-     logical</strong><br class="title-page-name"/><strong class="calibre1">data                   6   data.frame list   </strong><br class="title-page-name"/><strong class="calibre1">net.result             1   -none-     list   </strong><br class="title-page-name"/><strong class="calibre1">weights                1   -none-     list   </strong><br class="title-page-name"/><strong class="calibre1">startweights           1   -none-     list   </strong><br class="title-page-name"/><strong class="calibre1">generalized.weights    1   -none-     list   </strong><br class="title-page-name"/><strong class="calibre1">result.matrix         25   -none-     numeric</strong> </pre>
<p class="calibre2">For each component of the neural network model are displayed three features:</p>
<ul class="calibre16">
<li class="calibre17"><strong class="calibre1">Length</strong>: This is component length, that is how many elements of this type are contained in it</li>
<li class="calibre17"><strong class="calibre1">Class</strong>: This contains specific indication on the component class</li>
<li class="calibre17"><strong class="calibre1">Mode</strong>: This is the type of component (numeric, list, function, logical, and so on)</li>
</ul>
<p class="calibre2">To plot the graphical representation of the model with the weights on each connection, we can use the <kbd class="calibre13">plot()</kbd> function. The <kbd class="calibre13">plot()</kbd> function is a generic function for the representation of objects in R. Generic function means that it is suitable for different types of objects, from variables to tables to complex function outputs, producing different results. Applied to a nominal variable, it will produce a bar graph. Applied to a cardinal variable, it will produce a scatterplot. Applied to the same variable, but tabulated, that is, to its frequency distribution, it will produce a histogram. Finally, applied to two variables, a nominal and a cardinal, it will produce a boxplot.</p>
<pre class="calibre24"><strong class="calibre1">plot(net)</strong></pre>
<p class="calibre2"><span>The neural network plot is shown in the following graph:</span></p>
<div class="cdpaligncenter"><img class="image-border4" src="../images/00102.gif"/></div>
<p class="calibre2">In the previous graph, the black lines (these lines start from input nodes) show the connections between each layer and the weights on each connection, while the blue lines (these lines start from bias nodes which are distinguished by number 1) show the bias term added in each step. The bias can be thought of as the intercept of a linear model.</p>
<p class="calibre2">Though over time we have understood a lot about the mechanics that are the basis of the neural networks, in many respects, the model we have built and trained remains a black box. The fitting, weights, and model are not clear enough. We can be satisfied that the training algorithm is convergent and then the model is ready to be used.</p>
<p class="calibre2">We can print on video, the weights and biases:</p>
<pre class="calibre24"><strong class="calibre1">&gt; net$result.matrix</strong><br class="title-page-name"/><strong class="calibre1">                                         1</strong><br class="title-page-name"/><strong class="calibre1">error                      21.800203210980</strong><br class="title-page-name"/><strong class="calibre1">reached.threshold           0.009985137179</strong><br class="title-page-name"/><strong class="calibre1">steps                    9378.000000000000</strong><br class="title-page-name"/><strong class="calibre1">Intercept.to.1layhid1      -1.324633695625</strong><br class="title-page-name"/><strong class="calibre1">cylinders.to.1layhid1       0.291091600669</strong><br class="title-page-name"/><strong class="calibre1">displacement.to.1layhid1   -2.243406161080</strong><br class="title-page-name"/><strong class="calibre1">horsepower.to.1layhid1      0.616083122568</strong><br class="title-page-name"/><strong class="calibre1">weight.to.1layhid1          1.292334492287</strong><br class="title-page-name"/><strong class="calibre1">acceleration.to.1layhid1   -0.286145921068</strong><br class="title-page-name"/><strong class="calibre1">Intercept.to.1layhid2     -41.734205163355</strong><br class="title-page-name"/><strong class="calibre1">cylinders.to.1layhid2      -5.574494023650</strong><br class="title-page-name"/><strong class="calibre1">displacement.to.1layhid2   33.629686446649</strong><br class="title-page-name"/><strong class="calibre1">horsepower.to.1layhid2    -28.185856598271</strong><br class="title-page-name"/><strong class="calibre1">weight.to.1layhid2        -50.822997942647</strong><br class="title-page-name"/><strong class="calibre1">acceleration.to.1layhid2   -5.865256284330</strong><br class="title-page-name"/><strong class="calibre1">Intercept.to.1layhid3       0.297173606203</strong><br class="title-page-name"/><strong class="calibre1">cylinders.to.1layhid3       0.306910802417</strong><br class="title-page-name"/><strong class="calibre1">displacement.to.1layhid3   -5.897977831914</strong><br class="title-page-name"/><strong class="calibre1">horsepower.to.1layhid3      0.379215333054</strong><br class="title-page-name"/><strong class="calibre1">weight.to.1layhid3          2.651777936654</strong><br class="title-page-name"/><strong class="calibre1">acceleration.to.1layhid3   -1.035618563747</strong><br class="title-page-name"/><strong class="calibre1">Intercept.to.mpg           -0.578197055155</strong><br class="title-page-name"/><strong class="calibre1">1layhid.1.to.mpg           -3.190914666614</strong><br class="title-page-name"/><strong class="calibre1">1layhid.2.to.mpg            0.714673177354</strong><br class="title-page-name"/><strong class="calibre1">1layhid.3.to.mpg            1.958297807266</strong></pre>
<p class="calibre2">As can be seen, these are the same values that we can read in the network plot. For example, <kbd class="calibre13">cylinders.to.1layhid1 = 0.291091600669</kbd> is the weight for the connection between the input <span>cylinders and the first node of the hidden layer.</span></p>
<p class="calibre2">Now we can use the network to make predictions. For this, we had set aside 30 percent of the data in the <kbd class="calibre13">test_data</kbd> dataframe. It is time to use it.</p>
<pre class="calibre24"><strong class="calibre1">predict_net_test &lt;- compute(net,test_data[,2:6])</strong></pre>
<p class="calibre2"><span>In our case, we applied the function to the</span> <kbd class="calibre13">test_data</kbd> <span>dataset, using only the</span> <span>columns from <kbd class="calibre13">2</kbd> to <kbd class="calibre13">6</kbd>, representing the input variables of the network. To evaluate the network performance, we can use the <strong class="calibre1">Mean Squared Error</strong> (<strong class="calibre1">MSE</strong>) as a measure of how far away our predictions are from the real data.</span></p>
<pre class="calibre24"><strong class="calibre1">MSE.net &lt;- sum((test_data$mpg - predict_net_test$net.result)^2)/nrow(test_data)</strong></pre>
<p class="calibre2">Here <kbd class="calibre13">test_data$mpg</kbd> is the actual data and <kbd class="calibre13">predict_net_test$net.result</kbd> is the predicted data for the target of the analysis. Following is the result:</p>
<pre class="calibre24"><strong class="calibre1">&gt; MSE.net</strong><br class="title-page-name"/><strong class="calibre1">[1] 0.2591064572</strong></pre>
<p class="calibre2">It looks like a good result, but what do we compare it with? <span>To get an idea of the accuracy of the network prediction, we can build a linear regression model:</span></p>
<pre class="calibre24"><strong class="calibre1">Lm_Mod &lt;- lm(mpg~., data=train_data)</strong><br class="title-page-name"/><strong class="calibre1">summary(Lm_Mod)</strong></pre>
<p class="calibre2"><span>We build a linear regression model using the</span> <kbd class="calibre13">lm</kbd> <span>function. This function is used to fit linear models. It can be used to perform regression, single stratum analysis of variance, and analysis of covariance. To produce a summary of the results of model fitting obtained, we have used the</span> <kbd class="calibre13">summary()</kbd> <span>function, which returns the following results:</span></p>
<pre class="calibre24"><strong class="calibre1">&gt; summary(Lm_Mod)</strong><br class="title-page-name"/><strong class="calibre1">Call:</strong><br class="title-page-name"/><strong class="calibre1">lm(formula = mpg ~ ., data = train_data)</strong><br class="title-page-name"/><strong class="calibre1">Residuals:</strong><br class="title-page-name"/><strong class="calibre1">        Min          1Q      Median          3Q         Max</strong><br class="title-page-name"/><strong class="calibre1">-1.48013031 -0.34128989 -0.04310873  0.27697893  1.77674878</strong><br class="title-page-name"/><strong class="calibre1">Coefficients:</strong><br class="title-page-name"/><strong class="calibre1">                Estimate  Std. Error  t value        Pr(&gt;|t|)   </strong><br class="title-page-name"/><strong class="calibre1">(Intercept)   0.01457260  0.03268643  0.44583        0.656080  </strong><br class="title-page-name"/><strong class="calibre1">cylinders    -0.14056198  0.10067461 -1.39620        0.163809  </strong><br class="title-page-name"/><strong class="calibre1">displacement  0.06316568  0.13405986  0.47118        0.637899   </strong><br class="title-page-name"/><strong class="calibre1">horsepower   -0.16993594  0.09180870 -1.85098        0.065273 . </strong><br class="title-page-name"/><strong class="calibre1">weight       -0.59531412  0.09982123 -5.96380 0.0000000077563 ***</strong><br class="title-page-name"/><strong class="calibre1">acceleration  0.03096675  0.05166132  0.59942        0.549400   </strong><br class="title-page-name"/><strong class="calibre1">---</strong><br class="title-page-name"/><strong class="calibre1">Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</strong><br class="title-page-name"/><strong class="calibre1">Residual standard error: 0.5392526 on 268 degrees of freedom</strong><br class="title-page-name"/><strong class="calibre1">Multiple R-squared:  0.7183376, Adjusted R-squared:  0.7130827</strong><br class="title-page-name"/><strong class="calibre1">F-statistic: 136.6987 on 5 and 268 DF,  p-value: &lt; 0.00000000000000022204</strong></pre>
<p class="calibre2">Now we make the prediction with the linear regression model using the data contained in the <kbd class="calibre13">test_data</kbd> <span>dataframe:</span></p>
<pre class="calibre24"><strong class="calibre1">predict_lm &lt;- predict(Lm_Mod,test_data)</strong></pre>
<p class="calibre2">Finally, we calculate the MSE for the regression model:</p>
<pre class="calibre24"><strong class="calibre1">MSE.lm &lt;- sum((predict_lm - test_data$mpg)^2)/nrow(test_data)</strong></pre>
<p class="calibre2"><span>Following is the result:</span></p>
<pre class="calibre24"><strong class="calibre1">&gt; MSE.lm</strong><br class="title-page-name"/><strong class="calibre1">[1] 0.3124200509</strong></pre>
<p class="calibre2">From the comparison between the two models (neural network model versus linear regression model), once again the neural network <span>wins</span> (0.26 versus 0.31).</p>
<p class="calibre2">We now perform a visual comparison by drawing on a graph the actual value versus the predicted value, first for neural network and then for linear regression model:</p>
<pre class="calibre24"><strong class="calibre1">par(mfrow=c(1,2))</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">plot(test_data$mpg,predict_net_test$net.result,col='black',main='Real vs predicted for neural network',pch=18,cex=4)</strong><br class="title-page-name"/><strong class="calibre1">abline(0,1,lwd=5)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">plot(test_data$mpg,predict_lm,col='black',main='Real vs predicted for linear regression',pch=18,cex=4)</strong><br class="title-page-name"/><strong class="calibre1">abline(0,1,lwd=5)</strong></pre>
<p class="calibre2">The comparison between the performance of the neural network model (to the left) and the linear regression model (to the right) on the test set is plotted in the following graph:</p>
<div class="cdpaligncenter"><img class="image-border4" src="../images/00103.gif"/></div>
<p class="calibre2">As we can see, the predictions by the neural network are more concentrated around the line than those by the linear regression model, even if you do not note a big difference.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Classifing breast cancer with a neural network</h1>
                
            
            <article>
                
<p class="calibre2">The breast is made up of a set of glands and adipose tissue and is placed between the skin and the chest wall. In fact, it is not a single gland, but a set of glandular structures, called lobules, joined together to form a lobe. In a breast, there are 15 to 20 lobes. The milk reaches the nipple from the lobules through small tubes called milk ducts.<br class="title-page-name"/>
Breast cancer is a potentially serious disease if it is not detected and treated for a long time. It is caused by uncontrolled multiplication of some cells in the mammary gland that are transformed into malignant cells. This means that they have the ability to detach themselves from the tissue that has generated them to invade the surrounding tissues and eventually the other organs of the body. In theory, cancers can be formed from all types of breast tissues, but the most common ones are from glandular cells or from those forming the walls of the ducts.</p>
<p class="calibre2">The objective of this example is to identify each of a number of benign or malignant classes. To do this, we will use the data contained in the dataset named <kbd class="calibre13">BreastCancer</kbd> (Wisconsin Breast Cancer Database) contained in the <kbd class="calibre13">mlbench</kbd> package. This data has been taken from the UCI Repository Of Machine Learning Databases at DNA samples arrive periodically as Dr. Wolberg reports his clinical cases. The database therefore reflects this chronological grouping of the data. This grouping information appears immediately, having been removed from the data itself. Each variable, except for the first, was converted into 11 primitive numerical attributes with values ranging from 0 through 10. There are 16 missing values.</p>
<p class="calibre2">The dataframes contain 699 observations on 11 variables<span>—</span>1 being a character variable, 9 being ordered or nominal, and 1 target class:</p>
<ul class="calibre16">
<li class="calibre17"><kbd class="calibre13">Id</kbd>: Sample code number</li>
<li class="calibre17"><kbd class="calibre13">Cl.thickness</kbd>: Clump thickness</li>
<li class="calibre17"><kbd class="calibre13">Cell.size</kbd>: Uniformity of cell size</li>
<li class="calibre17"><kbd class="calibre13">Cell.shape</kbd>: Uniformity of cell shape</li>
<li class="calibre17"><kbd class="calibre13">Marg.adhesion</kbd>: Marginal adhesion</li>
<li class="calibre17"><kbd class="calibre13">Epith.c.size</kbd>: Single epithelial cell size</li>
<li class="calibre17"><kbd class="calibre13">Bare.nuclei</kbd>: Bare nuclei</li>
<li class="calibre17"><kbd class="calibre13">Bl.cromatin</kbd>: Bland chromatin</li>
<li class="calibre17"><kbd class="calibre13">Normal.nucleoli</kbd>: Normal nucleoli</li>
<li class="calibre17"><kbd class="calibre13">Mitoses</kbd>: Mitoses</li>
<li class="calibre17"><kbd class="calibre13">Class</kbd>: Class</li>
</ul>
<p class="calibre2">As said previously, <span>the objective of this example is to identify each of a number of benign or malignant classes. The following is the code that we will use in this example:</span></p>
<pre class="calibre24"><strong class="calibre1">###########################################################################</strong><br class="title-page-name"/><strong class="calibre1">########Chapter 5 - Introduction to Neural Networks - using R##############         </strong><br class="title-page-name"/><strong class="calibre1">####################Classifing breast cancer with R######################## </strong><br class="title-page-name"/><strong class="calibre1">###########################################################################<br class="title-page-name"/></strong><br class="title-page-name"/><strong class="calibre1">library("mlbench")</strong><br class="title-page-name"/><strong class="calibre1">library(neuralnet)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">data(BreastCancer)</strong><br class="title-page-name"/><strong class="calibre1">summary(BreastCancer)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">mvindex = unique (unlist (lapply (BreastCancer, function (x) which (is.na (x)))))</strong><br class="title-page-name"/><strong class="calibre1">data_cleaned &lt;- na.omit(BreastCancer) </strong><br class="title-page-name"/><strong class="calibre1">summary(data_cleaned)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">boxplot(data_cleaned[,2:10])</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Mitoses))</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">par(mfrow=c(3, 3))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Cl.thickness))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Cell.size))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Cell.shape))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Marg.adhesion))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Epith.c.size))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Bare.nuclei))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Bl.cromatin))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Normal.nucleoli))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Mitoses))</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">str(data_cleaned)</strong><br class="title-page-name"/><strong class="calibre1">input&lt;-data_cleaned[,2:10]</strong><br class="title-page-name"/><strong class="calibre1">indx &lt;- sapply(input, is.factor)</strong><br class="title-page-name"/><strong class="calibre1">input &lt;- as.data.frame(lapply(input, function(x) as.numeric(as.character(x))))</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">max_data &lt;- apply(input, 2, max)</strong><br class="title-page-name"/><strong class="calibre1">min_data &lt;- apply(input, 2, min)</strong><br class="title-page-name"/><strong class="calibre1">input_scaled &lt;- as.data.frame(scale(input,center = min_data, scale = max_data - min_data))</strong><br class="title-page-name"/><strong class="calibre1">View(input_scaled)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">Cancer&lt;-data_cleaned$Class</strong><br class="title-page-name"/><strong class="calibre1">Cancer&lt;-as.data.frame(Cancer)</strong><br class="title-page-name"/><strong class="calibre1">Cancer&lt;-with(Cancer, data.frame(model.matrix(~Cancer+0)))</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">final_data&lt;-as.data.frame(cbind(input_scaled,Cancer))</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">index = sample(1:nrow(final_data),round(0.70*nrow(final_data)))</strong><br class="title-page-name"/><strong class="calibre1">train_data &lt;- as.data.frame(final_data[index,])</strong><br class="title-page-name"/><strong class="calibre1">test_data &lt;- as.data.frame(final_data[-index,])</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">n = names(final_data[1:9])</strong><br class="title-page-name"/><strong class="calibre1">f = as.formula(paste("Cancerbenign + Cancermalignant ~", paste(n, collapse = " + ")))</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">net = neuralnet(f,data=train_data,hidden=5,linear.output=FALSE)</strong><br class="title-page-name"/><strong class="calibre1">plot(net)</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">predict_net_test &lt;- compute(net,test_data[,1:9])</strong><br class="title-page-name"/><strong class="calibre1">predict_result&lt;-round(predict_net_test$net.result, digits = 0)</strong><br class="title-page-name"/><strong class="calibre1">net.prediction = c("benign", "malignant")[apply(predict_result, 1, which.max)]</strong><br class="title-page-name"/><strong class="calibre1">predict.table = table(data_cleaned$Class[-index], net.prediction)</strong><br class="title-page-name"/><strong class="calibre1">predict.table</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">library(gmodels)</strong><br class="title-page-name"/><strong class="calibre1">CrossTable(x = data_cleaned$Class[-index], y = net.prediction,</strong><br class="title-page-name"/><strong class="calibre1"> prop.chisq=FALSE)</strong><br class="title-page-name"/><strong class="calibre1">###########################################################################</strong></pre>
<p class="calibre2">We begin analyzing the code line-by-line, by explaining in detail all the features applied to capture the results.</p>
<pre class="calibre24"><strong class="calibre1">library("mlbench")</strong><br class="title-page-name"/><strong class="calibre1">library("neuralnet")</strong></pre>
<p class="calibre2">The first two lines of the initial code are used to load the libraries needed to run the analysis.</p>
<div class="packt_tip">Remember, to install a library that is not present in the initial distribution of R, you must use the <kbd class="calibre61">install.package</kbd> function. <span class="calibre62">This is the main function to install packages. It takes a vector of names and a destination library, downloads the packages from the repositories and installs them.</span> This function should be used only once and not every time you run the code.</div>
<p class="calibre2">The <kbd class="calibre13">mlbench</kbd> library <span>contains a collection of artificial and real-world machine learning benchmark problems, including, for example, several datasets from the UCI Repository.</span></p>
<p class="calibre2"><span>The <kbd class="calibre13">neuralnet</kbd> library is used to train neural networks using backpropagation, RPROP with or without weight backtracking, or the modified GRPROP. The function allows flexible settings through custom-choice of error and activation function. Furthermore, the calculation of generalized weights is implemented.</span> A brief description of the nnet package, extracted from the official documentation, is shown in the following table:</p>
<table class="calibre40">
<tbody class="calibre6">
<tr class="calibre7">
<td class="calibre8"><kbd class="calibre13">neuralnet</kbd>: Training of neural networks</td>
</tr>
<tr class="calibre7">
<td class="calibre8"><strong class="calibre1">Description</strong>:</td>
</tr>
<tr class="calibre7">
<td class="calibre8">Training of neural networks using backpropagation, resilient backpropagation with (Riedmiller, 1994), or without weight backtracking (Riedmiller and Braun, 1993), or the modified globally convergent version by Anastasiadis et al. (2005). The package allows flexible settings through custom-choice of error and activation function.</td>
</tr>
<tr class="calibre7">
<td class="calibre8"><strong class="calibre1">Details</strong>:</td>
</tr>
<tr class="calibre7">
<td class="calibre8"><span>Package: <kbd class="calibre13">neuralnet</kbd></span><br class="title-page-name"/>
<span>Type: Package</span><br class="title-page-name"/>
<span>Version: 1.33</span><br class="title-page-name"/>
<span>Date: 2016-08-05</span><br class="title-page-name"/>
<span>License: GPL-2</span></td>
</tr>
<tr class="calibre7">
<td class="calibre8"><strong class="calibre1">Author(s)</strong>:</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2">Stefan Fritsch<br class="title-page-name"/>
Frauke Guenther<br class="title-page-name"/>
Marc Suling<br class="title-page-name"/>
Sebastian M. Mueller</p>
</td>
</tr>
</tbody>
</table>
<p class="calibre2"> </p>
<p class="calibre2"><span>Returning to the code, at this point we have to load the data to be analyzed:</span></p>
<pre class="calibre24"><strong class="calibre1">data(BreastCancer)</strong></pre>
<p class="calibre2"><span>With this command, we upload the data set named <kbd class="calibre13">BreastCancer</kbd>, as mentioned, in the <kbd class="calibre13">mlbench</kbd> library.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Exploratory analysis</h1>
                
            
            <article>
                
<p class="calibre2">Before starting with data analysis through the build and training of a neural network, we conduct an exploratory analysis to understand how the data is distributed and extract preliminary knowledge.</p>
<pre class="calibre24"><strong class="calibre1">summary(BreastCancer)</strong></pre>
<p class="calibre2"><span>With this command,</span> we will see a brief summary using the <kbd class="calibre13">summary()</kbd> function.</p>
<div class="packt_tip">Remember, the <kbd class="calibre61">summary()</kbd> function is a generic function used to produce result summaries of the results of various model fitting functions. The function invokes particular methods which depend on the class of the first argument.</div>
<p class="calibre2">In this case, the function was applied to a dataframe and the results are shown in the following screenshot:</p>
<div class="cdpaligncenter"><img class="image-border4" src="../images/00104.jpeg"/></div>
<p class="calibre2">The <kbd class="calibre13">summary()</kbd> function returns a set of statistics for each variable. In particular, it is useful to highlight the result provided for the <kbd class="calibre13">class</kbd> variable that contains the diagnosis of the cancer mass. In this case, 458 cases of benign <kbd class="calibre13">class</kbd> and 241 cases of <kbd class="calibre13">malignant</kbd> class were detected. Another feature to highlight is the Bare.nuclei variable. For this variable, 16 cases of missing value were detected.</p>
<p class="calibre2">A missing value is one whose value is unknown. Missing values are represented in R by the <kbd class="calibre13">NA</kbd> symbol. <kbd class="calibre13">NA</kbd> is a special value whose properties are different from other values. <kbd class="calibre13">NA</kbd> is one of the very few reserved words in R; you cannot give anything this name. <kbd class="calibre13">NA</kbd> can arise when you read in an Excel spreadsheet with empty cells, for example. You will also see <kbd class="calibre13">NA</kbd> when you try certain operations that are illegal or don't make sense. Missing values do not necessarily arise from an error; often in real life, there is a lack of detection.</p>
<p class="calibre2">A question arises spontaneously: do we have to worry about the presence of missing value? Unfortunately, yes, and this is due to the fact that almost every operation performed on an <kbd class="calibre13">NA</kbd> produces an <kbd class="calibre13">NA</kbd>. Then the presence of missing values in our dataset can cause errors in the calculations we will make later. This is why we are forced to remove the missing values.</p>
<p class="calibre2">To remove missing values, we must first identify them. The <kbd class="calibre13">is.na()</kbd> function finds missing values for us; this function returns a logical vector of the same length as its argument, with <em class="calibre14">T</em> for missing values and <em class="calibre14">F</em> for non-missing. It's fairly common to want to know the index of the missing values, and the <kbd class="calibre13">which()</kbd> function helps do this for us. <span>To find all the rows in a dataframe with at least one</span> <kbd class="calibre13">NA</kbd><span>, try this:</span></p>
<pre class="calibre24"><strong class="calibre1">mvindex = unique (unlist (lapply (BreastCancer, function (x) which (is.na (x)))))</strong></pre>
<p class="calibre2">The <kbd class="calibre13">lapply()</kbd> function applies the function to each column and returns a list whose <em class="calibre14">i</em>-th element is a vector containing the indices of the elements which have missing values in column <em class="calibre14">i</em>. The <kbd class="calibre13">unlist()</kbd> function turns that list into a vector and <kbd class="calibre13">unique()</kbd> gets rid of the duplicates.</p>
<p class="calibre2">Now we have the number of lines where the missing value (<kbd class="calibre13">NA</kbd>) appears, as we can see next:</p>
<pre class="calibre24"><strong class="calibre1">&gt; mvindex</strong><br class="title-page-name"/><strong class="calibre1"> [1] 24 41 140 146 159 165 236 250 276 293 295 298 316 322 412 618</strong></pre>
<p class="calibre2">Now we know there are missing values in our database and we know where they are. We just have to remove those lines from the original dataset. To do this, we can use the following functions:</p>
<ul class="calibre16">
<li class="calibre17"><kbd class="calibre13">na.omit</kbd>: Drops out any rows with missing values anywhere in them and forgets them forever</li>
<li class="calibre17"><kbd class="calibre13">na.exclude</kbd>: Drops out rows with missing values, but keeps track of where they were, so that when you make predictions, for example, you end up with a vector whose length is that of the original response</li>
</ul>
<p class="calibre2">We will use the first option, so as to eliminate them forever:</p>
<pre class="calibre24"><strong class="calibre1">data_cleaned &lt;- na.omit(BreastCancer)</strong> </pre>
<p class="calibre2">To confirm the removal of the rows where the missing values appeared, apply the <kbd class="calibre13">summary()</kbd> function again:</p>
<pre class="calibre24"><strong class="calibre1">summary(data_cleaned)</strong></pre>
<p class="calibre2"><span>The results are shown in the following screenshot:</span></p>
<div class="cdpaligncenter"><img class="image-border26" src="../images/00105.jpeg"/></div>
<p class="calibre2">As you can see now, there is no missing value anymore.</p>
<p class="calibre2">Now, let's go into our exploratory analysis. The first thing we can do is to plot the boxplots of the variables. A first idea is already made by looking at the results of the <kbd class="calibre13">summary()</kbd> function. Naturally, we will limit ourselves to numeric variables only.</p>
<pre class="calibre24"><strong class="calibre1">boxplot(data_cleaned[,2:10])</strong></pre>
<p class="calibre2">In the following graph, the boxplots of the numeric variables <span>(from 2° to 10°)</span> contained in the <span>cleaned</span> <span>dataset (<kbd class="calibre13">data_cleaned</kbd>) are shown:</span></p>
<div class="cdpaligncenter"><img class="image-border27" src="../images/00106.jpeg"/></div>
<p class="calibre2">From the analysis of the previous graph, we can note that several variables have outliers, with the variable <kbd class="calibre13">Mitoses</kbd> being the one that has the largest number.</p>
<div class="packt_tip">Outlier values are numerically different from the rest of the collected data. Statistics derived from samples containing outliers can be misleading.</div>
<p class="calibre2">To better identify the presence of outlier, we can plot histograms of the variables in the database. A histogram is an accurate graphical representation of the distribution of numerical data. It is an estimate of the probability distribution of a continuous variable. To construct a histogram, the first step is to specify the range of values (that is, divide the entire range of values into a series of intervals), and then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins must be adjacent, and are often of equal size. With histogram, we can see where the middle is in your data distribution, how close the data lies around this middle, and where possible outliers are to be found.</p>
<p class="calibre2">In R environment, we can simply make a histogram by using the <kbd class="calibre13">hist()</kbd> function, which computes a histogram of the given data values. We must put the name of the dataset in between the parentheses of this function. To plot many graphs in the same window, we will use the <kbd class="calibre13">par()</kbd> function, already used in the previous examples:</p>
<pre class="calibre24"><strong class="calibre1">par(mfrow=c(3, 3))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Cl.thickness))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Cell.size))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Cell.shape))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Marg.adhesion))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Epith.c.size))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Bare.nuclei))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Bl.cromatin))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Normal.nucleoli))</strong><br class="title-page-name"/><strong class="calibre1">hist(as.numeric(data_cleaned$Mitoses))</strong></pre>
<p class="calibre2">Since the function <kbd class="calibre13">hist()</kbd> requires a vector as argument, we have transformed the values contained in the dataset columns into numeric vectors using the <kbd class="calibre13">as.numeric(</kbd>) function. This function creates or coerces objects of type <kbd class="calibre13">numeric</kbd>. <span>In the following graphs are shown the histograms of the numeric variables</span> <span>(from 2° to 10°)</span> <span>contained in the</span> <span>cleaned</span> <span>dataset (<kbd class="calibre13">data_cleaned</kbd>):</span></p>
<div class="cdpaligncenter"><img class="image-border4" src="../images/00107.gif"/></div>
<p class="calibre2">From the analysis of the histograms, it is possible to note that some variables have outliers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Neural network model</h1>
                
            
            <article>
                
<p class="calibre2"><span>As we did in the previous example, before building and training the network, we have to run the standardization of data. In this case, we will adopt min-max standardization.</span></p>
<div class="packt_tip">Remember, it is good practice to normalize the data before training a neural network. With normalization, data units are eliminated, allowing you to easily compare data from different locations.</div>
<p class="calibre2">Before we begin, make a further check by using the <kbd class="calibre13">str()</kbd> function. This function provides a compact display of the internal structure of an object, a diagnostic function, and an alternative to the <kbd class="calibre13">summary()</kbd> function. Ideally, only one line for each basic structure is displayed. It is especially well suited to compactly display the (abbreviated) contents of (possibly nested) lists. The idea is to give reasonable output for any R object.</p>
<pre class="calibre24"><strong class="calibre1">str(data_cleaned)</strong></pre>
<p class="calibre2">The results are shown in the following <span>screenshot</span>:</p>
<div class="cdpaligncenter"><img class="image-border28" src="../images/00108.jpeg"/></div>
<p class="calibre2">As it is possible to note, the variables are present as a factor. We need to make a transformation for our calculations.</p>
<pre class="calibre24"><strong class="calibre1">input&lt;-data_cleaned[,2:10]</strong><br class="title-page-name"/><strong class="calibre1">indx &lt;- sapply(input, is.factor)</strong><br class="title-page-name"/><strong class="calibre1">input &lt;- as.data.frame(lapply(input, function(x) as.numeric(as.character(x))))</strong></pre>
<p class="calibre2">We first identified the variables of the factor type and then we transformed them into numeric type. We can now standardize.</p>
<p class="calibre2">For this example, we will use the min-max method (usually called feature scaling) to get all the scaled data in the range <em class="calibre14">[0, 1]</em>. The formula to achieve this is the following:</p>
<div class="calibre28"><img src="../images/00109.jpeg" class="calibre75"/></div>
<p class="calibre2">Before applying the method chosen for <span>normalization</span>, you must calculate the minimum and maximum values of each database column. To do this, we use the <kbd class="calibre13">apply()</kbd> function. This function returns a vector or an array or a list of values obtained by applying a function to margins of an array or matrix. Let's understand the meaning of the arguments used.</p>
<pre class="calibre24"><strong class="calibre1">max_data &lt;- apply(data_cleaned[,2:10], 2, max)</strong></pre>
<p class="calibre2">The first argument of the apply function specifies the dataset to apply the function to, in our case, the dataset named <kbd class="calibre13">data</kbd>. The second argument must contain a vector giving the subscripts which the function will be applied over. In our case, one indicates rows and two indicates columns. The third argument must contain the function to be applied; in our case, the max function. What we will do next is to calculate the minimums for each column:</p>
<pre class="calibre24"><strong class="calibre1">min_data &lt;- apply(data_cleaned[,2:10], 2, min)</strong></pre>
<p class="calibre2">Finally, <span>to normalize the data, we use the</span> <kbd class="calibre13">scale()</kbd> <span>function, which is a generic function whose default method centers and/or scales the columns of a numeric matrix, as shown in the following code:</span></p>
<pre class="calibre24"><strong class="calibre1">data_scaled &lt;- scale(</strong><strong class="calibre1">data_cleaned[,2:10]</strong><strong class="calibre1">,center = min_data, scale = max_data - min_data)</strong></pre>
<p class="calibre2"><span>To confirm the standardization of data, let's see the first 20 lines of the new matrix we created. To do this, we will use the <kbd class="calibre13">View()</kbd> function:</span></p>
<div class="cdpaligncenter"><span><img class="image-border4" src="../images/00110.jpeg"/></span></div>
<p class="calibre2"><span>As you can see now, the data is between zero and one. At this point, we reconstruct the dataset, adding our target (that is the <kbd class="calibre13">class</kbd> variable), which represents the diagnosis of the cancer (<kbd class="calibre13">benign</kbd> or <kbd class="calibre13">malignant</kbd>). This topic requires our attention: as we have seen before, this variable (<kbd class="calibre13">class</kbd>) is categorical. Particularly in the data frame is present as a factor, so that we can properly use int the network we must necessarily transform it. Our target is a dichotomous variable (only two values: <kbd class="calibre13">benign</kbd> and <kbd class="calibre13">malignant</kbd>), so it can easily be transformed into two dummy variables.</span></p>
<div class="packt_tip">A dummy variable is one that takes the value <kbd class="calibre61">0</kbd> or <kbd class="calibre61">1</kbd> to indicate the absence or presence of some categorical effect that may be expected to shift the outcome.</div>
<p class="calibre2">What we will do is create two new variables (<kbd class="calibre13">Cancerbenign</kbd> and <kbd class="calibre13">Cancermalignant</kbd>), starting with the <kbd class="calibre13">Class</kbd> variable representing our target. The <kbd class="calibre13">Cancerbenign</kbd> variable will contain values of one at each occurrence of the <kbd class="calibre13">benign</kbd> value present in the <kbd class="calibre13">Class</kbd> variable, and values of zero in other cases. In contrast, the <kbd class="calibre13">Cancermalignant</kbd> variable will contain values of one at each occurrence of the <kbd class="calibre13">malignant</kbd> value present in the <kbd class="calibre13">Class</kbd> variable and values of zero in other cases.</p>
<pre class="calibre24"><strong class="calibre1">Cancer&lt;-data_cleaned$Class</strong><br class="title-page-name"/><strong class="calibre1">Cancer&lt;-as.data.frame(Cancer)</strong><br class="title-page-name"/><strong class="calibre1">Cancer&lt;-with(Cancer, data.frame(model.matrix(~Cancer+0)))</strong></pre>
<p class="calibre2">To get the two new dummy variables, we used the <kbd class="calibre13">model.matrix()</kbd> function. This function creates a model matrix by expanding factors to a set of dummy variables (depending on the contrasts), and expanding interactions similarly. Finally, we add the new variables to the dataset:</p>
<pre class="calibre24"><strong class="calibre1">final_data&lt;-as.data.frame(cbind(input_scaled,Cancer))</strong></pre>
<p class="calibre2"><span>The time has come to train the network.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">The network training phase</h1>
                
            
            <article>
                
<p class="calibre2"><span>The artificial neural networks are composed of simple elements operating in parallel. Connections between network elements are fundamental as they decide network functions. These connections affect the result through its weight, which is regulated in the neural network training phase. In the following diagram is shown a comparison between serial and parallel processing:</span></p>
<div class="cdpaligncenter"><img class="image-border29" src="../images/00111.jpeg"/></div>
<p class="calibre2"><span>Then, in the training phase, the network is regulated by changing the connection weights, so that a particular input will lead to a specific destination. For example, the network can be adjusted by comparing the output (what we calculate practically) and the target (what we want to get), until the network output matches the target. To get sufficiently reliable results, many input/target pairs are needed to form a network. In the following diagram is shown a simple flow chart of the training phase:</span></p>
<div class="cdpaligncenter"><img class="image-border30" src="../images/00112.jpeg"/></div>
<p class="calibre2">The way these weights are adjusted is defined by the particular algorithm we adopt. After highlighting the importance of the algorithm in network training, much interest must be placed in the preparation of the data to be provided to the network.</p>
<p class="calibre2">In the network training, the weights and bias must be tuned to optimize the network performance. It represents the most important phase of the whole process, as the better the network is, the better the generalization will be able to operate with new data, unknown to it. At this stage, part of the collected data is taken randomly (usually 70 percent of the available cases).</p>
<p class="calibre2">After the neural network training, we can use the network, in that phase a part of the collected data taken randomly (usually 30 perecnt of the available cases) is passed to the network to test it. Then the neural network object can be saved and used as many times as you want with any new data. In the following figure is shown how an original dataset has been divided:</p>
<div class="cdpaligncenter"><img class="image-border31" src="../images/00113.jpeg"/></div>
<p class="calibre2">This subdivision of data in code looks like this:</p>
<pre class="calibre24"><strong class="calibre1">index = sample(1:nrow(final_data),round(0.70*nrow(final_data)))</strong><br class="title-page-name"/><strong class="calibre1">train_data &lt;- as.data.frame(final_data[index,])</strong><br class="title-page-name"/><strong class="calibre1">test_data &lt;- as.data.frame(final_data[-index,])</strong></pre>
<p class="calibre2">In the first line of the code just suggested, the dataset is split into 70:30, with the intention of using 70 percent of the data at our disposal to train the network and the remaining 30 percent to test the network. In the second and third lines, the data of the dataframe named <kbd class="calibre13">data</kbd> is subdivided into two new dataframes, called <kbd class="calibre13">train_data</kbd> and <kbd class="calibre13">test_data</kbd>. Now we have to build the function to be submitted to the network:</p>
<pre class="calibre24"><strong class="calibre1">n = names(final_data[1:9])</strong><br class="title-page-name"/><strong class="calibre1">f = as.formula(paste("Cancerbenign + Cancermalignant ~", paste(n, collapse = " + ")))</strong></pre>
<p class="calibre2">In the first line, we recover the names of the first nine <span>variables</span> in the <kbd class="calibre13">data_scaled</kbd> dataframe, using the <kbd class="calibre13">names()</kbd> function. In the second line, we build formula that we will use to train the network. What does this formula represent?</p>
<p class="calibre2">The models fitted by the <kbd class="calibre13">neuralnet()</kbd> function are specified in a compact symbolic form. The ~ operator is basic in the formation of such models. An expression of the form <em class="calibre14">y</em> ~ model is interpreted as a specification that the response <em class="calibre14">y</em> is modelled by a predictor specified symbolically by model. Such a model consists of a series of terms separated by + operators. The terms themselves consist of variable and factor names separated by : operators. Such a term is interpreted as the interaction of all the variables and factors appearing in the term. Let's look at the formula we set:</p>
<pre class="calibre24"><strong class="calibre1">&gt; f</strong><br class="title-page-name"/><strong class="calibre1">Cancerbenign + Cancermalignant ~ Cl.thickness + Cell.size + Cell.shape + </strong><br class="title-page-name"/><strong class="calibre1">    Marg.adhesion + Epith.c.size + Bare.nuclei + Bl.cromatin + </strong><br class="title-page-name"/><strong class="calibre1">    Normal.nucleoli + Mitoses</strong></pre>
<p class="calibre2"><span>We now have everything we need, we can create and train the network. We recall the advice we gave in the previous example for the correct choice of number of neurons in the hidden layer. We have eight input variables (<kbd class="calibre13">Cl.thickness</kbd>, <kbd class="calibre13">Cell.size</kbd>, <kbd class="calibre13">Cell.shape</kbd>, <kbd class="calibre13">Marg.adhesion</kbd>, <kbd class="calibre13">Epith.c.size</kbd>, <kbd class="calibre13">Bare.nuclei</kbd>, <kbd class="calibre13">Bl.cromatin</kbd>, <kbd class="calibre13">Normal.nucleoli</kbd>, and <kbd class="calibre13">Mitoses</kbd>) and one variable output (<kbd class="calibre13">Cancer</kbd>). Then we choose to set five neurons in the hidden layer:</span></p>
<pre class="calibre24"><strong class="calibre1">net = neuralnet(f,data=train_data,hidden=5,linear.output=FALSE)</strong></pre>
<p class="calibre2">The <kbd class="calibre13">hidden</kbd> argument accepts a vector with the number of neurons for each hidden layer, while the argument <kbd class="calibre13">linear.output</kbd> is used to specify whether we want to do regression (<kbd class="calibre13">linear.output=TRUE</kbd>) or classification (<kbd class="calibre13">linear.output=FALSE</kbd> (our case)).</p>
<p class="calibre2">The algorithm used in <kbd class="calibre13">neuralnet()</kbd>, by default, is based on the resilient backpropagation without weight backtracking, and additionally modifies one learning rate, either the learning rate associated with the smallest absolute gradient (<kbd class="calibre13">sag</kbd>) or the smallest learning rate (<kbd class="calibre13">slr</kbd>) itself.</p>
<p class="calibre2"><span>To plot the graphical representation of the model with the weights on each connection, we can use the <kbd class="calibre13">plot()</kbd> function, already widely explained in the previous section:</span></p>
<pre class="calibre24"><strong class="calibre1">plot(net)</strong></pre>
<p class="calibre2"><span>The neural network plot is shown in the following graph:</span></p>
<div class="cdpaligncenter"><img class="image-border4" src="../images/00114.jpeg"/></div>
<p class="calibre2"><span>In the previous graph, the black lines (these lines start from input nodes) show the connections between each layer and the weights on each connection, while the blue lines (these lines start from bias nodes which are distinguished by number one) show the bias term added in each step. The bias can be thought of as the intercept of a linear model.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Testing the network</h1>
                
            
            <article>
                
<p class="calibre2">We finally have the network trained and ready for use. Now, we can use it to make our predictions. Remember, we've set aside 30 percent of available data and then use them to test the network. It's time to use it.</p>
<pre class="calibre24"><strong class="calibre1">predict_net_test &lt;- compute(net,test_data[,1:9])</strong></pre>
<p class="calibre2">To predict data, we have used the compute function, which computes the outputs of all neurons for specific arbitrary covariate vectors, given a trained neural network. Let's look at the results by printing the first ten lines:</p>
<pre class="calibre24"><strong class="calibre1">&gt; head(predict_net_test$net.result,n=10)</strong><br class="title-page-name"/><strong class="calibre1">                 [,1]                       [,2]</strong><br class="title-page-name"/><strong class="calibre1">1  0.9999999935589190 0.000000003587253510720848</strong><br class="title-page-name"/><strong class="calibre1">2  0.0000011083596034 0.999999376764558189911725</strong><br class="title-page-name"/><strong class="calibre1">4  0.9792070465712006 0.017164709664531079685856</strong><br class="title-page-name"/><strong class="calibre1">5  0.9999999746453074 0.000000021909385204003642</strong><br class="title-page-name"/><strong class="calibre1">9  0.9999993390597798 0.000000327298596658228207</strong><br class="title-page-name"/><strong class="calibre1">14 0.9999999999953126 0.000000000000889095157872</strong><br class="title-page-name"/><strong class="calibre1">17 0.9999999999989946 0.000000000000442776879837</strong><br class="title-page-name"/><strong class="calibre1">19 0.0000001409393993 0.999999920006766185309743</strong><br class="title-page-name"/><strong class="calibre1">21 0.0000024771345578 0.999998553964539960148272</strong><br class="title-page-name"/><strong class="calibre1">23 0.9999999999999967 0.000000000000001305142352</strong></pre>
<p class="calibre2">As we can see, these are real numbers with several decimals. In order to compare them with the data contained in the dataset, we have to round them to the nearest integer. To do this, we will use the <kbd class="calibre13">round()</kbd> function that rounds the values in its first argument to the specified number of decimal places (default zero).</p>
<pre class="calibre24"><strong class="calibre1">predict_result&lt;-round(predict_net_test$net.result, digits = 0)</strong></pre>
<p class="calibre2">We now rebuild the starting variable. We no longer need the two dummy variables; they have done their job well, but now we no longer need them.</p>
<pre class="calibre24"><strong class="calibre1">net.prediction = c("benign", "malignant")[apply(predict_result, 1, which.max)]</strong></pre>
<p class="calibre2">Now, we can build the confusion matrix to check the performance of our classifier.</p>
<pre class="calibre24"><strong class="calibre1">predict.table = table(data_cleaned$Class[-index], net.prediction)</strong></pre>
<p class="calibre2">The confusion matrix is shown as follows:</p>
<pre class="calibre24"><strong class="calibre1">&gt; predict.table</strong><br class="title-page-name"/><strong class="calibre1">           net.prediction</strong><br class="title-page-name"/><strong class="calibre1">            benign malignant</strong><br class="title-page-name"/><strong class="calibre1">  benign       132         5</strong><br class="title-page-name"/><strong class="calibre1">  malignant      3        65</strong></pre>
<p class="calibre2">Although in a simple way, the matrix tells us that we only made eight errors. For more information about the confusion matrix, we can use the <kbd class="calibre13">CrossTable()</kbd> function contained in the <kbd class="calibre13">gmodels</kbd> package. As always, before loading the book, you need to install it.</p>
<pre class="calibre24"><strong class="calibre1">library(gmodels)</strong><br class="title-page-name"/><strong class="calibre1">CrossTable(x = data_cleaned$Class[-index], y = net.prediction,</strong><br class="title-page-name"/><strong class="calibre1">           prop.chisq=FALSE)</strong></pre>
<p class="calibre2"><span>The confusion matrix obtained by using the <kbd class="calibre13">CrossTable()</kbd> function is shown in the following screenshot:</span></p>
<div class="cdpaligncenter"><img class="image-border4" src="../images/00115.jpeg"/></div>
<p class="calibre2">The cells falling on the main diagonal contain counts of examples where the classifier correctly categorized the examples. In the top-left cell, labeled <kbd class="calibre13">TN</kbd>, are the true negative results. These 132 of 205 values indicate cases where the cancer was <kbd class="calibre13">benign</kbd>, and the algorithm correctly identified it as such. The bottom-right cell, labeled <kbd class="calibre13">TP</kbd>, indicates the true positive results, where the classifier and the clinically determined label agree that the mass is <kbd class="calibre13">malignant</kbd>. A total of 65 of 205 predictions were true positives.</p>
<p class="calibre2">The cells falling on the other diagonal contain counts of examples where the classifier incorrectly categorized the examples. The three examples in the lower-left <kbd class="calibre13">FN</kbd> cell are false negative results; in this case, the predicted value was <kbd class="calibre13">benign</kbd> but the cancer was actually <kbd class="calibre13">malignant</kbd>. Errors in this direction could be extremely costly, as they might lead a patient to believe that she is cancer-free, when in reality the disease may continue to spread. The cell labeled <kbd class="calibre13">FP</kbd> would contain the false positive results, if there were any. These values occur when the model classifies a cancer as malignant when in reality it was benign. Although such errors are less dangerous than a false negative result, they should also be avoided as they could lead to additional financial burden on the health care system, or additional stress for the patient, as additional tests or treatment may have to be provided.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Early stopping in neural network training</h1>
                
            
            <article>
                
<p class="calibre2">The epoch is a measure of each round trip from the forward propagation training and backpropagation update of weights and biases. The round trip of training has to stop once we have convergence (minimal error terms) or after a preset number of iterations.</p>
<p class="calibre2">Early stopping is a technique used to deal with overfitting of the model (more on overfitting in the next few pages). The training set is separated into two parts: one of them is to be used for training, while the other one is meant for validation purposes. We had separated our <kbd class="calibre13">IRIS</kbd> dataset into two parts: one 75 percent and another 25 percent.</p>
<p class="calibre2">With the training data, we compute the gradient and update the network weights and biases. The second set of data, the testing or validation data, is used to validate the model overfitting. If the error during validation increases for a specified number of iterations (<kbd class="calibre13">nnet.abstol</kbd>/<kbd class="calibre13">reltol</kbd>), the training is stopped and the weights and biases at that point are used by the model. This method is called <em class="calibre14">early stopping.</em></p>
<p class="calibre2">An early stopping neural network ensemble generalization error is comparable with an individual neural network of optimal architecture that is trained by a traditional algorithm. The individual neural network needs a complex and perfect tuning to attain this generalization without early stopping.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Avoiding overfitting in the model</h1>
                
            
            <article>
                
<p class="calibre2">The fitting of the training data causes the model to determine the weights and biases along with the activation function values. When the algorithm does too well in some training dataset, it is said to be too much aligned to that particular dataset. This leads to high variance in the output values when the test data is very different from the training data. This high estimate variance is called <strong class="calibre1">overfitting</strong>. The predictions are affected due to the training data provided.</p>
<p class="calibre2">There are many possible ways to handle overfitting in neural networks. The first is regularization, similar to regression. There are two kinds of regularizations:</p>
<ul class="calibre16">
<li class="calibre17">L1 or lasso regularization</li>
<li class="calibre17">L2 or ridge regularization</li>
<li class="calibre17">Max norm constraints</li>
<li class="calibre17">Dropouts in neural networks</li>
</ul>
<p class="calibre2"><span>Regularization introduces a cost term to impact the activation function. It tries to change most of the coefficients by bringing in more features with the objective function. Hence, it tries to push the coefficients for many variables to zero and reduce the cost term.</span></p>
<ul class="calibre16">
<li class="calibre17"><strong class="calibre1">Lasso or L1 regularization or L1 penalty</strong>: This has a penalty term, which uses the sum of absolute weights, so that the weights are optimized to reduce overfitting. <strong class="calibre1">Least Absolute Shrinkage And Selection Operator</strong> (<strong class="calibre1">LASSO</strong>) introduces the penalty weight to shrink the network weights towards zero.</li>
<li class="calibre17"><strong class="calibre1">L2 penalty or ridge regression</strong>: This is similar to L1, but the penalty is based on squared weights instead of the sum of absolute weights. Larger weights get more penalty.</li>
</ul>
<p class="calibre2">For both cases, only weights are considered for optimization, and biases (or offsets or intercepts) are excluded from the exercise.</p>
<ul class="calibre16">
<li class="calibre76"><span><span><strong class="calibre1">Max norm constraints</strong>: This is another regularization technique, whereby we enforce an absolute upper bound on the magnitude of the incoming weight vector for every neuron and the projected gradient descent cannot modify the weights due to the constraint. Here, the parameter vector cannot grow out of control (even if the learning rates are too high) because the updates to the weights are always bounded.</span></span></li>
<li class="calibre76"><strong class="calibre1">Dropout</strong>: This <span>is another overfitting prevention technique. While training, dropout is implemented by keeping a neuron active with some probability <em class="calibre14">p</em> (a hyperparameter) or setting it to zero otherwise. This means that some neurons may not be present during training and he</span>nce dropout. The n<span>etwork is unaffected and becomes more accurate even in the absence of certain information. This prevents the network from becoming too dependent on any one (or any small combination) of the neurons. The process of dropout is explained in the following diagram. The red (or dark) neurons are the ones dropped out, and the neural network model survives without these neurons and offers less overfitting and greater accuracy:</span></li>
</ul>
<div class="cdpaligncenter"><img class="image-border32" src="../images/00116.gif"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Generalization of neural networks</h1>
                
            
            <article>
                
<p class="calibre2">Generalization is aimed at fitting the training data. It is an extension of the training we have done on the neural networks model. It seeks to minimize the sum of squared errors of the model on the training data (such as using ordinary least squares) and reduce the complexity of the model.</p>
<p class="calibre2">The methods of generalization are listed here:</p>
<ul class="calibre16">
<li class="calibre17">Early stopping of training</li>
<li class="calibre17">Retraining neural networks with different training data
<ul class="calibre39">
<li class="calibre17">Using random sampling, stratified sampling, or any good mix of target data</li>
</ul>
</li>
<li class="calibre17">Training multiple neural networks and averaging out their outputs</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Scaling of data in neural network models</h1>
                
            
            <article>
                
<p class="calibre2">Data scaling or normalization is a process of making model data in a standard format so that the training is improved, accurate, and faster. The method of scaling data in neural networks is similar to data normalization in any machine learning problem.</p>
<p class="calibre2">Some simple methods of data normalization are listed here:</p>
<ul class="calibre16">
<li class="calibre17"><strong class="calibre1">Z-score normalization</strong>: As anticipated in previous sections, the arithmetic mean and standard deviation of the given data are calculated first. The standardized score or <em class="calibre14">Z</em>-score is then calculated as follows:</li>
</ul>
<div class="calibre30"><img src="../images/00117.jpeg" class="calibre77"/></div>
<p class="calibre2"> </p>
<p class="calibre54">Here, <em class="calibre14">X</em> is the value of the data element, <span>μ is the mean, and σ is the standard deviation. The <em class="calibre14">Z</em>-score or standard score indicates how many standard deviations the data element is from the mean. Since mean and standard deviation are sensitive to outliers, this standardization is sensitive to outliers.</span></p>
<ul class="calibre16">
<li class="calibre17"><strong class="calibre1">Min-max normalization</strong>: This calculates the following for each data element:</li>
</ul>
<div class="mce-root1"><img src="../images/00118.jpeg" class="calibre78"/></div>
<p class="calibre54"><span><span><span><span>Here, <em class="calibre14">x</em><sub class="calibre25"><em class="calibre14">i</em></sub> is the data element, <em class="calibre14">min(x)</em> is the minimum of all data values, and <em class="calibre14">max(x)</em> is the maximum of all data values. This method</span></span></span></span> transforms all the scores into a common range of [0, 1]. However, it suffers from outlier sensitivity.</p>
<ul class="calibre16">
<li class="calibre17"><strong class="calibre1">Median and MAD</strong>: The median and median absolute deviation (MAD) normalization calculates the normalized data value using the following formula:</li>
</ul>
<div class="calibre30"><img src="../images/00119.jpeg" class="calibre79"/></div>
<p class="calibre54">Here, <em class="calibre14">x<sub class="calibre25">i</sub></em> represents each data value. This method is insensitive to outliers and the points in the extreme tails of the distribution, and therefore it is robust. However, this technique does not retain the input distribution and does not transform the scores into a common numerical range.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Ensemble predictions using neural networks</h1>
                
            
            <article>
                
<p class="calibre2"><span>Another approach to regularization involves combining neural network models and averaging out the results. The resultant model is the most accurate one.</span></p>
<p class="calibre2"><span>A neural network ensemble is a set of neural network models taking a decision by averaging the results of individual models. Ensemble technique is a</span> simple way to improve generalization, especially when caused by noisy data or a small dataset. We train multiple neural networks and average their outputs.</p>
<p class="calibre2">As an example, we take 20 neural networks for the same learning problem, we adjust the various parameters in the training processing, and then the mean squared errors are compared with the mean squared errors of their average.</p>
<p class="calibre2">The following are the steps followed:</p>
<ol class="calibre19">
<li value="1" class="calibre17">The dataset is loaded and divided into a train and test set. The percentage split can be varied for different neural net models.</li>
<li value="2" class="calibre17">Multiple models are created with the different training sets and by adjusting the parameters in the <kbd class="calibre13">nnet()</kbd> function.</li>
<li value="3" class="calibre17">All the models are trained and errors in each model are tabulated.</li>
<li value="4" class="calibre17">The average error is found for each row in test data and the mean square error is calculated for each model.</li>
<li value="5" class="calibre17">The mean square error is compared with the mean square error of the average.</li>
<li value="6" class="calibre17">The best model is chosen from the comparison and is used further for prediction.</li>
</ol>
<p class="calibre2">This method allows us to play with the data and the function parameters to arrive at the optimal setting of the model. We can choose any number of models in the ensemble and do parallel processing of the models using R.</p>
<p class="calibre2">Overfitting is highly reduced and the best parameters of the model are arrived at here.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="calibre2">In this chapter, we covered the training and visualization of a simple neural network using R. Here, we can change the number of neurons, the number of hidden layers, the activation functions, and so on, to determine the training of the model.</p>
<p class="calibre2">While dealing with a regression problem, the last layer is a single unit, which will give continuous values. For a classification problem, there are n terminal units, each representing the class of output with its probability. The breast cancer example had two output neurons to represent the two classes of values that are output from the neural network.</p>
<p class="calibre2">We have learned how to train, test, and evaluate a dataset using NN model. We have also learned how to visualize the NN model in R environment. We have covered the concepts like early stopping, avoiding overfitting, generalization of NN, and scaling of NN parameters.</p>


            </article>

            
        </section>
    </body></html>