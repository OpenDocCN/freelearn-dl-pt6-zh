<html><head></head><body><div id="book-columns"><div id="book-inner"><div class="chapter" title="Chapter 1. Introduction to Deep Learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch01"/><span class="koboSpan" id="kobo.1.1">Chapter 1. Introduction to Deep Learning</span></h1></div></div></div><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"><span class="koboSpan" id="kobo.2.1"> </span></td><td valign="top"><p>
<span class="emphasis"><em><span class="koboSpan" id="kobo.3.1">"By far the greatest danger of Artificial Intelligence is that people conclude too early that they understand it."</span></em></span>
</p></td><td valign="top"><span class="koboSpan" id="kobo.4.1"> </span></td></tr><tr><td valign="top"><span class="koboSpan" id="kobo.5.1"> </span></td><td colspan="2" align="right" valign="top" style="text-align: center"><span class="koboSpan" id="kobo.6.1">--</span><span class="attribution"><span class="emphasis"><em><span class="koboSpan" id="kobo.7.1">Eliezer Yudkowsky</span></em></span></span></td></tr></table></div><p><span class="koboSpan" id="kobo.8.1">Ever thought, why it is often difficult to beat the computer in chess, even for the best players of the game? </span><span class="koboSpan" id="kobo.8.2">How Facebook is able to recognize your face amid hundreds of millions of photos? </span><span class="koboSpan" id="kobo.8.3">How can your mobile phone recognize your voice, and redirect the call to the correct person, from hundreds of contacts listed?</span></p><p><span class="koboSpan" id="kobo.9.1">The primary goal of this book is to deal with many of those queries, and to provide detailed solutions to the readers. </span><span class="koboSpan" id="kobo.9.2">This book can be used for a wide range of reasons by a variety of readers, however, we wrote the book with two main target audiences in mind. </span><span class="koboSpan" id="kobo.9.3">One of the primary target audiences is undergraduate or graduate university students learning about deep learning and Artificial Intelligence; the second group of readers are the software engineers who already have a knowledge of big data, deep learning, and statistical modeling, but want to rapidly gain knowledge of how deep learning can be used for big data and vice versa.</span></p><p><span class="koboSpan" id="kobo.10.1">This chapter will mainly try to set a foundation for the readers by providing the basic concepts, terminologies, characteristics, and the major challenges of deep learning. </span><span class="koboSpan" id="kobo.10.2">The chapter will also put forward the classification of different deep network algorithms, which have been widely used by researchers over the last decade. </span><span class="koboSpan" id="kobo.10.3">The following are the main topics that this chapter will cover:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.11.1">Getting started with deep learning</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.12.1">Deep learning terminologies</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.13.1">Deep learning: A revolution in Artificial Intelligence</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.14.1">Classification of deep learning networks</span></li></ul></div><p><span class="koboSpan" id="kobo.15.1">Ever since the dawn of civilization, people have always dreamt of building artificial machines or robots which can behave and work exactly like human beings. </span><span class="koboSpan" id="kobo.15.2">From the Greek mythological characters to the ancient Hindu epics, there are numerous such examples, which clearly suggest people's interest and inclination towards creating and having an artificial life.</span></p><p><span class="koboSpan" id="kobo.16.1">During the initial computer generations, people had always wondered if the computer could ever become as intelligent as a human being! </span><span class="koboSpan" id="kobo.16.2">Going forward, even in medical science, the need of automated machines has become indispensable and almost unavoidable. </span><span class="koboSpan" id="kobo.16.3">With this need and constant research in the same field, </span><span class="strong"><strong><span class="koboSpan" id="kobo.17.1">Artificial Intelligence</span></strong></span><span class="koboSpan" id="kobo.18.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.19.1">AI</span></strong></span><span class="koboSpan" id="kobo.20.1">) has turned out to be a flourishing technology with various applications in several domains, such as image processing, video processing, and many other diagnosis tools in medical science too.</span></p><p><span class="koboSpan" id="kobo.21.1">Although there are many problems that are resolved by AI systems on a daily basis, nobody knows the specific rules for how an AI system is programmed! </span><span class="koboSpan" id="kobo.21.2">A few of the intuitive problems are as follows:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.22.1">Google search, which does a really good job of understanding what you type or speak</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.23.1">As mentioned earlier, Facebook is also somewhat good at recognizing your face, and hence, understanding your interests</span></li></ul></div><p><span class="koboSpan" id="kobo.24.1">Moreover, with the integration of various other fields, for example, probability, linear algebra, statistics, machine learning, deep learning, and so on, AI has already gained a huge amount of popularity in the research field over the course of time.</span></p><p><span class="koboSpan" id="kobo.25.1">One of the key reasons for the early success of AI could be that it basically dealt with fundamental problems for which the computer did not require a vast amount of knowledge. </span><span class="koboSpan" id="kobo.25.2">For example, in 1997, IBM's Deep Blue chess-playing system was able to defeat the world champion Garry Kasparov [1]. </span><span class="koboSpan" id="kobo.25.3">Although this kind of achievement at that time can be considered significant, it was definitely not a burdensome task to train the computer with only the limited number of rules involved in chess! </span><span class="koboSpan" id="kobo.25.4">Training a system with a fixed and limited number of rules is termed as </span><span class="emphasis"><em><span class="koboSpan" id="kobo.26.1">hard-coded knowledge</span></em></span><span class="koboSpan" id="kobo.27.1"> of the computer. </span><span class="koboSpan" id="kobo.27.2">Many Artificial Intelligence projects have undergone this hard-coded knowledge about the various aspects of the world in many traditional languages. </span><span class="koboSpan" id="kobo.27.3">As time progresses, this hard-coded knowledge does not seem to work with systems dealing with huge amounts of data. </span><span class="koboSpan" id="kobo.27.4">Moreover, the number of rules that the data was following also kept changing in a frequent manner. </span><span class="koboSpan" id="kobo.27.5">Therefore, most of the projects following that system failed to stand up to the height of expectation.</span></p><p><span class="koboSpan" id="kobo.28.1">The setbacks faced by this hard-coded knowledge implied that those artificial intelligence systems needed some way of generalizing patterns and rules from the supplied raw data, without the need for external spoon-feeding. </span><span class="koboSpan" id="kobo.28.2">The proficiency of a system to do so is termed as </span><span class="emphasis"><em><span class="koboSpan" id="kobo.29.1">machine learning</span></em></span><span class="koboSpan" id="kobo.30.1">. </span><span class="koboSpan" id="kobo.30.2">There are various successful machine learning implementations which we use in our daily life. </span><span class="koboSpan" id="kobo.30.3">A few of the most common and important implementations are as follows:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.31.1">Spam detection</span></strong></span><span class="koboSpan" id="kobo.32.1">: Given an e-mail in your inbox, the model can detect whether to put that e-mail in spam or in the inbox folder. </span><span class="koboSpan" id="kobo.32.2">A common naive Bayes model can distinguish between such e-mails.</span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.33.1">Credit card fraud detection</span></strong></span><span class="koboSpan" id="kobo.34.1">: A model that can detect whether a number of transactions performed at a specific time interval are carried out by the original customer or not.</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.35.1">One of the most popular machine learning models, given by Mor-Yosef et al in 1990, used logistic regression, which could recommend whether caesarean delivery was needed for the patient or not!</span></li></ul></div><p><span class="koboSpan" id="kobo.36.1">There are many such models which have been implemented with the help of machine learning techniques.</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.37.1"><img src="graphics/image_01_001.jpg" alt="Introduction to Deep Learning"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.38.1">Figure 1.1: The figure shows the example of different types of representation. </span><span class="koboSpan" id="kobo.38.2">Let's say we want to train the machine to detect some empty spaces in between the jelly beans. </span><span class="koboSpan" id="kobo.38.3">In the image on the right side, we have sparse jelly beans, and it would be easier for the AI system to determine the empty parts. </span><span class="koboSpan" id="kobo.38.4">However, in the image on the left side, we have extremely compact jelly beans, and hence, it will be an extremely difficult task for the machine to find the empty spaces. </span><span class="koboSpan" id="kobo.38.5">Images sourced from USC-SIPI image database</span></p><p><span class="koboSpan" id="kobo.39.1">A large portion of performance of the machine learning systems depends on the data fed to the system. </span><span class="koboSpan" id="kobo.39.2">This is called </span><span class="emphasis"><em><span class="koboSpan" id="kobo.40.1">representation</span></em></span><span class="koboSpan" id="kobo.41.1"> of the data. </span><span class="koboSpan" id="kobo.41.2">All the information related to the representation is called the </span><span class="emphasis"><em><span class="koboSpan" id="kobo.42.1">feature</span></em></span><span class="koboSpan" id="kobo.43.1"> of the data. </span><span class="koboSpan" id="kobo.43.2">For example, if logistic regression is used to detect a brain tumor in a patient, the AI system will not try to diagnose the patient directly! </span><span class="koboSpan" id="kobo.43.3">Rather, the concerned doctor will provide the necessary input to the systems according to the common symptoms of that patient. </span><span class="koboSpan" id="kobo.43.4">The AI system will then match those inputs with the already received past inputs which were used to train the system.</span></p><p><span class="koboSpan" id="kobo.44.1">Based on the predictive analysis of the system, it will provide its decision regarding the disease. </span><span class="koboSpan" id="kobo.44.2">Although logistic regression can learn and decide based on the features given, it cannot influence or modify the way features are defined. </span><span class="koboSpan" id="kobo.44.3">Logistic regression is a type of regression model where the dependent variable has a limited number of possible values based on the independent variable, unlike linear regression. </span><span class="koboSpan" id="kobo.44.4">So, for example, if that model was provided with a caesarean patient's report instead of the brain tumor patient's report, it would surely fail to predict the correct outcome, as the given features would never match with the trained data.</span></p><p><span class="koboSpan" id="kobo.45.1">These dependencies of the machine learning systems on the representation of the data are not really unknown to us! </span><span class="koboSpan" id="kobo.45.2">In fact, most of our computer theory performs better based on how the data are represented. </span><span class="koboSpan" id="kobo.45.3">For example, the quality of a database is considered based on how the schema is designed. </span><span class="koboSpan" id="kobo.45.4">The execution of any database query, even on a thousand or a million lines of data, becomes extremely fast if the table is indexed properly. </span><span class="koboSpan" id="kobo.45.5">Therefore, the dependency of the data representation of the AI systems should not surprise us.</span></p><p><span class="koboSpan" id="kobo.46.1">There are many such examples in daily life too, where the representation of the data decides our efficiency. </span><span class="koboSpan" id="kobo.46.2">To locate a person amidst 20 people is obviously easier than to locate the same person in a crowd of 500 people. </span><span class="koboSpan" id="kobo.46.3">A visual representation of two different types of data representation is shown in the preceding </span><span class="emphasis"><em><span class="koboSpan" id="kobo.47.1">Figure 1.1</span></em></span><span class="koboSpan" id="kobo.48.1">.</span></p><p><span class="koboSpan" id="kobo.49.1">Therefore, if the AI systems are fed with the appropriate featured data, even the hardest problems could be resolved. </span><span class="koboSpan" id="kobo.49.2">However, collecting and feeding the desired data in the correct way to the system has been a serious impediment for the computer programmer.</span></p><p><span class="koboSpan" id="kobo.50.1">There can be numerous real-time scenarios where extracting the features could be a cumbersome task. </span><span class="koboSpan" id="kobo.50.2">Therefore, the way the data are represented decides the prime factors in the intelligence of the system.</span></p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note3"/><span class="koboSpan" id="kobo.51.1">Note</span></h3><p><span class="koboSpan" id="kobo.52.1">Finding cats amidst a group of humans and cats can be extremely complicated if the features are not appropriate. </span><span class="koboSpan" id="kobo.52.2">We know that cats have tails; therefore, we might like to detect the presence of tails as a prominent feature. </span><span class="koboSpan" id="kobo.52.3">However, given the different tail shapes and sizes, it is often difficult to describe exactly how a tail will look like in terms of pixel values! </span><span class="koboSpan" id="kobo.52.4">Moreover, tails could sometimes be confused with the hands of humans. </span><span class="koboSpan" id="kobo.52.5">Also, overlapping of some objects could omit the presence of a cat's tail, making the image even more complicated.</span></p></div></div><p><span class="koboSpan" id="kobo.53.1">From all the above discussions, it can be concluded that the success of AI systems depends mainly on how the data are represented. </span><span class="koboSpan" id="kobo.53.2">Also, various representations can ensnare and cache the different explanatory factors of all the disparities behind the data.</span></p><p>
<span class="strong"><strong><span class="koboSpan" id="kobo.54.1">Representation learning</span></strong></span><span class="koboSpan" id="kobo.55.1"> is one of the most popular and widely practiced learning approaches used to cope with these specific problems. </span><span class="koboSpan" id="kobo.55.2">Learning the representations of the next layer from the existing representation of data can be defined as representation learning. </span><span class="koboSpan" id="kobo.55.3">Ideally, all representation learning algorithms have this advantage of learning representations, which capture the underlying factors, a subset that might be applicable for each particular sub-task. </span><span class="koboSpan" id="kobo.55.4">A simple illustration is given in the following </span><span class="emphasis"><em><span class="koboSpan" id="kobo.56.1">Figure 1.2</span></em></span><span class="koboSpan" id="kobo.57.1">:</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.58.1"><img src="graphics/B05883_01_02.jpg" alt="Introduction to Deep Learning"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.59.1">Figure 1.2: The figure illustrates representation learning. </span><span class="koboSpan" id="kobo.59.2">The middle layers are able to discover the explanatory factors (hidden layers, in blue rectangular boxes). </span><span class="koboSpan" id="kobo.59.3">Some of the factors explain each task's target, whereas some explain the inputs</span></p><p><span class="koboSpan" id="kobo.60.1">However, dealing with extracting some high-level data and features from a massive amount of raw data, which requires some sort of human-level understanding, has shown its limitations. </span><span class="koboSpan" id="kobo.60.2">There can be many such examples:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.61.1">Differentiating the cry of two similar age babies.</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.62.1">Identifying the image of a cat's eye at both day and night time. </span><span class="koboSpan" id="kobo.62.2">This becomes clumsy, because a cat's eyes glow at night unlike during the daytime.</span></li></ul></div><p><span class="koboSpan" id="kobo.63.1">In all these preceding edge cases, representation learning does not appear to behave exceptionally, and shows deterrent behavior.</span></p><p>
<span class="strong"><strong><span class="koboSpan" id="kobo.64.1">Deep learning</span></strong></span><span class="koboSpan" id="kobo.65.1">, a sub-field of machine learning, can rectify this major problem of representation learning by building multiple levels of representations or learning a hierarchy of features from a series of other simple representations and features [2] [8].</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.66.1"><img src="graphics/B05883_01_03.jpg" alt="Introduction to Deep Learning"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.67.1">Figure 1.3: The figure shows how a deep learning system can represent the human image by identifying various combinations such as corners and contours, which can be defined in terms of edges. </span><span class="koboSpan" id="kobo.67.2">Image reprinted with permission from Ian Goodfellow, Yoshua Bengio, and Aaron Courville, Deep Learning, published by The MIT Press</span></p><p><span class="koboSpan" id="kobo.68.1">The preceding </span><span class="emphasis"><em><span class="koboSpan" id="kobo.69.1">Figure 1.3</span></em></span><span class="koboSpan" id="kobo.70.1"> shows an illustration of a deep learning model. </span><span class="koboSpan" id="kobo.70.2">It is generally a cumbersome task for the computer to decode the meaning of raw unstructured input data, as represented by this image, as a collection of different pixel values. </span><span class="koboSpan" id="kobo.70.3">A mapping function, which will convert the group of pixels to identify the image, is ideally difficult to achieve. </span><span class="koboSpan" id="kobo.70.4">Also, to directly train the computer for these kinds of mapping is almost insuperable. </span><span class="koboSpan" id="kobo.70.5">For these types of tasks, deep learning resolves the difficulty by creating a series of subsets of mappings to reach the desired output. </span><span class="koboSpan" id="kobo.70.6">Each subset of mappings corresponds to a different set of layer of the model. </span><span class="koboSpan" id="kobo.70.7">The input contains the variables that one can observe, and hence , are represented in the visible layers. </span><span class="koboSpan" id="kobo.70.8">From the given input we can incrementally extract the abstract features of the data. </span><span class="koboSpan" id="kobo.70.9">As these values are not available or visible in the given data, these layers are termed as hidden layers.</span></p><p><span class="koboSpan" id="kobo.71.1">In the image, from the first layer of data, the edges can easily be identified just by a comparative study of the neighboring pixels. </span><span class="koboSpan" id="kobo.71.2">The second hidden layer can distinguish the corners and contours from the first hidden layer's description of the edges. </span><span class="koboSpan" id="kobo.71.3">From this second hidden layer, which describes the corners and contours, the third hidden layer can identify the different parts of the specific objects. </span><span class="koboSpan" id="kobo.71.4">Ultimately, the different objects present in the image can be distinctly detected from the third layer.</span></p><p><span class="koboSpan" id="kobo.72.1">Deep learning started its journey exclusively in 2006, </span><span class="strong"><strong><span class="koboSpan" id="kobo.73.1">Hinton et al.</span></strong></span><span class="koboSpan" id="kobo.74.1"> in 2006[2]; also </span><span class="strong"><strong><span class="koboSpan" id="kobo.75.1">Bengio et al.</span></strong></span><span class="koboSpan" id="kobo.76.1"> in 2007[3] initially focused on the MNIST digit classification problem. </span><span class="koboSpan" id="kobo.76.2">In the last few years, deep learning has seen major transitions from digits to object recognition in natural images. </span><span class="koboSpan" id="kobo.76.3">Apart from this, one of the major breakthroughs was achieved by </span><span class="strong"><strong><span class="koboSpan" id="kobo.77.1">Krizhevsky et al.</span></strong></span><span class="koboSpan" id="kobo.78.1"> in 2012 [4] using the ImageNet dataset.</span></p><p><span class="koboSpan" id="kobo.79.1">The scope of this book is mainly limited to deep learning, so before diving into it directly, the necessary definitions of deep learning should be discussed.</span></p><p><span class="koboSpan" id="kobo.80.1">Many researchers have defined deep learning in many ways, and hence, in the last 10 years, it has gone through many definitions too! </span><span class="koboSpan" id="kobo.80.2">The following are few of the widely accepted definitions:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.81.1">As noted by GitHub, deep learning is a new area of machine learning research, which has been introduced with the objective of moving machine learning closer to one of its original goals: Artificial Intelligence. </span><span class="koboSpan" id="kobo.81.2">Deep learning is about learning multiple levels of representation and abstraction, which help to make sense of data such as images, sounds, and texts.</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.82.1">As recently updated by Wikipedia, deep learning is a branch of machine learning based on a set of algorithms that attempt to model high-level abstractions in the data by using a deep graph with multiple processing layers, composed of multiple linear and non-linear transformations.</span></li></ul></div><p><span class="koboSpan" id="kobo.83.1">As the definitions suggest, deep learning can also be considered as a special type of machine learning. </span><span class="koboSpan" id="kobo.83.2">Deep learning has achieved immense popularity in the field of data science with its ability to learn complex representation from various simple features. </span><span class="koboSpan" id="kobo.83.3">To have an in-depth grip on deep learning, we have listed out a few terminologies which will be frequently used in the upcoming chapters. </span><span class="koboSpan" id="kobo.83.4">The next topic of this chapter will help you to lay a foundation for deep learning by providing various terminologies and important networks used for deep learning.</span></p><div class="section" title="Getting started with deep learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec7"/><span class="koboSpan" id="kobo.84.1">Getting started with deep learning</span></h1></div></div></div><p><span class="koboSpan" id="kobo.85.1">To understand the journey of deep learning in this book, one must know all the terminologies and basic concepts of machine learning. </span><span class="koboSpan" id="kobo.85.2">However, if you already have enough insight into machine learning and related terms, you should feel free to ignore this section and jump to the next topic of this chapter. </span><span class="koboSpan" id="kobo.85.3">Readers who are enthusiastic about data science, and want to learn machine learning thoroughly, can follow </span><span class="emphasis"><em><span class="koboSpan" id="kobo.86.1">Machine Learning</span></em></span><span class="koboSpan" id="kobo.87.1"> by Tom M. </span><span class="koboSpan" id="kobo.87.2">Mitchell (1997) [5] and </span><span class="emphasis"><em><span class="koboSpan" id="kobo.88.1">Machine Learning: a Probabilistic Perspective</span></em></span><span class="koboSpan" id="kobo.89.1"> (2012) [6].</span></p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note4"/><span class="koboSpan" id="kobo.90.1">Note</span></h3><p><span class="koboSpan" id="kobo.91.1">Neural networks do not perform miracles. </span><span class="koboSpan" id="kobo.91.2">But, used sensibly, they can produce some amazing results.</span></p></div></div><div class="section" title="Deep feed-forward networks"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec6"/><span class="koboSpan" id="kobo.92.1">Deep feed-forward networks</span></h2></div></div></div><p><span class="koboSpan" id="kobo.93.1">Neural networks can be recurrent as well as feed-forward. </span><span class="koboSpan" id="kobo.93.2">Feed-forward networks do not have any loop associated in their graph, and are arranged in a set of layers. </span><span class="koboSpan" id="kobo.93.3">A network with many layers is said to be a deep network. </span><span class="koboSpan" id="kobo.93.4">In simple words, any neural network with two or more layers (hidden) is defined as a </span><span class="strong"><strong><span class="koboSpan" id="kobo.94.1">deep feed-forward network</span></strong></span><span class="koboSpan" id="kobo.95.1"> or </span><span class="strong"><strong><span class="koboSpan" id="kobo.96.1">feed-forward neural</span></strong></span><span class="koboSpan" id="kobo.97.1"> network. </span><span class="emphasis"><em><span class="koboSpan" id="kobo.98.1">Figure 1.4</span></em></span><span class="koboSpan" id="kobo.99.1"> shows a generic representation of a deep feed-forward neural network.</span></p><p><span class="koboSpan" id="kobo.100.1">Deep feed-forward networks work on the principle that with an increase in depth, the network can also execute more sequential instructions. </span><span class="koboSpan" id="kobo.100.2">Instructions in sequence can offer great power, as these instructions can point to the earlier instruction.</span></p><p><span class="koboSpan" id="kobo.101.1">The aim of a feed-forward network is to generalize some function </span><span class="emphasis"><em><span class="koboSpan" id="kobo.102.1">f</span></em></span><span class="koboSpan" id="kobo.103.1">. </span><span class="koboSpan" id="kobo.103.2">For example, classifier </span><span class="emphasis"><em><span class="koboSpan" id="kobo.104.1">y=f(x) </span></em></span><span class="koboSpan" id="kobo.105.1">maps from input </span><span class="emphasis"><em><span class="koboSpan" id="kobo.106.1">x</span></em></span><span class="koboSpan" id="kobo.107.1"> to category </span><span class="emphasis"><em><span class="koboSpan" id="kobo.108.1">y</span></em></span><span class="koboSpan" id="kobo.109.1">. </span><span class="koboSpan" id="kobo.109.2">A deep feed-forward network modified the mapping, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.110.1">y=f(x; α)</span></em></span><span class="koboSpan" id="kobo.111.1">, and learns the value of the parameter </span><span class="emphasis"><em><span class="koboSpan" id="kobo.112.1">α</span></em></span><span class="koboSpan" id="kobo.113.1">, which gives the most appropriate value of the function. </span><span class="koboSpan" id="kobo.113.2">The following </span><span class="emphasis"><em><span class="koboSpan" id="kobo.114.1">Figure 1.4</span></em></span><span class="koboSpan" id="kobo.115.1"> shows a simple representation of the deep-forward network, to provide the architectural difference with the traditional neural network.</span></p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note5"/><span class="koboSpan" id="kobo.116.1">Note</span></h3><p><span class="koboSpan" id="kobo.117.1">A deep neural network is a feed-forward network with many hidden layers.</span></p></div></div><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.118.1"><img src="graphics/B05883_01_04-1.jpg" alt="Deep feed-forward networks"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.119.1">Figure 1.4: Figure shows the representation of a shallow and deep feed-forward network</span></p></div><div class="section" title="Various learning algorithms"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec7"/><span class="koboSpan" id="kobo.120.1">Various learning algorithms</span></h2></div></div></div><p>
<span class="strong"><strong><span class="koboSpan" id="kobo.121.1">Datasets</span></strong></span><span class="koboSpan" id="kobo.122.1"> are considered to be the building blocks of a learning process. </span><span class="koboSpan" id="kobo.122.2">A dataset can be defined as a collection of interrelated sets of data, which is comprised of separate entities, but which can be used as a single entity depending on the use-case. </span><span class="koboSpan" id="kobo.122.3">The individual data elements of a dataset are called </span><span class="strong"><strong><span class="koboSpan" id="kobo.123.1">data points</span></strong></span><span class="koboSpan" id="kobo.124.1">.</span></p><p><span class="koboSpan" id="kobo.125.1">The following </span><span class="emphasis"><em><span class="koboSpan" id="kobo.126.1">Figure 1.5</span></em></span><span class="koboSpan" id="kobo.127.1"> gives the visual representation of the various data points collected from a social network analysis:</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.128.1"><img src="graphics/image_01_005.jpg" alt="Various learning algorithms"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.129.1">Figure 1.5: Image shows the scattered data points of social network analysis. </span><span class="koboSpan" id="kobo.129.2">Image sourced from Wikipedia</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.130.1">Unlabeled data</span></strong></span><span class="koboSpan" id="kobo.131.1">: This part of data consists of the human-generated objects, which can be easily obtained from the surroundings. </span><span class="koboSpan" id="kobo.131.2">Some of the examples are X-rays, log file data, news articles, speech, videos, tweets, and so on.</span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.132.1">Labelled data</span></strong></span><span class="koboSpan" id="kobo.133.1">: Labelled data are normalized data from a set of unlabeled data. </span><span class="koboSpan" id="kobo.133.2">These types of data are usually well formatted, classified, tagged, and easily understandable by human beings for further processing.</span></li></ul></div><p><span class="koboSpan" id="kobo.134.1">From the top-level understanding, machine learning techniques can be classified as supervised and unsupervised learning, based on how their learning process is carried out.</span></p><div class="section" title="Unsupervised learning"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec0"/><span class="koboSpan" id="kobo.135.1">Unsupervised learning</span></h3></div></div></div><p><span class="koboSpan" id="kobo.136.1">In unsupervised learning algorithms, there is no desired output from the given input datasets. </span><span class="koboSpan" id="kobo.136.2">The system learns meaningful properties and features from its experience during the analysis of the dataset. </span><span class="koboSpan" id="kobo.136.3">In deep learning, the system generally tries to learn from the whole probability distribution of the data points. </span><span class="koboSpan" id="kobo.136.4">There are various types of unsupervised learning algorithms, which perform clustering. </span><span class="koboSpan" id="kobo.136.5">To explain in simple words, clustering means separating the data points among clusters of similar types of data. </span><span class="koboSpan" id="kobo.136.6">However, with this type of learning, there is no feedback based on the final output, that is, there won't be any teacher to correct you! </span><span class="emphasis"><em><span class="koboSpan" id="kobo.137.1">Figure 1.6</span></em></span><span class="koboSpan" id="kobo.138.1"> shows a basic overview of unsupervised clustering:</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.139.1"><img src="graphics/image_01_006.jpg" alt="Unsupervised learning"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.140.1">Figure 1.6: Figures shows a simple representation of unsupervised clustering</span></p><p><span class="koboSpan" id="kobo.141.1">A real life example of an unsupervised clustering algorithm is Google News. </span><span class="koboSpan" id="kobo.141.2">When we open a topic under Google News, it shows us a number of hyper-links redirecting to several pages. </span><span class="koboSpan" id="kobo.141.3">Each of these topics can be considered as a cluster of hyper-links that point to independent links.</span></p></div><div class="section" title="Supervised learning"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec1"/><span class="koboSpan" id="kobo.142.1">Supervised learning</span></h3></div></div></div><p><span class="koboSpan" id="kobo.143.1">In supervised learning, unlike unsupervised learning, there is an expected output associated with every step of the experience. </span><span class="koboSpan" id="kobo.143.2">The system is given a dataset, and it already knows how the desired output will look, along with the correct relationship between the input and output of every associated layer. </span><span class="koboSpan" id="kobo.143.3">This type of learning is often used for classification problems.</span></p><p><span class="koboSpan" id="kobo.144.1">The following visual representation is given in </span><span class="emphasis"><em><span class="koboSpan" id="kobo.145.1">Figure 1.7</span></em></span><span class="koboSpan" id="kobo.146.1">:</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.147.1"><img src="graphics/image_01_007.jpg" alt="Supervised learning"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.148.1">Figure 1.7: Figure shows the classification of data based on supervised learning</span></p><p><span class="koboSpan" id="kobo.149.1">Real-life examples of supervised learning include face detection, face recognition, and so on.</span></p><p><span class="koboSpan" id="kobo.150.1">Although supervised and unsupervised learning look like different identities, they are often connected to each other by various means. </span><span class="koboSpan" id="kobo.150.2">Hence, the fine line between these two learnings is often hazy to the student fraternity.</span></p><p><span class="koboSpan" id="kobo.151.1">The preceding statement can be formulated with the following mathematical expression:</span></p><p><span class="koboSpan" id="kobo.152.1">The general product rule of probability states that for an </span><span class="emphasis"><em><span class="koboSpan" id="kobo.153.1">n</span></em></span><span class="koboSpan" id="kobo.154.1"> number of datasets n ε ℝ</span><sup><span class="koboSpan" id="kobo.155.1">t</span></sup><span class="koboSpan" id="kobo.156.1">,the joint distribution can be fragmented as follows:</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.157.1"><img src="graphics/Capture.jpg" alt="Supervised learning"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.158.1">The distribution signifies that the appeared unsupervised problem can be resolved by </span><span class="emphasis"><em><span class="koboSpan" id="kobo.159.1">t</span></em></span><span class="koboSpan" id="kobo.160.1"> number of supervised problems. </span><span class="koboSpan" id="kobo.160.2">Apart from this, the conditional probability of </span><span class="emphasis"><em><span class="koboSpan" id="kobo.161.1">p (k | n)</span></em></span><span class="koboSpan" id="kobo.162.1">, which is a supervised problem, can be solved using unsupervised learning algorithms to experience the joint distribution of </span><span class="emphasis"><em><span class="koboSpan" id="kobo.163.1">p (n, k)</span></em></span><span class="koboSpan" id="kobo.164.1">.</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.165.1"><img src="graphics/B05883_01_18.jpg" alt="Supervised learning"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.166.1">Although these two types are not completely separate identities, they often help to classify the machine learning and deep learning algorithms based on the operations performed. </span><span class="koboSpan" id="kobo.166.2">In generic terms, cluster formation, identifying the density of a population based on similarity, and so on are termed as unsupervised learning, whereas structured formatted output, regression, classification, and so on are recognized as supervised learning.</span></p></div><div class="section" title="Semi-supervised learning"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec2"/><span class="koboSpan" id="kobo.167.1">Semi-supervised learning</span></h3></div></div></div><p><span class="koboSpan" id="kobo.168.1">As the name suggests, in this type of learning both labelled and unlabeled data are used during the training. </span><span class="koboSpan" id="kobo.168.2">It's a class of supervised learning which uses a vast amount of unlabeled data during training.</span></p><p><span class="koboSpan" id="kobo.169.1">For example, semi-supervised learning is used in a Deep belief network (explained later), a type of deep network where some layers learn the structure of the data (unsupervised), whereas one layer learns how to classify the data (supervised learning).</span></p><p><span class="koboSpan" id="kobo.170.1">In semi-supervised learning, unlabeled data from </span><span class="emphasis"><em><span class="koboSpan" id="kobo.171.1">p (n)</span></em></span><span class="koboSpan" id="kobo.172.1"> and labelled data from </span><span class="emphasis"><em><span class="koboSpan" id="kobo.173.1">p (n, k)</span></em></span><span class="koboSpan" id="kobo.174.1"> are used to predict the probability of </span><span class="emphasis"><em><span class="koboSpan" id="kobo.175.1">k</span></em></span><span class="koboSpan" id="kobo.176.1">, given the probability of </span><span class="emphasis"><em><span class="koboSpan" id="kobo.177.1">n</span></em></span><span class="koboSpan" id="kobo.178.1">, or </span><span class="emphasis"><em><span class="koboSpan" id="kobo.179.1">p (k | n).</span></em></span>
</p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.180.1"><img src="graphics/image_01_010.jpg" alt="Semi-supervised learning"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.181.1">Figure 1.8: Figure shows the impact of a large amount of unlabelled data during the semi-supervised learning technique. </span><span class="koboSpan" id="kobo.181.2">Figure obtained from Wikipedia</span></p><p><span class="koboSpan" id="kobo.182.1">In the preceding </span><span class="emphasis"><em><span class="koboSpan" id="kobo.183.1">Figure 1.8</span></em></span><span class="koboSpan" id="kobo.184.1">, at the top it shows the decision boundary that the model uses after distinguishing the white and black circles. </span><span class="koboSpan" id="kobo.184.2">The figure at the bottom displays another decision boundary, which the model embraces. </span><span class="koboSpan" id="kobo.184.3">In that dataset, in addition to two different categories of circles, a collection of unlabeled data (grey circle) is also annexed. </span><span class="koboSpan" id="kobo.184.4">This type of training can be viewed as creating the cluster, and then marking those with the labelled data, which moves the decision boundary away from the high-density data region.</span></p><p><span class="koboSpan" id="kobo.185.1">The preceding </span><span class="emphasis"><em><span class="koboSpan" id="kobo.186.1">Figure 1.8</span></em></span><span class="koboSpan" id="kobo.187.1"> depicts the illustration of semi-supervised learning. </span><span class="koboSpan" id="kobo.187.2">You can refer to </span><span class="emphasis"><em><span class="koboSpan" id="kobo.188.1">Chapelle et al.'s</span></em></span><span class="koboSpan" id="kobo.189.1"> book [7] to know more about semi-supervised learning methods.</span></p><p><span class="koboSpan" id="kobo.190.1">So, as you have already got a foundation in what Artificial Intelligence, machine learning, and representation learning are, we can now move our entire focus to elaborate on deep learning with further description.</span></p><p><span class="koboSpan" id="kobo.191.1">From the previously mentioned definitions of deep learning, two major characteristics of deep learning can be pointed out, as follows:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.192.1">A way of experiencing unsupervised and supervised learning of the feature representation through successive knowledge from subsequent abstract layers</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.193.1">A model comprising of multiple abstract stages of non-linear information processing</span></li></ul></div></div></div></div></div></div></div>
<div id="book-columns"><div id="book-inner"><div class="section" title="Deep learning terminologies"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec8"/><span class="koboSpan" id="kobo.1.1">Deep learning terminologies</span></h1></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.2.1">Deep Neural Network</span></strong></span><span class="koboSpan" id="kobo.3.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.4.1">DNN</span></strong></span><span class="koboSpan" id="kobo.5.1">): This can be defined as a multilayer perceptron with many hidden layers. </span><span class="koboSpan" id="kobo.5.2">All the weights of the layers are fully connected to each other, and receive connections from the previous layer. </span><span class="koboSpan" id="kobo.5.3">The weights are initialized with either supervised or unsupervised learning.</span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.6.1">Recurrent Neural Networks</span></strong></span><span class="koboSpan" id="kobo.7.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.8.1">RNN</span></strong></span><span class="koboSpan" id="kobo.9.1">): RNN is a kind of deep learning network that is specially used in learning from time series or sequential data, such as speech, video, and so on. </span><span class="koboSpan" id="kobo.9.2">The primary concept of RNN is that the observations from the previous state need to be retained for the next state. </span><span class="koboSpan" id="kobo.9.3">The recent hot topic in deep learning with RNN is </span><span class="strong"><strong><span class="koboSpan" id="kobo.10.1">Long short-term memory</span></strong></span><span class="koboSpan" id="kobo.11.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.12.1">LSTM</span></strong></span><span class="koboSpan" id="kobo.13.1">).</span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.14.1">Deep belief network</span></strong></span><span class="koboSpan" id="kobo.15.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.16.1">DBN</span></strong></span><span class="koboSpan" id="kobo.17.1">): This type of network [9] [10] [11] can be defined as a probabilistic generative model with visible and multiple layers of latent variables (hidden). </span><span class="koboSpan" id="kobo.17.2">Each hidden layer possesses a statistical relationship between units in the lower layer through learning. </span><span class="koboSpan" id="kobo.17.3">The more the networks tend to move to higher layers, the more complex relationship becomes. </span><span class="koboSpan" id="kobo.17.4">This type of network can be productively trained using greedy layer-wise training, where all the hidden layers are trained one at a time in a bottom-up fashion.</span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.18.1">Boltzmann machine</span></strong></span><span class="koboSpan" id="kobo.19.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.20.1">BM</span></strong></span><span class="koboSpan" id="kobo.21.1">): This can be defined as a network that is a symmetrically connected, neuron-like unit, which is capable of taking stochastic decisions about whether to remain on or off. </span><span class="koboSpan" id="kobo.21.2">BMs generally have a simple learning algorithm, which allows them to uncover many interesting features that represent complex regularities in the training dataset.</span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.22.1">Restricted Boltzmann machine</span></strong></span><span class="koboSpan" id="kobo.23.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.24.1">RBM</span></strong></span><span class="koboSpan" id="kobo.25.1">): RBM, which is a generative stochastic Artificial Neural Network, is a special type of Boltzmann Machine. </span><span class="koboSpan" id="kobo.25.2">These types of networks have the capability to learn a probability distribution over a collection of datasets. </span><span class="koboSpan" id="kobo.25.3">An RBM consists of a layer of visible and hidden units, but with no visible-visible or hidden-hidden connections.</span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.26.1">Convolutional neural networks</span></strong></span><span class="koboSpan" id="kobo.27.1">: Convolutional neural networks are part of neural networks; the layers are sparsely connected to each other and to the input layer. </span><span class="koboSpan" id="kobo.27.2">Each neuron of the subsequent layer is responsible for only a part of the input. </span><span class="koboSpan" id="kobo.27.3">Deep convolutional neural networks have accomplished some unmatched performance in the field of location recognition, image classification, face recognition, and so on.</span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.28.1">Deep auto-encoder</span></strong></span><span class="koboSpan" id="kobo.29.1">: A deep auto-encoder is a type of auto-encoder that has multiple hidden layers. </span><span class="koboSpan" id="kobo.29.2">This type of network can be pre-trained as a stack of single-layered auto-encoders. </span><span class="koboSpan" id="kobo.29.3">The training process is usually difficult: first, we need to train the first hidden layer to restructure the input data, which is then used to train the next hidden layer to restructure the states of the previous hidden layer, and so on.</span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.30.1">Gradient descent</span></strong></span><span class="koboSpan" id="kobo.31.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.32.1">GD</span></strong></span><span class="koboSpan" id="kobo.33.1">): This is an optimization algorithm used widely in machine learning to determine the coefficient of a function (</span><span class="emphasis"><em><span class="koboSpan" id="kobo.34.1">f</span></em></span><span class="koboSpan" id="kobo.35.1">), which reduces the overall cost function. </span><span class="koboSpan" id="kobo.35.2">Gradient descent is mostly used when it is not possible to calculate the desired parameter analytically (for example, linear algebra), and must be found by some optimization algorithm.</span></li></ul></div><p><span class="koboSpan" id="kobo.36.1">In gradient descent, weights of the model are incrementally updated with every single iteration of the training dataset (epoch).</span></p><p><span class="koboSpan" id="kobo.37.1">The cost function, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.38.1">J (w)</span></em></span><span class="koboSpan" id="kobo.39.1">, with the sum of the squared errors can be written as follows:</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.40.1"><img src="graphics/B05883_01_19-1.jpg" alt="Deep learning terminologies"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.41.1">The direction of magnitude of the weight update is calculated by taking a step in the reverse direction of the cost gradient, as follows:</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.42.1"><img src="graphics/Capture-3.jpg" alt="Deep learning terminologies"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.43.1">In the preceding equation, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.44.1">η</span></em></span><span class="koboSpan" id="kobo.45.1"> is the learning rate of the network. </span><span class="koboSpan" id="kobo.45.2">Weights are updated incrementally after every epoch with the following rule:</span></p><pre class="programlisting"><span class="koboSpan" id="kobo.46.1">                         for one or more epochs, 
                           for each weight i, 
                             w</span><sub><span class="koboSpan" id="kobo.47.1">i</span></sub><span class="koboSpan" id="kobo.48.1">:= w + ∆w</span><sub><span class="koboSpan" id="kobo.49.1">i</span></sub><span class="koboSpan" id="kobo.50.1"> 
                           end  
                         end 
</span></pre><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.51.1"><img src="graphics/Capture-12.jpg" alt="Deep learning terminologies"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.52.1">Popular examples that can be optimized using gradient descent are Logistic Regression and Linear Regression.</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.53.1">Stochastic Gradient Descent</span></strong></span><span class="koboSpan" id="kobo.54.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.55.1">SGD</span></strong></span><span class="koboSpan" id="kobo.56.1">): Various deep learning algorithms, which operated on a large amount of datasets, are based on an optimization algorithm called stochastic gradient descent. </span><span class="koboSpan" id="kobo.56.2">Gradient descent performs well only in the case of small datasets. </span><span class="koboSpan" id="kobo.56.3">However, in the case of very large-scale datasets, this approach becomes extremely costly . </span><span class="koboSpan" id="kobo.56.4">In gradient descent, it takes only one single step for one pass over the entire training dataset; thus, as the dataset's size tends to increase, the whole algorithm eventually slows down. </span><span class="koboSpan" id="kobo.56.5">The weights are updated at a very slow rate; hence, the time it takes to converge to the global cost minimum becomes protracted.</span></li></ul></div><p><span class="koboSpan" id="kobo.57.1">Therefore, to deal with such large-scale datasets, a variation of gradient descent called stochastic gradient descent is used. </span><span class="koboSpan" id="kobo.57.2">Unlike gradient descent, the weight is updated after each iteration of the training dataset, rather than at the end of the entire dataset.</span></p><pre class="programlisting"><span class="koboSpan" id="kobo.58.1">                     until cost minimum is reached 
                       for each training sample j: 
                         for each weight i 
                           w</span><sub><span class="koboSpan" id="kobo.59.1">i</span></sub><span class="koboSpan" id="kobo.60.1">:= w + ∆w</span><sub><span class="koboSpan" id="kobo.61.1">i</span></sub><span class="koboSpan" id="kobo.62.1"> 
                         end 
                       end 
                     end 
</span></pre><p><span class="koboSpan" id="kobo.63.1"> </span></p><div class="mediaobject"><span class="koboSpan" id="kobo.64.1"><img src="graphics/Capture-13.jpg" alt="Deep learning terminologies"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.65.1">In the last few years, deep learning has gained tremendous popularity, as it has become a junction for research areas of many widely practiced subjects, such as pattern recognition, neural networks, graphical modelling, machine learning, and signal processing.</span></p><p><span class="koboSpan" id="kobo.66.1">The other important reasons for this popularity can be summarized by the following points:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.67.1">In recent years, the ability of </span><span class="strong"><strong><span class="koboSpan" id="kobo.68.1">GPU</span></strong></span><span class="koboSpan" id="kobo.69.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.70.1">Graphical Processing Units</span></strong></span><span class="koboSpan" id="kobo.71.1">) has increased drastically</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.72.1">The size of data sizes of the dataset used for training purposes has increased significantly</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.73.1">Recent research in machine learning, data science, and information processing has shown some serious advancements</span></li></ul></div><p><span class="koboSpan" id="kobo.74.1">Detailed descriptions of all these points will be provided in an upcoming topic in this chapter.</span></p></div></div></div>
<div id="book-columns"><div id="book-inner"><div class="section" title="Deep learning: A revolution in Artificial Intelligence"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec9"/><span class="koboSpan" id="kobo.1.1">Deep learning: A revolution in Artificial Intelligence</span></h1></div></div></div><p><span class="koboSpan" id="kobo.2.1">An extensive history of deep learning is beyond the scope of this book. </span><span class="koboSpan" id="kobo.2.2">However, to get an interest in and cognizance of this subject, some basic context of the background is essential.</span></p><p><span class="koboSpan" id="kobo.3.1">In the introduction, we already talked a little about how deep learning occupies a space in the perimeter of Artificial Intelligence. </span><span class="koboSpan" id="kobo.3.2">This section will detail more on how machine learning and deep learning are correlated or different from each other. </span><span class="koboSpan" id="kobo.3.3">We will also discuss how the trend has varied for these two topics in the last decade or so.</span></p><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"><span class="koboSpan" id="kobo.4.1"> </span></td><td valign="top"><p>

<span class="emphasis"><em><span class="koboSpan" id="kobo.5.1">"Deep Learning waves have lapped at the shores of computational linguistics for several years now, but 2015 seems like the year when the full force of the tsunami hit the major Natural Language Processing (NLP) conferences."</span></em></span>
</p></td><td valign="top"><span class="koboSpan" id="kobo.6.1"> </span></td></tr><tr><td valign="top"><span class="koboSpan" id="kobo.7.1"> </span></td><td colspan="2" align="right" valign="top" style="text-align: center"><span class="koboSpan" id="kobo.8.1">--</span><span class="attribution"><span class="emphasis"><em><span class="koboSpan" id="kobo.9.1">Dr. </span><span class="koboSpan" id="kobo.9.2">Christopher D. </span><span class="koboSpan" id="kobo.9.3">Manning, Dec 2015</span></em></span></span></td></tr></table></div><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.10.1"><img src="graphics/B05883_01_17.jpg" alt="Deep learning: A revolution in Artificial Intelligence"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.11.1">Figure 1.9: Figure depicts that deep learning was in the initial phase approximately 10 years back. </span><span class="koboSpan" id="kobo.11.2">However, machine learning was somewhat a trending topic in the researcher's community.</span></p><p><span class="koboSpan" id="kobo.12.1">Deep learning is rapidly expanding its territory in the field of Artificial Intelligence, and continuously surprising many researchers with its astonishing empirical results. </span><span class="koboSpan" id="kobo.12.2">Machine learning and deep learning both represent two different schools of thought. </span><span class="koboSpan" id="kobo.12.3">Machine learning can be treated as the most fundamental approach for AI, where as deep learning can be considered as the new, giant era, with some added functionalities of the subject.</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.13.1"><img src="graphics/B05883_01_18-1.jpg" alt="Deep learning: A revolution in Artificial Intelligence"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.14.1">Figure 1.10: Figure depicts how deep learning is gaining in popularity these days, and trying to reach the level of machine learning</span></p><p><span class="koboSpan" id="kobo.15.1">However, machine learning has often failed in completely solving many crucial problems of AI, mainly speech recognition, object recognition, and so on.</span></p><p><span class="koboSpan" id="kobo.16.1">The performance of traditional algorithms seems to be more challenging while working with high-dimensional data, as the number of random variables keeps on increasing. </span><span class="koboSpan" id="kobo.16.2">Moreover, the procedures used to attain the generalization in traditional machine-learning approaches are not sufficient to learn complicated obligations in high-dimensional spaces, which generally impel more computational costs of the overall model. </span><span class="koboSpan" id="kobo.16.3">The development of deep learning was mostly motivated by the collapse of the fundamental algorithms of machine learning on such functions, and also to overcome the afore mentioned obstacles.</span></p><p><span class="koboSpan" id="kobo.17.1">A large proportion of researchers and data scientists believe that, in the course of time, deep learning will occupy a major portion of Artificial Intelligence, and eventually make machine learning algorithms obsolete. </span><span class="koboSpan" id="kobo.17.2">To get a clear idea of this, we looked at the current Google trend of these two fields and came to the following conclusion:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.18.1">The curve of machine learning has always been the growing stage from the past decade. </span><span class="koboSpan" id="kobo.18.2">Deep learning is new, but growing faster than machine learning. </span><span class="koboSpan" id="kobo.18.3">When trends are closely observed, one will find that the growth rate is faster for deep learning compared to machine learning.</span></li></ul></div><p><span class="koboSpan" id="kobo.19.1">Both of the preceding </span><span class="emphasis"><em><span class="koboSpan" id="kobo.20.1">Figure 1.9</span></em></span><span class="koboSpan" id="kobo.21.1"> and </span><span class="emphasis"><em><span class="koboSpan" id="kobo.22.1">Figure 1.10</span></em></span><span class="koboSpan" id="kobo.23.1"> depict the visualizations of the Google trend.</span></p><div class="section" title="Motivations for deep learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec8"/><span class="koboSpan" id="kobo.24.1">Motivations for deep learning</span></h2></div></div></div><p><span class="koboSpan" id="kobo.25.1">One of the biggest-known problems that machine learning algorithms face is the </span><span class="strong"><strong><span class="koboSpan" id="kobo.26.1">curse of dimensionality</span></strong></span><span class="koboSpan" id="kobo.27.1"> [12] [13] [14]. </span><span class="koboSpan" id="kobo.27.2">This refers to the fact that certain learning algorithms may behave poorly when the number of dimensions in the dataset is high. </span><span class="koboSpan" id="kobo.27.3">In the next section, we will discuss how deep learning has given sufficient hope to this problem by introducing new features. </span><span class="koboSpan" id="kobo.27.4">There are many other related issues where deep architecture has shown a significant edge over traditional architectures. </span><span class="koboSpan" id="kobo.27.5">In this part of the chapter, we would like to introduce the more pronounced challenges as a separate topic.</span></p><div class="section" title="The curse of dimensionality"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec3"/><span class="koboSpan" id="kobo.28.1">The curse of dimensionality</span></h3></div></div></div><p><span class="koboSpan" id="kobo.29.1">The curse of dimensionality can be defined as the phenomena which arises during the analysis and organization of data in high-dimensional spaces (in the range of thousands or even higher dimensions). </span><span class="koboSpan" id="kobo.29.2">Machine learning problems face extreme difficulties when the number of dimensions in the dataset is high. </span><span class="koboSpan" id="kobo.29.3">High dimensional data are difficult to work with because of the following reasons:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.30.1">With the increasing number of dimensions, the number of features will tend to increase exponentially, which eventually leads to an increase in noise.</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.31.1">In standard practice, we will not get a high enough number of observations to generalize the dataset.</span></li></ul></div><p><span class="koboSpan" id="kobo.32.1">A straightforward explanation for the curse of dimensionality could be </span><span class="strong"><strong><span class="koboSpan" id="kobo.33.1">combinatorial explosion</span></strong></span><span class="koboSpan" id="kobo.34.1">. </span><span class="koboSpan" id="kobo.34.2">As per combinatorial explosion, with the collection of a number of variables, an enormous combination could be built. </span><span class="koboSpan" id="kobo.34.3">For example, with </span><span class="emphasis"><em><span class="koboSpan" id="kobo.35.1">n</span></em></span><span class="koboSpan" id="kobo.36.1"> binary variables, the number of possible combinations would be </span><span class="emphasis"><em><span class="koboSpan" id="kobo.37.1">O (2</span><sup><span class="koboSpan" id="kobo.38.1">n</span></sup><span class="koboSpan" id="kobo.39.1">)</span></em></span><span class="koboSpan" id="kobo.40.1">. </span><span class="koboSpan" id="kobo.40.2">So, in high-dimensional spaces, the total number of configurations is going to be almost uncountable, much larger than our number of examples available - most of the configurations will not have such training examples associated with them. </span><span class="emphasis"><em><span class="koboSpan" id="kobo.41.1">Figure 1.11</span></em></span><span class="koboSpan" id="kobo.42.1"> shows a pictorial representation of a similar phenomenon for better understanding.</span></p><p><span class="koboSpan" id="kobo.43.1">Therefore, this situation is cumbersome for any machine learning model, due to the difficulty in the training. </span><span class="strong"><strong><span class="koboSpan" id="kobo.44.1">Hughes effect</span></strong></span><span class="koboSpan" id="kobo.45.1"> [15] states the following:</span></p><div class="blockquote"><blockquote class="blockquote"><p>
<span class="emphasis"><em><span class="koboSpan" id="kobo.46.1">"With a fixed number of training samples, the predictive power reduces as the dimensionality increases."</span></em></span>
</p></blockquote></div><p><span class="koboSpan" id="kobo.47.1">Hence, the achievable precision of the model almost collapses as the number of explanatory variables increases.</span></p><p><span class="koboSpan" id="kobo.48.1">To cope with this scenario, we need to increase the size of the sample dataset fed to the system to such an extent that it can compete with the scenario. </span><span class="koboSpan" id="kobo.48.2">However, as the complexity of data also increases, the number of dimensions almost reaches one thousand. </span><span class="koboSpan" id="kobo.48.3">For such cases, even a dataset with hundreds of millions of images will not be sufficient.</span></p><p><span class="koboSpan" id="kobo.49.1">Deep learning, with its deeper network configuration, shows some success in partially solving this problem. </span><span class="koboSpan" id="kobo.49.2">This contribution is mostly attributed to the following reasons:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.50.1">Now, the researchers are able to manage the model complexity by redefining the network structure before feeding the sample for training</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.51.1">Deep convolutional networks focus on the higher level features of the data rather than the fundamental level information, which extensively further reduces the dimension of features</span></li></ul></div><p><span class="koboSpan" id="kobo.52.1">Although deep learning networks have given some insights to deal with the curse of dimensionality, they are not yet able to completely conquer the challenge. </span><span class="koboSpan" id="kobo.52.2">In Microsoft's recent research on super deep neural networks, they have come up with 150 layers; as a result, the parameter space has grown even bigger. </span><span class="koboSpan" id="kobo.52.3">The team has explored the research with even deep networks almost reaching to 1000 layers; however, the result was not up to the mark due to </span><span class="emphasis"><em><span class="koboSpan" id="kobo.53.1">overfitting</span></em></span><span class="koboSpan" id="kobo.54.1"> of the model!</span></p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note6"/><span class="koboSpan" id="kobo.55.1">Note</span></h3><p>
</p><p>
<span class="strong"><strong><span class="koboSpan" id="kobo.56.1">Over-fitting in machine learning</span></strong></span><span class="koboSpan" id="kobo.57.1">: The phenomenon when a model is over-trained to such an extent that it gives a negative impact to its performance is termed as over-fitting of the model. </span><span class="koboSpan" id="kobo.57.2">This situation occurs when the model learns the random fluctuations and unwanted noise of the training datasets. </span><span class="koboSpan" id="kobo.57.3">The consequences of these phenomena are unsatisfactory--the model is not able to behave well with the new dataset, which negatively impacts the model's ability to generalize.</span></p><p>
</p><p>
<span class="strong"><strong><span class="koboSpan" id="kobo.58.1">Under-fitting in machine learning</span></strong></span><span class="koboSpan" id="kobo.59.1">: This refers to a situation when the model is neither able to perform with the current dataset nor with the new dataset. </span><span class="koboSpan" id="kobo.59.2">This type of model is not suitable, and shows poor performance with the dataset.</span></p><p>
</p></div></div><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.60.1"><img src="graphics/B05883_01_11.jpg" alt="The curse of dimensionality"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.61.1">Figure 1.11: Figure shows that with the increase in the number of dimensions from one to three, from top to bottom, the number of random variables might increase exponentially. </span><span class="koboSpan" id="kobo.61.2">Image reproduced with permission from Nicolas Chapados from his article DataMining Algorithms for Actuarial Ratemaking.</span></p><p><span class="koboSpan" id="kobo.62.1">In the 1D example (top) of the preceding figure, as there are only 10 regions of interest, it should not be a tough task for the learning algorithm to generalize correctly. </span><span class="koboSpan" id="kobo.62.2">However, with the higher dimension 3D example (bottom), the model needs to keep track of all the </span><span class="emphasis"><em><span class="koboSpan" id="kobo.63.1">10*10*10=1000</span></em></span><span class="koboSpan" id="kobo.64.1"> regions of interest, which is much more cumbersome (or almost going to be an impossible task for the model). </span><span class="koboSpan" id="kobo.64.2">This can be used as the simplest example of the curse of dimensionality.</span></p></div><div class="section" title="The vanishing gradient problem"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec4"/><span class="koboSpan" id="kobo.65.1">The vanishing gradient problem</span></h3></div></div></div><p><span class="koboSpan" id="kobo.66.1">The vanishing gradient problem [16] is the obstacle found while training the Artificial neural networks, which is associated with some gradient-based method, such as Backpropagation. </span><span class="koboSpan" id="kobo.66.2">Ideally, this difficulty makes learning and training the previous layers really hard. </span><span class="koboSpan" id="kobo.66.3">The situation becomes worse when the number of layers of a deep neural network increases aggressively.</span></p><p><span class="koboSpan" id="kobo.67.1">The gradient descent algorithms particularly update the weights by the negative of the gradient multiplied by small scaler value (lies between </span><code class="literal"><span class="koboSpan" id="kobo.68.1">0</span></code><span class="koboSpan" id="kobo.69.1"> and </span><code class="literal"><span class="koboSpan" id="kobo.70.1">1</span></code><span class="koboSpan" id="kobo.71.1">).</span></p><p><span class="koboSpan" id="kobo.72.1">                </span></p><div class="mediaobject"><span class="koboSpan" id="kobo.73.1"><img src="graphics/Capture-6.jpg" alt="The vanishing gradient problem"/></span></div><p>
</p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.74.1"><img src="graphics/B05883_01_24.jpg" alt="The vanishing gradient problem"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.75.1">As shown in the preceding equations, we will repeat the gradient until it reaches zero. </span><span class="koboSpan" id="kobo.75.2">Ideally, though, we generally set some hyper-parameter for the maximum number of iterations. </span><span class="koboSpan" id="kobo.75.3">If the number of iterations is too high, the duration of the training will also be longer. </span><span class="koboSpan" id="kobo.75.4">On the other hand, if the number of iterations becomes imperceptible for some deep neural network, we will surely end up with inaccurate results.</span></p><p><span class="koboSpan" id="kobo.76.1">In the vanishing gradient problem, the gradients of the network's output, with respect to the parameters of the previous layers, become extremely small. </span><span class="koboSpan" id="kobo.76.2">As a result, the resultant weight will not show any significant change with each iteration. </span><span class="koboSpan" id="kobo.76.3">Therefore, even a large change in the value of parameters for the earlier layers does not have a significant effect on the overall output. </span><span class="koboSpan" id="kobo.76.4">As a result of this problem, the training of the deep neural networks becomes infeasible, and the prediction of the model becomes unsatisfactory. </span><span class="koboSpan" id="kobo.76.5">This phenomenon is known as the vanishing gradient problem. </span><span class="koboSpan" id="kobo.76.6">This will result in some elongated cost function, as shown in next </span><span class="emphasis"><em><span class="koboSpan" id="kobo.77.1">Figure 1.12</span></em></span><span class="koboSpan" id="kobo.78.1">:</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.79.1"><img src="graphics/image_01_020.jpg" alt="The vanishing gradient problem"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.80.1">Figure 1.12: Image of a flat gradient and an elongated cost function</span></p><p><span class="koboSpan" id="kobo.81.1">An example with large gradient is also shown in the following </span><span class="emphasis"><em><span class="koboSpan" id="kobo.82.1">Figure 1.13</span></em></span><span class="koboSpan" id="kobo.83.1">, where the gradient descent can converge quickly:</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.84.1"><img src="graphics/image_01_021.jpg" alt="The vanishing gradient problem"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.85.1">Figure 1.13: Image of a larger gradient cost function; hence the gradient descent can converge much more quickly</span></p><p><span class="koboSpan" id="kobo.86.1">This is a substantial challenge in the success of deep learning, but now, thanks to various different techniques, this problem has been overcome to some extent. </span><span class="strong"><strong><span class="koboSpan" id="kobo.87.1">Long short-term memory</span></strong></span><span class="koboSpan" id="kobo.88.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.89.1">LSTM</span></strong></span><span class="koboSpan" id="kobo.90.1">) network was one of the major breakthroughs which nullified this problem in 1997. </span><span class="koboSpan" id="kobo.90.2">A detailed description is given in </span><a class="link" href="ch04.html" title="Chapter 4. Recurrent Neural Network"><span class="koboSpan" id="kobo.91.1">Chapter 4</span></a><span class="koboSpan" id="kobo.92.1">, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.93.1">Recurrent Neural Network</span></em></span><span class="koboSpan" id="kobo.94.1">. </span><span class="koboSpan" id="kobo.94.2">Also, some researchers have tried to resolve the problem with different techniques, with feature preparation, activation functions, and so on.</span></p></div><div class="section" title="Distributed representation"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec5"/><span class="koboSpan" id="kobo.95.1">Distributed representation</span></h3></div></div></div><p><span class="koboSpan" id="kobo.96.1">All the deep networks are mostly based on the concept of distributed representations, which is the heart of theoretical advantage behind the success of deep learning algorithms. </span><span class="koboSpan" id="kobo.96.2">In the context of deep learning, distributed representations are multiscale representations, and are closely related to multiscale modelling of theoretical chemistry and physics. </span><span class="koboSpan" id="kobo.96.3">The basic idea behind a distributed representation is that the perceived feature is the result of multiple factors, which work as a combination to produce the desired results. </span><span class="koboSpan" id="kobo.96.4">A daily life example could be the human brain, which uses distributed representation for disguising the objects in the surroundings.</span></p><p><span class="koboSpan" id="kobo.97.1">An Artificial neural network, in this kind of representation, will be built in such a way that it will have numerous features and layers required to represent our necessary model. </span><span class="koboSpan" id="kobo.97.2">The model will describe the data, such as speech, video, or image, with multiple interdependent layers, where each of the layers will be responsible for describing the data at a different level of scale. </span><span class="koboSpan" id="kobo.97.3">In this way, the representation will be distributed across many layers, involving many scales. </span><span class="koboSpan" id="kobo.97.4">Hence, this kind of representation is termed as distributed representation.</span></p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note7"/><span class="koboSpan" id="kobo.98.1">Note</span></h3><p><span class="koboSpan" id="kobo.99.1">A distributed representation is dense in nature. </span><span class="koboSpan" id="kobo.99.2">It follows a many-to-many relationship between two types of representations. </span><span class="koboSpan" id="kobo.99.3">One concept can be represented using more than one neuron. </span><span class="koboSpan" id="kobo.99.4">On the other hand, one neuron depicts more than one concept.</span></p></div></div><p><span class="koboSpan" id="kobo.100.1">The traditional clustering algorithms that use non-distributed representation, such as nearest-neighbor algorithms, decision trees, or Gaussian mixtures, all require </span><span class="emphasis"><em><span class="koboSpan" id="kobo.101.1">O(N)</span></em></span><span class="koboSpan" id="kobo.102.1"> parameters to distinguish </span><span class="emphasis"><em><span class="koboSpan" id="kobo.103.1">O(N)</span></em></span><span class="koboSpan" id="kobo.104.1"> input regions. </span><span class="koboSpan" id="kobo.104.2">At one point of time, one could hardly have believed that any other algorithm could behave better than this! </span><span class="koboSpan" id="kobo.104.3">However, the deep networks, such as sparse coding, RBM, multi-layer neural networks, and so on, can all distinguish as many as </span><span class="emphasis"><em><span class="koboSpan" id="kobo.105.1">O(2</span><sup><span class="koboSpan" id="kobo.106.1">k</span></sup><span class="koboSpan" id="kobo.107.1">)</span></em></span><span class="koboSpan" id="kobo.108.1"> number of input regions with only </span><span class="emphasis"><em><span class="koboSpan" id="kobo.109.1">O(N)</span></em></span><span class="koboSpan" id="kobo.110.1"> parameters (where </span><span class="emphasis"><em><span class="koboSpan" id="kobo.111.1">k</span></em></span><span class="koboSpan" id="kobo.112.1"> represents the total number of non-zero elements in sparse representation, and </span><span class="emphasis"><em><span class="koboSpan" id="kobo.113.1">k=N</span></em></span><span class="koboSpan" id="kobo.114.1"> for other non-sparse RBMs and dense representations).</span></p><p><span class="koboSpan" id="kobo.115.1">In these kinds of operations, either same clustering is applied on different parts of the input, or several clustering takes place in parallel. </span><span class="koboSpan" id="kobo.115.2">The generalization of clustering to distributed representations is termed as multi-clustering.</span></p><p><span class="koboSpan" id="kobo.116.1">The exponential advantage of using distributed representation is due to the reuse of each parameter in multiple examples, which are not necessarily near to each other. </span><span class="koboSpan" id="kobo.116.2">For example, Restricted Boltzmann machine could be an appropriate example in this case. </span><span class="koboSpan" id="kobo.116.3">However, with local generalization, non-identical regions in the input space are only concerned with their own private set of parameters.</span></p><p><span class="koboSpan" id="kobo.117.1">The key advantages are as follows:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.118.1">The representation of the internal structure of data is robust in terms of damage resistance and graceful degradation</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.119.1">They help to generalize the concepts and relations among the data, hence enabling the reasoning abilities.</span></li></ul></div><p><span class="koboSpan" id="kobo.120.1">The following </span><span class="emphasis"><em><span class="koboSpan" id="kobo.121.1">Figure 1.14</span></em></span><span class="koboSpan" id="kobo.122.1"> represents a real-time example of distributed representations:</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.123.1"><img src="graphics/B05883_01_14-2.jpg" alt="Distributed representation"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.124.1">Figure 1.14: Figure shows how distributed representation helped the model to distinguish among various types of expressions in the images</span></p></div></div></div></div></div>
<div id="book-columns"><div id="book-inner"><div class="section" title="Classification of deep learning networks"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec10"/><span class="koboSpan" id="kobo.1.1">Classification of deep learning networks</span></h1></div></div></div><p>
<span class="strong"><strong><span class="koboSpan" id="kobo.2.1">Artificial neural networks</span></strong></span><span class="koboSpan" id="kobo.3.1"> in machine learning are often termed as new generation neural networks by many researchers. </span><span class="koboSpan" id="kobo.3.2">Most of the learning algorithms that we hear about were essentially built so as to make the system learn exactly the way the biological brain learns. </span><span class="koboSpan" id="kobo.3.3">This is how the name </span><span class="strong"><strong><span class="koboSpan" id="kobo.4.1">Artificial neural networks</span></strong></span><span class="koboSpan" id="kobo.5.1"> came about! </span><span class="koboSpan" id="kobo.5.2">Historically, the concept of deep learning emanated from </span><span class="strong"><strong><span class="koboSpan" id="kobo.6.1">Artificial neural networks</span></strong></span><span class="koboSpan" id="kobo.7.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.8.1">ANN</span></strong></span><span class="koboSpan" id="kobo.9.1">). </span><span class="koboSpan" id="kobo.9.2">The practice of deep learning started back in the 1960s, or possibly even earlier. </span><span class="koboSpan" id="kobo.9.3">With the rise of deep learning, ANN, has gained more popularity in the research field.</span></p><p>
<span class="strong"><strong><span class="koboSpan" id="kobo.10.1">Multi-Layer Perceptron</span></strong></span><span class="koboSpan" id="kobo.11.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.12.1">MLP</span></strong></span><span class="koboSpan" id="kobo.13.1">) or feed-forward neural networks with many hidden intermediate layers which are referred to as </span><span class="strong"><strong><span class="koboSpan" id="kobo.14.1">deep neural networks</span></strong></span><span class="koboSpan" id="kobo.15.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.16.1">DNN</span></strong></span><span class="koboSpan" id="kobo.17.1">), are some good examples of the deep architecture model. </span><span class="koboSpan" id="kobo.17.2">The first popular deep architecture model was published by Ivakhnenko and Lapa in 1965 using supervised deep feed-forward multilayer perceptron [17].</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.18.1"><img src="graphics/B05883_01_15-1.jpg" alt="Classification of deep learning networks"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.19.1">Figure 1.15: The GMDH network has four inputs (the component of the input vector x), and one output y ,which is an estimate of the true function y= f(x) = y</span></p><p><span class="koboSpan" id="kobo.20.1">Another paper from Alexey Ivakhnenko, who was working at that time on a better prediction of fish population in rivers, used the </span><span class="strong"><strong><span class="koboSpan" id="kobo.21.1">group method of data handling algorithm</span></strong></span><span class="koboSpan" id="kobo.22.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.23.1">GMDH</span></strong></span><span class="koboSpan" id="kobo.24.1">), which tried to explain a type of deep network with eight trained layers, in 1971. </span><span class="koboSpan" id="kobo.24.2">It is still considered as one of most popular papers of the current millennium[18]. </span><span class="koboSpan" id="kobo.24.3">The preceding </span><span class="emphasis"><em><span class="koboSpan" id="kobo.25.1">Figure 1.15</span></em></span><span class="koboSpan" id="kobo.26.1"> shows the GMDH network of four inputs.</span></p><p><span class="koboSpan" id="kobo.27.1">Going forward, </span><span class="strong"><strong><span class="koboSpan" id="kobo.28.1">Backpropagation</span></strong></span><span class="koboSpan" id="kobo.29.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.30.1">BP</span></strong></span><span class="koboSpan" id="kobo.31.1">), which was a well-known algorithm for learning the parameters of similar type of networks, found its popularity during the 1980s. </span><span class="koboSpan" id="kobo.31.2">However, networks having a number of hidden layers are difficult to handle due to many reasons, hence, BP failed to reach the level of expectation [8] [19]. </span><span class="koboSpan" id="kobo.31.3">Moreover, backpropagation learning uses the gradient descent algorithm, which is based on local gradient information, and these operations start from some random initial data points. </span><span class="koboSpan" id="kobo.31.4">While propagating through the increasing depth of networks, these often get collected in some undesired local optima; hence, the results generally get stuck in poor solutions.</span></p><p><span class="koboSpan" id="kobo.32.1">The </span><span class="emphasis"><em><span class="koboSpan" id="kobo.33.1">optimization constraints</span></em></span><span class="koboSpan" id="kobo.34.1"> related to the deep architecture model were pragmatically reduced when an efficient, unsupervised learning algorithm was established in two papers [8] [20]. </span><span class="koboSpan" id="kobo.34.2">The two papers introduced a class of deep generative models known as a </span><span class="strong"><strong><span class="koboSpan" id="kobo.35.1">Deep belief network</span></strong></span><span class="koboSpan" id="kobo.36.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.37.1">DBN</span></strong></span><span class="koboSpan" id="kobo.38.1">).</span></p><p><span class="koboSpan" id="kobo.39.1">In 2006, two more unsupervised deep models with non-generative, non-probabilistic features were published, which became immensely popular with the researcher community. </span><span class="koboSpan" id="kobo.39.2">One is an energy-based unsupervised model [21], and the other is a variant of auto-encoder with subsequent layer training, much like the previous DBN training [3]. </span><span class="koboSpan" id="kobo.39.3">Both of these algorithms can be efficiently used to train a deep neural network, almost exactly like the DBN.</span></p><p><span class="koboSpan" id="kobo.40.1">Since 2006, the world has seen a tremendous explosion in the research of deep learning. </span><span class="koboSpan" id="kobo.40.2">The subject has seen continuous exponential growth, apart from the traditional shallow machine learning techniques.</span></p><p><span class="koboSpan" id="kobo.41.1">Based on the learning techniques mentioned in the previous topics of this chapter, and depending on the use case of the techniques and architectures used, deep learning networks can be broadly classified into two distinct groups.</span></p><div class="section" title="Deep generative or unsupervised models"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec9"/><span class="koboSpan" id="kobo.42.1">Deep generative or unsupervised models</span></h2></div></div></div><p><span class="koboSpan" id="kobo.43.1">Many deep learning networks fall under this category, such as Restricted Boltzmann machine, Deep Belief Networks, Deep Boltzmann machine, De-noising Autoencoders, and so on. </span><span class="koboSpan" id="kobo.43.2">Most of these networks can be used to engender samples by sampling within the networks. </span><span class="koboSpan" id="kobo.43.3">However, a few other networks, for example sparse coding networks and the like, are difficult to sample, and hence, are, not generative in nature.</span></p><p><span class="koboSpan" id="kobo.44.1">A popular deep unsupervised model is the </span><span class="strong"><strong><span class="koboSpan" id="kobo.45.1">Deep Boltzmann machine</span></strong></span><span class="koboSpan" id="kobo.46.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.47.1">DBM</span></strong></span><span class="koboSpan" id="kobo.48.1">) [22] [23] [24] [25]. </span><span class="koboSpan" id="kobo.48.2">A traditional DBM contains many layers of hidden variables; however, the variables within the same layer have no connections between them. </span><span class="koboSpan" id="kobo.48.3">The traditional </span><span class="strong"><strong><span class="koboSpan" id="kobo.49.1">Boltzmann machine</span></strong></span><span class="koboSpan" id="kobo.50.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.51.1">BM</span></strong></span><span class="koboSpan" id="kobo.52.1">), despite having a simpler algorithm, is too much complex to study and very slow to train. </span><span class="koboSpan" id="kobo.52.2">In a DBM, each layer acquires higher-order complicated correlations between the responses of the latent features of the previous layers. </span><span class="koboSpan" id="kobo.52.3">Many real-life problems, such as object and speech recognition, which require learning complex internal representations, are much easier to solve with DBMs.</span></p><p><span class="koboSpan" id="kobo.53.1">A DBM with one hidden layer is termed as a </span><span class="strong"><strong><span class="koboSpan" id="kobo.54.1">Restricted Boltzmann machine</span></strong></span><span class="koboSpan" id="kobo.55.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.56.1">RBM</span></strong></span><span class="koboSpan" id="kobo.57.1">). </span><span class="koboSpan" id="kobo.57.2">Similar to a DBM, an RBM does not have any hidden-to-hidden and visible-to-visible connections. </span><span class="koboSpan" id="kobo.57.3">The crucial property of an RBM is reflected in constituting many RBMs. </span><span class="koboSpan" id="kobo.57.4">With numerous latent layers formed, the feature activation of a previous RBM acts as the input training data for the next. </span><span class="koboSpan" id="kobo.57.5">This kind of architecture generates a different kind of network named </span><span class="strong"><strong><span class="koboSpan" id="kobo.58.1">Deep belief network</span></strong></span><span class="koboSpan" id="kobo.59.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.60.1">DBN</span></strong></span><span class="koboSpan" id="kobo.61.1">). </span><span class="koboSpan" id="kobo.61.2">Various applications of the Restricted Boltzmann machine and Deep belief network are discussed in detail in </span><a class="link" href="ch05.html" title="Chapter 5.  Restricted Boltzmann Machines"><span class="koboSpan" id="kobo.62.1">
Chapter 5
</span></a><span class="koboSpan" id="kobo.63.1">, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.64.1">Restricted Boltzmann Machines</span></em></span><span class="koboSpan" id="kobo.65.1">.</span></p><p><span class="koboSpan" id="kobo.66.1">A primary component of DBN is a set of layers, which reduces its time complexity linear of size and depth of the networks. </span><span class="koboSpan" id="kobo.66.2">Along with DBN property, which could overcome the major drawback of BP by starting the training from some desired initialization data points, it has other attractive catching characteristics too. </span><span class="koboSpan" id="kobo.66.3">Some of them are listed as follows:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.67.1">DBN can be considered as a probabilistic generative model.</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.68.1">With hundreds of millions of parameters, DBNs generally undergo the over-fitting problem. </span><span class="koboSpan" id="kobo.68.2">Also, the deep architecture, due to its voluminous dataset, often experiences the under-fitting problem. </span><span class="koboSpan" id="kobo.68.3">Both of these problems can be effectively diminished in the pre-training step.</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.69.1">Effective uses of unlabeled data are practiced by DBN.</span></li></ul></div><p><span class="koboSpan" id="kobo.70.1">One more deep generative network, which can be used for unsupervised (as well as supervised) learning is the </span><span class="strong"><strong><span class="koboSpan" id="kobo.71.1">sum-product network</span></strong></span><span class="koboSpan" id="kobo.72.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.73.1">SPN</span></strong></span><span class="koboSpan" id="kobo.74.1">) [26], [27]. </span><span class="koboSpan" id="kobo.74.2">SPNs are deep networks, which can be viewed as directed acyclic graphs, where the leaves of the graph are the observed variables, and the internal nodes are the sum and product operations. </span><span class="koboSpan" id="kobo.74.3">The 'sum' nodes represent the mixture models, and the 'product' nodes frame the feature hierarchy. </span><span class="koboSpan" id="kobo.74.4">SPNs are trained using the expectation-maximization algorithm together with Back propagation. </span><span class="koboSpan" id="kobo.74.5">The major hindrance in learning SPNs is that the gradient rapidly diminishes when moving towards the deep layers. </span><span class="koboSpan" id="kobo.74.6">Specifically, the standard gradient descent of the regular deep neural networks generated from the derivative of the conditional likelihood, goes through the tribulation. </span><span class="koboSpan" id="kobo.74.7">A solution to reduce this problem is to substitute the marginal inference with the most probable state of the latent variables, and then disseminate the gradient through this. </span><span class="koboSpan" id="kobo.74.8">An exceptional outcome on small-scale image recognition was presented by Domingo and Gens in [28]. </span><span class="koboSpan" id="kobo.74.9">The following </span><span class="emphasis"><em><span class="koboSpan" id="kobo.75.1">Figure 1.16</span></em></span><span class="koboSpan" id="kobo.76.1"> shows a sample SPN network for better understanding. </span><span class="koboSpan" id="kobo.76.2">It shows a block diagram of the sum-product network:</span></p><p>
</p><div class="mediaobject"><span class="koboSpan" id="kobo.77.1"><img src="graphics/image_01_024.jpg" alt="Deep generative or unsupervised models"/></span></div><p>
</p><p><span class="koboSpan" id="kobo.78.1">Figure 1.16: Block diagram of sum-product network</span></p><p><span class="koboSpan" id="kobo.79.1">Another type of popular deep generative network, which can be used as unsupervised (as well as supervised) learning, is the </span><span class="strong"><strong><span class="koboSpan" id="kobo.80.1">Recurrent neural network</span></strong></span><span class="koboSpan" id="kobo.81.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.82.1">RNN</span></strong></span><span class="koboSpan" id="kobo.83.1">). </span><span class="koboSpan" id="kobo.83.2">The depth of this type of network directly depends on the length of the input data sequence. </span><span class="koboSpan" id="kobo.83.3">In the unsupervised RNN model, experiences from previous data samples are used to predict the future data sequence. </span><span class="koboSpan" id="kobo.83.4">RNNs have been used as an excellent powerful model for data sequencing text or speech, however, their popularity has recently decreased due to the rise of vanishing gradient problems [29] [16]. </span><span class="koboSpan" id="kobo.83.5">Using stochastic curvature estimates, Hessian-free optimization [30] has somewhat overcome the limitations. </span><span class="koboSpan" id="kobo.83.6">Recently, Bengio et al. </span><span class="koboSpan" id="kobo.83.7">[31] and Sutskever [32] have come out with different variations to train the generating RNNs, which outperform the Hessian-free optimization models. </span><span class="koboSpan" id="kobo.83.8">RNN is further elucidated in this book in </span><a class="link" href="ch04.html" title="Chapter 4. Recurrent Neural Network"><span class="koboSpan" id="kobo.84.1">
Chapter 4
</span></a><span class="koboSpan" id="kobo.85.1">, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.86.1">Recurrent Neural Network</span></em></span><span class="koboSpan" id="kobo.87.1">.</span></p><p><span class="koboSpan" id="kobo.88.1">Among the other subclasses of unsupervised deep networks, the energy-based deep models are mostly known architecture [33] [34]. </span><span class="koboSpan" id="kobo.88.2">A typical example of the unsupervised model category of deep networks is deep autoencoder. </span><span class="koboSpan" id="kobo.88.3">Most of the variants of deep autoencoder are generative in nature; however, the properties and implementations generally vary from each other. </span><span class="koboSpan" id="kobo.88.4">Popular examples are predictive sparse coders, Transforming Autoencoder, De-noising Autoencoder and their stacked versions, and so on. </span><span class="koboSpan" id="kobo.88.5">Auto-encoders are explained in detail in </span><a class="link" href="ch06.html" title="Chapter 6.  Autoencoders"><span class="koboSpan" id="kobo.89.1">
Chapter 6
</span></a><span class="koboSpan" id="kobo.90.1">, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.91.1">Autoencoders</span></em></span><span class="koboSpan" id="kobo.92.1">.</span></p></div><div class="section" title="Deep discriminate models"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec10"/><span class="koboSpan" id="kobo.93.1">Deep discriminate models</span></h2></div></div></div><p><span class="koboSpan" id="kobo.94.1">Most of the discriminative techniques used in supervised learning are shallow architectures such as Hidden Marcov models [35], [36], [37], [38], [39], [40], [41] or conditional random fields. </span><span class="koboSpan" id="kobo.94.2">However, recently, a deep-structured conditional random field model has evolved, by passing the output of every lower layer as the input of the higher layers. </span><span class="koboSpan" id="kobo.94.3">There are multiple versions of deep-structured conditional random fields which have been successfully accomplished to for natural language processing, phone recognition, language recognition, and so on. </span><span class="koboSpan" id="kobo.94.4">Although discriminative approaches are successful for deep-architectures, they have not been able to reach the expected outcome yet.</span></p><p><span class="koboSpan" id="kobo.95.1">As mentioned in the previous section, RNNs have been used for unsupervised learning. </span><span class="koboSpan" id="kobo.95.2">However, RNNs can also be used as a discriminative model and trained with supervised learning. </span><span class="koboSpan" id="kobo.95.3">In this case, the output becomes a label sequence related to the input data sequence. </span><span class="koboSpan" id="kobo.95.4">Speech recognition techniques have already seen such discriminative RNNs a long time ago, but with very little success. </span><span class="koboSpan" id="kobo.95.5">Paper [42] shows that a Hidden Marcov Model was used to mutate the RNN classification outcome into a labelled sequence. </span><span class="koboSpan" id="kobo.95.6">But unfortunately, the use of Hidden Marcov model for all these reasons did not take enough advantage of the full capability of RNNs.</span></p><p><span class="koboSpan" id="kobo.96.1">A few other methods and models have recently been developed for RNNs, where the fundamental idea was to consider the RNN output as some conditional distributions, and distribute all over the possible input sequences [43], [44],[45],[46]. </span><span class="koboSpan" id="kobo.96.2">This helped RNNs to undergo sequence classification while embedding the long-short-term-memory to its model. </span><span class="koboSpan" id="kobo.96.3">The major benefit was that it neither required the pre-segmentation of the training dataset, nor the post-processing of the outputs. </span><span class="koboSpan" id="kobo.96.4">Basically, the segmentation of the dataset is automatically performed by the algorithm, and one differentiable objective function could be derived for optimization of the conditional distributions across the label sequence. </span><span class="koboSpan" id="kobo.96.5">The effectiveness of this type of algorithm is extensively applicable for handwriting recognition operations.</span></p><p><span class="koboSpan" id="kobo.97.1">One more popular type of discriminative deep architecture is the </span><span class="strong"><strong><span class="koboSpan" id="kobo.98.1">convolutional neural network</span></strong></span><span class="koboSpan" id="kobo.99.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.100.1">CNN</span></strong></span><span class="koboSpan" id="kobo.101.1">). </span><span class="koboSpan" id="kobo.101.2">In CNN, each module comprises of a convolutional layer and one pooling layer. </span><span class="koboSpan" id="kobo.101.3">To form a deep model, the modules are generally stacked one on top of the other, or with a deep neural network on the top of it. </span><span class="koboSpan" id="kobo.101.4">The convolutional layer helps to share many weights, and the pooling layer segregates the output of the convolutional later, minimizing the rate of data from the previous layer. </span><span class="koboSpan" id="kobo.101.5">CNN has been recognized as a highly efficient model, especially for tasks like image recognition, computer vision, and so on. </span><span class="koboSpan" id="kobo.101.6">Recently, with specific modifications in CNN design, it has also been found equally effective in speech recognition too. </span><span class="strong"><strong><span class="koboSpan" id="kobo.102.1">Time-delay neural network</span></strong></span><span class="koboSpan" id="kobo.103.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.104.1">TDNN</span></strong></span><span class="koboSpan" id="kobo.105.1">) [47] [48], originated for early speech recognition, is a special case for convolutional neural network, and can also be considered its predecessor.</span></p><p><span class="koboSpan" id="kobo.106.1">In this type of model, the weight sharing is limited to only time dimension, and no pooling layer is present. </span><a class="link" href="ch03.html" title="Chapter 3.  Convolutional Neural Network"><span class="koboSpan" id="kobo.107.1">
Chapter 3
</span></a><span class="koboSpan" id="kobo.108.1">, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.109.1">Convolutional Neural Networks</span></em></span><span class="koboSpan" id="kobo.110.1"> discusses the concept and applications of CNNs in depth.</span></p><p><span class="koboSpan" id="kobo.111.1">Deep learning, with its many models, has a wide range of applications too. </span><span class="koboSpan" id="kobo.111.2">Many of the top technology companies, such as Facebook, Microsoft, Google, Adobe, IBM, and so on are extensively using deep learning. </span><span class="koboSpan" id="kobo.111.3">Apart from computer science, deep learning has also provided valuable contributions to other scientific fields as well.</span></p><p><span class="koboSpan" id="kobo.112.1">Modern CNNs used for object recognition have given a major insight into visual processing, which even neuroscientists can explore further. </span><span class="koboSpan" id="kobo.112.2">Deep learning also provides the necessary functional tools for processing large-scale data, and to make predictions in scientific fields. </span><span class="koboSpan" id="kobo.112.3">This field is also very successful in predicting the behaviors of molecules in order to enhance the pharmaceutical researches.</span></p><p><span class="koboSpan" id="kobo.113.1">To summarize, deep learning is a sub-field of machine learning, which has seen exceptional growth in usefulness and popularity due to its much wider applicability. </span><span class="koboSpan" id="kobo.113.2">However, the coming years should be full of challenges and opportunities to ameliorate deep learning even further, and explore the subject for new data enthusiasts.</span></p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note8"/><span class="koboSpan" id="kobo.114.1">Note</span></h3><p><span class="koboSpan" id="kobo.115.1">To help the readers to get more insights into deep learning, here are a few other excellent and frequently updated reading lists available online:
</span><a class="ulink" href="http://deeplearning.net/tutorial/"><span class="koboSpan" id="kobo.116.1">http://deeplearning.net/tutorial/
</span></a>
<a class="ulink" href="http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial"><span class="koboSpan" id="kobo.117.1">http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial
</span></a>
<a class="ulink" href="http://deeplearning.net/reading-list/"><span class="koboSpan" id="kobo.118.1">
http://deeplearning.net/reading-list/
</span></a>
</p></div></div></div></div></div></div>
<div id="book-columns"><div id="book-inner"><div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec11"/><span class="koboSpan" id="kobo.1.1">Summary</span></h1></div></div></div><p><span class="koboSpan" id="kobo.2.1">Over the past decade, we have had the privilege of hearing about the greatest inventions of deep learning from many of the great scientists and companies working in Artificial Intelligence. </span><span class="koboSpan" id="kobo.2.2">Deep learning is an approach to machine learning which has shown tremendous growth in its usefulness and popularity in the last few years. </span><span class="koboSpan" id="kobo.2.3">The reason is mostly due to its capability to work with large datasets involving high dimensional data, resolving major issues such as vanishing gradient problems, and so on, and techniques to train deeper networks. </span><span class="koboSpan" id="kobo.2.4">In this chapter, we have explained most of these concepts in detail, and have also classified the various algorithms of deep learning, which will be elucidated in detail in subsequent chapters.</span></p><p><span class="koboSpan" id="kobo.3.1">The next chapter of this book will introduce the association of big data with deep learning. </span><span class="koboSpan" id="kobo.3.2">The chapter will mainly focus on how deep learning plays a major role in extracting valuable information from large-scale data.</span></p></div></div></div></body></html>