- en: Image Classification and Recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we looked at the process of developing deep neural
    network models for classification and regression problems. In both cases, we were
    dealing with structured data and the models were of the supervised learning type,
    where target variables were available. Images or pictures belong to the unstructured
    category of data. In this chapter, we will illustrate the use of deep learning
    neural networks for image classification and recognition using the Keras package
    with the help of an easy-to-follow example. We will get started with a small sample
    size to illustrate the steps involved in developing an image-classification model.
    We will apply this model to a supervised learning situation involving the labeling
    of images or pictures.
  prefs: []
  type: TYPE_NORMAL
- en: Keras contains several built-in datasets for image classification, such as CIFAR10,
    CIFAR100, MNIST, and fashion-MNIST. CIFAR10 contains 50,000 32 x 32 color training
    images and 10,000 testing images with 10 label categories. CIFAR100, on the other
    hand, contains 50,000 32 x 32 color training images and 10,000 testing images
    with as many as 100 label categories. The MNIST dataset has 60,000 28 x 28 grayscale
    images for training and 10,000 images for testing with 10 different digits. The
    fashion-MNIST dataset has 60,000 28 x 28 grayscale images for training and 10,000
    images for testing with 10 fashion categories. These datasets are already in a
    format that can be used straightaway to develop deep neural network models with
    a minimal need for data-preparation-related steps. However, to get a better handle
    on dealing with image data, we will start by reading raw images from our computer
    into RStudio and go over all the steps needed to make image data ready for building
    a classification model.
  prefs: []
  type: TYPE_NORMAL
- en: The steps involved include exploring image data, resizing and reshaping images,
    one-hot encoding, developing a sequential model, compiling the model, fitting
    the model, evaluating the model, making predictions, and model-performance assessment
    using a confusion matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, in this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Handling image data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating and fitting the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model evaluation and prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance optimization tips and best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling image data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will read image data into R and explore it further to understand
    the various characteristics of image data. The code for reading and displaying
    images is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the preceding code, we will make use of the `keras` and
    `EBImage` libraries. The `EBImage` library is useful for handling and exploring
    image data. We will start by reading 18 JPEG image files that are stored in the `image18`
    folder of my computer. These images each contain 6 pictures of bicycles, cars,
    and airplanes that were downloaded from the internet. These image files are read
    using the `readImage` function and are stored in `mypic`.
  prefs: []
  type: TYPE_NORMAL
- en: 'All 18 images are shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/44e3c243-de5b-4199-b4ae-dd2183181391.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From the preceding screenshot, we can see the six images of bicycles, cars,
    and airplanes. You might have noticed that not all of the pictures are of the
    same size. For example, the fifth and sixth bicycles noticeably vary in size.
    Similarly, the fourth and fifth airplanes are clearly of different sizes, too.
    Let''s take a closer look at the data for the fifth bicycle using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Using the `print` function, we can look at how the image of a bicycle (unstructured
    data) has been converted into numbers (structured data). The dimensions for the
    fifth bicycle are 299 x 169 x 3, which leads to a total of 151,593 data points,
    or pixels, obtained by multiplying the three numbers. The first number, 299, represents
    the image width in terms of pixels and the second number, 169, represents the
    image height in terms of pixels. Note that a colored image consists of three channels
    representing the colors red, blue, and green. The small table extracted from the
    data shows the first five rows of data in the *x*-dimension, and the first six
    rows of data in the *y*-dimension, and the value for the *z*-dimension is one.
    Although all values in the body of the table are `1`, they are expected to vary
    between `0` and `1`.
  prefs: []
  type: TYPE_NORMAL
- en: A color image has red, green, and blue channels. A grayscale image has only
    one channel.
  prefs: []
  type: TYPE_NORMAL
- en: 'These data points for the fifth bicycle are used for creating a histogram,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e4f078ef-6f58-4453-80e3-65b411e56765.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding histogram shows the distribution of intensity values for the fifth
    image's data. It can be seen that most of the data points have high-intensity
    values for this image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now look at the following histogram of data based on the 16th image
    (that of an airplane) for comparison:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00dbaf85-4c53-4c46-a5d5-fcfb93c55782.png)'
  prefs: []
  type: TYPE_IMG
- en: From the preceding histogram, we can see that this image has different intensity
    values for the red, green, and blue colors. In general, intensity values lie between
    zero and one. Data points that are closer to zero represent a darker color in
    the image and those closer to one indicate a brighter color in the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at data related to the 16th image, of an airplane, using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: From the output provided in the preceding code, we can see that the two images
    have different dimensions. The dimensions for the 16th image are 318 x 159 x 3,
    which results in a total of 151,686 data points or pixels.
  prefs: []
  type: TYPE_NORMAL
- en: In order to prepare this data for developing an image classification model,
    we will start by resizing all images to the same dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will go over the steps for making our image data ready for
    developing an image classification model. These steps will involve resizing images
    to obtain the same size for all images, followed by reshaping, data partitioning,
    and the one-hot encoding of the response variables.
  prefs: []
  type: TYPE_NORMAL
- en: Resizing and reshaping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To prepare the data for developing a classification model, we start by resizing
    the dimensions of all 18 images to the same size using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As can be seen from the preceding code, all images are now resized to 28 x
    28 x 3\. Let''s plot all the images again to see the impact of resizing using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'When we reduce the dimensions of a picture, it will lead to a lower number
    of pixels, which in turn will cause pictures to have lower quality, as can be
    seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0e274d67-8078-4686-97f5-f43f485b07b4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we will reshape the dimensions of 28 x 28 x 3 into a single dimension
    of 28 x 28 x 3 (or 2,352 vectors) using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: By observing the structure of the preceding data using `str(mypic)`, we can
    see that there are 18 different items in the list that correspond to the 18 images
    that we started with.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will create training, validation, and test data.
  prefs: []
  type: TYPE_NORMAL
- en: Training, validation, and test data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will use the first three images of the bicycles, cars, and airplanes respectively
    for training, the fourth image of each type for validation, and the remaining
    two images of each type for testing. Thus, the training data will have nine images,
    the validation data will have three images, and the test data will have six images.
    The following is the code to achieve this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the preceding code, we will use the `rbind` function to
    combine the rows of data that we have for each image when creating training, validation,
    and `test` data. After combining the rows of data from the nine images, the structure
    of `trainx` indicates that there are 9 rows and 2,352 columns. Similarly, for
    the validation data, we have 3 rows and 2,352 columns, and for the test data,
    we have 6 rows and 2,352 columns.
  prefs: []
  type: TYPE_NORMAL
- en: One-hot encoding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the one-hot encoding of the response variables, we use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding code, we can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We have stored target values for each image in `trainy` , `validy`, and `testy`,
    where `0`, `1`, and `2` indicate bicycle, car, and airplane images respectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We carry out one-hot encoding of `trainy` , `validy`, and `testy` by using the `to_categorical`
    function. One-hot encoding here helps to convert a factor variable into a combination
    of zeros and ones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we have the data in a format that can be used for developing a deep neural
    network classification model, and that is what we will do in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and fitting the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will develop an image classification model to classify the
    images of the bicycles, cars, and airplanes. We will first specify a model architecture,
    then we will compile the model, and then fit the model using training and validation
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Developing the model architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When developing the model architecture, we start by creating a sequential model
    and then add various layers. The following is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: As can be seen from the preceding code, the input layer has  `2352` units (28
    x 28 x 3). For the initial model, we use two hidden layers with 256 and 128 units
    respectively. For both hidden layers, we will use the `relu` activation function.
    For the output layer, we will use 3 units since the target variable has 3 classes,
    representing a bicycle, car, and airplane. The total number of parameters for
    this model is 635,651.
  prefs: []
  type: TYPE_NORMAL
- en: Compiling the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After developing the model architecture, we can compile the model using the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We compile the model by using `categorical_crossentropy` for loss, since we
    are doing multiclass classification. We have specified `adam` and `accuracy` for
    the optimizer and metrics, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Fitting the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we are ready to train the model. The following is the code for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding code, we can see the following facts:'
  prefs: []
  type: TYPE_NORMAL
- en: We can fit the model using `independent` variables stored in `trainx` and `target`
    variables stored in `trainLabels`. To safeguard against overfitting, we will use
    `validation_data`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that, in the previous chapters, we made use of `validation_split` by specifying
    a certain percentage, such as 20%; however, if we used `validation_split` with
    a 20% rate, it would have used the last 20% of the training data (all airplane
    images) for validation.
  prefs: []
  type: TYPE_NORMAL
- en: This would have created a situation where the training data had no sample from
    the airplane images and the classification model would have been based on bicycle
    and car images only.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, the resulting image classification model would be biased and would
    have performed well only with bicycle and car images. Therefore, instead of using
    the `validation_split `function, in this situation, we make use of `validation_data`, where
    we have made sure that we have a sample of each type represented in both the training
    and validation data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following graphs show the loss and accuracy for 30 epochs separately for
    training and validation data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/90692e5d-7fe2-4fd2-b639-2de1f207dc26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can make the following observations from the preceding plots:'
  prefs: []
  type: TYPE_NORMAL
- en: From the parts of the graphs dealing with accuracy, we can see that from the
    eighteenth epoch onward, the accuracy values for the training data attain the
    highest value of 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the other hand, the accuracy based on the validation data is mainly around
    two thirds, or 66.7%. Since we have data from three images that is used for validation,
    if all three images' from validation data is correctly classified, the reported
    accuracy will be 1\. In this case, two out of three images are correctly classified,
    and that leads to accuracy of 66.7%.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From the parts of the graphs dealing with loss, we can see that for the training
    data, the loss values drop significantly from about 3 to less than 1 after 8 epochs.
    They continue to reduce from then on; however, the rate of decrease in the loss
    values slows down.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An approximately similar pattern can be seen based on the validation data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, since the loss uses probability values in its calculation, we observe
    a clearer trend for the loss-related plot compared to the accuracy-related plot.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, let's evaluate the model's image classification performance in greater
    detail to understand its behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Model evaluation and prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will carry out model evaluation and create a confusion matrix
    with the help of predictions, both for training and test data. Let's start by
    evaluating the image classification performance of the model using training data.
  prefs: []
  type: TYPE_NORMAL
- en: Loss, accuracy, and confusion matrices for training data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will now obtain loss and accuracy values for the training data and then
    create a confusion matrix using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the preceding output, the loss and accuracy values are `0.056`
    and `1` respectively. The confusion matrix based on the training data indicates
    that all nine images are correctly classified into three categories, and therefore
    the resulting accuracy is 1.
  prefs: []
  type: TYPE_NORMAL
- en: Prediction probabilities for training data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can now look at the probabilities of the three classes for all nine images
    in the training data that this model provides. The following is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding output, the first three columns show the probability of an
    image being a bicycle, car, or airplane, and the total of these three probabilities
    is 1\. We can make the following observations from the output:'
  prefs: []
  type: TYPE_NORMAL
- en: The probabilities for the first image in the training data are `0.943`, `0.007`,
    and `0.049` for bicycle, car, and airplane respectively. Since the highest probability
    is for the first class, the predicted class based on the model is `0` (for bicycle),
    and this is also the actual class of the image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although all 9 images are correctly classified, the probability of correct classification
    varies from `0.806` (image 2) to `0.998` (image 5).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the car images (rows 4 to 6), the probability of correct classification
    ranges from `0.989` to `0.998` and is consistently high for all three images.
    Therefore, this classification model gives its best performance when classifying
    car images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For bicycle images (rows 1 to 3), the probability of correct classification
    ranges from `0.806` to `0.956`, which indicates some difficulty in correctly classifying
    bicycle images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the second sample, which represents a bicycle image, the second-highest
    probability is `0.189` of being an airplane image. Clearly, this model is little
    bit confused when it comes to deciding whether this image is a bicycle or an airplane.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the airplane images (rows 7 to 9), the probability of correct classification
    ranges from `0.931` to `0.959`, which is  also consistently high for all three
    images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking at prediction probabilities allows us to dig deeper into the classification
    performance of the model, which cannot be obtained only by looking at the accuracy
    value. However, while good performance with training data is necessary, it is
    not sufficient to arrive at a reliable image-classification model. When a classification
    model suffers from an overfitting problem, we have difficulty replicating good
    results based on training data on test data that the model has not seen. Therefore,
    a real test of a good classification model is when it performs well with the test
    data. Let's now review the image-classification performance of the model for test
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Loss, accuracy, and confusion matrices for test data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can now obtain loss and accuracy values for the test data and then create
    a confusion matrix using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the preceding output, the loss and accuracy values for the
    images in the test data are `0.552` and `0.833` respectively. These results are
    slightly inferior to the numbers that we saw for the training data; however, some
    amount of performance deterioration is expected when a model is assessed based
    on unseen data. The confusion matrix indicates one incorrectly classified image,
    where an image of a car is mistaken for an image of an airplane. Therefore, with
    five out of six correct classifications, the model accuracy based on the test
    data is 83.3%. Let's now look more deeply into the model's prediction performance
    by investigating the probability values based on images in the test data.
  prefs: []
  type: TYPE_NORMAL
- en: Prediction probabilities for test data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can now review the probabilities for the three classes for all six images
    in the test data. The following is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Looking at these predicted probabilities, we can make the following observations:'
  prefs: []
  type: TYPE_NORMAL
- en: Bicycle images are predicted correctly, as shown by the first two samples. However,
    prediction probabilities are relatively lower at `0.587` and `0.533`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The results for car images (rows 3 and 4) are mixed, with the fourth sample,
    correctly predicted with a high probability of `0.985`, but the third car image
    is misclassified as an airplane with about `0.7` probability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Airplane images are represented by the fifth and sixth samples. The prediction
    probabilities for these two images are `0.739` and `0.867` respectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although five out of six images are correctly classified, many prediction probabilities
    are relatively low when compared to the model's performance on training data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, overall, we can say that there is definitely some scope to improve
    the model's performance further. In the next section, we will explore improving
    the model's performance.
  prefs: []
  type: TYPE_NORMAL
- en: Performance optimization tips and best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explore a deeper network for improving the performance
    of the image-classification model. We will look at the results for comparison.
  prefs: []
  type: TYPE_NORMAL
- en: Deeper networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code used for experimenting with a deeper network in this section are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding code, we can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We are increasing the number of units in the first and second hidden layers
    to `512` and `256` respectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are also adding dropout layers after each hidden layer with a 10% dropout
    rate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The total number of parameters with this change has now gone up to `1336835`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This time, we will also run the model for 50 epochs. We do not make any other
    changes to the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following graphs provide accuracy and loss values for the training and
    validation data for 50 epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b84682d8-3b5d-46f7-9e11-b4a021d69b5c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From the preceding graphs, we can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: There are some major changes observed in the accuracy and loss values compared
    to the earlier model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The accuracy for both the training and validation data after 50 epochs is 100%.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, the closeness of the training- and validation-related curves for
    loss and accuracy indicate that this image-classification model is not likely
    to suffer from an overfitting problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To further explore any changes in the image-classification performance of the
    model that may not be obvious from a graphical summary, let''s look at some numerical
    summaries:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will look at the results based on the training data first, and will make
    use of the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: From the preceding output, we can see that the loss value has now reduced to
    `0.034` and the accuracy is maintained at `1.0`. We obtain the same confusion
    matrix results for the training data as we did earlier as all nine images are
    correctly classified by the model, which gives an accuracy level of 100%.
  prefs: []
  type: TYPE_NORMAL
- en: 'To look more deeply at the classification performance of the model, we make
    use of the following code and output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding prediction probabilities that we obtain as an output of
    the training data, we can make the following observations:'
  prefs: []
  type: TYPE_NORMAL
- en: Correct classifications are now made with higher probability values than the
    earlier model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The lowest correct classification probability based on the second row is `0.899`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, this model seems to be more sure when correctly classifying images
    compared to what was observed with the previous model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now let''s see whether this improvement is also seen with the test data. We
    will use the following codes and output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: As indicated in the preceding output, the test data loss and accuracy values
    are `0.401` and `0.833` respectively. We do see some improvement in loss values;
    however, the accuracy value is again the same as it was earlier. Looking at the
    confusion matrix, we can see that this time, an image of a car is misclassified
    as an airplane. Therefore, we do not see any major differences based on the confusion
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s review the prediction probabilities using the following code and
    its output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the prediction probabilities for the test data, we can make the following
    two observations:'
  prefs: []
  type: TYPE_NORMAL
- en: We see a consistently similar pattern to the one that we observed based on the
    results from the training data. This model correctly classifies images in the
    test data with higher probabilities (`0.74` to `0.99`) than the earlier model
    (`0.53` to `0.98`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the fourth sample in the test data, the model seems to be confused between
    the image of a bicycle and an airplane, when in reality, this image is of a car.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, overall, we have observed that by developing a deeper neural network,
    we are able to improve the model's performance. The improvement in the performance
    was not obvious from the accuracy calculation; however, the calculation of prediction
    probabilities allowed us to develop better insights and compare model performance.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored image data and a deep neural network image-classification
    model. We used data from 18 images of bicycles, cars, and airplanes, and carried
    out appropriate data processing to make the data ready to use with the Keras library.
    We partitioned image data into training, validation, and test data, and subsequently
    developed a deep neural model using training data and evaluated its performance
    by looking at the loss, accuracy, confusion matrix, and probability values for
    both the training and test data. We also made modifications to the model to improve
    its classification performance. In addition, we observed that when the confusion
    matrix provides the same level of performance, prediction probabilities may be
    able to help in extracting finer differences between the two models.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will go over the steps to develop a deep neural network
    image-classification model using **convolutional neural networks** (**CNNs**),
    which are becoming very popular when it comes to image classification applications.
    CNNs are regarded as the gold standard for image-classification problems, and
    are very effective for large-scale image-classification applications.
  prefs: []
  type: TYPE_NORMAL
