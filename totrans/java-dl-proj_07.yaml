- en: Stock Price Prediction Using LSTM Network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stock market price prediction is one of the most challenging tasks. One of the
    major reasons is noise and the volatile features of this type of dataset. Therefore,
    how to predict stock price movement accurately is still an open question for the
    modern trading world. However classical machine learning algorithms, such as Support
    vector machines, decision trees, and tree ensembles (for example, random forest
    and gradient-boosted trees), have been used in the last decade.
  prefs: []
  type: TYPE_NORMAL
- en: However, stock market prices have severe volatility and a historical perspective,
    which make them suited for time series analysis. This also challenges those classical
    algorithms, since long-term dependencies cannot be availed using those algorithms.
    Considering these challenges and the limitations of existing algorithms, in this
    chapter, we will see how to develop a real-life plain stock open or close price
    prediction using, LSTM on top of DL4J library.
  prefs: []
  type: TYPE_NORMAL
- en: 'A time series dataset generated from a real-life stock dataset will be used
    to train the LSTM model, which will be used to predict only one day ahead at a
    time. Briefly, we will learn the following topics throughout this end-to-end project:'
  prefs: []
  type: TYPE_NORMAL
- en: Stock price prediction and online trading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data collection and description
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stock price prediction with LSTM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FAQs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: State-of-the-art automated stock trading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Usually, in a security exchange, exchanges maintain order book lists of all
    buy and sell orders with their quantity and prices, and they execute them when
    a match is found between somebody buying and selling. In addition, exchanges keep
    and provide statistics about state trading, often captured as **OHCL** (short
    for, **open-high-close-low**) and volume for both currencies of a trader pair.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the way, bar charts are used, showing open, high, low, and closing prices.
    Unlike line charts, OHLC charts enable technical analysts to evaluate intra-day
    volatility and see where prices opened and closed. Take a look at this diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/82d2422a-194a-432b-ba95-c5cb07a2f637.png)'
  prefs: []
  type: TYPE_IMG
- en: 'OHLC pricing model showing the open, high, low, and close prices of a certain
    time period (source: http://en.tradimo.com/tradipedia/ohlc-chart/)'
  prefs: []
  type: TYPE_NORMAL
- en: This data is being presented as aggregated in some periods, from seconds to
    days, and even months. There are dedicated servers working on collecting this
    data for professional traders and institutions. Although you cannot expect to
    have all the order data available for free, some of it is accessible to the public
    and can be used. The first set is historical stock trading data (OHLC), and the
    second contains the technical indicators of stock trading.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, Bitcoin, which is one of the first cryptocurrencies, has attracted
    the interest of investors and traders. This is because of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: With Bitcoin, is possible to start trading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bitcoin allows you to stay pseudo-anonymous
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There has been, dramatic growth during Bitcoin's history (see the following
    graph for some statistics), which lures long-term investors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is high volatility, which attracts daytraders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It is hard to predict the value of Bitcoin in the long term, as the value behind
    Bitcoin is less tangible, and its price mostly reflects market perception and
    is highly dependent on news, regulations, collaboration of governments and banks,
    technical issues of platform, such as transactions fees and size of block, interest
    of institutional investors in including Bitcoin into their portfolio and so on.
    Take a look at this screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5ff3ea00-951a-4fdb-81e1-cff8e2922efb.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Bitcoin and its dramatic price increases until September 2017 (source: http://www.bitcoin2040.com/bitcoin-price-history/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now the question would be how to analyze this dataset in an automated way to
    help an investor or an online currency trader. Well, in the world of traditional
    securities, such as company''s stocks, it used to be humans who would do the analytics,
    predict stock prices, and make the trades. Currently, the volume of Bitcoin trading
    is relatively low compared to traditional exchanges. Two of the reasons for this
    are high volatility in the stock market and regulations of cryptocurrencies. Take
    a look at this diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/71929ab3-01a2-46fa-8a9d-fee88f1af575.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Bitcoin buy and sell orders for the BTC/USD pair (until June 18th, 2018, source:
    https://cex.io/trade#)'
  prefs: []
  type: TYPE_NORMAL
- en: So, today, people mostly buy and sell Bitcoins with all the consequences of
    irrational behavior connected to that, but some attempts to automate Bitcoin trading
    have been made. The most famous one was a paper by MIT and another one by Stanford
    researchers, published in 2014.
  prefs: []
  type: TYPE_NORMAL
- en: Many things have changed, and taking into account the massive Bitcoin price
    increase during the last three years, anyone who would just buy and hold would
    be satisfied enough with the results. Definitely, some traders use **machine learning**
    (**ML**) for trading, and such applications look promising. Up to now, a few best
    possible approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the training, use order-book data instead of derived *OHLC + volume data*.
    Therefore, for training and prediction, use data in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: Split the data into a time series of a certain size (where size is a parameter
    to adjust).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cluster the time series data into *K* clusters, where *K* is the only parameter
    to tune. It is assumed that clusters with some natural trends will appear (sharp
    drop/rise in price and so on).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each cluster, train the regression/classifier to predict the price and the
    price change, respectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the inferencing and evaluation, this approach considers the most recent
    time series with the size of a specific window and trains the model. Then it classifies
    the data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It takes the most-recent time series with window size used for training and
    classifies it—which of the clusters does it belong to?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It uses the ML model to predict the clusters for the price and the price change
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This solution comes from 2014, but, still, it gives a certain level of robustness.
    By having many parameters to identify, and not having order-book historical data
    available, in this project, we use a simpler approach and dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a stock price predictive model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As stated earlier, the stock market price has severe volatility and historical
    perspective, which make it suited for time analysis. This also challenges those
    classical algorithms, since long-term dependencies cannot be availed using those
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'As outlined in following diagram, first we collect historical financial data.
    The data is then converted into a time series after the necessary preprocessing
    and feature engineering. The resultant time series data is then fed into the LSTM
    to carry out the training. The following diagram illustrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f14e1f05-03e4-49e8-b51d-2cb98fb5e010.png)'
  prefs: []
  type: TYPE_IMG
- en: High-level data pipeline of the prototype used for this project
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we will be using LSTM not only because it outperforms classical
    algorithms but also because we can solve long-term dependencies with it. Consequently,
    our project will have the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Load and preprocess the data, and split it into train-and-test sets
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the `LSTM` model with the data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the model on test data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Visualize the model's performance
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will go into the details of each step. However, before that, knowing about
    the dataset is mandatory.
  prefs: []
  type: TYPE_NORMAL
- en: Data collection and exploratory analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As stated earlier, we will utilize historical stock data for training our LSTM
    network. The dataset has one minute OHLC data from 506 different securities for
    the period of January 2016 to December 2016\. Let''s take a look at the data we''ll
    be using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following snapshot shows the output from this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/208ceae0-fcfb-426c-8b6a-9155f4a640b9.png)'
  prefs: []
  type: TYPE_IMG
- en: A snapshot of the historical dataset used in this project
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the preceding screenshot, our dataset has seven features. They''re
    described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`date`: Time elapsed between January 2016 and December 2016'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`symbol`: Ticker symbols for 506 different securities'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`open`: The price at the opening of the time interval'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`close`: The price at the closing of the time interval'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`high`: The highest price from all orders executed during the interval'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`low`: Same, but the lowest price'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`volume`: The sum of all stocks that were transferred during the time interval'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now let''s take a look at some ticker symbols (see more in the `securities.csv`
    file):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The is snapshot shows the output from the previous code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f37203cb-a74a-45d1-a265-b15798aa6f39.png)'
  prefs: []
  type: TYPE_IMG
- en: Some symbols whose stock price data is used in this project
  prefs: []
  type: TYPE_NORMAL
- en: 'If we need to learn about securities, the following table gives us some insight
    into this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3a316da5-b3f4-456e-8f19-ae25733137ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Some securities and their details, whose stock price data is used in this project
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we decide to see the average price of four categories—open, close, low,
    and high—for all individual securities. Take a look at this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This snapshot shows the output from the previous code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0d3ef10e-1382-4c28-925b-47e88fdf52dd.png)'
  prefs: []
  type: TYPE_IMG
- en: Average prices for the open, close, low, and high categories
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding table, however, did not provide much insight, except when it
    came to the average prices. Therefore, knowing the minimum and maximum prices
    gives us an idea whether the stock market really has very high volatility. Take
    a look at this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This snapshot shows the code''s output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/04cd7d7a-8537-4109-82b3-ad82144cae72.png)'
  prefs: []
  type: TYPE_IMG
- en: Average max and min prices for the open, close, low, and high categories
  prefs: []
  type: TYPE_NORMAL
- en: This table shows, for example, that the minimum opening and closing prices are
    not significantly different. However, the maximum opening price or even the closing
    price is very different. This is the nature of time series data, and it motivated
    me to choose `LSTM` by converting the data into a time series.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the training and test sets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most important parts of the data science pipeline, after data collection
    (which was in a sense outsourced—we use data collected by others) is data preprocessing,
    that is, clearing the dataset and transforming it to suit our needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, our goal is to predict the direction of price change from the actual price
    in dollars over time. To do that, we define variables such as `file`, `symbol`,
    `batchSize`, `splitRatio`, and `epochs`. You can see the explanation of each variable
    in the inline comments within this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We use the `StockDataSetIterator` constructor variable to prepare the dataset
    for the model. Here, we prepare the input dataset for the model as a sequence
    format for `category = PriceCategory.ALL`, which means we will predict all five
    price categories (open, close, low, high, and volume). Take a look at this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, the `PriceCategory` constructor that we used has
    the following signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In the same line, the following options are valid too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Whereas, inside, the constructor function of the `StockDataSetIterator` class
    has the following functionalities:'
  prefs: []
  type: TYPE_NORMAL
- en: We read the stock data from the file, and for each symbol we create a list
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We set the `miniBatchSize`, `exampleLength`, and `category` variables to class
    properties
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then the `split` variable is computed based on the `splitRation` variable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We separate the `stockDataList` into two parts: train and test'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then the stock data is split into training and test sets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We call the function `initializeOffsets()` to initial value for the array `exampleStartOffsets`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Following this, the `StockDataSetIterator()` constructor has the following
    signature, which generates the test dataset as a `List<Pair<INDArray, INDArray>>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following code, `StockData` is a case class that provides the structure
    of the dataset to be extracted or prepared from the input `CSV` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we have the following getter and setter methods for the aforementioned
    variable, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have seen the signature for the `StockData.java` class, it''s time
    to create the test dataset as `StockDataSetIterator`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding method, the `initializeOffsets()` method is invoked to initialize
    the mini-batch offsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The actual reading is done using the `readStockDataFromFile()` method. Inside
    the constructor, first, we call the function `readStockDataFromFile()` to read
    data from the file and load it to the `stockDataList`. Then we initialize the
    `StockDataList` list to contain data read from the `csv` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we initialize max in min arrays with `Double.MIN_VALUE` and `Double.MAX_VALUE`.
    Then the `CSV` file is read line by line for five values. The values are inserted
    subsequently into the constructor of the `StockData` object, and we add this object
    to `StockDataList`. Additionally, we throw if we have any exception. Finally,
    the method returns `StockDataList`. The signature of the method is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Then the `generateTestDataSet()` method actually generates the features only
    consumable by the `LSTM` model as `List<Pair<INDArray, INDArray>>`, where the
    ordering is set as `f` for faster construct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In the previous code block, we save the `miniBatchSize`, `exampleLength`, and
    `category` variables as class properties. Then we compute the `split` variable
    based on the `splitRation` variable. We then separate the `stockDataList` into
    two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Indices starting from the beginning to `split` belong to train set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices starting from split+1 to the end of the list belong to test set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The test data generated is quite different from the train dataset. Call the
    function `generatedTestDataSet()` to set up the test dataset. First, we set a
    window variable by the example length and the prediction length. Then we loop
    through from 0 to test the data length minus the window. Consider the following::'
  prefs: []
  type: TYPE_NORMAL
- en: 'Read five input variables: open price, close price, low price, high price,
    and volume.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Base on the value of `category`, read the label value. If `category` is equal
    to `ALL`, then read five variables such as input variables. Otherwise, read only
    one variable via the value of `category`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the preceding code block, the labels are being fed using the `feedLabel()`
    method, which goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, we initialize variable `value`. We then check
    the value of variable `category`, and the computed value of variable `value` can
    be seen using math notation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`value = (data.getOpen() - minArray[0]) / (maxArray[0] - minArray[0])`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then both the features and labels are used to prepare the dataset. Take a look
    at this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, we loop through the `epochs` time, and for each
    time we loop until we have the data, fitting the network with a data get in function
    `iterator.next()`. Consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We initialize two variables: `input` using `actualMinibatchSize` and `label`
    with `category`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We then loop from 0 to `actualMiniBatchSize`. Each time, we create two additional
    variables: `curData` , which is a `StockData` point of current time. Then we put
    their value into the `input` list. Similarly the`nextData` variable is also a
    `StockData` point of the day, which is after the day of `curData` . Finally, we
    put the value of `nextData` to `label` list.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LSTM network construction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As stated earlier, I wrote a class called `RecurrentNets.java` to build an LSTM
    network. We create a `MultilayerNetwork` LSTM network that consists of an input
    layer, four LSTM layers, three dense layers, and an output layer. The input consists
    of sequences of genetic variants.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `BuildBuildLstmNetworks()` method with two parameters—number of
    input for input layers and number of output for output layers, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, before we start creating and building the network, let''s see what our
    model would look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f4bfded0-ee1e-4a5e-9966-35f85db1c7b5.png)'
  prefs: []
  type: TYPE_IMG
- en: The stock price LSTM network
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, the `createAndBuildLstmNetworks()` method is used to create and build
    the network with the preceding parameter setting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Since we created and used an `LSTM` net several times in this chapter, I decided
    not to discuss its details. However, one important thing here is the use of the
    `IDENTITY` activation with `Root Means Square Errors (RMSE)`, which is used for
    regression problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'In short, to perform regression with a neural network in DL4J, you would set
    up a multilayer neural network and add an output layer at the end with the following
    properties, as shown previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: For more information on regression analysis using DL4j, interested readers can
    visit [https://deeplearning4j.org/evaluation#Regression](https://deeplearning4j.org/evaluation#Regression).
  prefs: []
  type: TYPE_NORMAL
- en: Network training, and saving the trained model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that our network as well as the training and test sets are ready, we can
    start training the network. For this, again we use the DL4J-provided `fit()` method.
    We loop through `epochs` times, for each time looping until we have the data.
    We fit the network with a `miniBatchSize` amount of data at each time step, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the training is completed, we save the trained model to disk (in directory
    `data`). Here I specified a sample name `StockPriceLSTM_+ category name + .zip`
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s take a look at the number of parameters at each layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Nevertheless, we enable the DL4J UI to view the training progress and params,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8621da6a-21ff-4d2a-b57c-51a991d9a3fa.png)'
  prefs: []
  type: TYPE_IMG
- en: Network parameters on the UI
  prefs: []
  type: TYPE_NORMAL
- en: The graphs look as though they are not regularized, probably because we do not
    have enough training data.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring the saved model for inferencing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have finished the training, and the trained model is at hand, we
    can either directly use that trained one on the fly as well as restore the saved
    model from disk, or start the inferencing. Take a look at this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Evaluating the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The number of parameters is the same as the one we saved on disk. This means
    our trained model is not contaminated, so we are safe. Next up, we start evaluating
    the model on the test set. But, as stated earlier, we will perform a two-way evaluation
    of the model. First, we predict one feature of a stock, one day ahead, as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, we perform the training for a single category,
    for example, by setting any one of the following options:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We can do the evaluation simultaneously for all the categories by setting `PriceCategory
    category = PriceCategory.***ALL***; // **ALL**: predict close price`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, we predict all the features (open, close, low, high prices, and volume)
    of a stock, one day ahead. The process of evaluation on a category is the same
    within case all categories. There is only one thing different: We need to loop
    through a number of categories using `PlotUtil` for the draw `XY` line chart,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, we go to the function `predictAllCategories()`
    to see how evaluation goes on in all categories. Next, we create two arrays, `predicts`
    and `actuals`, to store the predicted result and the actual result. Then we loop
    over the test data. Then we do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Call the function `net.rnnTimeStep()` with parameter as the key of row i-th
    and append the result to the `predicts` list
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Actual value gets from the value of test data row *i*^(th)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Print the predicted value and actual values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we loop through five categories; we''re using the `PlotUtil.java`
    to draw an *XY* line chart between predicted and actual values. Consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The initial two double arrays are named `pred` and `actu` with size equal to
    the size of the predicted length.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loop through the `predicts` and `actuals` arrays and, get the double value of
    each element in each list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With each value of *n* has four values from 0 to 4\. Set the variable `name`
    to the ledge of the *Y* column.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Call the function `PlotUtil` to draw the *XY* line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By the way, the `PlotUtil.java` class is used to draw an *XY* line for predicted
    versus actual values, which goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block,the `addSeries()` method is used to add the *XY*
    series, which is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Apart from these, finding the min, max values of `predicted` and `actual` values
    that we used in the preceding code happen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Finding min:** First, we set variable `min` as `MAX_VALUE.` Then we loop
    through the `predicted` and `actual` arrays, such that if `min` is greater than
    any element, then we reset `min` as the current element. Then we take the integer
    closest lower bound of value of min:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '**Finding max:** First, we set the variable `max` as `MIN_VALUE.` Then we loop
    through the `predicts` and `actual` arrays such that if `max` < any element, we
    reset `max` as this element. Then we take the integer closest to the upper bound
    of the value of max as shown here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we use the `addSeries()` method to add a series to dataSet while plotting
    the graph. Nevertheless, since the task is a regression, we perform the evaluation
    showing regression metrics too, such as `MSE`, `MAE`, `R2`, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, based on the preceding plans and based on the value of variable `category`,
    we have two methods to evaluate the model. If the category is `ALL`, then the
    network will predict all categories; otherwise, the network will work only on
    one category. First, for only a single category, say `OPEN`. Take a look at this
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Then the regression metrics will be printed as follows (you may experience
    slightly different result, though):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we observe the following screenshot showing predicted versus actual
    `OPEN` prices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9d1020c0-ee25-4e63-85d1-c322756232db.png)'
  prefs: []
  type: TYPE_IMG
- en: Predicted versus actual prices for `OPEN` category
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, for only the `**ALL**` category, we run a similar code, except that `PriceCategory.ALL`
    is used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Then the regression metrics will be printed as follows (you may experience
    slightly different result, though):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now take a look at the following graph, showing predicted versus actual `ALL`
    prices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8b74636f-a246-4971-b678-f266defb34f5.png)'
  prefs: []
  type: TYPE_IMG
- en: Predicted versus actual prices for `ALL` categories
  prefs: []
  type: TYPE_NORMAL
- en: From the graph, we can see that the price for `OPEN` and `HIGH` shows a good
    fit, whereas `LOW` shows a somewhat good fit. Unfortunately, `CLOSE` and `VOLUME`
    show a very disappointing fit (see the preceding regression result table). One
    possible reason could be lack of data. And also, the hyperparameters used are
    not hypertuned at all. Nevertheless, most of the hyperparameters were chosen naively.
  prefs: []
  type: TYPE_NORMAL
- en: Frequently asked questions (FAQs)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will see some frequently asked questions that may be already
    on your mind. Answers to these questions can be found in Appendix A:'
  prefs: []
  type: TYPE_NORMAL
- en: Can I extend this project for Bitcoin price prediction purposes? If so, how
    and where can I get such datasets?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What happens if you take predicted values as input for the next prediction?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I understand that this is a regression problem, but how can I predict whether
    a price will go up or down?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I would like to extend this app and deploy a web application. How can I do that?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I want to extend this application not only for price prediction, but also for
    anomaly detection in prices. How can I do that?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can I use similar technique for stock price recommendation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter,we saw how to develop a demo project for predicting stock prices
    for five categories: `OPEN`, `CLOSE`, `LOW`, `HIGH`, and `VOLUME`. However, our
    approach cannot generate an actual signal. Still, it gives some idea of how to
    use LSTM. I know there are some serious drawbacks of this approach. Nevertheless,
    we did not use enough data, which potentially limits the performance of such a
    model.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how to apply deep learning approaches to a
    video dataset. We will describe how to process and extract features from a large
    collection of video clips. Then we will make the overall pipeline scalable and
    faster by distributing the training on multiple devices (CPUs and GPUs), and run
    them in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: We will see a complete example of how to develop a deep learning application
    that accurately classifies a large collection of a video dataset, such as `UCF101`,
    using a combined CNN-LSTM network with DL4J. It overcomes the limitations of standalone
    CNN or `LSTM` networks. The training will be carried out on an Amazon EC2 GPU
    compute cluster. Eventually, this end-to-end project can be treated as a primer
    for human activity recognition from video or so.
  prefs: []
  type: TYPE_NORMAL
- en: Answers to questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Answer** **to question** **1:** Some historical Bitcoin data can be downloaded
    from Kaggle, for example, [https://www.kaggle.com/mczielinski/bitcoin-historical-data/data](https://www.kaggle.com/mczielinski/bitcoin-historical-data/data).'
  prefs: []
  type: TYPE_NORMAL
- en: Once you've downloaded the dataset, try to extract the most important features
    and convert the dataset into a time series so that it can be fed into an LSTM
    model. Then the model can be trained with the time series for each time step.
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question 2:** Our sample project only calculates the stock
    price of those stocks whose actual stock price is given, and not the next day''s
    stock price. It shows `actual` and `predicted`, but the next day''s stock price
    should only contain `predicted`. This is what is happening if we take predicted
    values as input for the next prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f9c0c769-0e8a-467d-9771-8c9d377e2565.png)'
  prefs: []
  type: TYPE_IMG
- en: Predicted versus actual prices for `ALL` categories, where predicted values
    are input for the next prediction
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question** **3:** Well, then the task would be a binary classification
    problem. To make this happen, you need to make two changes:'
  prefs: []
  type: TYPE_NORMAL
- en: Convert the dataset such that there will be two labels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace the `IDENTITY` activation function and `RMSE` loss with cross-entropy
    loss
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Answer to question 4:** That is a great idea. You can try improving the modeling
    by following questions 1 and 2\. Then you can save the model on disk for later
    stage inferencing. Finally, you can serve this model as a web application, as
    suggested in previous chapters.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer** **to question** **5**: Applying anomaly detection in such a dataset
    is very challenging, and I am not sure whether it is feasible, since the market
    has very high volatility. Therefore, the time series will have very many vicissitudes
    sometimes, which is the nature of the stock market. This helps the trained model
    to identify that abnormal volatility.'
  prefs: []
  type: TYPE_NORMAL
- en: Answer **to question 6:** Yes, you can. You can try using **Machine Learning
    based ZZAlpha Ltd. Stock Recommendations 2012-2014 Data Set.** This dataset can
    be downloaded from `UCI ML repository` at [https://archive.ics.uci.edu/ml/datasets/Machine+Learning+based+ZZAlpha+Ltd.+Stock+Recommendations+2012-2014](https://archive.ics.uci.edu/ml/datasets/Machine+Learning+based+ZZAlpha+Ltd.+Stock+Recommendations+2012-2014).
    The repository also describes the problem as well as the dataset.
  prefs: []
  type: TYPE_NORMAL
