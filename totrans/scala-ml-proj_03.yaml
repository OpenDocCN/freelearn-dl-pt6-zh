- en: High Frequency Bitcoin Price Prediction from Historical and Live Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bitcoin is a worldwide cryptocurrency and digital payment system considered
    the **first decentralized digital currency**, since the system works without a
    central repository or single administrator. In recent times, it has gained much
    popularity and attention among people around the world.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will see how to develop a real-life project using Scala,
    Spark ML, Cryptocompare API, and Bitcoin historical (and live) data to predict
    the price for an upcoming week, month, and so on that help us taking automated
    decision for online cryptocurrency. In addition to this, we will see how to generate
    a simple signal for online Bitcoin trading.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Briefly, we will learn the following topics throughout this end-to-end project:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Bitcoin, cryptocurrency, and online trading
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Historical and live-price data collection
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High-level pipeline of the prototype
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gradient-boosted trees regression for Bitcoin price prediction
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demo prediction and signal generation using the Scala play framework
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Future outlook—using the same technique for other datasets
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bitcoin, cryptocurrency, and online trading
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bitcoin, the first cryptocurrency by date of launch and by market cap (as of
    December2017) has attracted investors and traders because of its ease of starting
    trading, ability to stay pseudo-anonymous, and, of course, dramatic growth during
    its history (see *Table 1* and *Figure 1* for some statistics). This lures long-term
    investors; its high volatility also attracts day traders.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'However, it''s hard predict the value of Bitcoin in the long term, as the value
    behind Bitcoin is less tangible. The price mostly reflects market perception and
    is highly dependent on news, regulations, collaboration of governments and banks,
    technical issues of the platform (such as transactions fee and block size), interest
    of institutional investors in including Bitcoin into their portfolio, and more:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/49e8ae72-5c00-48ac-8a1b-ded0004f484f.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Bitcoin and its dramatic price increases'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: 'Nonetheless, from a short-term perspective, Bitcoin price is a by-product of
    market activity usually happening on a platform, called **exchange** (Bitstamp,
    Coinbase, Kraken, and Bitfinex among the most well-known **exchanges**). Users,
    after registration and after going through **KYC** (**Know Your Customer**) procedures,
    can trade Bitcoin in it for fiat currencies such as dollars and euros, as well
    as for other cryptocurrencies, called **alt-coins** or alternative coins (Ethereum,
    Litecoin, and Dash are well known):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 1 – Bitcoin historical price movement**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '| **Date** | **USD: 1 BTC** |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
- en: '| Jan 2009 to Mar 2010 | Basically none |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
- en: '| Mar 2010 | $0.003 |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
- en: '| May 2010 | Less than $0.01 |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
- en: '| Jul 2010 | $0.08![](img/90581ab4-0591-4dca-b5ed-443e38e1d7c0.png) |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
- en: '| Feb to Apr 2011 | $1.00![](img/90581ab4-0591-4dca-b5ed-443e38e1d7c0.png)
    |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
- en: '| 8 Jul 2011 | $31.00![](img/90581ab4-0591-4dca-b5ed-443e38e1d7c0.png) |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
- en: '| Dec 2011 | $2.00![](img/a45968d6-6644-4ea0-b057-04ae1126bf6d.png) |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
- en: '| Dec 2012 | $13.00 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
- en: '| 11 Apr 2013 | $266![](img/90581ab4-0591-4dca-b5ed-443e38e1d7c0.png) |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
- en: '| May 2013 | $130![](img/a45968d6-6644-4ea0-b057-04ae1126bf6d.png) |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
- en: '| Jun 2013 | $100![](img/a45968d6-6644-4ea0-b057-04ae1126bf6d.png) |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
- en: '| Nov 2013 | $350 to $1,242![](img/b6f31e88-ab89-497f-80de-74f781252588.png)
    |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
- en: '| Dec 2013 | $600 to $1,000![](img/5a96adb5-2395-4d3f-aafe-9a5611dcf169.png)
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
- en: '| Jan 2014 | $750 to $1,000![](img/32d8f6a6-d273-4f99-8151-9439ab44d07a.png)
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
- en: '| Feb 2014 | $550 to $750![](img/1ca1dfd2-722d-4c6b-96a9-2e0f148bca0b.png)
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
- en: '| Mar 2014 | $450 to $700![](img/5057f2fa-69b0-44ff-9c33-b7a637d18f48.png)
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
- en: '| Apr 2014 | $340 to $530![](img/56ee8714-fe1c-4fc1-9388-9f959cf22b1b.png)
    |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
- en: '| May 2014 | $440 to $630![](img/0cb1f1cf-928d-4ec2-8d06-23fad044b50a.png)
    |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
- en: '| Mar 2015 | $200 to $300![](img/9e3940a9-ff01-4626-be01-e8dbebe89654.png)
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
- en: '| Early Nov 2015 | $395 to $504![](img/d0532b1c-66e1-4127-b5a3-6528ce9a8fe7.png)
    |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
- en: '| May to Jun 2016 | $450 to $750![](img/bd67159a-b317-4476-9ad2-d26a9c13b868.png)
    |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
- en: '| Jul to Sept 2016 | $600 to $630![](img/0610538f-261e-4188-a43d-a0bca9d5be7c.png)
    |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
- en: '| Oct to Nov 2016 | $600 to $780![](img/45f5cbb4-1622-4d1a-b774-43651f28fa2d.png)
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
- en: '| Jan 2017 | $800 to $1,150![](img/68fe4e41-afe2-4443-970f-12f2f1828000.png)
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
- en: '| 5-12 Jan 2017 | $750 to $920![](img/9fe99d9e-0593-41b5-8e75-2065a34c5e6e.png)
    |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
- en: '| 2-3 Mar 2017 | $1,290+ ![](img/de8a003e-b813-4e3c-9391-aff3af19b018.png)
    |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
- en: '| Apr 2017 | $1,210 to $1,250![](img/736f9408-d05a-43f0-b2cf-95381b850962.png)
    |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
- en: '| May 2017 | $2,000 ![](img/e74ec91a-4184-4ab1-9baf-6381881e32d1.png) |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
- en: '| May to June 2017 | $2,000 to $3,200+![](img/3039f1b3-23ee-4a3f-86af-496ac578b85d.png)
    |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
- en: '| Aug 2017 | $4,400 ![](img/090e34d8-4208-49d0-931f-2dc81ddd3f91.png) |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
- en: '| Sept 2017 | $5,000![](img/cc407ad7-fc7f-419c-9f30-9f77f5b14b48.png) |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
- en: '| 12 Sept 2017 | $2,900![](img/3b77d917-ab15-4e2a-8fc6-a48fd221c8af.png) |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
- en: '| 13 Oct 2017 | $5,600![](img/3afb31a2-f86b-4345-a3ef-c960f07632b7.png) |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
- en: '| 21 Oct 2017 | $6,180 ![](img/4646b186-f179-4514-abe8-74eef5a3aa0d.png) |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
- en: '| 6 Nov 2017 | $7,300 ![](img/ae5187a3-3bd3-4bcb-a9da-7f08c8ba90db.png) |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
- en: '| 12 Nov 2017 | $5,519 to 6,295 ![](img/b1721a3b-6f03-4de9-8551-2f2f9be53230.png)
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
- en: '| 17-20 Nov 2017 | $7,600 to 8,100 ![](img/2fdfb5d0-b68b-46a9-a6bc-85cb52ed1acb.png)
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
- en: '| 15 Dec 2017 | 17,900 ![](img/c5c30f2c-62d2-4287-acbb-18d6e63baebc.png) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
- en: Exchanges maintain order books—lists of all buy and sell orders, with their
    quantities and prices—and execute when a match is found between somebody buying
    and somebody selling. In addition, exchanges also keep and provide statistics
    about the state of trading, often captured as OCHL and volume for both currencies
    of the trader pai. For this project, we will be using the BTC/USD cryptocurrency
    pair.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: This data is presented as aggregated by period, from seconds to days, and even
    months. There are dedicated servers working on collecting Bitcoin data for professional
    traders and institutions. Although one cannot expect to have all orders data available
    free, some of it is accessible to the public and can be used.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据按周期汇总展示，从秒到天，甚至到月。为专业交易员和机构收集比特币数据的专用服务器也在运行。虽然不可能期望所有订单数据都能免费获取，但其中一些数据对公众开放并且可以使用。
- en: State-of-the-art automated trading of Bitcoin
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最先进的比特币自动化交易
- en: In the world of traditional securities, such as a company's stocks, it used
    to be humans who would do the analytics, predict the prices of stocks, and trade.
    Today, the development of **machine learning ** (**ML**) and the growing availability
    of data has almost eliminated humans from high-frequency trading, as a regular
    person can't capture and process all data, and emotions affect one's decisions;
    so it's dominated by automated trading systems by investment institutions.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统证券的世界中，比如公司的股票，过去是由人类来进行分析、预测股票价格并进行交易的。今天，**机器学习**（**ML**）的发展和数据的日益丰富几乎已将人类从高频交易中排除，因为普通人无法捕捉并处理所有数据，而且情绪会影响决策；因此，这一领域现在主要由投资机构的自动化交易系统主导。
- en: Currently, the volume of Bitcoin trading is relatively low compared to traditional
    exchanges; financial institutions, being traditionally careful and risk averse,
    haven't got their hands on Bitcoin trading yet (at least, it's not well-known).
    One of the reasons is high fees and uncertainty regarding regulations of cryptocurrencies.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当前，比特币交易的交易量相对于传统交易所较低；金融机构传统上谨慎且风险厌恶，尚未涉足比特币交易（至少，尚未公开知晓）。其中一个原因是高费用和对加密货币法规的不确定性。
- en: 'So today, mostly individuals buy and sell Bitcoins, with all the consequences
    of irrational behavior connected to that, but some attempts to automate Bitcoin
    trading have been made. The most famous one was stated in a paper by MIT, and
    another one was by Stanford researchers, published in 2014\. Many things have
    changed, and taking into account the massive Bitcoin price increase during these
    three years, anyone who just buys and holds on would be satisfied enough with
    the results:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 所以今天，大多数人购买和出售比特币，伴随着所有与非理性行为相关的后果，但也有人尝试自动化比特币交易。最著名的一次尝试是在MIT的一篇论文中提出的，另一次是在2014年由斯坦福研究人员发布的。很多事情发生了变化，考虑到这三年中比特币价格的大幅上涨，任何只是买入并持有的人都会对结果感到满意：
- en: '![](img/f706ebab-7205-4b72-9e9b-b46121b5d0c3.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f706ebab-7205-4b72-9e9b-b46121b5d0c3.png)'
- en: 'Figure 2: Bitcoin buy and sell orders (until November 2017)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：比特币买卖订单（截至2017年11月）
- en: Definitely, some traders use ML for trading, and such applications look promising.
    So far, the best possible approach that was identified from research papers is
    as follows.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，确实有一些交易员使用**机器学习**进行交易，这类应用看起来前景广阔。到目前为止，从研究论文中确定的最佳方法如下：
- en: Training
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练
- en: 'Use order book data, instead of derived OHLC + volume data. Therefore, for
    training and prediction, use data that looks like this:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用订单簿数据，而不是衍生的OHLC + 成交量数据。因此，训练和预测时，使用的数据看起来是这样的：
- en: Split the data into a time series of a certain `size` (`size` is a parameter
    to tune).
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据划分为一定`大小`的时间序列（`大小`是一个需要调整的参数）。
- en: Cluster the time series data into `K` clusters (`K` is a parameter to tune).
    It's assumed that clusters with some natural trends would appear (sharp drop/rise
    in price and so on).
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将时间序列数据聚类为`K`个聚类（`K`是一个需要调整的参数）。假设会出现一些具有自然趋势的聚类（如价格剧烈下降/上升等）。
- en: For each cluster, train the regression and classifier to predict the price and
    price change, respectively.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个聚类，训练回归模型和分类器，分别预测价格和价格变化。
- en: Prediction
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测
- en: 'This approach considers the most recent time series with the size of a specific
    window and trains the model. Then it classifies the data as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法考虑了具有特定窗口大小的最新时间序列，并对模型进行训练。然后，它对数据进行如下分类：
- en: Takes the most recent time series with window size used for training
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 采用用于训练的最新时间序列和窗口大小
- en: Classifies it—which of the clusters does it belong to?
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行分类——它属于哪个聚类？
- en: Uses the ML model for that cluster to predict the price or price change
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用该聚类的ML模型预测价格或价格变化
- en: This solution dates back to 2014, but still it gives a certain level of robustness.
    By having many parameters to identify, and not having the order-book historical
    data available easily, in this project, we use a simpler approach and dataset.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解决方案可以追溯到2014年，但它仍然提供了一定程度的鲁棒性。由于需要识别许多参数，并且没有容易获得的订单簿历史数据，本项目使用了更简单的方法和数据集。
- en: High-level data pipeline of the prototype
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原型的高级数据管道
- en: The goal of this chapter is to develop a prototype of a system that will predict
    the short-term change of Bitcoin price, using historical data to train the algorithm,
    and real-time data to predict and select algorithms that perform better. In the
    scope of this project, there is no attempt to predict the actual price in dollars,
    but only whether it would increase or not. This is because Bitcoin price, to some
    extent, is not actually about price but about market expectations. This can be
    seen as patterns in a trader's behavior, which, on a higher level, is represented
    by previous price itself.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是开发一个原型系统，该系统将预测比特币价格的短期变化，使用历史数据训练算法，并使用实时数据预测和选择表现更好的算法。在本项目范围内，并不尝试预测实际的美元价格，而仅仅是预测其是否会上涨。因为比特币价格在某种程度上实际上并不只是价格本身，而是市场预期。这可以看作是交易者行为中的模式，从更高层次上讲，表现为历史价格本身。
- en: '![](img/4031f5ff-0aa6-415e-89a1-8303f1ab3c2c.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4031f5ff-0aa6-415e-89a1-8303f1ab3c2c.png)'
- en: 'Figure 3: High-level data pipeline of the prototype'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：原型的高级数据管道
- en: Of course, there is an objective price associated with Bitcoin; miners are willing
    to sell Bitcoins for profit. So the base price can be estimated by knowing all
    bills that all miners have to pay for the Bitcoins they mine, but that is outside
    the scope of this project.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，比特币有一个客观的价格；矿工愿意出售比特币以获取利润。因此，基准价格可以通过了解所有矿工为开采比特币必须支付的费用来估算，但这超出了本项目的范围。
- en: From this perspective, rather than trying to predict the price in dollars, it
    might make sense to look for trends of the price rising, dropping, or staying
    the same, and act accordingly. The second goal is to build a tool for experiments
    that allows us to try different approaches to predicting prices and evaluate it
    on real-life data easily. The code has to be flexible, robust, and easily extensible.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个角度来看，与其试图预测美元价格，不如寻找价格上涨、下跌或保持不变的趋势，并根据这些趋势采取行动。第二个目标是构建一个实验工具，允许我们尝试不同的价格预测方法，并能轻松在实际数据上进行评估。代码必须具有灵活性、稳健性，并且易于扩展。
- en: 'Therefore, in summary, there are three main components of the system:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总结来说，系统有三个主要组成部分：
- en: Scala script for preprocessing of historical data into the required format
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于将历史数据预处理成所需格式的Scala脚本
- en: Scala app to train the ML model
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scala应用程序用于训练机器学习模型
- en: Scala web service to predict future prices
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scala 网络服务预测未来价格
- en: Historical and live-price data collection
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 历史和实时价格数据收集
- en: As stated earlier, we will utilize both historical as well live data. We will
    be using the Bitcoin historical price data from Kaggle. For the real-time data,
    Cryptocompare API will be used.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将同时使用历史数据和实时数据。我们将使用来自Kaggle的比特币历史价格数据。对于实时数据，将使用Cryptocompare API。
- en: Historical data collection
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 历史数据收集
- en: For training the ML algorithm, there is a `Bitcoin Historical Price Data` dataset
    available to the public on Kaggle (version 10). The dataset can be downloaded
    from [https://www.kaggle.com/mczielinski/bitcoin-historical-data/](https://www.kaggle.com/mczielinski/bitcoin-historical-data/).
    It has 1 minute OHLC data for BTC-USD pairs from several exchanges.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练机器学习算法，有一个公开的`比特币历史价格数据`数据集（版本10），可以在Kaggle上找到。该数据集包含来自多个交易所的BTC-USD对的1分钟OHLC数据，可以从[https://www.kaggle.com/mczielinski/bitcoin-historical-data/](https://www.kaggle.com/mczielinski/bitcoin-historical-data/)下载。
- en: 'At the beginning of the project, for most of them, data was available from
    January 1, 2012 to May 31, 2017; but for the Bitstamp exchange, it''s available
    until October 20, 2017 (as well as for Coinbase, but that dataset became available
    later):'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目初期，大多数数据可用的时间范围是从2012年1月1日到2017年5月31日；但是对于Bitstamp交易所，数据可用时间截至2017年10月20日（对于Coinbase也是如此，但该数据集稍后才提供）：
- en: '![](img/3fcf81e6-a1ed-4dc7-b3b5-35d4c0f7ec32.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3fcf81e6-a1ed-4dc7-b3b5-35d4c0f7ec32.png)'
- en: 'Figure 4: The Bitcoin historical dataset on Kaggle'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：Kaggle上的比特币历史数据集
- en: 'Note that you need to be a registered user and be logged in in order to download
    the file. The file that we are using is `bitstampUSD_1-min_data_2012-01-01_to_2017-10-20.csv`*.*
    Now, let us get the data we have. It has eight columns:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您需要是注册用户并已登录才能下载该文件。我们使用的文件是`bitstampUSD_1-min_data_2012-01-01_to_2017-10-20.csv`*。*现在，让我们来获取我们拥有的数据。它有八列：
- en: '**Timestamp**: The time elapsed in seconds since January 1, 1970\. It is 1,325,317,920
    for the first row and 1,325,317,920 for the second 1\. (Sanity check! The difference
    is 60 seconds).'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间戳**：自1970年1月1日以来的秒数。对于第一行，它是1,325,317,920，对于第二行也是1,325,317,920。（完整性检查！它们之间的差异是60秒）。'
- en: '**Open**: The price at the opening of the time interval. It is 4.39 dollars.
    Therefore it is the price of the first trade that happened after **Timestamp**
    (1,325,317,920 in the first row''s case).'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开盘价**：该时间区间的开盘价格。为4.39美元。因此，它是发生在**时间戳**（第一个行中的时间戳为1,325,317,920）之后的第一次交易的价格。'
- en: '**Close**: The price at the closing of the time interval.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收盘价**：该时间区间的收盘价格。'
- en: '**High**: The highest price from all orders executed during the interval.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最高价**：在该区间内执行的所有订单中的最高价格。'
- en: '**Low**: The same as **High** but it is the lowest price.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最低价**：与**最高价**相同，但它是最低价格。'
- en: '**Volume_(BTC)**: The sum of all Bitcoins that were transferred during the
    time interval. So, take all transactions that happened during the selected interval
    and sum up the BTC values of each of them.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易量_(BTC)**：在该时间区间内转移的所有比特币的总和。因此，选择该区间内发生的所有交易并将每笔交易的BTC值相加。'
- en: '**Volume_(Currency)**: The sum of all dollars transferred.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易量_(货币)**：转移的所有美元的总和。'
- en: '**Weighted_Price**: This is derived from the volumes of BTC and USD. By dividing
    all dollars traded by all bitcoins, we can get the weighted average price of BTC
    during this minute. So `Weighted_Price=Volume_(Currency)/Volume_(BTC)`.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加权价格**：这是根据BTC和USD的交易量得出的。通过将所有交易的美元数额除以所有比特币的交易量，我们可以得出该分钟的BTC加权平均价格。所以`加权价格=交易量_(货币)/交易量_(BTC)`。'
- en: One of the most important parts of the data-science pipeline after data collection
    (which is in a sense outsourced; we use data collected by others) is data preprocessing—clearing
    a dataset and transforming it to suit our needs.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学流程中最重要的部分之一是数据预处理——清理数据集并将其转换为适合我们需求的形式，这发生在数据收集之后（在某种意义上，数据收集是外包的；我们使用的是他人收集的数据）。
- en: Transformation of historical data into a time series
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 历史数据转换为时间序列
- en: Stemming from our goal—predict the direction of price change—we might ask ourselves,
    *does having an actual price in dollars help to achieve this?* Historically, the
    price of Bitcoin was usually rising, so if we try to fit a linear regression,
    it will show further exponential growth (whether in the long run this will be
    true is yet to be seen).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们的目标出发——预测价格变化的方向——我们可能会问自己，*实际的美元价格是否有助于实现这一目标？* 历史上，比特币的价格通常是上涨的，所以如果我们尝试拟合线性回归，它将显示出进一步的指数增长（长期内是否会如此，还需要观察）。
- en: Assumptions and design choices
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 假设和设计选择
- en: 'One of the assumptions of this project is as follows: whether we are thinking
    about Bitcoin trading in November 2016 with a price of about $700, or trading
    in November 2017 with a price in the $6500-7000 range, patterns in how people
    trade are similar. Now, we have several other assumptions, as described in the
    following points:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目的一个假设是：无论我们是在考虑2016年11月比特币的交易价格大约为700美元，还是2017年11月的价格在6500至7000美元区间，交易模式是相似的。现在，我们还有几个其他的假设，如下所述：
- en: '**Assumption one**: From what has been said previously, we can ignore the actual
    price and rather look at its change. As a measure of this, we can take the delta
    between opening and closing prices. If it is positive, it means the price grew
    during that minute; the price went down if it is negative and stayed the same
    if delta = 0.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假设一**：根据前面的说法，我们可以忽略实际价格，而是关注价格变化。作为这一变化的度量，我们可以取开盘价和收盘价之间的差值。如果为正，表示该分钟内价格上涨；如果为负，表示价格下跌；如果差值为0，表示价格保持不变。'
- en: In the following figure, we can see that Delta was -1.25 for the first minute
    observed, -12.83 for the second one, and -0.23 for the third one. Sometimes, the
    open price can differ significantly from the close price of the previous minute
    (although Delta is negative during all three of the observed minutes, for the
    third minute the shown price was actually higher than close for a second). But
    such things are not very common, and usually the open price doesn't change significantly
    compared to the close price of the previous minute.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在下图中，我们可以看到，观察的第一分钟 Delta 为 -1.25，第二分钟为 -12.83，第三分钟为 -0.23。有时候，开盘价与上一分钟的收盘价差异较大（尽管在观察的三分钟内，Delta
    都是负值，但在第三分钟，显示的价格实际上比收盘价略高）。但这种情况并不常见，通常情况下开盘价与上一分钟的收盘价变化不大。
- en: '**Assumption two**: The next need to consider...  is predicting the price change
    in a **black box** environment. We do not use other sources of knowledge such
    as news, Twitter feeds, and others to predict how the market would react to them.
    This is a more advanced topic. The only data we use is price and volume. For simplicity
    of the prototype, we can focus on price only and construct time series data.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假设二**：接下来需要考虑的是在**黑箱**环境下预测价格变化。我们不使用新闻、Twitter 动态等其他信息来源来预测市场如何对它们做出反应。这是一个更为高级的话题。我们唯一使用的数据是价格和成交量。为了简化原型，我们可以只关注价格并构建时间序列数据。'
- en: Time series prediction is a prediction of a parameter based on the values of
    this parameter in the past. One of the most common examples is temperature prediction.
    Although there are many supercomputers using satellite and sensor data to predict
    the weather, a simple time series analysis can lead to some valuable results.
    We predict the price at T+60 seconds, for instance, based on the price at T, T-60s,
    T-120s and so on.
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 时间序列预测是基于该参数过去的值来预测该参数的未来值。最常见的一个例子是温度预测。尽管有许多超级计算机使用卫星和传感器数据来预测天气，但简单的时间序列分析也能得出一些有价值的结果。例如，我们可以基于T时刻、T-60秒、T-120秒等时刻的价格来预测T+60秒时的价格。
- en: '**Assumption three**: Not all data in the dataset is valuable. The first 600,000
    records are not informative, as price changes are rare and trading volumes are
    small. This can affect the model we are training and thus make end results worse.
    That is why the first 600,000 of rows are eliminated from the dataset.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假设三**：数据集中并非所有数据都有价值。前60万条记录不具备信息量，因为价格变化稀少，成交量较小。这可能会影响我们训练的模型，从而导致最终结果变差。因此，数据集中前60万条记录会被剔除。'
- en: '**Assumption four**: We need to `Label `our data so that we can use a supervised
    ML algorithm. This is the easiest measure, without concerns about transaction
    fees.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假设四**：我们需要`标签化`我们的数据，以便使用监督式机器学习算法。这是最简单的措施，且无需担心交易费用。'
- en: Data preprocessing
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: 'Taking into account the goals of data preparation, Scala was chosen as an easy
    and interactive way to manipulate data:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到数据准备的目标，选择了 Scala 作为一种简便且交互性强的数据处理方式：
- en: '[PRE0]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](img/c6304756-3dc9-45f6-af8d-71eef2a2a4c7.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6304756-3dc9-45f6-af8d-71eef2a2a4c7.png)'
- en: 'Figure 5: A glimpse of the Bitcoin historical price dataset'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：比特币历史价格数据集一瞥
- en: '[PRE1]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '>>>'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '>>>'
- en: '[PRE2]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the preceding code, we load data from the file downloaded from Kaggle and
    look at what is inside. There are `3045857` rows in the dataset and `8` columns,
    described before. Then we create the `Delta` column, containing the difference
    between closing and opening prices (that is, to consider only that data where
    meaningful trading has started to occur):'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们从 Kaggle 下载的文件中加载数据，并查看其内容。数据集中有`3045857`行数据，`8`列，之前已经描述过。接着我们创建了`Delta`列，包含了收盘价与开盘价之间的差值（也就是只考虑那些已经开始有意义的交易数据）：
- en: '[PRE3]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following code labels our data by assigning 1 to the rows the `Delta` value
    of which was positive; it assigns `0` otherwise:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码通过将`Delta`值为正的行标记为1，其他行标记为`0`，为我们的数据打上标签：
- en: '[PRE4]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This code transforms the original dataset into time series data. It takes the
    Delta values of `WINDOW_SIZE` rows (`22` in this experiment) and makes a new row
    out of them. In this way, the first row has `Delta` values from `t0` to `t21`,
    and the second one has values from `t1` to `t22`. Then we create the corresponding
    array with labels (`1` or `0`).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将原始数据集转换为时间序列数据。它将`WINDOW_SIZE`行（在此实验中为`22`）的 Delta 值合并成一行。这样，第一行包含从`t0`到`t21`的
    Delta 值，第二行包含从`t1`到`t22`的 Delta 值。然后我们创建相应的标签数组（`1`或`0`）。
- en: 'Finally, we save `X` and `Y` into files where `612000` rows were cut off from
    the original dataset; `22` means rolling window size and 2 classes represents
    that labels are binary `0` and `1`:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将 `X` 和 `Y` 保存到文件中，其中 `612000` 行数据被从原始数据集中截取；`22` 表示滚动窗口大小，2 个类别表示标签是二进制的
    `0` 和 `1`：
- en: '[PRE5]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the preceding code segment:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码段中：
- en: '[PRE6]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Real-time data through the Cryptocompare API
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过 Cryptocompare API 获取实时数据
- en: 'For real-time data, the Cryptocompare API is used ([https://www.cryptocompare.com/api/#](https://www.cryptocompare.com/api/)),
    more specifically HistoMinute ([https://www.cryptocompare.com/api/#-api-data-histominute-](https://www.cryptocompare.com/api/#-api-data-histominute-)),
    which gives us access to OHLC data for the past seven days at most. The details
    of the API will be discussed in a section devoted to implementation, but the API
    response is very similar to our historical dataset, and this data is retrieved
    using a regular HTTP request. For example, a simple JSON response from [https://min-api.cryptocompare.com/data/histominute?fsym=BTC&tsym=USD&limit=23&aggregate=1&e=Bitstamp](https://min-api.cryptocompare.com/data/histominute?fsym=BTC&tsym=USD&limit=23&aggregate=1&e=Bitstamp) has
    the following structure:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实时数据，使用 Cryptocompare API（[https://www.cryptocompare.com/api/#](https://www.cryptocompare.com/api/#)），更具体来说是
    HistoMinute（[https://www.cryptocompare.com/api/#-api-data-histominute-](https://www.cryptocompare.com/api/#-api-data-histominute-)），它使我们可以访问最多过去七天的
    OHLC 数据。API 的细节将在专门讨论实现的部分中说明，但 API 响应与我们的历史数据集非常相似，这些数据是通过常规的 HTTP 请求获取的。例如，来自
    [https://min-api.cryptocompare.com/data/histominute?fsym=BTC&tsym=USD&limit=23&aggregate=1&e=Bitstamp](https://min-api.cryptocompare.com/data/histominute?fsym=BTC&tsym=USD&limit=23&aggregate=1&e=Bitstamp)
    的简单 JSON 响应具有以下结构：
- en: '[PRE7]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Through Cryptocompare HistoMinute, we can get `open`, `high`, `low`, `close`,
    `volumefrom`, and `volumeto` from each minute of historical data. This data is
    stored for 7 days only; if you need more, use the hourly or daily path. It uses
    BTC conversion if data is not available because the coin is not being traded in
    the specified currency:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 Cryptocompare HistoMinute，我们可以获取每分钟的历史数据中的 `open`、`high`、`low`、`close`、`volumefrom`
    和 `volumeto`。这些数据仅保存 7 天；如果需要更多数据，可以使用按小时或按日的路径。如果数据不可用（因为该货币没有在指定的货币中进行交易），它会使用
    BTC 转换：
- en: '![](img/15833859-b3f2-4974-9f9d-3ae6f49d9630.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/15833859-b3f2-4974-9f9d-3ae6f49d9630.png)'
- en: 'Figure 6: Open, high, low, close, and volume values through Cryptocompare HistoMinute'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：通过 Cryptocompare HistoMinute 获取的开盘价、最高价、最低价、收盘价和交易量值
- en: 'Now, the following method fetches the correctly formed URL of the Cryptocompare
    API ([https://www.cryptocompare.com/api/#-api-data-histominute-](https://www.cryptocompare.com/api/#-api-data-histominute-)),
    which is a fully formed URL with all parameters, such as currency, limit, and
    aggregation specified. It finally returns the future that will have a response
    body parsed into the data model, with the price list to be processed at an upper
    level:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，以下方法获取正确格式的 Cryptocompare API URL（[https://www.cryptocompare.com/api/#-api-data-histominute-](https://www.cryptocompare.com/api/#-api-data-histominute-)），这是一个完全形成的
    URL，指定了所有的参数，如货币、限制和聚合等。它最终返回一个 future 对象，该对象将解析响应体并转化为数据模型，价格列表将在上层进行处理：
- en: '[PRE8]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the preceding code segment, the `CryptoCompareResponse` class is the model
    of API, which takes the following parameters:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码段中，`CryptoCompareResponse` 类是 API 的模型，它需要以下参数：
- en: '`Response`'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`响应`'
- en: '`Type`'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`类型`'
- en: '`Aggregated`'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`聚合`'
- en: '`Data`'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`数据`'
- en: '`FirstValueInArray`'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FirstValueInArray`'
- en: '`TimeTo`'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TimeTo`'
- en: '`TimeFrom`'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TimeFrom`'
- en: 'Now, it has the following signature:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，它具有以下签名：
- en: '[PRE9]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Again, the preceding two code segments the **open-high-low-close** (also known
    as **OHLC**), are a model class for mapping with CryptoAPI response `data` array
    internals. It takes these parameters:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 再次说明，前两个代码段中的 **open-high-low-close**（也称为 **OHLC**）是用于与 CryptoAPI 响应的 `data`
    数组内部映射的模型类。它需要这些参数：
- en: '`Time`: Timestamp in seconds, `1508818680`, for instance.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Time`：时间戳（以秒为单位），例如 `1508818680`。'
- en: '`Open`: Open price at a given minute interval.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Open`：给定分钟间隔的开盘价。'
- en: '`High`: Highest price.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`High`：最高价。'
- en: '`Low`: Lowest price.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Low`：最低价。'
- en: '`Close`: Price at the closing of the interval.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Close`：区间结束时的价格。'
- en: '`Volumefrom`: Trading volume in the `from` currency. It''s BTC in our case.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Volumefrom`：`from` 货币的交易量。在我们的例子中是 BTC。'
- en: '`Volumeto`: The trading volume in the `to` currency, USD in our case.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Volumeto`：`to` 货币的交易量，在我们的例子中是 USD。'
- en: Dividing `Volumeto` by `Volumefrom` gives us the weighted price of BTC.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 `Volumeto` 除以 `Volumefrom` 可以给我们带来 BTC 的加权价格。
- en: 'Now, it has the following signature:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，它具有以下签名：
- en: '[PRE10]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Model training for prediction
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测模型训练
- en: 'Inside the project, in the package folder `prediction.training`, there is a
    Scala object called `TrainGBT.scala`. Before launching, you have to specify/change
    four things:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目中，`prediction.training`包下有一个名为`TrainGBT.scala`的Scala对象。在启动之前，你需要指定/更改以下四个设置：
- en: In the code, you need to set up `spark.sql.warehouse.dir` in some actual place
    on your computer that has several gigabytes of free space: `set("spark.sql.warehouse.dir",
    "/home/user/spark")`
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在代码中，你需要设置` spark.sql.warehouse.dir`，将其指向你电脑中某个有足够存储空间的实际路径：`set("spark.sql.warehouse.dir",
    "/home/user/spark")`
- en: The `RootDir` is the main folder, where all files and train models will be `stored:rootDir
    = "/home/user/projects/btc-prediction/"`
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RootDir`是主文件夹，所有文件和训练模型将存储在此处：`rootDir = "/home/user/projects/btc-prediction/"`'
- en: Make sure that the `x` filename matches the one produced by the Scala script
    in the preceding step: `x = spark.read.format("com.databricks.spark.csv ").schema(xSchema).load(rootDir
    + "scala_test_x.csv")`
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保`x`文件名与前一步Scala脚本生成的文件名匹配：`x = spark.read.format("com.databricks.spark.csv
    ").schema(xSchema).load(rootDir + "scala_test_x.csv")`
- en: Make sure that the `y` filename matches the one produced by Scala script: `y_tmp=spark.read.format("com.databricks.spark.csv").schema(ySchema).load(rootDir
    + "scala_test_y.csv")`
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保`y`文件名与Scala脚本生成的文件名匹配：`y_tmp=spark.read.format("com.databricks.spark.csv").schema(ySchema).load(rootDir
    + "scala_test_y.csv")`
- en: The code for training uses the Apache Spark ML library (and libraries required
    for it) to train the classifier, which means they have to be present in your `class`
    path to be able to run it. The easiest way to do that (since the whole project
    uses SBT) is to run it from the project root folder by typing `sbt``run-main prediction.training.TrainGBT`,
    which will resolve all dependencies and launch training.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的代码使用了Apache Spark的ML库（以及为其所需的库）来训练分类器，这意味着这些库必须出现在你的`class`路径中，才能运行它。最简单的做法是（由于整个项目使用SBT），从项目根文件夹运行，输入`
    sbt run-main prediction.training.TrainGBT`，这将解析所有依赖并启动训练。
- en: 'Depending on the number of iterations and depth, it can take several hours
    to train the model. Now let us see how training is performed on the example of
    the gradient-boosted trees model. First, we need to create a `SparkSession` object:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 根据迭代次数和深度的不同，训练模型可能需要几个小时。现在，让我们通过梯度提升树模型的示例来看看训练是如何进行的。首先，我们需要创建一个`SparkSession`对象：
- en: '[PRE11]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Then, we define a schema of data for `x` and `y`. We rename the columns to
    `t0`-`t21,` to indicate that it''s a time series:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义`x`和`y`的数据模式。我们将列重命名为`t0`至`t21`，表示它是时间序列数据：
- en: '[PRE12]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then we read the files we defined for the schema. It was more convenient to
    generate two separate files in Scala for data and labels, so here we have to join
    them into a single DataFrame:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们读取为模式定义的文件。为了方便起见，我们在Scala中生成了两个单独的文件来存储数据和标签，因此这里我们需要将它们合并为一个DataFrame：
- en: '[PRE13]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The next step is required by Spark—we need to vectorize the features:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是Spark要求的——我们需要将特征向量化：
- en: '[PRE14]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We split the data into train and test sets randomly in the proportion of 75%
    to 25%. We set the seed so that the splits would be equal among all times we run
    the training:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据随机拆分为训练集和测试集，比例为75%对25%。我们设置种子，以确保每次运行训练时，数据拆分相同：
- en: '[PRE15]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We then define the model. It tells which columns are features and which are
    labels. It also sets parameters:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义模型。它告诉我们哪些列是特征，哪些是标签，同时设置参数：
- en: '[PRE16]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create a `pipeline` of steps—vector assembling of features and running GBT:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个`pipeline`步骤——特征向量组合和GBT运行：
- en: '[PRE17]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Defining evaluator function—how the model knows whether it is doing well or
    not. As we have only two classes that are imbalanced, accuracy is a bad measurement;
    area under the ROC curve is better:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 定义评估器函数——模型如何知道自己是否表现良好。由于我们只有两个不平衡的类别，准确率是一个不好的衡量标准；ROC曲线下的面积更合适：
- en: '[PRE18]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'K-fold cross-validation is used to avoid overfitting; it takes out one-fifth
    of the data at each iteration, trains the model on the rest, and then tests on
    this one-fifth:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 使用K折交叉验证来避免过拟合；每次迭代会去除五分之一的数据，利用其余数据训练模型，然后在这一五分之一的数据上进行测试：
- en: '[PRE19]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After we get the trained model (which can take an hour or more depending on
    the number of iterations and parameters we want to iterate on, specified in `paramGrid`),
    we then compute the predictions on the test data:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得训练后的模型后（根据迭代次数和我们在`paramGrid`中指定的参数，可能需要一个小时或更长时间），我们接着在测试数据上计算预测结果：
- en: '[PRE20]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In addition, evaluate quality of predictions:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，评估预测的质量：
- en: '[PRE21]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The trained model is saved for later usage by the prediction service:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后的模型将被保存，以便预测服务后续使用：
- en: '[PRE22]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In summary, the code for model training is given as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now let us see how the training went:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Therefore, we have not received very high accuracy, as the ROC is only 60.50%
    out of the best GBT model. Nevertheless, if we tune the hyperparameters, we will
    get better accuracy.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: However, as I did not have enough time, I did not iterate the training for long,
    but you should definitely try.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Scala Play web service
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As an application framework, Play2 was chosen as an easy-to-configure and robust
    framework. Compared to Spring (another popular framework), it takes less time
    to make a small app from scratch. The Play comes with Guice for dependency injection
    and SBT as the package manager:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '**Spark ML**: The Spark ML library was chosen as it is one of the best-maintained
    libraries in the Java world. Many algorithms not available in the library itself
    are implemented by third-party developers and can be trained on top of Spark.
    A drawback of Spark is that it is quite slow, as by design it is supposed to be
    distributed; so it uses Hadoop and writes a lot into the filesystem.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Akka**: This allows implementing the actor''s pattern—having several instances
    of independent objects and passing messages to each other concurrently, which
    increases robustness.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anorm**: The library to work with SQL on top of JDBC. Slick is another option
    and it is more powerful, but compatibility issues between libraries required for
    Akka and Slick made it worth choosing another library.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**H2**: A database that is the default for Play and Ruby-on-Rails as an easy-to-start
    database, with the possibility to store data in a local database file without
    the need to install a DB server. This gives portability and increases the speed
    of development. In later stages, it can be replaced with another, as Scala code
    isn''t tied to any particular database; all of it is done on the configuration
    level.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concurrency through Akka actors
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Concurrency is achieved through utilization of the `actor` model using the
    Akka Scala library. Actors act as independent entities and can pass async messages
    to other actors. In this project, there are three actors: `SchedulerActor`, `PredictionActor`,
    and `TraderActor`:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '`SchedulerActor`: Requests price data, stores them into DB, sends a message
    with prices to `PredictionActor`, receives an answer, and passes it to `TraderActor`.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PredictionActor`: After receiving a message with prices, it predicts the next
    price using the best model available (this has to be chosen in `application.conf`;
    we will see the details later on). It passes a message with the prediction back
    to `SchedulerActor`, uses the rest of the modes from the `model` folder to make
    predictions on previous data, and uses the latest price to evaluate predictions.
    The results of such predictions are stored in the DB.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TraderActor`: After receiving a message about prediction, using `rules` (which
    at this moment are as simple as *buy if the price is predicted to grow **and do
    nothing otherwise*), this writes its decision into logs. It can send an HTTP request
    to a URL to trigger this decision.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web service workflow
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let's take a deeper look into how code works to perform predictions. As
    shown earlier, every 60 seconds, the app is triggered to fetch data from Cryptocompare,
    store prices into the database, and run predictions, saving backtrack test results
    about quality prediction.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll look deeper into which Scala classes play an important
    role in this project and how they communicate.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: JobModule
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When the application is launched, everything starts with `JobModule`. It configures
    the creation of `Scheduler`, which sends messages to `SchedulerActor` as given
    in the `application.conf` rate:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'To enable this module, inside `application.conf`, the following line is required:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Scheduler
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`Scheduler` takes the frequency constant from the `application.conf` and uses
    the `Actor` system to send an `update` message (the content does not matter; `SchedulerActor`
    reacts to any message) to `SchedulerActor` every X seconds:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: SchedulerActor
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The relevant parts of the code are displayed and explained. Now let us see
    how to obtain price data:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '`ConstructUrl` returns a completely formed URL for the request to the Cryptocompare
    API. More details are given in section related to the API:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Creates instances of `PredictionActor` and `TraderActor`:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `Receive` method is defined in the `actor` trait and has to be implemented.
    It is triggered when someone passes a message to this `actor` (`Scheduler` in
    our case):'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'In the preceding code, `case _ =>` means that we react to any message of any
    type and content. The first thing that is done is an async call to the Cryptocompare
    API by the URL specified before. This is done with the help of `RestClient`, which
    returns `Future` with the response JSON. After receiving the response (inside
    `futureResponse` on complete callback), `.json` is mapped into the custom case
    class `CryptoCompareResponse`:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The case class is similar to **POJO** (**Plain Old Java Object**) without the
    need to write constructors and getters/setters:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This companion object is required for mapping JSON into this class. The `CryptocompareResponse`
    object stores the output of the API—a list of OHLC data, time range of data and
    others which that are not relevant to us. The `OHLC` class corresponds to actual
    price data:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'After the data is ready, prices are stored in the DB by calling `storePriceData(cryptoCompareResponse)`.
    At first, it does a batch insert (using Anorm''s **BatchSQL**) into the `PRICE_STAGING`
    table and re-inserts into `PRICE` with deduplication with respect to timestamp,
    as we are receiving overlapping price data:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'After storing into the DB, `SchedulerActor` transforms OHLC data into (timestamp,
    delta) tuples, where delta is (`closePrice`-`openPrice`). So the format is suitable
    for the ML model. The transformed data is passed as a message to `PredictionActor`
    with explicit waiting for a response. This is done by using the `?` operator.
    We ask the prediction `actor`:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Its response is mapped to the `CurrentDataWithShortTermPrediction` class and
    passed to `TraderActor` using the `!` operator. Unlike `?`, the `!` operator does
    not require a response:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This was basic a walkthrough of `SchedulerActor`. We read data from the Cryptocompare
    API, store it into the database, send to `PredictionActor` and wait for its response.
    Then we forward its response to `TraderActor`.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Now let's see what happens inside `PredictionActor`.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: PredictionActor and the prediction step
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Scala web application, which takes the most recent Bitcoin price data on
    the Bitstamp exchange every minute from the Cryptocompare API, uses a trained
    ML classifier to predict the direction of price change for the next minute. It
    notifies the user about the decision.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, to launch it, from a directory with project type `sbt run` (or `$ sudo
    sbt run` when required). Now let us see the contents of the `application.conf`
    file:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now you can understand that there are also several variables to configure/change
    based on your platform and choice:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'Change the `rootDir` directory to the one you have used in `TrainGBT`:'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Specify the name for the database file:'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Specify the version of the model that is used for the actual prediction:'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Note that the folder with such a name has to be inside `rootDir`. So inside
    `rootDir`, create a folder named `models` and copy all the folders of trained
    models there.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: 'This class also implements the `actor` trait and overrides the receive method.
    The best practice for it is to define types that can be received by the `actor`
    inside the companion object, thus establishing an interface for other classes:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'At first, `PredictionActor` loads a list of models from the `models` folder
    and loads the `etalon` model:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'First, we extract a list of subdirectories inside the `models` folder, and
    from each of them, we load the trained `PipeLine` model. In a similar way, the `etalon` model
    is loaded, but we already know its directory. Here''s how a message of the `PriceData`
    type is handled inside the `receive` method:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The predicted label (string) and classification details are logged, so is it
    possible to see the probability distribution for each class? If the `actor` receives
    a message of another type, an error is shown and nothing more is done. Then the
    results are sent back to `SchedulerActor` and sent in the variable `predictedWithCurrent`,
    as was shown in the preceding code:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The `sender` is an `ActorRef` reference to an object that has sent the message
    we are processing at the moment, so we can pass the message back with the `!` operator.
    Then, for each model we have loaded in the beginning, we predict the label for
    1-minute-old data (rows 0-21 out of 23 in total) and get the actual price delta
    for the latest minute we know:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'For each model, we store the following in the DB name of the model: the timestamp
    for each test prediction made, the label that was predicted by the model, and
    the actual delta. This information is used later to generate reports on the model''s
    performance:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: TraderActor
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`TraderActor` receives the prediction and, based on the label, writes a log
    message. It can trigger an HTTP request to the specified endpoint:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Predicting prices and evaluating the model
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`ShortTermPredictionServiceImpl` is the class that actually performs the prediction
    with the given model and data. At first, it transforms `PriceData` into a Spark
    DataFrame with the scheme corresponding to the one used for training by calling
    `transformPriceData(priceData: PriceData)`*.* Then, the `model.transform(dataframe)`
    method is called; we extract the variables we need, write into the debugger log
    and return to the caller:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'While running, the application collects data about the prediction output: predicted
    label and actual price delta. This information is used to build the root web page,
    displaying statistics such as **TPR** (**true positive rate**), **FPR** (**false
    positive rate**), **TNR** (**true negative rate**), and **FNR **(**false negative
    rate**), which were described earlier.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: 'These statistics are counted on the fly from the `SHORT_TERM_PREDICTION_BINARY`
    table. Basically, by using the `CASE-WHEN` construction, we add new columns: TPR,
    FPR, TNR, and FNR. They are defined as follows:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: TPR with value `1` if the predicted label was 1 and price delta was > `0`, and
    value `0` otherwise
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FPR with value `1` if the predicted label was 1 and price delta was <= `0`,
    and value `0` otherwise
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TNR with value `1` if the predicted label was 0 and price delta was <= `0`,
    and value `0` otherwise
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FNR with value `1` if the predicted label was 0 and price delta was > `0`, and
    value 0 otherwise
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, all records are grouped by model name, and TPR, FPR, TNR, and FNR are
    summed up, giving us the total numbers for each model. Here is the SQL code responsible
    for this:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Demo prediction using Scala Play framework
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have seen all the steps for this project, it's time to see a live
    demo. We will wrap up the whole application as a Scala Play web app. Well, before
    seeing the demo, let's get our project up and running. However knowing some basic
    of RESTful architecture using Scala Play would be helpful.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: Why RESTful architecture?
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Well, Play’s architecture is RESTful by default. At its core, Play is based
    on the Model-View-Controller pattern. Each entry point, paired with an HTTP verb,
    maps to a Controller function. The controller enables views to be web pages, JSON,
    XML, or just about anything else.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: Play’s stateless architecture enables horizontal scaling, ideal for serving
    many incoming requests without having to share resources (such as a session) between
    them. It is at the forefront of the Reactive programming trend, in which servers
    are event-based and parallel processing is used to cater to the ever-increasing
    demands of modern websites.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: In certain configurations, Play enables fully asynchronous and non-blocking
    I/O throughout the entire application. The purpose is to reach new heights in
    terms of scalability on the web through efficient thread management and parallel
    processing, while avoiding the **callback hell** that JavaScript-based solutions
    tend to engender.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: AngularJs is a JavaScript-based open-source front-end web application framework
    mainly maintained by Google and by a community of individuals and corporations
    to address many of the challenges encountered in developing single-page applications.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: Now question would be why AngularJS? Well, HTML is great for declaring static
    documents, but it falters when we try to use it for declaring dynamic views in
    web-applications. AngularJS lets you extend HTML vocabulary for your application.
    The resulting environment is extraordinarily expressive, readable, and quick to
    develop.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Another question would be, are not there any alternatives? Well**,** other frameworks
    deal with HTML’s shortcomings by either abstracting away HTML, CSS, and/or JavaScript
    or by providing an imperative way for manipulating the DOM. Neither of these address
    the root problem that HTML was not designed for dynamic views.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Finally, what is about the extensibility? Well, AngularJS is a toolset for building
    the framework most suited to your application development. It is fully extensible
    and works well with other libraries. Every feature can be modified or replaced
    to suit your unique development workflow and feature needs. Read on to find out
    how.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Project structure
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The wrapped up Scala web ML app has the following directory structure:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7fa0cf7c-e77e-4a59-aec0-98d57b3b2c98.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Scala ML web app directory structure'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding structure, `bitcoin_ml` folder has all the backend and frontend
    codes. The `models` folder has all the trained models. An example-trained model
    is given in the `gbt_22_binary_classes_32660767` folder. Finally, database files
    and traces are there in the `DataBase.mv.db` and `DataBase.trace.db` files respectively.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'Then let us see the sub-folder structure of the `bitcoin_ml` folder that contains
    the actual codes:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/90451c79-4115-4029-8ed0-e73b57b18799.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
- en: Figure 8: The bitcoin_ml directory structure
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding figure, the `conf` folder has the Scala web app configuration
    file, `application.conf` containing necessary configurations (as shown already).
    All the dependencies are defined in the `build.sbt` fileshown as follows*:*
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: To be frank, at the beginning of writing, I did not think of wrapping up this
    application as a Scala Play web app. Therefore, things went a bit unstructured.
    However, do not worry to know more about backend as well frontend, refer to the
    options trading application in [Chapter 7](c4a322da-d64b-4c40-a5b8-7ffec8381b41.xhtml),
    *Options Trading Using Q-Learning and Scala Play Framework*.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Running the Scala Play web app
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To run the application, just follow these steps:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Download the historical Bitcoin data from [https://www.kaggle.com/mczielinski/bitcoin-historical-data](https://www.kaggle.com/mczielinski/bitcoin-historical-data).
    Then unzip and extract the `.csv` file.
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open your preferred IDE (for example, Eclipse/IntelliJ) and create the Maven
    or SBT project.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the `Preprocess.scala` script to convert the historical data into a time
    series. This script should generate two `.csv` files (that is, `scala_test_x.csv`
    and `scala_test_y.csv`).
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then train the `GradientBoostedTree` model (use `TrainGBT.scala` script) using
    the previously generated files.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the best (i.e. cross-validated) `Pipeline` model containing all the pipelines'
    steps.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then download the Scala Play app and all the files (that is, `Bitcoin_price_prediction`)
    from the Packt repository or GitHub (see in the book).
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then copy the trained model to `Bitcoin_price_prediction/models/`.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then:  `$ cd Bitcoin_price_prediction/bitcoin_ml/conf/` and update the parameter
    values in the `application.conf` as shown earlier.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, run the project using the `$ sudo sbt run` command.
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After launching with `$ sudo sbt run`, the application will read all models
    from the `models` folder, the `etalon` model being specified by `ml.model_version`.
    Every 30 seconds (specified in `constants.frequency = 30` in `application.conf`),
    the latest price data is retrieved from the Cryptocompare API. A prediction using
    the `etalon` model is made and the results are shown to the user in the form of
    a log message in the console, with the possibility to trigger an HTTP request
    to the specified endpoint.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, all models from the `models` folder are used to make a prediction
    on the previous 22-minute data and use the latest price data for a current minute
    as a way to check the quality of predictions. All predictions made by each model
    are stored in a database file. When a user visits `http://localhost:9000`, a table
    with a summary of predictions is shown to the user:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Model name
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TPR, (not rate actually, in this case, just raw count) - how many times model
    predicted that price would increase and how many times that was true
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FPR,  how many times model has predicted price increase, but price dropped or
    stayed the same
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TNR, how many times model predicted non-increase of price and was correct
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FNR, how many times model predicted non-increase of price and was wrong
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Total count of predictions made by the model
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alright, here we go, after launching the app using `$` sudo sbt `run` (on a
    terminal):'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a475c8d5-3fd1-4ab5-b796-7350d540ee9f.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Sample signals generated by the model based on historical prices
    and live data'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding figure shows some sample signals generated by our model based
    on historical prices and live data. Additionally, we can see the raw prediction
    by the model. When you try to access the app from your browser at `http://localhost:9000`,
    you should see this (the count will increase with time, though):'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5876680a-d23f-4462-b4e1-4cda118482a4.png)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Model performance using the Scala Play2 framework'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding figure, the performance is not satisfactory, but I would suggest
    that you train the model with the most suitable hyperparameters and for more iterations,
    for example, 10,000 times. Additionally, in the next section, I tried to provide
    some more insights and improvement guidelines.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: Finally, if you plan to deploy this application after making some extension
    (if any), then I would suggest to take a quick look at the last section in [Chapter
    7](c4a322da-d64b-4c40-a5b8-7ffec8381b41.xhtml), *Options Trading Using Q-Learning
    and Scala Play Framework*, where you will find deployment guideline on server
    to be exposed as web app.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, a complete ML pipeline was implemented, from collecting historical
    data, to transforming it into a format suitable for testing hypotheses, training
    ML models, and running a prediction on `Live` data, and with the possibility to
    evaluate many different models and select the best one.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: The test results showed that, as in the original dataset, about 600,000 minutes
    out of 2.4 million can be classified as **increasing price** (close price was
    higher than open price); the dataset can be considered imbalanced. Although random
    forests are usually performed well on an imbalanced dataset, the area under the
    ROC curve of 0.74 isn't best. As we need to have fewer false positives (fewer
    times when we trigger **purchase** and the price drops), we might consider a punishing
    model for such errors in a stricter way.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: 'Although the results achieved by classifiers can''t be used for profitable
    trading, there is a foundation on top of which new approaches can be tested in
    a relatively rapid way. Here, some possible directions for further development
    are listed:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: 'Implementation of the pipeline discussed in the beginning: Convert your time
    series data into several clusters and train the regression model/classifier for
    each of them; then classify recent data into one of the clusters and use the prediction
    model trained for that cluster. As by definition, ML is **deriving patterns from
    data**, there might not be only one pattern that fits all of the history of Bitcoin;
    that''s why we need to understand that a market can be in different phases, and
    each phase has its own pattern.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the major challenges with Bitcoin price prediction might be that the
    training data (historical) doesn't belong to the same distribution as test data
    during random splits into train-test sets. As the patterns in price changed during
    2013 and 2016, they might belong to completely different distributions. It might
    require a manual inspection of data and some infographics. Probably, someone has
    already done this research.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the main things to try would be to train two **one-versus-all** classifiers:
    one is trained to predict when the price grows higher than 20$, for example. Another
    predicts when the price drop by 20$; so it makes sense to take long/short positions,
    respectively.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maybe, predicting the delta of the next minute isn't what we need; we'd rather
    predict the average price. As the Open price can be much higher than last minute's
    Close price, and the Close price of the next minute can be slightly less than
    open but still higher than current, it would make it profitable trade. So how
    to exactly label data is also an open question.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Try with different time-series window size (even 50 minutes might suit) using
    ARIMA time series prediction model, as it is one of the most widely used algorithms.
    Then try to predict price change, not for the next minute but for 2-3 following
    minutes. Additionally, try by incorporating trading volume as well.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Label the data as **price increased** if the price was higher by 20$ during
    at least one of three following minutes so that we can make a profit from trade.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Currently, `Scheduler` isn't synchronized with Cryptocompare minutes. This means
    we can get data about the minute interval 12:00:00 - 12:00:59 at any point of
    the following minute - 12:01:00 or 12:01:59\. In the latter case, it doesn't make
    sense to make trade, as we made a prediction based on already **old **data.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instead of making a prediction every minute on **older** data to accumulate
    prediction results for `actor`, it's better to take maximum available HistoMinute
    data (seven days), split it into time series data using a Scala script that was
    used for historical data, and predict for seven days' worth of data. Run this
    as a scheduled job once a day; it should reduce the load on the DB and `PredictionActor`.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Compared to usual datasets, where the order of rows doesn''t matter much, in
    Bitcoin, historical data rows are sorted by ascending order of date, which means
    that:'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Latest data might be more relevant to today's price, and less can be more; taking
    a smaller subset of data might give better performance
  id: totrans-340
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The ways of subsampling data can matter (splitting into train-test sets)
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally try with LSTM network for even better predictive accuracy (see chapter
    10 for some clue)
  id: totrans-342
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The understanding of variations in genome sequences assists us in identifying
    people who are predisposed to common diseases, solving rare diseases, and finding
    the corresponding population group of individuals from a larger population group.
    Although classical ML techniques allow researchers to identify groups (clusters)
    of related variables, the accuracy and effectiveness of these methods diminish
    for large and high-dimensional datasets such as the whole human genome. On the
    other hand, deep neural network architectures (the core of deep learning) can
    better exploit large-scale datasets to build complex models.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how to apply the K-means algorithm on large-scale
    genomic data from the 1,000 Genomes Project aiming at clustering genotypic variants
    at the population scale. Then we'll train an H2O-based deep learning model for
    predicting geographic ethnicity. Finally, Spark-based Random Forest will be used
    to enhance the predictive accuracy.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
