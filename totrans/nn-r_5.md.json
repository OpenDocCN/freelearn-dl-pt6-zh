["```py\n###########################################################################\n########Chapter 5 - Introduction to Neural Networks - using R############## \n##########R program to build, train and test neural networks############### \n###########################################################################\nlibrary(\"neuralnet\")\nlibrary(\"ISLR\")\n\ndata = Auto\nView(data)\n\nplot(data$weight, data$mpg, pch=data$origin,cex=2)\npar(mfrow=c(2,2))\nplot(data$cylinders, data$mpg, pch=data$origin,cex=1)\nplot(data$displacement, data$mpg, pch=data$origin,cex=1)\nplot(data$horsepower, data$mpg, pch=data$origin,cex=1)\nplot(data$acceleration, data$mpg, pch=data$origin,cex=1)\n\nmean_data <- apply(data[1:6], 2, mean)\nsd_data <- apply(data[1:6], 2, sd)\n\ndata_scaled <- as.data.frame(scale(data[,1:6],center = mean_data, scale = sd_data))\nhead(data_scaled, n=20)\n\nindex = sample(1:nrow(data),round(0.70*nrow(data)))\ntrain_data <- as.data.frame(data_scaled[index,])\ntest_data <- as.data.frame(data_scaled[-index,])\n\nn = names(data_scaled)\nf = as.formula(paste(\"mpg ~\", paste(n[!n %in% \"mpg\"], collapse = \" + \")))\n\nnet = neuralnet(f,data=train_data,hidden=3,linear.output=TRUE)\nplot(net)\n\npredict_net_test <- compute(net,test_data[,2:6])\nMSE.net <- sum((test_data$mpg - predict_net_test$net.result)^2)/nrow(test_data)\n\nLm_Mod <- lm(mpg~., data=train_data)\nsummary(Lm_Mod)\npredict_lm <- predict(Lm_Mod,test_data)\nMSE.lm <- sum((predict_lm - test_data$mpg)^2)/nrow(test_data)\n\npar(mfrow=c(1,2))\nplot(test_data$mpg,predict_net_test$net.result,col='black',main='Real vs predicted for neural network',pch=18,cex=4)\nabline(0,1,lwd=5)\nplot(test_data$mpg,predict_lm,col='black',main='Real vs predicted for linear regression',pch=18,cex=4)\nabline(0,1,lwd=5)\n###########################################################################\n```", "```py\nlibrary(\"neuralnet\")\nlibrary(\"ISLR\")\n```", "```py\ndata = Auto\nView(data)\n```", "```py\nplot(data$weight, data$mpg, pch=data$origin,cex=2)\n```", "```py\npar(mfrow=c(2,2))\nplot(data$cylinders, data$mpg, pch=data$origin,cex=1)\nplot(data$displacement, data$mpg, pch=data$origin,cex=1)\nplot(data$horsepower, data$mpg, pch=data$origin,cex=1)\nplot(data$acceleration, data$mpg, pch=data$origin,cex=1)\n```", "```py\nmean_data <- apply(data[1:6], 2, mean)\nsd_data <- apply(data[1:6], 2, sd)\n```", "```py\n> mean_data\n mpg    cylinders displacement   horsepower       weight \n 23.445918     5.471939   194.411990   104.469388  2977.584184 \nacceleration\n 15.541327\n```", "```py\n> sd_data\n mpg    cylinders displacement    horsepower       weight \n 7.805007     1.705783    04.644004     38.491160   849.402560 \nacceleration\n 2.758864\n```", "```py\ndata_scaled <- as.data.frame(scale(data[,1:6],center = mean_data, scale = sd_data))\n```", "```py\nhead(data_scaled, n=20)\n```", "```py\n> head(data_scaled, n=20)\n mpg  cylinders displacement horsepower     weight acceleration\n1  -0.69774672  1.4820530   1.07591459  0.6632851  0.6197483  -1.28361760\n2  -1.08211534  1.4820530   1.48683159  1.5725848  0.8422577  -1.46485160\n3  -0.69774672  1.4820530   1.18103289  1.1828849  0.5396921  -1.64608561\n4  -0.95399247  1.4820530   1.04724596  1.1828849  0.5361602  -1.28361760\n5  -0.82586959  1.4820530   1.02813354  0.9230850  0.5549969  -1.82731962\n6  -1.08211534  1.4820530   2.24177212  2.4299245  1.6051468  -2.00855363\n7  -1.21023822  1.4820530   2.48067735  3.0014843  1.6204517  -2.37102164\n8  -1.21023822  1.4820530   2.34689042  2.8715843  1.5710052  -2.55225565\n9  -1.21023822  1.4820530   2.49023356  3.1313843  1.7040399  -2.00855363\n10 -1.08211534  1.4820530   1.86907996  2.2220846  1.0270935  -2.55225565\n11 -1.08211534  1.4820530   1.80218649  1.7024847  0.6892089  -2.00855363\n12 -1.21023822  1.4820530   1.39126949  1.4426848  0.7433646  -2.73348966\n13 -1.08211534  1.4820530   1.96464205  1.1828849  0.9223139  -2.18978763\n14 -1.21023822  1.4820530   2.49023356  3.1313843  0.1276377  -2.00855363\n15  0.07099053 -0.8629108  -0.77799001 -0.2460146 -0.7129531  -0.19621355\n16 -0.18525522  0.3095711   0.03428778 -0.2460146 -0.1702187  -0.01497955\n17 -0.69774672  0.3095711   0.04384399 -0.1940546 -0.2396793  -0.01497955\n18 -0.31337809  0.3095711   0.05340019 -0.5058145 -0.4598340   0.16625446\n19  0.45535916 -0.8629108  -0.93088936 -0.4278746 -0.9978592  -0.37744756\n20  0.32723628 -0.8629108  -0.93088936 -1.5190342 -1.3451622   1.79736053\n```", "```py\nindex = sample(1:nrow(data),round(0.70*nrow(data)))\ntrain_data <- as.data.frame(data_scaled[index,])\ntest_data <- as.data.frame(data_scaled[-index,])\n```", "```py\nn = names(data_scaled)\nf = as.formula(paste(\"mpg ~\", paste(n[!n %in% \"mpg\"], collapse = \" + \")))\n```", "```py\n> f\nmpg ~ cylinders + displacement + horsepower + weight + acceleration\n```", "```py\nnet = neuralnet(f,data=train_data,hidden=3,linear.output=TRUE)\n```", "```py\n> summary(net)\n Length Class      Mode \ncall                   5   -none-     call \nresponse             274   -none-     numeric\ncovariate           1370   -none-     numeric\nmodel.list             2   -none-     list \nerr.fct                1   -none-     function\nact.fct                1   -none-     function\nlinear.output          1   -none-     logical\ndata                   6   data.frame list \nnet.result             1   -none-     list \nweights                1   -none-     list \nstartweights           1   -none-     list \ngeneralized.weights    1   -none-     list \nresult.matrix         25   -none-     numeric \n```", "```py\nplot(net)\n```", "```py\n> net$result.matrix\n 1\nerror                      21.800203210980\nreached.threshold           0.009985137179\nsteps                    9378.000000000000\nIntercept.to.1layhid1      -1.324633695625\ncylinders.to.1layhid1       0.291091600669\ndisplacement.to.1layhid1   -2.243406161080\nhorsepower.to.1layhid1      0.616083122568\nweight.to.1layhid1          1.292334492287\nacceleration.to.1layhid1   -0.286145921068\nIntercept.to.1layhid2     -41.734205163355\ncylinders.to.1layhid2      -5.574494023650\ndisplacement.to.1layhid2   33.629686446649\nhorsepower.to.1layhid2    -28.185856598271\nweight.to.1layhid2        -50.822997942647\nacceleration.to.1layhid2   -5.865256284330\nIntercept.to.1layhid3       0.297173606203\ncylinders.to.1layhid3       0.306910802417\ndisplacement.to.1layhid3   -5.897977831914\nhorsepower.to.1layhid3      0.379215333054\nweight.to.1layhid3          2.651777936654\nacceleration.to.1layhid3   -1.035618563747\nIntercept.to.mpg           -0.578197055155\n1layhid.1.to.mpg           -3.190914666614\n1layhid.2.to.mpg            0.714673177354\n1layhid.3.to.mpg            1.958297807266\n```", "```py\npredict_net_test <- compute(net,test_data[,2:6])\n```", "```py\nMSE.net <- sum((test_data$mpg - predict_net_test$net.result)^2)/nrow(test_data)\n```", "```py\n> MSE.net\n[1] 0.2591064572\n```", "```py\nLm_Mod <- lm(mpg~., data=train_data)\nsummary(Lm_Mod)\n```", "```py\n> summary(Lm_Mod)\nCall:\nlm(formula = mpg ~ ., data = train_data)\nResiduals:\n Min          1Q      Median          3Q         Max\n-1.48013031 -0.34128989 -0.04310873  0.27697893  1.77674878\nCoefficients:\n Estimate  Std. Error  t value        Pr(>|t|) \n(Intercept)   0.01457260  0.03268643  0.44583        0.656080 \ncylinders    -0.14056198  0.10067461 -1.39620        0.163809 \ndisplacement  0.06316568  0.13405986  0.47118        0.637899 \nhorsepower   -0.16993594  0.09180870 -1.85098        0.065273 . \nweight       -0.59531412  0.09982123 -5.96380 0.0000000077563 ***\nacceleration  0.03096675  0.05166132  0.59942        0.549400 \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\nResidual standard error: 0.5392526 on 268 degrees of freedom\nMultiple R-squared:  0.7183376, Adjusted R-squared:  0.7130827\nF-statistic: 136.6987 on 5 and 268 DF,  p-value: < 0.00000000000000022204\n```", "```py\npredict_lm <- predict(Lm_Mod,test_data)\n```", "```py\nMSE.lm <- sum((predict_lm - test_data$mpg)^2)/nrow(test_data)\n```", "```py\n> MSE.lm\n[1] 0.3124200509\n```", "```py\npar(mfrow=c(1,2))\n\nplot(test_data$mpg,predict_net_test$net.result,col='black',main='Real vs predicted for neural network',pch=18,cex=4)\nabline(0,1,lwd=5)\n\nplot(test_data$mpg,predict_lm,col='black',main='Real vs predicted for linear regression',pch=18,cex=4)\nabline(0,1,lwd=5)\n```", "```py\n###########################################################################\n########Chapter 5 - Introduction to Neural Networks - using R############## \n####################Classifing breast cancer with R######################## \n########################################################################### \nlibrary(\"mlbench\")\nlibrary(neuralnet)\n\ndata(BreastCancer)\nsummary(BreastCancer)\n\nmvindex = unique (unlist (lapply (BreastCancer, function (x) which (is.na (x)))))\ndata_cleaned <- na.omit(BreastCancer) \nsummary(data_cleaned)\n\nboxplot(data_cleaned[,2:10])\nhist(as.numeric(data_cleaned$Mitoses))\n\npar(mfrow=c(3, 3))\nhist(as.numeric(data_cleaned$Cl.thickness))\nhist(as.numeric(data_cleaned$Cell.size))\nhist(as.numeric(data_cleaned$Cell.shape))\nhist(as.numeric(data_cleaned$Marg.adhesion))\nhist(as.numeric(data_cleaned$Epith.c.size))\nhist(as.numeric(data_cleaned$Bare.nuclei))\nhist(as.numeric(data_cleaned$Bl.cromatin))\nhist(as.numeric(data_cleaned$Normal.nucleoli))\nhist(as.numeric(data_cleaned$Mitoses))\n\nstr(data_cleaned)\ninput<-data_cleaned[,2:10]\nindx <- sapply(input, is.factor)\ninput <- as.data.frame(lapply(input, function(x) as.numeric(as.character(x))))\n\nmax_data <- apply(input, 2, max)\nmin_data <- apply(input, 2, min)\ninput_scaled <- as.data.frame(scale(input,center = min_data, scale = max_data - min_data))\nView(input_scaled)\n\nCancer<-data_cleaned$Class\nCancer<-as.data.frame(Cancer)\nCancer<-with(Cancer, data.frame(model.matrix(~Cancer+0)))\n\nfinal_data<-as.data.frame(cbind(input_scaled,Cancer))\n\nindex = sample(1:nrow(final_data),round(0.70*nrow(final_data)))\ntrain_data <- as.data.frame(final_data[index,])\ntest_data <- as.data.frame(final_data[-index,])\n\nn = names(final_data[1:9])\nf = as.formula(paste(\"Cancerbenign + Cancermalignant ~\", paste(n, collapse = \" + \")))\n\nnet = neuralnet(f,data=train_data,hidden=5,linear.output=FALSE)\nplot(net)\n\npredict_net_test <- compute(net,test_data[,1:9])\npredict_result<-round(predict_net_test$net.result, digits = 0)\nnet.prediction = c(\"benign\", \"malignant\")[apply(predict_result, 1, which.max)]\npredict.table = table(data_cleaned$Class[-index], net.prediction)\npredict.table\n\nlibrary(gmodels)\nCrossTable(x = data_cleaned$Class[-index], y = net.prediction,\n prop.chisq=FALSE)\n###########################################################################\n```", "```py\nlibrary(\"mlbench\")\nlibrary(\"neuralnet\")\n```", "```py\ndata(BreastCancer)\n```", "```py\nsummary(BreastCancer)\n```", "```py\nmvindex = unique (unlist (lapply (BreastCancer, function (x) which (is.na (x)))))\n```", "```py\n> mvindex\n [1] 24 41 140 146 159 165 236 250 276 293 295 298 316 322 412 618\n```", "```py\ndata_cleaned <- na.omit(BreastCancer) \n```", "```py\nsummary(data_cleaned)\n```", "```py\nboxplot(data_cleaned[,2:10])\n```", "```py\npar(mfrow=c(3, 3))\nhist(as.numeric(data_cleaned$Cl.thickness))\nhist(as.numeric(data_cleaned$Cell.size))\nhist(as.numeric(data_cleaned$Cell.shape))\nhist(as.numeric(data_cleaned$Marg.adhesion))\nhist(as.numeric(data_cleaned$Epith.c.size))\nhist(as.numeric(data_cleaned$Bare.nuclei))\nhist(as.numeric(data_cleaned$Bl.cromatin))\nhist(as.numeric(data_cleaned$Normal.nucleoli))\nhist(as.numeric(data_cleaned$Mitoses))\n```", "```py\nstr(data_cleaned)\n```", "```py\ninput<-data_cleaned[,2:10]\nindx <- sapply(input, is.factor)\ninput <- as.data.frame(lapply(input, function(x) as.numeric(as.character(x))))\n```", "```py\nmax_data <- apply(data_cleaned[,2:10], 2, max)\n```", "```py\nmin_data <- apply(data_cleaned[,2:10], 2, min)\n```", "```py\ndata_scaled <- scale(data_cleaned[,2:10],center = min_data, scale = max_data - min_data)\n```", "```py\nCancer<-data_cleaned$Class\nCancer<-as.data.frame(Cancer)\nCancer<-with(Cancer, data.frame(model.matrix(~Cancer+0)))\n```", "```py\nfinal_data<-as.data.frame(cbind(input_scaled,Cancer))\n```", "```py\nindex = sample(1:nrow(final_data),round(0.70*nrow(final_data)))\ntrain_data <- as.data.frame(final_data[index,])\ntest_data <- as.data.frame(final_data[-index,])\n```", "```py\nn = names(final_data[1:9])\nf = as.formula(paste(\"Cancerbenign + Cancermalignant ~\", paste(n, collapse = \" + \")))\n```", "```py\n> f\nCancerbenign + Cancermalignant ~ Cl.thickness + Cell.size + Cell.shape + \n Marg.adhesion + Epith.c.size + Bare.nuclei + Bl.cromatin + \n Normal.nucleoli + Mitoses\n```", "```py\nnet = neuralnet(f,data=train_data,hidden=5,linear.output=FALSE)\n```", "```py\nplot(net)\n```", "```py\npredict_net_test <- compute(net,test_data[,1:9])\n```", "```py\n> head(predict_net_test$net.result,n=10)\n [,1]                       [,2]\n1  0.9999999935589190 0.000000003587253510720848\n2  0.0000011083596034 0.999999376764558189911725\n4  0.9792070465712006 0.017164709664531079685856\n5  0.9999999746453074 0.000000021909385204003642\n9  0.9999993390597798 0.000000327298596658228207\n14 0.9999999999953126 0.000000000000889095157872\n17 0.9999999999989946 0.000000000000442776879837\n19 0.0000001409393993 0.999999920006766185309743\n21 0.0000024771345578 0.999998553964539960148272\n23 0.9999999999999967 0.000000000000001305142352\n```", "```py\npredict_result<-round(predict_net_test$net.result, digits = 0)\n```", "```py\nnet.prediction = c(\"benign\", \"malignant\")[apply(predict_result, 1, which.max)]\n```", "```py\npredict.table = table(data_cleaned$Class[-index], net.prediction)\n```", "```py\n> predict.table\n net.prediction\n benign malignant\n benign       132         5\n malignant      3        65\n```", "```py\nlibrary(gmodels)\nCrossTable(x = data_cleaned$Class[-index], y = net.prediction,\n prop.chisq=FALSE)\n```"]