<html><head></head><body>
		<div id="_idContainer005" class="Content">
			<h1 id="_idParaDest-1"><em class="italics"><a id="_idTextAnchor000"/>Preface</em></h1>
		</div>
		<div>
			<div id="_idContainer006" class="Content">
			</div>
		</div>
		<div id="_idContainer007" class="Content">
			<h2><a id="_idTextAnchor001"/>About</h2>
			<p>This section briefly introduces the author, the coverage of this book, the technical skills you'll need to get started, and the hardware and software requirements required to complete all of the included activities and exercises.</p>
		</div>
		<div id="_idContainer012" class="Content">
			<h2 id="_idParaDest-2"><a id="_idTextAnchor002"/>About the Book</h2>
			<p><em class="italics">Artificial Vision and Language Processing for Robotics</em> begins by discussing the theory behind robots. You’ll compare different methods used to work with robots and explore computer vision, its algorithms, and limits. You’ll then learn how to control the robot with natural language processing commands. As you make your way through this book, you’ll study Word2Vec and GloVe embedding techniques, non-numeric data, as well as recurrent neural networks (RNNs) and their advanced models. You’ll create a simple Word2Vec model with Keras, build a convolutional neural network (CNN), and improve it with data augmentation and transfer learning. You’ll walk through ROS and build a conversational agent to manage your robot. You’ll also integrate your agent with ROS and convert an image to text and text to speech. You’ll learn how to build an object recognition system with the help of a video clip.</p>
			<p>By the end of this book, you’ll have the skills you need to build a functional application that can integrate with ROS to extract useful information from your environment.</p>
			<h3 id="_idParaDest-3"><a id="_idTextAnchor003"/>About the Authors</h3>
			<p><strong class="bold">Álvaro Morena Alberola</strong> is a computer engineer and loves robotics and artificial intelligence. Currently, he is working as a software developer. He is extremely interested in the core part of AI, which is based on artificial vision. Álvaro likes working with new technologies and learning how to use advanced tools. He perceives robotics as a way of easing human lives; a way of helping people perform tasks that they cannot do on their own.</p>
			<p><strong class="bold">Gonzalo Molina Gallego</strong> is a computer science graduate and specializes in artificial intelligence and natural language processing. He has experience of working on text-based dialog systems, creating conversational agents, and advising good methodologies. Currently, he is researching new techniques on hybrid-domain conversational systems. Gonzalo thinks that conversational user interfaces are the future.</p>
			<p><strong class="bold">Unai Garay Maestre</strong> is a computer science graduate and specializes in the field of artificial intelligence and computer vision. He successfully contributed to the CIARP conference of 2018 with a paper that takes a new approach to data augmentation using variational autoencoders. He also works as a machine learning developer using deep neural networks applied to images.</p>
			<h3 id="_idParaDest-4"><a id="_idTextAnchor004"/>Objectives</h3>
			<ul>
				<li>Explore ROS and build a basic robotic system</li>
				<li>Identify conversation intents with NLP techniques</li>
				<li>Learn and use word embedding with Word2Vec and GloVe</li>
				<li>Use deep learning to implement artificial intelligence (AI) and object recognition</li>
				<li>Develop a simple object recognition system using CNNs</li>
				<li>Integrate AI with ROS to enable your robot to recognize objects</li>
			</ul>
			<h3 id="_idParaDest-5"><a id="_idTextAnchor005"/>Audience</h3>
			<p><em class="italics">Artificial Vision and Language Processing for Robotics</em> is for robotics engineers who want to learn how to integrate computer vision and deep learning techniques to create complete robotic systems. It will be beneficial if you have a working knowledge of Python and a background in deep learning. Knowledge of ROS is a plus.</p>
			<h3 id="_idParaDest-6"><a id="_idTextAnchor006"/>Approach</h3>
			<p><em class="italics">Artificial Vision and Language Processing for Robotics</em> takes a practical approach to equip you with tools for creating systems that integrate computer vision and NLP to control a robot. The book is divided into three parts: NLP, computer vision, and robotics. It introduces advanced topics after a detailed introduction to the basics. It also contains multiple activities for you to practice and apply your new skills in a highly relevant context.</p>
			<h3 id="_idParaDest-7"><a id="_idTextAnchor007"/>Minimum Hardware Requirements</h3>
			<p>For the optimal student experience, we recommend the following hardware configuration:</p>
			<ul>
				<li>Processor: 2GHz dual core processor or better</li>
				<li>Memory: 8 GB RAM</li>
				<li>Storage: 5 GB available hard disk space</li>
				<li>A good internet connection</li>
			</ul>
			<p>To train neural networks, we recommend using <strong class="bold">Google Colab</strong>. But if you want to train these networks with your computer, you will need:</p>
			<ul>
				<li>NVIDIA GPU</li>
			</ul>
			<h3 id="_idParaDest-8"><a id="_idTextAnchor008"/>Software Requirements</h3>
			<p>We don’t recommend using Ubuntu 16.04 for this book because of compatibility issues with ROS Kinetic. But if you want to use Ubuntu 18.04, there is a version that is ROS supported, named Melodic. During the project, you will need to install several libraries to complete all of the exercises, such as <strong class="inline">NLTK</strong> (&lt;= 3.4), <strong class="inline">spaCy</strong> (&lt;=2.0.18), <strong class="inline">gensim</strong> (&lt;=3.7.0), <strong class="inline">NumPy</strong> (&lt;=1.15.4), <strong class="inline">sklearn</strong> (&lt;=0.20.1), <strong class="inline">Matplotlib</strong> (&lt;=3.0.2), <strong class="inline">OpenCV</strong> (&lt;=4.0.0.21), <strong class="inline">Keras</strong> (&lt;=2.2.4), and <strong class="inline">Tensorflow</strong> (&lt;=1.5, &gt;=2.0). The installation process for each library is explained in the exercises.</p>
			<p>To use YOLO in your Ubuntu system, you will need to install the <strong class="bold">NVIDIA</strong> drivers of your GPU and the NVIDIA <strong class="bold">CUDA</strong> toolkit.</p>
			<h3 id="_idParaDest-9"><a id="_idTextAnchor009"/>Conventions</h3>
			<p>Code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "With the <strong class="inline">TfidfVectorizer </strong>method, we can convert the collection of documents in our corpus to a matrix of TF-IDF features"</p>
			<p>A block of code is set as follows:</p>
			<p class="snippet">vectorizer = TfidfVectorizer()</p>
			<p class="snippet">X = vectorizer.fit_transform(corpus)</p>
			<p>New terms and important words are shown in bold. Words that you see on the screen, for example, in menus or dialog boxes, appear in the text like this: "<strong class="bold">Morphological analysis</strong>: Focused on the words of a sentence and analyzing its morphemes"</p>
			<h3 id="_idParaDest-10"><a id="_idTextAnchor010"/>Installation and Setup</h3>
			<p>Before you start this book, you need to install the following software. You will find the steps to install these here:</p>
			<p><strong class="bold">Installing Git LFS</strong></p>
			<p>In order to download all the resources from the GitHub of this book and be able to use images to train your neural network model, you will need to install <strong class="bold">Git LFS</strong> (Git Large File Storage). It replaces large files such as audio samples, videos, datasets, and graphics with text pointers inside Git.</p>
			<p>If you have not cloned the repository:</p>
			<ol>
				<li>Install Git LFS</li>
				<li>Clone the Git repository</li>
				<li>From the repository folder, execute <strong class="inline">gitlfs pull</strong></li>
				<li>Done</li>
			</ol>
			<p>If the repository is already cloned:</p>
			<ol>
				<li value="1">Install Git LFS</li>
				<li>From the repository folder, execute: <strong class="inline">gitlfs pull</strong></li>
				<li>Done</li>
			</ol>
			<p>Installing Git LFS: <a href="https://github.com/git-lfs/git-lfs/wiki/Installation">https://github.com/git-lfs/git-lfs/wiki/Installation</a></p>
			<p><strong class="bold">[Recommended] Google Colaboratory</strong></p>
			<p>If you have the option, use Google Colaboratory. It is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud. You can also take advantage of running it on a GPU.</p>
			<p>The steps for using it are as follows:</p>
			<ol>
				<li value="1">Upload the entire GitHub to your Google Drive account, so you can use the files that are stored in the repository. Make sure you have made use of Git LFS first to load all the files.</li>
				<li>Go to the folder where you want to open a new Google Colab Notebook, click New &gt; More &gt; Colaboratory. Now, you have a Google Colab Notebook opened and saved in the corresponding folder, and you are ready to use Python, Keras, or any other library that is already installed.<div id="_idContainer008" class="IMG---Figure"><img src="image/C13550_Preface_01.jpg" alt=""/></div></li>
				<li>If you want to install a specific library, you can do so using the “pip” package installation or any other command-line installation and adding “!” at the beginning. For instance, “!pip install sklearn”, which would install scikit-learn.</li>
				<li>If you want to be able to load files from your Google Drive, you need to execute these two lines of code in a Google Colab cell:<p class="snippet">from google.colab import drive</p><p class="snippet">drive.mount(‘drive’)</p></li>
				<li>Then, open the link that appears in the output and log in with the Google account that you used to create the Google Colab Notebook.</li>
				<li>You can now navigate to where the files were uploaded using <strong class="inline">ls</strong> to list the files in the current directory and <strong class="inline">cd</strong> to navigate to a specific folder:<div id="_idContainer009" class="IMG---Figure"><img src="image/C13550_Preface_02.jpg" alt=""/></div></li>
				<li>Now, the Google Colab Notebook is capable of loading any file and performing any task, just like a Jupyter notebook opened in that folder would do.</li>
			</ol>
			<p><strong class="bold">Installing ROS Kinetic</strong></p>
			<p>These are the steps you must follow to install the framework in your Ubuntu system:</p>
			<ol>
				<li value="1">Prepare Ubuntu for accepting the ROS software:<p class="snippet">sudosh -c ‘echo “deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main” &gt; /etc/apt/sources.list.d/ros-latest.list’</p></li>
				<li>Configure the download keys:<p class="snippet">sudo apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net:80 --recv-key 421C365BD9FF1F717815A3895523BAEEB01FA116</p></li>
				<li>Ensure that the system is updated:<p class="snippet">sudo apt-get update</p></li>
				<li>Install the full framework to not miss functionalities:<p class="snippet">sudo apt-get install ros-kinetic-desktop-full</p></li>
				<li>Initialize and update <strong class="inline">rosdep</strong>:<p class="snippet">sudo rosdep init</p><p class="snippet">rosdep update</p></li>
				<li>Add environment variables to the <strong class="inline">bashrc</strong> file if you want to avoid declaring them each time you work with ROS:<p class="snippet">echo “source /opt/ros/kinetic/setup.bash” &gt;&gt; ~/.bashrcsource ~/.bashrc</p><h4>Note</h4><p class="callout">It might be appropriate to reboot your computer after this process for the system to implement the new configuration.</p></li>
				<li>Check that the framework is correctly working by starting it:<p class="snippet">roscore</p></li>
			</ol>
			<p><strong class="bold">Configuring TurtleBot</strong></p>
			<h4>No<a id="_idTextAnchor011"/>te</h4>
			<p class="callout">It may happen that TurtleBot is not compatible with your ROS distribution (we are using Kinetic Kame), but don’t worry, there are lots of robots that you can simulate in Gazebo. You can look up different robots and try to use them with your ROS distribution.</p>
			<p>This is the configuration process for TurtleBot:</p>
			<ol>
				<li value="1">Install its dependencies:<p class="snippet">sudo apt-get install ros-kinetic-turtlebotros-kinetic-turtlebot-apps ros-kinetic-turtlebot-interactions ros-kinetic-turtlebot-simulator ros-kinetic-kobuki-ftdiros-kinetic-ar-track-alvar-msgs</p></li>
				<li>Download the TurtleBot simulator package in your <strong class="inline">catkin</strong> workspace:<p class="snippet">cd ~/catkin_ws/src</p><p class="snippet">git clone https://github.com/turtlebot/turtlebot_simulator</p></li>
				<li>After that, you should be able to use TurtleBot with Gazebo.<p>If you get an error trying to visualize TurtleBot in Gazebo, download the <strong class="inline">turtlebot_simulator</strong> folder from our GitHub and replace it.</p><p>Start ROS services:</p><p class="snippet">roscore</p><p>Launch TurtleBot World:</p><p class="snippet">cd ~/catkin_ws</p><p class="snippet">catkin_make</p><p class="snippet">sourcedevel/setup.bash</p><p class="snippet">roslaunchturtlebot_gazeboturtlebot_world.launch</p></li>
			</ol>
			<p><strong class="bold">Basic Installation of Darknet</strong></p>
			<p>Follow these steps for installing Darknet:</p>
			<ol>
				<li value="1">Download the framework:<p class="snippet">git clone https://github.com/pjreddie/darknet</p></li>
				<li>Switch to the downloaded folder and run the compilation command:<p class="snippet">cd darknet</p><p class="snippet">make</p><p>You should see an output like the following if the compilation process was correctly completed:</p></li>
			</ol>
			<div>
				<div id="_idContainer010" class="IMG---Figure">
					<img src="image/C13550_Preface_03.jpg" alt=""/>
				</div>
			</div>
			<h6>The Darknet compilation output</h6>
			<p><strong class="bold">Advanced Installation of Darknet</strong></p>
			<p>This is the installation process that you must complete in order to achieve the chapter objectives. It will allow you to use GPU computation to detect and recognize objects in real time. Before performing this installation, you must have some dependencies installed on your Ubuntu system, such as:</p>
			<ul>
				<li><strong class="keyword">NVIDIA drivers</strong>: Drivers that will allow your system to correctly work with your GPU. As you may know, it must be an NVIDIA model.</li>
				<li><strong class="keyword">CUDA</strong>: This is an NVIDIA toolkit that provides a development environment for building applications that need GPU usage.</li>
				<li><strong class="keyword">OpenCV</strong>: This is a free artificial vision library, which is very useful for working with images.<h4>Note</h4><p class="callout">It is important to consider that all these dependencies are available in several versions. You must find the version of each tool that is compatible with your specific GPU and system.</p><p>Once your system is ready, you can perform the advanced installation:</p></li>
			</ul>
			<ol>
				<li value="1">Download the framework if you didn’t do the basic installation:<p class="snippet">git clone https://github.com/pjreddie/darknet</p></li>
				<li>Modify the Makefile first lines to enable OpenCV and CUDA. It should be as follows:<p class="snippet">GPU=1</p><p class="snippet">CUDNN=0</p><p class="snippet">OPENCV=1</p><p class="snippet">OPENMP=0</p><p class="snippet">DEBUG=0</p></li>
				<li>Save Makefile changes, switch to <strong class="inline">darknet</strong> directory and run the compilation command:<p class="snippet">cd darknet</p><p class="snippet">make</p><p>Now, you should see an output similar to this one:</p></li>
			</ol>
			<div>
				<div id="_idContainer011" class="IMG---Figure">
					<img src="image/C13550_Preface_04.jpg" alt=""/>
				</div>
			</div>
			<h6>The Darknet compilation with CUDA and OpenCV</h6>
			<p><strong class="bold">Installing YOLO</strong></p>
			<p>Before performing this installation, you must have some dependencies installed on your Ubuntu system, as mentioned in the <em class="italics">advanced installation of Darknet.</em></p>
			<h4>Note</h4>
			<p class="callout">It is important to take into account that all these dependencies are available in several versions. You must find the version of each tool that is compatible with your specific GPU and system.</p>
			<p>Once your system is ready, you can perform the advanced installation:</p>
			<ol>
				<li value="1">Download the framework:<p class="snippet">git clone https://github.com/pjreddie/darknet</p></li>
				<li>Modify the Makefile first lines to enable OpenCV and CUDA. It should be as follows:<p class="snippet">GPU=1</p><p class="snippet">CUDNN=0</p><p class="snippet">OPENCV=1</p><p class="snippet">OPENMP=0</p><p class="snippet">DEBUG=0</p></li>
				<li>Sav<a id="_idTextAnchor012"/>e Makefile changes, switch to the darknet directory, and run the compilation command:<p class="snippet">cd darknet</p><p class="snippet">Make</p></li>
			</ol>
			<h3 id="_idParaDest-11"><a id="_idTextAnchor013"/>Additional Resources</h3>
			<p>The code bundle for this book is also hosted on GitHub at: <a href="https://github.com/PacktPublishing/Artificial-Vision-and-Language-Processing-for-Robotics">https://github.com/PacktPublishing/Artificial-Vision-and-Language-Processing-for-Robotics</a>.</p>
			<p>We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check them out!</p>
			<p>Links to documentation:</p>
			<p>ROS Kinetic - <a href="http://wiki.ros.org/kinetic/Installation">http://wiki.ros.org/kinetic/Installation</a></p>
			<p>Git Large File Storage - <a href="https://git-lfs.github.com/">https://git-lfs.github.com/</a></p>
		</div>
	</body></html>