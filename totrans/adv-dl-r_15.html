<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Text classification Using Long Short-Term Memory Network</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, we used a recurrent neural network to develop a movie review sentiment classification model for text data that are characterized by a sequence of words. <strong>Long Short-Term Memory</strong> (<strong>LSTM</strong>) neural networks are a special type of <strong>Recurrent Neural Networks</strong> (<strong>RNNs</strong>) that are useful with data involving sequences and provide advantages that we will discuss in the next section. This chapter illustrates the steps for using an LSTM neural network for sentiment classification. The steps involved in applying an LSTM network to a business problem may include text data preparation, creating the LSTM model, training the model, and assessing the model performance.</p>
<p>More specifically, in this chapter, we will cover the following topics:</p>
<ul>
<li>Why do we use LSTM networks?</li>
<li>Preparing text data for model building</li>
<li>Creating a long short-term memory network model</li>
<li>Fitting the LSTM model</li>
<li>Evaluating model performance</li>
<li>Performance optimization tips and best practices</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Why do we use LSTM networks?</h1>
                </header>
            
            <article>
                
<p>We have seen, in the previous chapter, that recurrent neural networks provide decent performance when working with data involving sequences. One of the key advantages of using LSTM networks lies in the fact that they address the vanishing gradient problem that makes network training difficult for a long sequence of words or integers. Gradients are used for updating RNN parameters and for a long sequence of words or integers; these gradients become smaller and smaller to the extent that, effectively, no network training can take place. LSTM networks help to overcome this problem and make it possible to capture long-term dependencies between keywords or integers in sequences that are separated by a large distance. For example, consider the following two sentences, where the first sentence is short and the second sentence is relatively longer:</p>
<ul>
<li><strong>Sentence-1</strong>: I like to eat chocolates.</li>
<li><strong>Sentence-2</strong>: I like, whenever there is a chance and usually there are many of them, to eat chocolates.</li>
</ul>
<p>In these sentences, the two important words that capture the main essence of the sentence are <strong>like</strong> and <strong>chocolates</strong>. In the first sentence, the words <strong>like</strong> and <strong>chocolates</strong> are closer to each other and they are separated by just two words in between. On the other hand, in the second sentence, these two words are separated by as many as 14 words that lie between them. LSTM networks are designed to deal with such long-term dependencies that are observed in longer sentences or longer sequences of integers. In this chapter, we focus on applying LSTM networks for developing a movie review sentiment classification model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Preparing text data for model building</h1>
                </header>
            
            <article>
                
<p>We will continue to use IMDB movie review data that we used in the previous chapter on recurrent neural networks. This data is already available in a format where we can use it for developing deep network models with minimum need for data processing. </p>
<p>Let's take a look at the following code:</p>
<pre># IMDB data<br/>library(keras)<br/>imdb &lt;- dataset_imdb(num_words = 500) <br/>c(c(train_x, train_y), c(test_x, test_y)) %&lt;-% imdb<br/>train_x &lt;- pad_sequences(train_x, maxlen = 200) <br/>test_x &lt;- pad_sequences(test_x, maxlen = 200)</pre>
<p><span>The sequence of integers capturing train and test data is stored in <kbd>train_x</kbd> and <kbd>test_x</kbd> respectively. Similarly, <kbd>train_y</kbd> and <kbd>test_y</kbd> store labels capturing information about whether movie reviews are positive or negative. We have specified the number of most frequent words to be 500. For padding, we are using 200 as the maximum length of a sequence of integers for both train and test data.</span></p>
<p><span>When the actual length of integers is less than 200, then zeros get added at the beginning of the sequence to artificially increase the length of integers to 200. However, when the length of integers is more than 200, integers at the beginning are removed so that the total length of integers is maintained at 200. </span></p>
<p>As mentioned earlier, both train and test datasets are balanced and contain data involving 25,000 movie reviews each. For each movie review, positive or negative labels are also available.</p>
<div class="packt_infobox"><span>Note that the choice of value for </span><kbd>maxlen</kbd><span> can impact model performance. If the value chosen is too small, more words or integers in a sequence will get truncated. On the other hand, if the value chosen is too large, then more words or integers in a sequence will need padding, with zeroes getting added. One way to avoid too much padding or too much truncation is to choose a value closer to the median.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a long short-term memory network model</h1>
                </header>
            
            <article>
                
<p>In this section, we will start with a simple LSTM network architecture and look at calculations to arrive at the number of parameters. Subsequently, we will compile the model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">LSTM network architecture</h1>
                </header>
            
            <article>
                
<p><span>We will start with a simple flow chart of the LSTM network architecture, as shown in the following screenshot:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/ac568b12-cbe5-4312-b47e-1e95783f27ee.png" style="width:6.33em;height:16.50em;"/></p>
<p><span>The preceding flow chart for the LSTM network highlights the layers in the architecture and activation functions used. In the LSTM layer, the</span> <kbd>tanh</kbd> <span>activation function is used which is the default activation function for the layer. In the dense layer, the</span> <kbd>sigmoid</kbd><span> activation function is used.</span></p>
<p>Let's have a look at the following code and summary of the model:</p>
<pre># Model architecture<br/>model &lt;- keras_model_sequential() %&gt;%<br/>         layer_embedding(input_dim = 500, output_dim = 32) %&gt;%<br/>         layer_lstm(units = 32) %&gt;%<br/>         layer_dense(units = 1, activation = "sigmoid")<br/>model<br/><strong>__________________________________________________________________________</strong><br/><strong>Layer (type)                      Output Shape                  Param #     </strong><br/><strong>==========================================================================</strong><br/><strong>embedding (Embedding)             (None, None, 32)              16000       </strong><br/><strong>__________________________________________________________________________</strong><br/><strong>lstm (LSTM)                       (None, 32)                    8320        </strong><br/><strong>__________________________________________________________________________</strong><br/><strong>dense (Dense)                     (None, 1)                     33          </strong><br/><strong>==========================================================================</strong><br/><strong>Total params: 24,353</strong><br/><strong>Trainable params: 24,353</strong><br/><strong>Non-trainable params: 0</strong><br/><strong>__________________________________________________________________________</strong></pre>
<p>Apart from what we used for the RNN model in the last chapter, we are replacing <kbd>layer_simple_rnn</kbd> with <kbd>layer_lstm</kbd> for the LSTM network in this example. For the embedding layer, we have a total of 16,000 (500 x 32) parameters. The calculation shown as follows calculates the number of parameters for the LSTM layer:</p>
<p><em>=4 x [units in LSTM layer x (units in LSTM layer + output dimension) + units in LSTM layer] </em></p>
<p><em>= 4 x [32(32+32) + 32]</em></p>
<p><em>= 8320</em></p>
<p>For a similar architecture involving the RNN layer, we will have 2,080 parameters. The four-fold increase in the number of parameters for the LSTM layer also leads to more training time and hence requires relatively higher processing costs. The number <span>of parameters for the dense layer is <em>[(32x1) + 1]</em>, which comes to 33. Hence, overall there are 24,353 parameters in this network.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Compiling the LSTM network model</h1>
                </header>
            
            <article>
                
<p>For compiling the LSTM network model, we will use the following code:</p>
<pre># Compile<br/>model %&gt;% compile(optimizer = "rmsprop",  <br/>         loss = "binary_crossentropy",<br/>         metrics = c("acc"))</pre>
<p>We are using <kbd>rmsprop</kbd> as optimizer and <kbd>binary_crossentropy</kbd> for loss, since movie reviews have a binary response or, in other words, they are either positive or negative. For metrics, we are making use of classification accuracy. After compiling the model, we are ready to go to the next step of fitting the LSTM model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fitting the LSTM model</h1>
                </header>
            
            <article>
                
<p>For training the LSTM model, we will use the following code:</p>
<pre># Fit model<br/>model_one &lt;- model %&gt;% fit(train_x, train_y,<br/>         epochs = 10,<br/>         batch_size = 128,<br/>         validation_split = 0.2)<br/>plot(model_one)</pre>
<p>We will use train data to fit the LSTM model with ten epochs and use a batch size of 128. We will also reserve 20% of train data as validation data for assessing loss and accuracy values during model training.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Loss and accuracy plot</h1>
                </header>
            
            <article>
                
<p> The following screenshot shows the loss and accuracy plot for <kbd>model_one</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7e6e0763-3476-4566-b4ab-2006bc2b2e06.png"/></p>
<p>The plot for loss and accuracy based on training and validation data shows overall closeness between the curves. The observations from the plot are as follows:</p>
<ul>
<li>There<span> </span>is no major divergence between the two lines, which indicates the lack of an over-fitting problem.</li>
<li>An increase in the number of epochs may not provide any significant improvement in model performance.</li>
<li>However, the loss and accuracy values based on the validation data show some amount of unevenness or oscillation where they deviate from the training loss and accuracy by a relatively high amount.</li>
<li>Epochs 4 and 8 especially stand out in this regard showing significant deviation from the loss and accuracy based on training data.</li>
</ul>
<p>Next, we will move toward evaluating <kbd>model_one</kbd> and use it for prediction of the movie review sentiment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Evaluating model performance </h1>
                </header>
            
            <article>
                
<p>In this section, we will evaluate the model based on both training and test data. We will also create a confusion matrix for both train and test data to gain further insights into the movie review sentiment classification performance of the model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model evaluation with train data</h1>
                </header>
            
            <article>
                
<p>We will first evaluate the model performance with train data using the following code:</p>
<pre># Evaluate<br/>model %&gt;% evaluate(train_x, train_y)<br/>$loss<br/> [1] 0.3749587<br/>$acc<br/> [1] 0.82752</pre>
<p>As seen from the preceding output, for the training data, we obtain a loss value of <kbd>0.375</kbd> and an accuracy of about <kbd>0.828</kbd>. This is a decent performance considering a relatively simple LSTM architecture. We next use this model to make predictions for the movie review sentiment and summarize the results by developing a confusion matrix using the following code:</p>
<pre># Confusion Matrix<br/>pred &lt;- model %&gt;% predict_classes(train_x)<br/>table(Predicted=pred, Actual=imdb$train$y)<br/>         Actual<br/> Predicted     0     1<br/>         0  9258  1070<br/>         1  3242 11430</pre>
<p>We can make the following observations from the confusion matrix:</p>
<ul>
<li>It <span>is observed that this model seems to be more accurate in predicting positive movie reviews (11,430 correct predictions) compared to negative movie reviews (9,258 correct predictions). In other words, this model correctly classifies positive reviews at the rate of about 91.4% (also called the sensitivity of the model) for the training data.</span></li>
<li><span>Similarly, this model correctly classifies negative reviews at the rate of about 74.1% (also called specificity of the model) for the training data.</span></li>
<li><span>It is also observed that the negative movie reviews are being misclassified as a positive review at the rate of about three times (3,242 reviews) more compared to a positive review being misclassified as negative (1,070 reviews).</span></li>
<li><span>Hence, although overall, this model seems to perform well for the training data, looking deeper, we observe some bias toward correctly classifying positive movie reviews at the cost of lower accuracy in correctly classifying negative reviews.</span></li>
</ul>
<p>It will be interesting to see whether the model performance observed, based on training data, results in similar behavior for the test data or not.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model evaluation with test data</h1>
                </header>
            
            <article>
                
<p>We will now use the test data to obtain loss and accuracy values for the model using the following code:</p>
<pre># Evaluate<br/>model %&gt;% evaluate(test_x, test_y)<br/>$loss<br/> [1] 0.3997277<br/>$acc<br/> [1] 0.81992</pre>
<p>As seen from the preceding output, for the test data, we obtain a loss value of 0.399 and an accuracy of about 0.819. These values, as expected, are slightly inferior to those obtained for the train data. However, they are close enough to results based on the train data to consider this model behavior consistent.</p>
<p>The code to obtain a confusion matrix using test data is as follows:</p>
<pre># Confusion Matrix<br/>pred1 &lt;- model %&gt;$ predict_classes(text_x)<br/>table(Predicted=pred1, Actual=imdb$test$y)<br/>         Actual<br/> Predicted     0     1<br/>         0  9159  1161<br/>         1  3341 11339</pre>
<p>From the confusion matrix shown above, the following observations can be made:</p>
<ul>
<li>The confusion matrix based on predictions using the test data shows a similar pattern that we observed earlier for the training data.</li>
<li>This model also seems to perform better when accurately classifying positive movie reviews (at a rate of about 90.7%), compared to correctly classifying negative reviews (at a rate of about 73.3%).</li>
<li>Hence, the model continues to show bias in the performance when correctly classifying positive movie reviews.</li>
</ul>
<p>In the next section, we will carry out some experimentation to explore possible improvements for the model's movie review sentiment classification performance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Performance optimization tips and best practices</h1>
                </header>
            
            <article>
                
<p>In this section, we will carry out three different experiments to search for an improved LSTM based movie review sentiment classification model. This will involve trying a different optimizer at the time of compiling the model, adding another LSTM layer when developing the model architecture, and using a bidirectional LSTM layer in the network.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Experimenting with the Adam optimizer</h1>
                </header>
            
            <article>
                
<p>We will use the <kbd>adam</kbd> (<span class="ILfuVd"><span class="e24Kjd">Adaptive Moment Optimization)</span></span> optimizer instead of the <kbd>rmsprop</kbd> (Root Mean Square Propagation) optimizer that we used earlier when compiling the model. To make a comparison of model performance easier, we will keep everything else the same as earlier, as shown in the following code:</p>
<pre># Model architecture<br/>model &lt;- keras_model_sequential() %&gt;%<br/>         layer_embedding(input_dim = 500, output_dim = 32) %&gt;%<br/>         layer_lstm(units = 32) %&gt;%<br/>         layer_dense(units = 1, activation = "sigmoid")<br/><br/># Compile<br/>model %&gt;% compile(optimizer = "adam",  <br/>         loss = "binary_crossentropy",<br/>         metrics = c("acc"))<br/><br/># Fit model<br/>model_two &lt;- model %&gt;% fit(train_x, train_y,<br/>         epochs = 10,<br/>         batch_size = 128,<br/>         validation_split = 0.2)<br/>plot(model_two)</pre>
<p>After running the preceding codes and training the model, the accuracy and loss values for each epoch are stored in <kbd>model_two</kbd>. We use the loss and accuracy values in <kbd>model_two</kbd> to develop the following plot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/2c80e3bf-c6f5-4c71-b9a8-008cd2ff70c2.png" style="width:38.58em;height:36.67em;"/></p>
<p>From the preceding loss and accuracy plot, we can make the following observations:</p>
<ul>
<li>The loss and accuracy plot based on the training and validation data shows a slightly improved pattern compared to the plot for the first model that we built with <kbd>model_one</kbd>.</li>
<li>In the plot based on <kbd>model_one</kbd>, we observed that loss and accuracy values for validation data occasionally showed major deviations from the values based on the training data. In this plot, we do not see any such major deviation between the two lines.</li>
</ul>
<ul>
<li>Also, the loss and accuracy values based on the last few values of validation data seem flat, suggesting that the ten epochs that we have used are sufficient to train the model and an increasing number of epochs is not likely to help in improving the model performance.</li>
</ul>
<p>Next, let's obtain the loss, accuracy, and confusion matrix for the training data using the following code:</p>
<pre class="cdpcomment"># Loss and accuracy<br/>model %&gt;% evaluate(train_x, train_y)<br/>$loss<br/>[1] 0.3601628<br/>$acc<br/>[1] 0.8434<br/><br/>pred &lt;- model %&gt;%   predict_classes(train_x)<br/><br/># Confusion Matrix<br/>table(Predicted=pred, Actual=imdb$train$y)<br/>         Actual<br/>Predicted     0     1<br/>        0 11122  2537<br/>        1  1378  9963</pre>
<p>From the preceding code output, we can make the following observations:</p>
<ul>
<li>By using the <kbd>adam</kbd> optimizer, we obtain loss and accuracy for training data as 0.360 and 0.843 respectively. Both these numbers show an improvement compared to the earlier model where we had used the <kbd>rmsprop</kbd> optimizer.</li>
<li>Another difference can be observed from the confusion matrix. This model performs better when correctly classifying negative movie reviews (at a rate of about 88.9%) compared to the correct classification of positive reviews (at a rate of about 79.7%).</li>
<li>This behavior is the opposite of what was observed in the previous model. This model seems to be biased toward correctly classifying negative movie review sentiment compared to correctly classifying positive reviews.</li>
</ul>
<p>Having reviewed the performance of the model using the training data, we will now repeat the process with the test data, with the following code for obtaining the loss, accuracy, and confusion matrix:</p>
<pre class="cdpcomment"># Loss and accuracy<br/>model %&gt;% evaluate(test_x, test_y)<br/>$loss<br/>[1] 0.3854687<br/>$acc<br/>[1] 0.82868<br/><br/>pred1 &lt;- model %&gt;%   predict_classes(test_x)<br/><br/># Confusion Matrix<br/>table(Predicted=pred1, Actual=imdb$test$y)<br/>         Actual<br/>Predicted     0     1<br/>        0 10870  2653<br/>        1  1630  9847</pre>
<p>From the preceding code output, we can make the following observations:</p>
<ul>
<li>The loss and accuracy based on test data are 0.385 and 0.829 respectively. These results, based on the test data, also show better model performance compared to the previous model with the test data.</li>
<li>The confusion matrix shows a similar pattern that we observed for the training data. Negative movie review sentiments are correctly classified at a rate of about 86.9% for the test data.</li>
<li>Similarly, positive movie review sentiments are correctly classified by the model at a rate of about 78.8% for the test data.</li>
<li>This behavior is consistent with the <span>model performance that was obtained using the training data.</span></li>
</ul>
<p>Although trying the <kbd>adam</kbd> optimizer improves overall movie review sentiment classification performance, it still retains bias when correctly classifying one category compared to the other. A good model should not only improve the overall performance, but it should also minimize any bias when correctly classifying a category. The following code provides a table showing the number of negative and positive reviews in the <kbd>train</kbd> and <kbd>test</kbd> data:</p>
<pre># Number of positive and negative reviews in the train data<br/>table(train_y)<br/>train_y<br/>    0     1 <br/>12500 12500 <br/><br/># Number of positive and negative review in the test data<br/>table(test_y)<br/>test_y<br/>    0     1 <br/>12500 12500 </pre>
<p><span>It can be seen from the preceding output of code that this movie review data is balanced where both train and test data has 25,000 reviews each. This data is also balanced in terms of the number of positive or negative reviews. Both train and test datasets have 12,500 positive and 12,500 negative movie reviews each. Hence, there is no bias in the amount of negative or positive reviews provided to the model for training.</span> However, the bias seen when correctly classifying negative and positive movie reviews is certainly something that needs improvement.</p>
<p>In the next experiment, let's explore with more LSTM layers and see whether or not we can obtain a better movie review sentiment classification model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Experimenting with the LSTM network having an additional layer</h1>
                </header>
            
            <article>
                
<p>In this second experiment to improve the performance of the classification model, we will add an extra LSTM layer. Let's have a look at the following code:</p>
<pre># Model architecture<br/>model &lt;- keras_model_sequential() %&gt;%<br/>         layer_embedding(input_dim = 500, output_dim = 32) %&gt;%<br/>         layer_lstm(units = 32,<br/>                    return_sequences = TRUE) %&gt;%<br/>         layer_lstm(units = 32) %&gt;%<br/>         layer_dense(units = 1, activation = "sigmoid")<br/><br/># Compiling model<br/>model %&gt;% compile(optimizer = "adam",   <br/>         loss = "binary_crossentropy",<br/>         metrics = c("acc"))<br/><br/># Fitting model<br/>model_three &lt;- model %&gt;% fit(train_x, train_y,<br/>         epochs = 10,<br/>         batch_size = 128,<br/>         validation_split = 0.2)<br/><br/># Loss and accuracy plot<br/>plot(model_three)</pre>
<p>By adding an extra LSTM layer to the network, as shown in the preceding code, the total number of parameters with these two LSTM layers will now increase to 32,673 compared to 24,353 that we had previously with one LSTM layer. This increase in the number of parameters will also lead to higher training time when training the network. We are also retaining the use of the Adam optimizer when compiling the model. We are keeping everything else the same as what we had used in the previous model.</p>
<p><span>A simple flow chart for the network architecture with two LSTM layers used in this experiment, is shown in the following screenshot:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/0418119a-4dae-4bfa-a9b1-0897d0815d18.png" style="width:8.33em;height:25.83em;"/></p>
<p>The preceding flow chart shown for the LSTM network highlights the two layers in the architecture and activation functions used. In both LSTM layers, <kbd>tanh</kbd> is used as the default activation function. In the dense layer, we continue to use the <kbd>sigmoid</kbd> activation function that we used earlier.</p>
<p><span>After training the model, the accuracy and loss values for each epoch is stored in <kbd>model_three</kbd>. We use the loss and accuracy values in <kbd>model_three</kbd> to develop the following plot:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/9cc7906f-0224-47de-8ec8-ef9ed8d7b438.png" style="width:46.17em;height:44.00em;"/></p>
<p>From the loss and accuracy plot shown, we can make the following observations:</p>
<ul>
<li>The plot for loss and accuracy values doesn't indicate the presence of an over-fitting problem since the curves for the training and validation data are close to each other.</li>
</ul>
<ul>
<li>As in the earlier model, the loss and accuracy for the validation data seem to remain flat for the last few epochs, indicating ten epochs are sufficient for training the model, and increasing the number of epochs is not likely to improve results.</li>
</ul>
<p>We can now obtain the loss, accuracy, and confusion matrix for the training data using the following code:</p>
<pre># Loss and accuracy<br/>model %&gt;% evaluate(train_x, train_y)<br/>$loss<br/>[1] 0.3396379<br/>$acc<br/>[1] 0.85504<br/><br/>pred &lt;- model %&gt;%   predict_classes(train_x)<br/><br/># Confusion Matrix<br/>table(Predicted=pred, Actual=imdb$train$y) <br/>         Actual<br/>Predicted     0     1<br/>        0 11245  2369<br/>        1  1255 10131</pre>
<p>From the preceding code output, we can make the following observations:</p>
<ul>
<li>The loss and accuracy values based on training data are obtained as <kbd>0.339</kbd> and <kbd>0.855</kbd> respectively. Both loss and accuracy show improvement compared to the earlier two models.</li>
<li>We can use this model to make predictions for each review in the training data, compare them with actual labels, and then summarize the results in the form of a confusion matrix.</li>
<li>For the training data, the confusion matrix shows that the model correctly classifies negative movie reviews about 90% of the time and correctly classifies positive reviews about 81% of the time.</li>
<li>So, although there is an overall improvement in the model performance, we continue to observe bias when correctly classifying one category compared to the other. </li>
</ul>
<p>After reviewing the performance of the model using training data, we will now repeat the process with the test data. Following is the code for obtaining the loss, accuracy, and confusion matrix:</p>
<pre># Loss and accuracy<br/>model %&gt;% evaluate(test_x, test_y)<br/>$loss<br/>[1] 0.3761043<br/>$acc<br/>[1] 0.83664<br/><br/>pred1 &lt;- model %&gt;%   predict_classes(test_x)<br/><br/># Confusion Matrix<br/>table(Predicted=pred1, Actual=imdb$test$y)<br/>         Actual<br/>Predicted     0     1<br/>        0 10916  2500<br/>        1  1584 10000</pre>
<p>From the preceding<span> </span><span>code</span><span> output, we can make the following observations:</span></p>
<ul>
<li>For the test data, the loss and accuracy values are 0.376 and 0.837 respectively. Both results show a better classification performance compared to the previous two models for the test data.</li>
<li>The confusion matrix shows that negative movie reviews are correctly classified at a rate of about 87.3%, and positive reviews are correctly classified at a rate of about 80%.</li>
<li>Hence, these results are consistent with those obtained using the training data and show a similar bias to that we observed for the training data.</li>
</ul>
<p>To summarize, by adding an extra LSTM layer, we were able to improve the movie review sentiment classification performance of the model. However, we continue to observe bias when correctly classifying one category compared to the other category. Hence, although we obtained moderate success in improving model performance, there is scope to further improve the classification performance of the model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Experimenting with a bidirectional LSTM layer</h1>
                </header>
            
            <article>
                
<p>A bidirectional LSTM, as the name indicates, not only uses the sequence of integers provided as input but also makes use of its reverse order as additional input. There could be situations where this approach may help to achieve further model classification performance improvements by capturing useful patterns in the data that may not have been captured by the original LSTM network.</p>
<p>For this experiment, we will modify the LSTM layer in the first experiment, as shown in the following code:</p>
<pre># Model architecture<br/>model &lt;- keras_model_sequential() %&gt;%<br/>          layer_embedding(input_dim = 500, output_dim = 32) %&gt;%<br/>          bidirectional(layer_lstm(units = 32)) %&gt;%<br/>          layer_dense(units = 1, activation = "sigmoid")<br/># Model summary<br/>summary(model)<br/>Model<br/>__________________________________________________________<br/>Layer (type)              Output Shape           Param #  <br/>==========================================================<br/>embedding_8 (Embedding)   (None, None, 32)       16000    <br/>__________________________________________________________<br/>bidirectional_5 (Bidirect (None, 64)             16640    <br/>__________________________________________________________<br/>dense_11 (Dense)          (None, 1)              65       <br/>==========================================================<br/>Total params: 32,705<br/>Trainable params: 32,705<br/>Non-trainable params: 0<br/>__________________________________________________________</pre>
<p><span>From the preceding</span><span> </span><span>code</span><span> output, we can make the following observations:</span></p>
<ul>
<li><span>We converted the LSTM layer into a bidirectional LSTM layer using the bidirectional</span> <kbd>()</kbd><span> function.</span></li>
<li><span>This change doubles the number of parameters related to the LSTM layer to 16,640, as can be seen from the model summary.</span></li>
<li><span>The total number of parameters for this architecture now increases to 32,705. This increase in the number of parameters will further reduce the speed at which the network will be</span> trained<span>.</span></li>
</ul>
<p>Here is a<span> simple flow chart for the bidirectional LSTM network architecture:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/2c0b3651-c617-4563-816c-1469d82c371b.png" style="width:9.08em;height:21.17em;"/></p>
<p>The flow chart for the bidirectional LSTM network shows embedding, bidirectional, and dense layers. In the bidirectional LSTM layer, <kbd>tanh</kbd> is used as the activation function and the dense layer uses the <kbd>sigmoid</kbd> activation function. The code for compiling and training the model is as follows:</p>
<pre># Compiling model<br/>model %&gt;% compile(optimizer = "adam",   <br/>          loss = "binary_crossentropy",<br/>          metrics = c("acc"))<br/><br/># Fitting model<br/> model_four &lt;- model %&gt;% fit(train_x, train_y,<br/>          epochs = 10,<br/>          batch_size = 128,<br/>          validation_split = 0.2)<br/><br/># Loss and accuracy plot<br/>plot(model_four)</pre>
<p>As seen from the preceding code, we will continue to use the <kbd>adam</kbd> optimizer and keep the other settings the same as earlier for compiling and then fitting the model.</p>
<p><span>After we train the model, the accuracy and loss values for each epoch are stored in <kbd>model_four</kbd>. We use the loss and accuracy values in <kbd>model_four</kbd> to develop the following plot:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/ab926820-55f4-4c95-8056-ad5ee3a57beb.png" style="width:45.08em;height:47.50em;"/></p>
<p>From the preceding plot, we can make the following observations:</p>
<ul>
<li>The loss and accuracy plot doesn't show any cause for concern regarding over-fitting as the lines for training and validation are reasonably close to each other.</li>
<li>The plot also shows that we do not need more than ten epochs to train this model.</li>
</ul>
<p class="mce-root">We will obtain the loss, accuracy, and confusion matrix for the training data using the following code:</p>
<pre># Loss and accuracy<br/>model %&gt;% evaluate(train_x, train_y)<br/>$loss<br/>[1] 0.3410529<br/>$acc<br/>[1] 0.85232<br/><br/>pred &lt;- model %&gt;%   predict_classes(train_x)<br/><br/># Confusion Matrix<br/>table(Predicted=pred, Actual=imdb$train$y)<br/>         Actual<br/>Predicted     0     1<br/>        0 10597  1789<br/>        1  1903 10711</pre>
<p>From the preceding<span> </span><span>code</span><span> output, we can make the following observations:</span></p>
<ul>
<li>For the training data, we obtain loss and accuracy values of 0.341 and 0.852 respectively. These results are only marginally inferior to the previous results and are not significantly different.</li>
<li>The confusion matrix this time shows a more even performance for correctly classifying positive and negative movie reviews.</li>
<li>For negative movie reviews, the correct classification rate is about 84.8% and for positive reviews, it is about 85.7%.</li>
<li>This difference of about 1% is much smaller than what we observed for the earlier models.</li>
</ul>
<p class="mce-root">We will now repeat the preceding process with the test data. Following is the code for obtaining the loss, accuracy, and confusion matrix:</p>
<pre># Loss and accuracy<br/>model %&gt;% evaluate(test_x, test_y)<br/>$loss<br/>[1] 0.3737377<br/>$acc<br/>[1] 0.83448<br/><br/>pred1 &lt;- model %&gt;%   predict_classes(test_x)<br/><br/>#Confusion Matrix<br/>table(Predicted=pred1, Actual=imdb$test$y)<br/>         Actual<br/>Predicted     0     1<br/>        0 10344  1982<br/>        1  2156 10518</pre>
<p>From the preceding code output, we can make the following observations:</p>
<ul>
<li>For the test data, the loss and accuracy values are 0.374 and 0.834 respectively.</li>
<li>The confusion matrix shows that the negative reviews are correctly classified by the model at a rate of about 82.8%.</li>
<li>This model correctly classifies positive movie reviews at a rate of about 84.1%.</li>
<li>These results are consistent with those obtained for the training data.</li>
</ul>
<p>The experiment with bidirectional LSTM helped to obtain somewhat comparable performance in terms of loss and accuracy than that were obtained with two LSTM layers in the previous experiment. However, the main gain that is observed is in achieving results where we can correctly classify a negative or positive movie review with much better consistency.</p>
<p>In this chapter, we used the LSTM network to develop a movie review sentiment classification model. When data involves sequences, LSTM networks help to capture long term dependencies in the sequence of words or integers. We experimented with four different LSTM models by making some changes to the model and the results for the same are summarized in the following table.</p>
<p>This table summarizes the performance of the four LSTM models:</p>
<table border="1" style="border-collapse: collapse">
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign"><strong>Model</strong></td>
<td class="CDPAlignCenter CDPAlign"><strong>LSTM Layers</strong></td>
<td class="CDPAlignCenter CDPAlign"><strong>Optimizer</strong></td>
<td class="CDPAlignCenter CDPAlign"><strong>Data</strong></td>
<td class="CDPAlignCenter CDPAlign"><strong>Loss</strong></td>
<td class="CDPAlignCenter CDPAlign"><strong>Accuracy</strong></td>
<td class="CDPAlignCenter CDPAlign">
<p class="mce-root"><strong>Accuracy for Negative Reviews or Specificity</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p class="mce-root"><strong>Accuracy for Positive Reviews or Sensitivity</strong></p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">One</td>
<td class="CDPAlignCenter CDPAlign">1</td>
<td class="CDPAlignCenter CDPAlign"><kbd>rmsprop</kbd></td>
<td class="CDPAlignCenter CDPAlign">Train</td>
<td class="CDPAlignCenter CDPAlign">0.375</td>
<td class="CDPAlignCenter CDPAlign">82.8%</td>
<td class="CDPAlignCenter CDPAlign">74.1%</td>
<td class="CDPAlignCenter CDPAlign">91.4%</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign"> </td>
<td class="CDPAlignCenter CDPAlign"> </td>
<td class="CDPAlignCenter CDPAlign"> </td>
<td class="CDPAlignCenter CDPAlign">Test</td>
<td class="CDPAlignCenter CDPAlign">0.399</td>
<td class="CDPAlignCenter CDPAlign">81.9%</td>
<td class="CDPAlignCenter CDPAlign">73.3%</td>
<td class="CDPAlignCenter CDPAlign">90.7%</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">Two</td>
<td class="CDPAlignCenter CDPAlign">1</td>
<td class="CDPAlignCenter CDPAlign"><kbd>adam</kbd></td>
<td class="CDPAlignCenter CDPAlign">Train</td>
<td class="CDPAlignCenter CDPAlign">0.360</td>
<td class="CDPAlignCenter CDPAlign">84.3%</td>
<td class="CDPAlignCenter CDPAlign">88.9%</td>
<td class="CDPAlignCenter CDPAlign">79.7%</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign"> </td>
<td class="CDPAlignCenter CDPAlign"> </td>
<td class="CDPAlignCenter CDPAlign"> </td>
<td class="CDPAlignCenter CDPAlign">Test</td>
<td class="CDPAlignCenter CDPAlign">0.385</td>
<td class="CDPAlignCenter CDPAlign">82.9%</td>
<td class="CDPAlignCenter CDPAlign">86.9%</td>
<td class="CDPAlignCenter CDPAlign">78.8%</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">Three</td>
<td class="CDPAlignCenter CDPAlign">2</td>
<td class="CDPAlignCenter CDPAlign"><kbd>adam</kbd></td>
<td class="CDPAlignCenter CDPAlign">Train</td>
<td class="CDPAlignCenter CDPAlign">0.339</td>
<td class="CDPAlignCenter CDPAlign">85.5%</td>
<td class="CDPAlignCenter CDPAlign">90.0%</td>
<td class="CDPAlignCenter CDPAlign">81.0%</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign"> </td>
<td class="CDPAlignCenter CDPAlign"> </td>
<td class="CDPAlignCenter CDPAlign"> </td>
<td class="CDPAlignCenter CDPAlign">Test</td>
<td class="CDPAlignCenter CDPAlign">0.376</td>
<td class="CDPAlignCenter CDPAlign">83.7%</td>
<td class="CDPAlignCenter CDPAlign">87.3%</td>
<td class="CDPAlignCenter CDPAlign">80.0%</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">Four</td>
<td class="CDPAlignCenter CDPAlign">bidirectional</td>
<td class="CDPAlignCenter CDPAlign"><kbd>adam</kbd></td>
<td class="CDPAlignCenter CDPAlign">Train</td>
<td class="CDPAlignCenter CDPAlign">0.341</td>
<td class="CDPAlignCenter CDPAlign">85.2%</td>
<td class="CDPAlignCenter CDPAlign">84.8%</td>
<td class="CDPAlignCenter CDPAlign">85.7%</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign"> </td>
<td class="CDPAlignCenter CDPAlign"> </td>
<td class="CDPAlignCenter CDPAlign"> </td>
<td class="CDPAlignCenter CDPAlign">Test</td>
<td class="CDPAlignCenter CDPAlign">0.374</td>
<td class="CDPAlignCenter CDPAlign">83.4%</td>
<td class="CDPAlignCenter CDPAlign">82.8%</td>
<td class="CDPAlignCenter CDPAlign">84.1%</td>
</tr>
</tbody>
</table>
<p>We can make the following observations from the preceding table:</p>
<ul>
<li>Out of the four models that were tried, the bidirectional LSTM model provided better performance compared to the other three models. It has the lowest loss value based on test data.</li>
<li>Although overall accuracy is slightly lower for the fourth model compared to the third model, accuracy for correctly classifying negative and positive reviews is much more consistent, varying from 82.8% to 84.1%, or a spread of only about 1.3%.</li>
<li>The third model seems biased toward negative reviews that correctly classifies such reviews at a rate of 87.3% for the test data. For the third model, the correct classification of positive reviews in the test data is only at 80%. Hence, the spread between the correct classification of negative and positive reviews for the third model is more than 7%.</li>
<li>The spread between sensitivity and specificity is even higher for the first two models. </li>
</ul>
<p>Although the fourth model provides good results, additional improvements can certainly be explored by experimenting further with other variables. Variables that can be used for further experiments may include the number of most frequent words, use of pre versus post for padding and/or truncation, the maximum length used for padding, the number of units in the LSTM layer, and the choice of another optimizer at the time of compiling the model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we illustrated the use of LSTM networks for developing a movie review sentiment classification model. One of the problems faced by recurrent neural networks that we used in the previous chapter is that it involves difficulty in capturing long-term dependency that may exist between two words/integers in a sequence of words or integers. <strong>Long Short-Term Memory</strong> (<strong>LSTM</strong>) networks are designed to artificially retain long-term memories that are important when dealing with long sentences or a long sequence of integers.</p>
<p>In the next chapter, we will continue to work with text data and explore the use of <strong>Convolutional Recurrent Neural Network</strong><strong>s</strong> (<strong>CRNNs</strong>), which combine the benefits of <strong>Convolutional Neural Networks</strong> (<strong>CNNs</strong>) and <strong>Recurrent Neural Networks</strong> (<strong>RNNs</strong>) into a single network. We will illustrate the use of this type of network with the help of an interesting and publicly available text dataset, <kbd>reuter_50_50</kbd>.</p>


            </article>

            
        </section>
    </body></html>