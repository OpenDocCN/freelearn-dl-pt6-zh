["```py\n$ wget https://d1p17r2m4rzlbo.cloudfront.net/wp-content/uploads/2017/04/a943287.csv \n```", "```py\nimport pandas as pd, numpy as np\nfrom skimage import io\n# Location of file is /content/a943287.csv\n# be sure to change to location of downloaded file on your machine\ndata = pd.read_csv('/content/a943287.csv')\n```", "```py\ndata_male = data[data['please_select_the_gender_of_the_person_in_the_picture']==\"male\"].reset_index(drop='index')\ndata_female = data[data['please_select_the_gender_of_the_person_in_the_picture']==\"female\"].reset_index(drop='index')\nfinal_data = pd.concat([data_male[:1000],data_female[:1000]],axis=0).reset_index(drop='index')\n```", "```py\nx = []\ny = []\nfor i in range(final_data.shape[0]):\n     try:\n         image = io.imread(final_data.loc[i]['image_url'])\n         if(image.shape==(300,300,3)):\n             x.append(image)\n             y.append(final_data.loc[i]['please_select_the_gender_of_the_person_in_the_picture'])\n     except:\n         continue\n```", "```py\nx2 = []\ny2 = []\nfor i in range(len(x)):\n      x2.append(x[i])\n      img_label = np.where(y[i]==\"male\",1,0)\n      y2.append(img_label)\n```", "```py\nx2 = np.array(x2)\nx2 = x2.reshape(x2.shape[0],x2.shape[1],x2.shape[2],3)\n```", "```py\nX = np.array(x2)/255\nY = np.array(y2)\n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.1, random_state=42)\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras import backend as K\n\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu',input_shape=(300,300,3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(512, kernel_size=(3, 3), activation='relu',padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n```", "```py\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n```", "```py\nhistory = model.fit(X_train, y_train, batch_size=32,epochs=10,verbose=1,validation_data = (X_test, y_test))\n```", "```py\nimport cv2\nx2 = []\ny2 = []\nfor i in range(len(x)):\n  img = cv2.resize(x[i],(50,50))\n  x2.append(img)\n  img_label = np.where(y[i]==\"male\",1,0)\n  y2.append(img_label)\n```", "```py\nx2 = np.array(x2)\nx2 = x2.reshape(x2.shape[0],x2.shape[1],x2.shape[2],3)\nX = np.array(x2)/255\nY = np.array(y2)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.1, random_state=42)\n```", "```py\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu',input_shape=(50,50,3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(512, kernel_size=(3, 3), activation='relu',padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n```", "```py\nhistory = model.fit(X_train, y_train, batch_size=32,epochs=10,verbose=1,validation_data = (X_test, y_test))\n```", "```py\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu',input_shape=(300,300,3)))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(512, kernel_size=(3, 3), activation='relu',padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n```", "```py\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, batch_size=32,epochs=10,verbose=1,validation_data = (X_test, y_test))\n```", "```py\nfrom keras.applications import vgg16\nfrom keras.utils.vis_utils import plot_model\nfrom keras.applications.vgg16 import preprocess_input\nvgg16_model = vgg16.VGG16(include_top=False, weights='imagenet',input_shape=(300,300,3))\n```", "```py\nfrom keras.applications.vgg16 import preprocess_input\nimg = preprocess_input(img.reshape(1,224,224,3))\n```", "```py\nimport cv2\nx2_vgg16 = []\nfor i in range(len(x)):\n    img = x[i]\n    img = preprocess_input(img.reshape(1,300,300,3))\n```", "```py\n    img_new = vgg16_model.predict(img.reshape(1,300,300,3))\n    x2_vgg16.append(img_new)\n```", "```py\nx2_vgg16 = np.array(x2_vgg16)\nx2_vgg16= x2_vgg16.reshape(x2_vgg16.shape[0],x2_vgg16.shape[2],x2_vgg16.shape[3],x2_vgg16.shape[4])\nY = np.array(y2)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x2_vgg16,Y, test_size=0.1, random_state=42)\n```", "```py\nmodel_vgg16 = Sequential()\nmodel_vgg16.add(Conv2D(512, kernel_size=(3, 3), activation='relu',input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])))\nmodel_vgg16.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_vgg16.add(Flatten())\nmodel_vgg16.add(Dense(512, activation='relu'))\nmodel_vgg16.add(Dropout(0.5))\nmodel_vgg16.add(Dense(1, activation='sigmoid'))\nmodel_vgg16.summary()\n```", "```py\nmodel_vgg16.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n```", "```py\nhistory_vgg16 = model_vgg16.fit(X_train/np.max(X_train), y_train, batch_size=16,epochs=10,verbose=1,validation_data = (X_test/np.max(X_train), y_test))\n```", "```py\nplt.imshow(x[3])\nplt.grid('off')\n```", "```py\nfrom keras.applications.vgg16 import preprocess_input\nmodel_vgg16.predict(vgg16_model.predict(preprocess_input(x[3].reshape(1,300,300,3)))/np.max(X_train))\nfrom keras import models\nactivation_model = models.Model(inputs=vgg16_model.input,outputs=vgg16_model.layers[1].output)\nactivations = activation_model.predict(preprocess_input(x[3].reshape(1,300,300,3)))\n```", "```py\nfig, axs = plt.subplots(6, 6, figsize=(10, 10))\nfig.subplots_adjust(hspace = .5, wspace=.5)\nfirst_layer_activation = activations[0]\nfor i in range(6):\n  for j in range(6):\n    try:\n      axs[i,j].set_ylim((224, 0))\n      axs[i,j].contourf(first_layer_activation[:,:,((6*i)+j)],6,cmap='viridis')\n      axs[i,j].set_title('filter: '+str((6*i)+j))\n      axs[i,j].axis('off')\n    except:\n      continue\n```", "```py\nactivation_model = models.Model(inputs=vgg16_model.input,outputs=vgg16_model.layers[1].output)\nactivations = activation_model.predict(preprocess_input(np.array(x[:36]).reshape(36,300,300,3)))\nfig, axs = plt.subplots(6, 6, figsize=(10, 10))\nfig.subplots_adjust(hspace = .5, wspace=.5)\nfirst_layer_activation = activations\nfor i in range(6):\n  for j in range(6):\n    try:\n      axs[i,j].set_ylim((224, 0))\n      axs[i,j].contourf(first_layer_activation[((6*i)+j),:,:,7],6,cmap='viridis')\n      axs[i,j].set_title('filter: '+str((6*i)+j))\n      axs[i,j].axis('off')\n    except:\n      continue\n```", "```py\nfor i, layer in enumerate(model.layers):\n     print(i, layer.name)\n```", "```py\nactivation_model = models.Model(inputs=vgg16_model.input,outputs=vgg16_model.layers[-1].output)\nactivations = activation_model.predict(preprocess_input(x[3].reshape(1,300,300,3)))\n```", "```py\nimport cv2\nx2 = []\nfor i in range(len(x)):\n    img = x[i]\n    img = preprocess_input(img.reshape(1,300,300,3))\n    img_new = vgg19_model.predict(img.reshape(1,300,300,3))\n    x2.append(img_new)\n```", "```py\nx2 = np.array(x2)\nx2= x2.reshape(x2.shape[0],x2.shape[2],x2.shape[3],x2.shape[4])\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x2,Y, test_size=0.1, random_state=42)\n```", "```py\nmodel_vgg19 = Sequential()\nmodel_vgg19.add(Conv2D(512, kernel_size=(3, 3), activation='relu',input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])))\nmodel_vgg19.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_vgg19.add(Flatten())\nmodel_vgg19.add(Dense(512, activation='relu'))\nmodel_vgg19.add(Dropout(0.5))\nmodel_vgg19.add(Dense(1, activation='sigmoid'))\nmodel_vgg19.summary()\n```", "```py\nmodel_vgg19.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n```", "```py\nhistory_vgg19 = model_vgg19.fit(X_train/np.max(X_train), y_train, batch_size=16,epochs=10,verbose=1,validation_data = (X_test/np.max(X_train), y_test))\n```", "```py\ntotal_loss = real_loss + 0.3 * aux_loss_1 + 0.3 * aux_loss_2\n```", "```py\nfrom keras.applications import inception_v3\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.utils.vis_utils import plot_model\ninception_model = inception_v3.InceptionV3(include_top=False, weights='imagenet',input_shape=(300,300,3))\n```", "```py\nimport cv2\nx2 = []\nfor i in range(len(x)):\n    img = x[i]\n    img = preprocess_input(img.reshape(1,300,300,3))\n    img_new = inception_model.predict(img.reshape(1,300,300,3))\n    x2.append(img_new)\n```", "```py\nx2 = np.array(x2)\nx2= x2.reshape(x2.shape[0],x2.shape[2],x2.shape[3],x2.shape[4])\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x2,Y, test_size=0.1, random_state=42)\n```", "```py\nmodel_inception_v3 = Sequential()\nmodel_inception_v3.add(Conv2D(512, kernel_size=(3, 3), activation='relu',input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])))\nmodel_inception_v3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_inception_v3.add(Flatten())\nmodel_inception_v3.add(Dense(512, activation='relu'))\nmodel_inception_v3.add(Dropout(0.5))\nmodel_inception_v3.add(Dense(1, activation='sigmoid'))\nmodel_inception_v3.summary()\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n```", "```py\nhistory_inception_v3 = model_inception_v3.fit(X_train/np.max(X_train), y_train, batch_size=16,epochs=10,verbose=1,validation_data = (X_test/np.max(X_train), y_test)) \n```", "```py\nfrom keras.applications import resnet50\nfrom keras.applications.resnet50 import preprocess_input\nresnet50_model = resnet50.ResNet50(include_top=False, weights='imagenet',input_shape=(300,300,3))\n```", "```py\nimport cv2\nx2 = []\nfor i in range(len(x)):\n    img = x[i]\n    img = preprocess_input(img.reshape(1,300,300,3))\n    img_new = resnet50_model.predict(img.reshape(1,300,300,3))\n    x2.append(img_new)\n```", "```py\nx2 = np.array(x2)\nx2= x2.reshape(x2.shape[0],x2.shape[2],x2.shape[3],x2.shape[4])\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x2,Y, test_size=0.1, random_state=42)\n```", "```py\nmodel_resnet50 = Sequential()\nmodel_resnet50.add(Conv2D(512, kernel_size=(3, 3), activation='relu',input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])))\nmodel_resnet50.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_resnet50.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\nmodel_resnet50.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_resnet50.add(Flatten())\nmodel_resnet50.add(Dense(512, activation='relu'))\nmodel_resnet50.add(Dropout(0.5))\nmodel_resnet50.add(Dense(1, activation='sigmoid'))\nmodel_resnet50.summary()\n\nmodel_resnet50.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n```", "```py\nhistory_resnet50 = model_resnet50.fit(X_train/np.max(X_train), y_train, batch_size=32,epochs=10,verbose=1,validation_data = (X_test/np.max(X_train), y_test))\n```", "```py\n$ git clone https://github.com/udacity/P1_Facial_Keypoints.git import pandas as pddata = pd.read_csv('/content/P1_Facial_Keypoints/data/training_frames_keypoints.csv')\n```", "```py\nimport cv2, numpy as np\nfrom copy import deepcopy\nx=[]\nx_img = []\ny=[]\n```", "```py\nfor i in range(data.shape[0]):\n     img_path = '/content/P1_Facial_Keypoints/data/training/' + data.iloc[i,0]\n     img = cv2.imread(img_path)\n```", "```py\n kp = deepcopy(data.iloc[i,1:].tolist())\n kp_x = (np.array(kp[0::2])/img.shape[1]).tolist()\n kp_y = (np.array(kp[1::2])/img.shape[0]).tolist()\n kp2 = kp_x + kp_y\n```", "```py\nimg = cv2.resize(img,(224,224))\n```", "```py\npreprocess_img = preprocess_input(img.reshape(1,224,224,3))\n vgg16_img = vgg16_model.predict(preprocess_img)\n```", "```py\n x_img.append(img)\n x.append(vgg16_img)\n y.append(kp2)\n```", "```py\nx = np.array(x)\nx = x.reshape(x.shape[0],7,7,512)\ny = np.array(y)\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nmodel_vgg16 = Sequential()\nmodel_vgg16.add(Conv2D(512, kernel_size=(3, 3), activation='relu',input_shape=(x.shape[1],x.shape[2],x.shape[3])))\nmodel_vgg16.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_vgg16.add(Flatten())\nmodel_vgg16.add(Dense(512, activation='relu'))\nmodel_vgg16.add(Dropout(0.5))\nmodel_vgg16.add(Dense(y.shape[1], activation='sigmoid'))\nmodel_vgg16.summary()\n```", "```py\nmodel_vgg16.compile(loss='mean_absolute_error',optimizer='adam')\n```", "```py\nhistory = model_vgg16.fit(x/np.max(x), y, epochs=10, batch_size=32, verbose=1, validation_split = 0.1)\n```", "```py\npred = model_vgg16.predict(vgg16_model.predict(preprocess_input(x_img[-2].reshape(1,224,224,3)))/np.max(x))\n```"]