["```py\n    import cv2\n    import numpy as np\n    import matplotlib.pyplot as plt\n    ```", "```py\n    image = cv2.imread('Dataset/obj_det/image6.jpg')\n    Width = image.shape[1]\n    Height = image.shape[0]\n    scale = 0.00392\n    ```", "```py\n    # read class names from text file\n    classes = None\n    with open(\"Models/yolov3.txt\", 'r') as f:\n        classes = [line.strip() for line in f.readlines()]\n    ```", "```py\n    COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n    ```", "```py\n    net = cv2.dnn.readNet('Models/yolov3.weights', 'Models/yolov3.cfg')\n    ```", "```py\n    blob = cv2.dnn.blobFromImage(image.copy(), scale, (416,416), (0,0,0), True, crop=False)\n    ```", "```py\n    net.setInput(blob)\n    ```", "```py\n    # function to get the output layer names in the architecture\n    def get_output_layers(net):\n\n        layer_names = net.getLayerNames()\n\n        output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n        return output_layers\n    ```", "```py\n    def draw_bounding_box(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n        label = str(classes[class_id])\n        color = COLORS[class_id]\n        cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n        cv2.putText(img, label + \" \" + str(confidence), (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n    ```", "```py\n    # run inference through the network\n    # and gather predictions from output layers\n    outs = net.forward(get_output_layers(net))\n    ```", "```py\n    # apply non-max suppression\n    class_ids = []\n    confidences = []\n    boxes = []\n    conf_threshold = 0.5\n    nms_threshold = 0.4\n    indexes = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n    ```", "```py\n    for out in outs:\n        for detection in out:\n            scores = detection[5:]\n            class_id = np.argmax(scores)\n            confidence = scores[class_id]\n            if confidence > 0.5:\n                center_x = int(detection[0] * Width)\n                center_y = int(detection[1] * Height)\n                w = int(detection[2] * Width)\n                h = int(detection[3] * Height)\n                x = center_x - w / 2\n                y = center_y - h / 2\n                class_ids.append(class_id)\n                confidences.append(float(confidence))\n                boxes.append([x, y, w, h])\n    ```", "```py\n    for i in indexes:\n        i = i[0]\n        box = boxes[i]\n        x = box[0]\n        y = box[1]\n        w = box[2]\n        h = box[3]\n\n        draw_bounding_box(image, class_ids[i], round(confidences[i],2), round(x), round(y), round(x+w), round(y+h))\n    ```", "```py\n    # display output image    \n    plt.axis(\"off\")\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    # save output image to disk\n    cv2.imwrite(\"object-detection6.jpg\", image)\n    ```", "```py\npip install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl\n```", "```py\nfrom imageai.Detection import ObjectDetection\n```", "```py\ndetector = ObjectDetection()\n```", "```py\ndetector.setModelTypeAsYOLOv3()\ndetector.setModelPath(\"Models/yolo.h5\")\ndetector.loadModel()\n```", "```py\ndetections = detector.detectObjectsFromImage(input_image=\"Dataset/obj_det/sample.jpg\", output_image_path=\"samplenew.jpg\")\n```", "```py\ncustom_objects = detector.CustomObjects(car=True)\ndetections = detector.detectCustomObjectsFromImage(custom_objects=custom_objects, input_image=\"Dataset/obj_det/sample.jpg\", output_image_path=\"samplenew.jpg\")\n```", "```py\nfrom imageai.Detection import VideoObjectDetection\nfrom matplotlib import pyplot as plt\n```", "```py\nvideo_detector = VideoObjectDetection()\n```", "```py\nvideo_detector.setModelTypeAsYOLOv3()\nvideo_detector.setModelPath(\"Models/yolo.h5\")\nvideo_detector.loadModel()\n```", "```py\ncolor_index = {'bus': 'red', 'handbag': 'steelblue', 'giraffe': 'orange', 'spoon': 'gray', 'cup': 'yellow', 'chair': 'green', 'elephant': 'pink', 'truck': 'indigo', 'motorcycle': 'azure', 'refrigerator': 'gold', 'keyboard': 'violet', 'cow': 'magenta', 'mouse': 'crimson', 'sports ball': 'raspberry', 'horse': 'maroon', 'cat': 'orchid', 'boat': 'slateblue', 'hot dog': 'navy', 'apple': 'cobalt', 'parking meter': 'aliceblue', 'sandwich': 'skyblue', 'skis': 'deepskyblue', 'microwave': 'peacock', 'knife': 'cadetblue', 'baseball bat': 'cyan', 'oven': 'lightcyan', 'carrot': 'coldgrey', 'scissors': 'seagreen', 'sheep': 'deepgreen', 'toothbrush': 'cobaltgreen', 'fire hydrant': 'limegreen', 'remote': 'forestgreen', 'bicycle': 'olivedrab', 'toilet': 'ivory', 'tv': 'khaki', 'skateboard': 'palegoldenrod', 'train': 'cornsilk', 'zebra': 'wheat', 'tie': 'burlywood', 'orange': 'melon', 'bird': 'bisque', 'dining table': 'chocolate', 'hair drier': 'sandybrown', 'cell phone': 'sienna', 'sink': 'coral', 'bench': 'salmon', 'bottle': 'brown', 'car': 'silver', 'bowl': 'maroon', 'tennis racket': 'palevilotered', 'airplane': 'lavenderblush', 'pizza': 'hotpink', 'umbrella': 'deeppink', 'bear': 'plum', 'fork': 'purple', 'laptop': 'indigo', 'vase': 'mediumpurple', 'baseball glove': 'slateblue', 'traffic light': 'mediumblue', 'bed': 'navy', 'broccoli': 'royalblue', 'backpack': 'slategray', 'snowboard': 'skyblue', 'kite': 'cadetblue', 'teddy bear': 'peacock', 'clock': 'lightcyan', 'wine glass': 'teal', 'frisbee': 'aquamarine', 'donut': 'mincream', 'suitcase': 'seagreen', 'dog': 'springgreen', 'banana': 'emeraldgreen', 'person': 'honeydew', 'surfboard': 'palegreen', 'cake': 'sapgreen', 'book': 'lawngreen', 'potted plant': 'greenyellow', 'toaster': 'ivory', 'stop sign': 'beige', 'couch': 'khaki'}\n```", "```py\ndef forFrame(frame_number, output_array, output_count, returned_frame):\n    plt.clf()\n    this_colors = []\n    labels = []\n    sizes = []\n    counter = 0\n```", "```py\n    for eachItem in output_count:\n        counter += 1\n        labels.append(eachItem + \" = \" + str(output_count[eachItem]))\n        sizes.append(output_count[eachItem])\n        this_colors.append(color_index[eachItem])\n```", "```py\n    plt.subplot(1, 2, 1)\n    plt.title(\"Frame : \" + str(frame_number))\n    plt.axis(\"off\")\n    plt.imshow(returned_frame, interpolation=\"none\")\n    plt.subplot(1, 2, 2)\n    plt.title(\"Analysis: \" + str(frame_number))\n    plt.pie(sizes, labels=labels, colors=this_colors, shadow=True, startangle=140, autopct=\"%1.1f%%\")\n    plt.pause(0.01)\n```", "```py\nplt.show()\nvideo_detector.detectObjectsFromVideo(input_file_path=\"path_to_video.mp4\", output_file_path=\"output-video\" ,  frames_per_second=20, per_frame_function=forFrame,  minimum_percentage_probability=30, return_detected_frame=True, log_progress=True)\n```", "```py\n    !pip3 install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl\n    ```"]