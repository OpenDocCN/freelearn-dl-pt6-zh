["```py\ncd ch5\njupyter notebook\n```", "```py\nfrom cntk.layers import Convolution2D, Sequential, Dense, MaxPooling\nfrom cntk.ops import log_softmax, relu\nfrom cntk.initializer import glorot_uniform\nfrom cntk import input_variable, default_options\n\nfeatures = input_variable((3,28,28))\nlabels = input_variable(10)\n\nwith default_options(initialization=glorot_uniform, activation=relu):\n    model = Sequential([\n        Convolution2D(filter_shape=(5,5), strides=(1,1), num_filters=8, pad=True),\n        MaxPooling(filter_shape=(2,2), strides=(2,2)),\n        Convolution2D(filter_shape=(5,5), strides=(1,1), num_filters=16, pad=True),\n        MaxPooling(filter_shape=(3,3), strides=(3,3)),\n        Dense(10, activation=log_softmax)\n    ])\n\nz = model(features)\n```", "```py\nimport os\nfrom cntk.io import MinibatchSource, StreamDef, StreamDefs, ImageDeserializer, INFINITELY_REPEAT\nimport cntk.io.transforms as xforms\n\ndef create_datasource(folder, max_sweeps=INFINITELY_REPEAT):\n    mapping_file = os.path.join(folder, 'mapping.bin')\n\n    stream_definitions = StreamDefs(\n        features=StreamDef(field='image', transforms=[]),\n        labels=StreamDef(field='label', shape=10)\n    )\n\n    deserializer = ImageDeserializer(mapping_file, stream_definitions)\n\n    return MinibatchSource(deserializer, max_sweeps=max_sweeps)\n```", "```py\ntrain_datasource = create_datasource('mnist_train')\ntest_datasource = create_datasource('mnist_test', max_sweeps=1, train=False)\n```", "```py\nfrom cntk import Function\nfrom cntk.losses import cross_entropy_with_softmax\nfrom cntk.metrics import classification_error\nfrom cntk.learners import sgd\n\n@Function\ndef criterion_factory(output, targets):\n    loss = cross_entropy_with_softmax(output, targets)\n    metric = classification_error(output, targets)\n\n    return loss, metric\n\nloss = criterion_factory(z, labels)\nlearner = sgd(z.parameters, lr=0.2)\n```", "```py\nfrom cntk.logging import ProgressPrinter\nfrom cntk.train import TestConfig\n\nprogress_writer = ProgressPrinter(0)\ntest_config = TestConfig(test_datasource)\n\ninput_map = {\n    features: train_datasource.streams.features,\n    labels: train_datasource.streams.labels\n}\n\nloss.train(train_datasource, \n           max_epochs=1,\n           minibatch_size=64,\n           epoch_size=60000, \n           parameter_learners=[learner], \n           model_inputs_to_streams=input_map, \n           callbacks=[progress_writer, test_config])\n```", "```py\naverage      since    average      since      examples\n    loss       last     metric       last              \n ------------------------------------------------------\nLearning rate per minibatch: 0.2\n      105        105      0.938      0.938            64\n 1.01e+07   1.51e+07      0.901      0.883           192\n 4.31e+06          2      0.897      0.895           448\n 2.01e+06          2      0.902      0.906           960\n 9.73e+05          2      0.897      0.893          1984\n 4.79e+05          2      0.894      0.891          4032\n[...]\n```", "```py\nimport os\nfrom cntk.io import MinibatchSource, StreamDef, StreamDefs, ImageDeserializer, INFINITELY_REPEAT\nimport cntk.io.transforms as xforms\n\ndef create_datasource(folder, train=True, max_sweeps=INFINITELY_REPEAT):\n    mapping_file = os.path.join(folder, 'mapping.bin')\n\n    image_transforms = []\n\n    if train:\n        image_transforms += [\n xforms.crop(crop_type='randomside', side_ratio=0.8),\n xforms.scale(width=28, height=28, channels=3, interpolations='linear')\n ]\n\n    stream_definitions = StreamDefs(\n        features=StreamDef(field='image', transforms=image_transforms),\n        labels=StreamDef(field='label', shape=10)\n    )\n\n    deserializer = ImageDeserializer(mapping_file, stream_definitions)\n\n    return MinibatchSource(deserializer, max_sweeps=max_sweeps)\n\n```"]