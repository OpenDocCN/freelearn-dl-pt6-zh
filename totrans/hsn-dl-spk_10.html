<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Deploying on a Distributed System</h1>
                </header>
            
            <article>
                
<p class="mce-root">The upcoming chapters of this book will show what we have learned so far in order to implement some practical and real-world use cases of CNNs and RNNs. But before doing that, let's consider DL4J in a production environment. This chapter is divided into four main sections:</p>
<ul>
<li class="mce-root">Some considerations about the setup for a DL4J environment in production, with focus in particular on memory management, CPU, and GPU setup, and job submission for training</li>
<li>Distributed training architecture details (data parallelism and strategies implemented in DL4J)</li>
<li class="mce-root">The practical way to import, train, and execute Python (Keras and TensorFlow) models in a DL4J (JVM)-based production environment</li>
<li class="mce-root">A comparison between DL4J and a couple of alternative DL frameworks for the Scala programming language (with particular focus on their readiness for production)</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setup of a distributed environment with DeepLearning4j</h1>
                </header>
            
            <article>
                
<p>This section explains some <span><span>tricks</span></span> to do when setting up a production environment for DL4J neural network model training and execution.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Memory management</h1>
                </header>
            
            <article>
                
<p>In <a href="3b6f47c0-6e17-484b-ad30-b6f92eb0473c.xhtml" target="_blank">Chapter 7</a><a href="3b6f47c0-6e17-484b-ad30-b6f92eb0473c.xhtml" target="_blank"/><a href="3b6f47c0-6e17-484b-ad30-b6f92eb0473c.xhtml" target="_blank"/><a href="3b6f47c0-6e17-484b-ad30-b6f92eb0473c.xhtml" target="_blank"/><a href="3b6f47c0-6e17-484b-ad30-b6f92eb0473c.xhtml" target="_blank"/>, <em>Training Neural Networks with Spark</em>, in the <em>Performance considerations </em>section, we learned how DL4J handles memory when training or running a model. Because it relies on ND4J, it also utilizes off-heap memory and not only heap memory. Being off-heap, it means that it is outside the scope managed by the JVM's <strong>Garbage Collection</strong> (<strong>GC</strong>) mechanism (the memory is allocated outside the JVM). At the JVM level, there are only pointers to off-heap memory locations; they can be passed to the C++ code via the Java Native Interface (JNI, <a href="https://docs.oracle.com/javase/8/docs/technotes/guides/jni/spec/jniTOC.html">https://docs.oracle.com/javase/8/docs/technotes/guides/jni/spec/jniTOC.html</a>) for use in ND4J operations.</p>
<p>In DL4J, it is possible to manage memory allocations using two different approaches:</p>
<ul>
<li>JVM GC and weak reference tracking</li>
<li>Memory workspaces</li>
</ul>
<p>In this section, both approaches are going to be covered. The idea behind both is the same: once an <kbd>INDArray</kbd> is no longer required, the off-heap memory associated with it should be released so that it can be reused. The difference between the two approaches is as follows:</p>
<ul>
<li><strong>JVM GC</strong>: When an <kbd>INDArray</kbd> is collected by the garbage collector, its off-heap memory is deallocated, with the assumption that it is not used elsewhere</li>
<li><strong>Memory workspaces</strong>: When an <kbd>INDArray</kbd> leaves the workspace scope, its off-heap memory may be reused, without deallocation and reallocation</li>
</ul>
<p>Please refer to <a href="3b6f47c0-6e17-484b-ad30-b6f92eb0473c.xhtml" target="_blank">Chapter 7</a><span>, </span><em>Training Neural Networks with Spark</em><span>, in the</span> <em>Performance considerations</em> section, for details on how to configure the limits for the heap and off-heap memory.</p>
<p>The memory workspaces approach needs more explanation. Compared to the JVM GC approach, it gives the best results in terms of performance in cyclic workloads. Within a workspace, any operation is possible with <kbd>INDArrays</kbd>. Then at the end of the workspace loop, all <kbd>INDArrays</kbd> content in memory is invalidated. Whether an <kbd>INDArray</kbd> should be needed outside a workspace (which could be the case when moving results out of it), it is possible to use the <kbd>detach</kbd> method of the <kbd>INDArray</kbd> itself to create an independent copy of it.</p>
<p>Workspaces are enabled by default in DL4J releases from 1.0.0-alpha or later. In order to use them, they need to be activated for DL4J release 0.9.1 or older. In DL4J 0.9.1, at network configuration time, workspaces can be activated this way (for training):</p>
<pre>val conf = new NeuralNetConfiguration.Builder()<br/>     .trainingWorkspaceMode(WorkspaceMode.SEPARATE)</pre>
<p>Or for inference, they can be activated as follows:</p>
<pre>val conf = new NeuralNetConfiguration.Builder()<br/>     .inferenceWorkspaceMode(WorkspaceMode.SINGLE)</pre>
<p>A <kbd>SEPARATE</kbd> workspace is slower, but it uses less memory, while a <kbd>SINGLE</kbd> workspace is faster, but requires more memory. The choice between <kbd>SEPARATE</kbd> and <kbd>SINGLE</kbd> depends on the compromise you choose between memory footprint and performance. When workspaces are enabled, all the memory used during training is made reusable and tracked without interference by the JVM GC. Only the <kbd>output</kbd> method, which uses workspaces internally for the feed-forward loop, is an exception, but then it detaches the resulting <kbd>INDArray</kbd> from the workspaces, so it can then be handled by the JVM GC. Starting from release 1.0.0-beta, the <kbd>SEPARATE</kbd> and <kbd>SINGLE</kbd> modes have been deprecated. The available modes are <kbd>ENABLED</kbd> (default) and <kbd>NONE</kbd>.</p>
<p>Please remember that, when a training process uses workspaces, in order to get the most from this approach, periodic GC calls need to be disabled, as follows:</p>
<pre>Nd4j.getMemoryManager.togglePeriodicGc(false)</pre>
<p>Or their frequency needs to be reduced, as follows:</p>
<pre>val gcInterval = 10000 // In milliseconds<br/> Nd4j.getMemoryManager.setAutoGcWindow(gcInterval)</pre>
<p>This setting should be done before invoking the <kbd>fit</kbd> method for the model in training. The workspace modes are available also for <kbd>ParallelWrapper</kbd> (in the case of training demanded to DL4J only, running multiple models on the same server).</p>
<p>In some cases, to save memory, it would be necessary to release all the workspaces created during training or evaluation. This can be done by invoking the following method of <kbd>WorkspaceManager</kbd>:</p>
<pre>Nd4j.getWorkspaceManager.destroyAllWorkspacesForCurrentThread</pre>
<p>It destroys all workspaces that have been created within the calling thread. Workspaces created in some external threads that are no longer needed can be destroyed using the same method in that thread.</p>
<p>In DL4J release 1.0.0-alpha and later, when using the <kbd>nd4j-native</kbd> backend, it is also possible to use a memory-mapped file instead of RAM. While it is slower, it allows memory allocation in a manner that is impossible to achieve using RAM. This option is mostly workable in those cases where <kbd>INDArrays</kbd> can't fit into RAM. Here's how this could be done programmatically:</p>
<pre>val mmap = WorkspaceConfiguration.builder<br/>    .initialSize(1000000000)<br/>    .policyLocation(LocationPolicy.MMAP)<br/>    .build<br/>    <br/>try (val ws = Nd4j.getWorkspaceManager.getAndActivateWorkspace(mmap, "M2")) {<br/>    val ndArray = Nd4j.create(20000) //INDArray<br/>}</pre>
<p>In this example, a temporary file of 2 GB is created, a workspace is mapped there, and the <kbd>ndArray</kbd> <kbd>INDArray</kbd> is created in that workspace.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CPU and GPU setup</h1>
                </header>
            
            <article>
                
<p>As mentioned before in this book, any application implemented through DL4J can be executed on CPUs or GPUs. To switch from CPUs to GPUs, a change in the application dependencies for ND4J is needed. Here's an example for CUDA release 9.2 (or later) and NVIDIA-compatible hardware (the example is for Maven, but the same dependency could be set for Gradle or sbt), as follows:</p>
<pre>&lt;dependency&gt;<br/> &lt;groupId&gt;org.nd4j&lt;/groupId&gt;<br/> &lt;artifactId&gt;nd4j-cuda-9.2&lt;/artifactId&gt;<br/> &lt;version&gt;0.9.1&lt;/version&gt;<br/>&lt;/dependency&gt;</pre>
<p>This dependency replaces that for <kbd>nd4j-native</kbd>.</p>
<p>When you have multiple GPUs in your system, whether it should restrict their usage and force to execute on a single one, it is possible to change this programmatically through the <kbd>CudaEnvironment</kbd> helper class (<a href="https://deeplearning4j.org/api/latest/org/nd4j/jita/conf/CudaEnvironment.html">https://deeplearning4j.org/api/latest/org/nd4j/jita/conf/CudaEnvironment.html</a>) of the <kbd>nd4j-cuda</kbd> library. The following line of code needs to be executed as the first instruction in a DL4J application entry point:</p>
<pre>CudaEnvironment.getInstance.getConfiguration.allowMultiGPU(true)</pre>
<p>In section 10.1.1, we have learned how to configure heap and off-heap memory in DL4J. Some considerations need to be made when executing on GPUs. It should be clear that the settings for the command-line arguments <kbd>org.bytedeco.javacpp.maxbytes</kbd> and <kbd>org.bytedeco.javacpp.maxphysicalbytes</kbd> define the memory limits for the GPU(s), because for <kbd>INDArrays</kbd><em>,</em> the off-heap memory is mapped to the GPU (<kbd>nd4j-cuda</kbd> is used).</p>
<p>Also, when running on GPUs, most probably less RAM would be used in the JVM heap, while more would be used in the off-heap, as this is where all of the <kbd>INDArrays</kbd> are stored. Allocating too much to the JVM heap would leave a real risk of having not enough memory left off-heap. Anyway, while doing proper settings, in some situations, execution could lead to the following exception:</p>
<pre>RuntimeException: Can't allocate [HOST] memory: [memory]; threadId: [thread_id];</pre>
<p>This means that we have run out of off-heap memory. In situations like this (in particular for training), we need to consider <kbd>WorkspaceConfiguration</kbd> to handle the <kbd>INDArrays</kbd> memory allocation (as learned in the <em>Memory management</em> section). If not, the <kbd>INDArrays</kbd> and their off-heap resources would be reclaimed through the JVM GC approach, which might severely increase latency and generate other potential out of memory issues.</p>
<p>The command-line arguments to set the memory limits are optional. Not specifying anything means that by default 25% of the total system RAM is set as the limit for the heap memory, while by default twice the RAM reserved for the heap memory would be set for the off-heap memory. It is up to us to find the perfect balance, particularly in cases of execution on GPUs, considering the expected amount of off-heap memory for the <kbd>INDArrays</kbd>.</p>
<p>Typically, CPU RAM is greater than GPU RAM. For this reason, how much RAM is being used off-heap needs to be monitored. DL4J allocates memory on the GPU equivalent to the amount of off-heap memory specified through the previously mentioned command-line arguments. In order to make the communication between CPU and GPU more efficient, DL4J allocates off-heap memory on the CPU RAM too. This way, a CPU can access data from an <kbd>INDArray</kbd> with no need to fetch data from a GPU any time there is a call for it.</p>
<p>However there is one caveat: if a GPU has less than 2 GB of RAM, it's probably not suitable for DL production workloads. In that case, a CPU should be used. Typically, DL workloads require a minimum of 4 GB of RAM (8 GB of RAM is recommended on a GPU).</p>
<p>Here is a final consideration: with a CUDA backend and using workspaces, it <span>is also possible to use <kbd>HOST_ONLY</kbd> memory. Programmatically, this could be set up as in the following example:</span></p>
<pre>val basicConfig = WorkspaceConfiguration.builder<br/>   .policyAllocation(AllocationPolicy.STRICT)<br/>   .policyLearning(LearningPolicy.FIRST_LOOP)<br/>   .policyMirroring(MirroringPolicy.HOST_ONLY)<br/>   .policySpill(SpillPolicy.EXTERNAL)<br/>   .build</pre>
<p>This reduces performance, but it can be <span>useful as in-memory cache pairs</span> when using the <kbd>unsafeDuplication</kbd> method of <kbd>INDArray</kbd>, which performs efficient (but unsafe) <kbd>INDArray</kbd> duplication.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a job to be submitted to Spark for training</h1>
                </header>
            
            <article>
                
<p>At this stage, I am assuming you have already started browsing and trying the code examples in the GitHub repository (<a href="https://github.com/PacktPublishing/Hands-On-Deep-Learning-with-Apache-Spark">https://github.com/PacktPublishing/Hands-On-Deep-Learning-with-Apache-Spark</a>) associated with this book. If so, you should have noticed that all of the Scala examples use Apache Maven (<a href="https://maven.apache.org/">https://maven.apache.org/</a>) for packaging and dependency management. In this section, I am going to refer to this tool in order to build a DL4J job that will then be submitted to Spark to train a model.</p>
<p>Once you are confident that the job that you have developed is ready for training in the destination Spark cluster, the first thing to do is to build the uber-JAR file (also called the fat JAR file), which contains the Scala DL4J Spark program classes and dependencies. Check that all of the required DL4J dependencies for the given project are present in the <kbd>&lt;dependencies&gt;</kbd> block of the project POM file. Check that the correct version of the dl4j-Spark library has been selected; all of the examples in this book are meant to be used with Scala 2.11.x and Apache Spark 2.2.x. The code should look as follows:</p>
<pre>&lt;dependency&gt;<br/>     &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;<br/>     &lt;artifactId&gt;dl4j-spark_2.11&lt;/artifactId&gt;<br/>     &lt;version&gt;0.9.1_spark_2&lt;/version&gt;<br/>&lt;/dependency&gt;</pre>
<p>If your project POM file, as well as the other dependencies, contains references to Scala and/or any of the Spark libraries, please declare their scope as <kbd>provided</kbd>, as they are already available across the cluster nodes. This way, the uber-JAR would be lighter.</p>
<p>Once you have checked for the proper dependencies, you need to instruct the POM file on how to build the uber-JAR. There are three techniques to build an uber-JAR: unshaded, shaded, and JAR of JARs. The best approach for this case would be a shaded uber-JAR. Along with the unshaded approach, it works with the Java default class loader (so there is no need to bundle an extra special class loader), but brings the advantage of skipping some dependency version conflicts and the possibility, when there are files present in multiple JARs with the same path, to apply an appending transformation to them. Shading can be achieved in Maven through the Shade plugin (<a href="http://maven.apache.org/plugins/maven-shade-plugin/">http://maven.apache.org/plugins/maven-shade-plugin/</a>). The plugin needs to be registered in the <kbd>&lt;plugins&gt;</kbd> section of the POM file as follows:</p>
<pre>&lt;plugin&gt;<br/>    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;<br/>    &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;<br/>    &lt;version&gt;3.2.1&lt;/version&gt;<br/>    &lt;configuration&gt;<br/>      &lt;!-- put your configurations here --&gt;<br/>    &lt;/configuration&gt;<br/>    &lt;executions&gt;<br/>      &lt;execution&gt;<br/>        &lt;phase&gt;package&lt;/phase&gt;<br/>        &lt;goals&gt;<br/>          &lt;goal&gt;shade&lt;/goal&gt;<br/>        &lt;/goals&gt;<br/>      &lt;/execution&gt;<br/>    &lt;/executions&gt;<br/>&lt;/plugin&gt;</pre>
<p>This plugin executes when the following <span>command is issued:</span></p>
<pre>mvn package -DskipTests</pre>
<p>At the end of the packaging process, the latest versions of this plugin replace the slim JAR with the uber-JAR, renaming it with the original filename. For a project with the following coordinates, t<span>he name of the uber-JAR would be</span><span> </span><kbd>rnnspark-1.0.jar</kbd><em>:</em></p>
<pre>&lt;groupId&gt;org.googlielmo&lt;/groupId&gt;<br/>&lt;artifactId&gt;rnnspark&lt;/artifactId&gt;<br/>&lt;version&gt;1.0&lt;/version&gt;</pre>
<p> The slim JAR is preserved anyway, but it is renamed as <kbd>original-rnnspark-1.0.jar</kbd>. They both can be found inside the <kbd>target</kbd> sub-directory of the project root directory.</p>
<p>The JAR can then be submitted to the Spark cluster for training using the <kbd>spark-submit</kbd> script, the same way as for any other Spark job, as follows:</p>
<pre><strong>$SPARK_HOME/bin/spark-submit --class &lt;package&gt;.&lt;class_name&gt; --master &lt;spark_master_url&gt; &lt;uber_jar&gt;.jar</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Spark distributed training architecture details</h1>
                </header>
            
            <article>
                
<p>The <em>Distributed network training with Spark and DeepLearning4J</em> section i<span>n </span><a href="3b6f47c0-6e17-484b-ad30-b6f92eb0473c.xhtml" target="_blank">Chapter 7</a><span>, <em>Training Neural Networks with Spark</em>,</span> explains why it is important to train MNNs in a distributed way across a cluster, and states that DL4J uses a parameter averaging approach to parallel training. This section goes through the architecture details of the distributed training approaches (parameter averaging and gradient sharing, which replaced the parameter averaging approach in DL4J starting from release 1.0.0-beta of the framework). The way DL4J approaches distributed training is transparent to developers, but it is good to have knowledge of it anyway.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model parallelism and data parallelism</h1>
                </header>
            
            <article>
                
<p>Parallelizing/distributing training computation can happen as <strong>model parallelism</strong> or <strong>data parallelism</strong>.</p>
<p>In model parallelism (see following diagram), different nodes of the cluster are responsible for the computation in different parts of a single MNN (an approach could be that each layer in the network is assigned to a different node):</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7d5a9a36-ede6-4b17-a35a-f71efc2d529f.png" style="width:36.00em;height:27.83em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 10.1: Model parallelism</div>
<p>In data parallelism (see the following diagram), different cluster nodes have a complete copy of the network model, but they get a different subset of the training data. The results from each node are then combined, as demonstrated in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/4f2147d0-b25b-4698-ba8c-698dca76d88b.png" style="width:35.67em;height:32.33em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 10.2: Data parallelism</div>
<p>These two approaches can <span>also</span><span> </span><span>be combined; they aren't mutually exclusive. Model parallelism works well in practice, but data parallelism has to be preferred for distributed training; matters like implementation, fault tolerance, and optimized cluster resource utilization (just to mention a few) are definitely easier for data parallelism than for model parallelism.</span></p>
<p>The data parallelism approach requires some way of combining the results and synchronizing the model parameters across workers. In the next two subsections, we are going to explore just the two (parameter averaging and gradient sharing) that have been implemented in DL4J.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Parameter averaging</h1>
                </header>
            
            <article>
                
<p>Parameter averaging happens as follows:</p>
<ol>
<li>The master first initializes the neural network parameters based on the model configuration</li>
<li>Then, it distributes a copy of the current parameters to each worker</li>
<li>The training starts on each worker using its own subset of data</li>
<li>The master sets the global parameters to the average parameters for each worker</li>
<li>In those cases where there is more data to process, the flow repeats from <em>Step 2</em></li>
</ol>
<p>The following diagram shows a representation from <em>Step 2</em> to <em>Step 4</em>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/bcfecfcc-1965-401b-b353-82b078608429.png" style="width:75.42em;height:31.58em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 10.3: Parameter averaging</div>
<p>In this diagram, <strong>W</strong> represents the parameters (weights and biases) in the network. In DL4J, this implementation uses Spark's TreeAggregate (<a href="https://umbertogriffo.gitbooks.io/apache-spark-best-practices-and-tuning/content/treereduce_and_treeaggregate_demystified.html">https://umbertogriffo.gitbooks.io/apache-spark-best-practices-and-tuning/content/treereduce_and_treeaggregate_demystified.html</a>).</p>
<p>Parameter averaging is a simple approach, but it comes with some challenges. The most intuitive idea for doing averaging is to simply average the parameters after each iteration. While this approach can work, the added overhead could be extremely high and the network communication and synchronization costs may nullify any benefit from scaling the cluster by adding extra nodes. For this reason, parameter averaging is typically implemented with an averaging period (number of minibatches per worker) greater than one. If the averaging period is too infrequent, the local parameters in each worker may significantly diverge, resulting in a poor model. Good averaging periods are of the order of once in every 10 to 20 minibatches per worker. Another challenge is related to the optimization methods (the updaters of DL4J). It has been demonstrated that these methods (<a href="http://ruder.io/optimizing-gradient-descent/">http://ruder.io/optimizing-gradient-descent/</a>) improve the convergence properties during neural network training. But they have an internal state that could probably be averaged as well. This results in a faster convergence in each worker, but at the cost of doubling the size of the network transfers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Asynchronous stochastic gradient sharing</h1>
                </header>
            
            <article>
                
<p>Asynchronous stochastic gradient sharing is the approach that has been chosen in the latest release of DL4J (and future ones as well). The main difference between asynchronous stochastic gradient sharing and parameter averaging is that in <span>asynchronous stochastic gradient sharing</span>, updates instead of parameters are transferred from the workers to the parameter server. From an architectural perspective, this is similar to parameter averaging (see the following diagram):</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/79e28023-42f8-4305-8972-923b5354f0be.png" style="width:67.83em;height:28.33em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 10.4: A<span>synchronous stochastic gradient sharing</span> architecture</div>
<p>What is different is the formula through which the parameters are calculated:</p>
<p><img class="fm-editor-equation" src="assets/159c04a0-1d94-43b1-bc89-5ad05105fc87.png" style="width:15.25em;height:4.50em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/c91cb8c9-1433-4549-b7aa-381e8950a0a3.png" style="width:0.83em;height:1.25em;"/> is the scaling factor. The <span>asynchronous stochastic gradient sharing</span> algorithm is obtained by allowing the updates <img class="fm-editor-equation" src="assets/108002a8-d16d-451e-836f-f5c30eb9e7bf.png" style="width:3.00em;height:1.33em;"/> to be applied to the parameter vectors as soon as they are computed.</p>
<p>One of the main benefits of <span>asynchronous stochastic gradient sharing</span> is that it is possible to obtain higher throughput in a distributed system, rather than waiting for the parameter averaging step to be completed, so the workers can spend more time performing useful computations. Another benefit is the following: the workers can potentially incorporate parameter updates from other workers sooner, when compared to the case of using synchronous updating.</p>
<p>One downside of <span>asynchronous stochastic gradient sharing</span> is the so-called stale gradient problem. The calculation of gradients (updates) requires time, and by the time a worker has finished his calculations and applied the results to the global parameter vector, the parameters may have been updated more than once (a problem you can't see in the parameter averaging, as this has a synchronous nature). Several approaches have been proposed in order to mitigate the stale gradient problem. Among these, one is by scaling the value <img class="fm-editor-equation" src="assets/c91cb8c9-1433-4549-b7aa-381e8950a0a3.png" style="width:0.83em;height:1.25em;"/> separately for each update, based on the staleness of the gradients. Another way is called soft synchronization: rather than updating the global parameter vector immediately, the parameter server waits to collect a given number of updates from any of the learners. Then, the formula through which the parameters are updated becomes this:</p>
<p><img class="fm-editor-equation" src="assets/7ed522f5-d93c-42d3-997c-26e0fea27211.png" style="width:19.92em;height:4.25em;"/></p>
<p>Here, <em>s</em> is the number of updates that the parameter server waits to collect and <img class="fm-editor-equation" src="assets/7fbd793e-4160-4bee-bba8-18fec6a7f311.png" style="width:4.17em;height:1.42em;"/> is a Scalar staleness-dependent scaling factor.</p>
<p>In DL4J, while the parameter averaging implementation has always been fault tolerant, the gradient sharing implementation has been made fully fault tolerant starting from release 1.0.0-beta3.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing Python models into the JVM with DL4J</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, we have learned how powerful and, at the same time, how easy the DL4J APIs are when it comes to configuring, building, and training multilayer neural network models. The possibilities to implement new models are almost innumerable relying on this framework only in Scala or Java.</p>
<p>But, let's have a look at the following search results from Google; they concern TensorFlow neural network models that are available on the web:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d75b5945-793d-4b08-b910-141e38adc3e8.png" style="width:33.83em;height:9.83em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 10.5: The result of a Google search about TensorFlow neural network models</div>
<p>You can see that it is quite an impressive number in terms of results. And this is just a raw search. Refining the search to more specific model implementations means that the numbers are pretty high. But what's TensorFlow? TensorFlow (<a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a>) is a powerful and comprehensive open source framework for ML and DL, developed by the Google Brain team. At present, it is the most popularly used framework by data scientists. So it has a big community, and lots of shared models and examples are available for it. This explains the big numbers. Among those models, the chances of finding a pre-trained model that fits your specific use case needs are high. So, where's the problem? TensorFlow is mostly Python.</p>
<p>It provides support for other programming languages, such as Java for the JVM, but its Java API is currently experimental and isn't covered by the TensorFlow API stability guarantees. Furthermore, the TensorFlow Python API presents a steep learning curve for non-Python developers and software engineers with no or a basic data science background. How then can they benefit from this framework? How can we reuse an existing valid model in a JVM-based environment? Keras (<a href="https://keras.io/">https://keras.io/</a>) comes to the rescue. It is an open source, high-level neural network library written in Python that can be used to replace the TensorFlow high-level API (the following diagram shows the TensorFlow framework architecture):</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c632938e-2c0f-4e23-9ea7-0b8593e06ea9.png" style="width:36.50em;height:19.08em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 10.6: The TensorFlow architecture</div>
<p>Compared to TensorFlow, Keras is lightweight and allows easier prototyping. It can run not only on top of TensorFlow, but also on other backend Python engines. And last but not least, it can be used to import Python models into DL4J. The Keras Model Import DL4J library provides facilities for importing neural network models configured and trained through the Keras framework.</p>
<p>The following diagram shows that once a model has been imported into DL4J, the full production stack is at disposal for using it:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/841beb3d-cdf3-4dff-86f9-c55d732296d5.png" style="width:56.75em;height:27.50em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 10.7: Importing a Keras model into DL4J</div>
<p>Let's now go into detail to understand how this happens. For the examples in this section, I am assuming you have already Python 2.7.x and the <kbd>pip</kbd> (<a href="https://pypi.org/project/pip/">https://pypi.org/project/pip/</a>) package installer for Python on your machine. In order to implement a model in Keras, we have to install Keras itself and choose a backend (TensorFlow for the examples presented here). TensorFlow has to be installed first, as follows:</p>
<pre><strong>sudo pip install tensorflow</strong></pre>
<p>That's for the CPU only. If you need to run it on GPUs, you need to install the following:</p>
<pre><strong>sudo pip install tensorflow-gpu</strong></pre>
<p>We can now install Keras, as follows:</p>
<pre><strong>sudo pip install keras</strong></pre>
<p>Keras uses TensorFlow as its default tensor manipulation library, so no extra action has to be taken if TensorFlow is our backend of choice.</p>
<p>Let's start simple, implementing an MLP model using the Keras API. After the necessary imports, enter the following lines of code:</p>
<pre>from keras.models import Sequential<br/> from keras.layers import Dense</pre>
<p>We create a <kbd>Sequential</kbd> model, as follows:</p>
<pre>model = Sequential()</pre>
<p>Then, we add layers through the <kbd>add</kbd> method of <kbd>Sequential</kbd>, as follows:</p>
<pre>model.add(Dense(units=64, activation='relu', input_dim=100))<br/> model.add(Dense(units=10, activation='softmax'))</pre>
<p>The configuration of the learning process for this model can be done through the <kbd>compile</kbd> method, as follows:</p>
<pre>model.compile(loss='categorical_crossentropy',<br/>               optimizer='sgd',<br/>               metrics=['accuracy'])</pre>
<p>Finally, we serialize the model in HDF5 format, as follows:</p>
<pre>model.save('basic_mlp.h5')</pre>
<p><strong><span>Hierarchical Data Format</span></strong> (<strong><span>HDF</span></strong>) is a set of file formats (with the extensions .hdf5 and .h5) to store and manage large amounts of data, in particular multidimensional numeric arrays. Keras uses it to save and load models.</p>
<p>After saving this simple program, <kbd>basic_mlp.py</kbd>, and running it, as follows the model will be serialized and saved in the <kbd>basic_mlp.h5</kbd> file:</p>
<pre><strong>sudo python basic_mlp.py</strong></pre>
<p>Now, we are ready to import this model into DL4J. We need to add to the Scala project the usual DataVec API, DL4J core, and ND4J dependencies, plus the DL4J model import library, as follows:</p>
<pre>groupId: org.deeplearning4j<br/> artifactId: deeplearning4j-modelimport<br/> version: 0.9.1</pre>
<p>Copy the <kbd>basic_mlp.h5</kbd> file in the resource folder of the project, then programmatically get its path, as follows:</p>
<pre>val basicMlp = new ClassPathResource("basic_mlp.h5").getFile.getPath</pre>
<p>Then, load the model as DL4J <kbd>MultiLayerNetwork</kbd><em>,</em> using the <kbd>importKerasSequentialModelAndWeights</kbd> method of the <kbd>KerasModelImport</kbd> class (<a href="https://static.javadoc.io/org.deeplearning4j/deeplearning4j-modelimport/1.0.0-alpha/org/deeplearning4j/nn/modelimport/keras/KerasModelImport.html">https://static.javadoc.io/org.deeplearning4j/deeplearning4j-modelimport/1.0.0-alpha/org/deeplearning4j/nn/modelimport/keras/KerasModelImport.html</a>), as follows:</p>
<pre>val model = KerasModelImport.importKerasSequentialModelAndWeights(basicMlp)</pre>
<p>Generate some mock data, as follows:</p>
<pre>val input = Nd4j.create(256, 100)<br/> var output = model.output(input)</pre>
<p>Now, we can train the model the usual way in DL4J, as follows:</p>
<pre>model.fit(input, output)</pre>
<p>All the considerations made in <a href="3b6f47c0-6e17-484b-ad30-b6f92eb0473c.xhtml" target="_blank">Chapter 7</a>, <em>Training Neural Networks with Spark</em>, <a href="b30120ea-bd42-4cb7-95d9-5ecaa2b7c181.xhtml" target="_blank">Chapter 8</a>, <em>Monitoring and Debugging Neural Network Training</em>, and <a href="869a9495-e759-4810-8623-d8b76ba61398.xhtml" target="_blank">Chapter 9</a>, <em>Interpreting Neural Network Output</em>, about training, monitoring, and evaluation with DL4J, apply here too.</p>
<p>It is possible, of course, to train the model in Keras (as in the following example):</p>
<pre>model.fit(x_train, y_train, epochs=5, batch_size=32)</pre>
<p>Here, <kbd>x_train</kbd> and <kbd>y_train</kbd> are NumPy (<a href="http://www.numpy.org/">http://www.numpy.org/</a>) arrays) and evaluate it before saving it in serialized form, as follows:</p>
<p><kbd>loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)</kbd></p>
<p>You can finally import the pre-trained model in the same way as explained previously, and just run it.</p>
<p>The same as for <kbd>Sequential</kbd> model imports, DL4J allows also the importing of Keras <kbd>Functional</kbd> models.</p>
<p>The latest versions of DL4J, also allow the importing of TensorFlow models. Imagine you want to import this (<a href="https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py">https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py</a>) pre-trained model (a CNN estimator for the <kbd>MNIST</kbd> database). At the end of the training, which happens in TensorFlow, you can save the model in a serialized form. TensorFlow's file format is based on Protocol Buffers (<a href="https://developers.google.com/protocol-buffers/?hl=en">https://developers.google.com/protocol-buffers/?hl=en</a>), which is a language and platform neutral extensible serialization mechanism for structured data.</p>
<p>Copy the serialized <kbd>mnist.pb</kbd> file into the resource folder of the DL4J Scala project and then programmatically get it and import the model, as follows:</p>
<pre>val mnistTf = new ClassPathResource("mnist.pb").getFile<br/> val sd = TFGraphMapper.getInstance.importGraph(mnistTf)</pre>
<p>Finally, feed the model with images and start to do predictions, as follows:</p>
<pre>for(i &lt;- 1 to 10){<br/>    val file = "images/img_%d.jpg"<br/>    file = String.format(file, i)<br/>    val prediction = predict(file) //INDArray<br/>    val batchedArr = Nd4j.expandDims(arr, 0) //INDArray<br/>    sd.associateArrayWithVariable(batchedArr, sd.variables().get(0))<br/>    val out = sd.execAndEndResult //INDArray<br/>    Nd4j.squeeze(out, 0)<br/>    ...<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Alternatives to DL4J for the Scala programming language</h1>
                </header>
            
            <article>
                
<p>DL4J isn't the only framework for deep learning available for the Scala programming language. Two open source alternatives exist. In this section, we are going to learn more about them and do a comparison with DL4J.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">BigDL</h1>
                </header>
            
            <article>
                
<p>BigDL (<a href="https://bigdl-project.github.io/0.6.0/">https://bigdl-project.github.io/0.6.0/</a>) is an open source, distributed, deep learning framework for Apache Spark implemented by Intel (<a href="https://www.intel.com">https://www.intel.com</a>). It is licensed with the Apache 2.0 license, the same as for DL4J. It has been implemented in Scala and exposes APIs for Scala and Python. It doesn't provide support for CUDA. While DL4J allows cross-platform execution in standalone mode (including Android mobile devices) and distributed mode (with and without Spark), BigDL has been designed to execute in a Spark cluster only. The available benchmarks state that training/running this framework is faster than the most popular Python frameworks, such as TensorFlow or Caffe, because BigDL uses the Intel Math Kernel Library (MKL, <a href="https://software.intel.com/en-us/mkl">https://software.intel.com/en-us/mkl</a>), assuming it is running on Intel processor-based machines.</p>
<p>It provides high-level APIs for neural networks and the possibility to import Python models from Keras, Caffe, or Torch.</p>
<p>While it has been implemented in Scala, at the time this chapter was written, it supports only Scala 2.10.x.</p>
<p>Looking at the latest evolution of this framework, it seems that Intel is going to provide more support for importing Python models implemented with other frameworks (and is starting also to provide support for some TensorFlow operations) and enhancements of the Python API, rather than the Scala API. </p>
<p>What about community and contributions? BigDL is supported and driven by Intel, which keeps an eye in particular on how this framework is used on hardware based on their microprocessors. So, this could be a potential risk in adopting this framework in other production hardware contexts. While DL4J is supported by Skymind (<a href="https://skymind.ai/">https://skymind.ai/</a>), the company owned by Adam Gibson, who is one of the authors of this framework, the vision, in terms of future evolution, isn't restricted to the company business. The goal is to make the framework more comprehensive in terms of capabilities and try to further reduce the gap between the JVM languages and Python in relation to available numeric computation and DL tools/features. Also, the number of contributors, commits, and releases are increasing for DL4J.</p>
<p>Compared to the Scala BigDL API, the DL4J API for Scala (and Java) is more high level (some sort of DSL), which is in particular of great help for Scala developers approaching the DL world for the first time, as it speeds up the the process of getting familiar with the framework, and allows programmers to focus more on the model being trained and implemented.</p>
<p>If your plan is to stay in the JVM world, I definitely believe DL4J is a better choice than BigDL.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">DeepLearning.scala</h1>
                </header>
            
            <article>
                
<p>DeepLearning.scala (<a href="https://deeplearning.thoughtworks.school/">https://deeplearning.thoughtworks.school/</a>) is a DL framework from ThoughtWorks (<a href="https://www.thoughtworks.com/">https://www.thoughtworks.com/</a>). Implemented in Scala, the goal since the start has been, to get the most from the functional programming and object-oriented paradigms for this language. It supports GPU-accelerated <em>N</em>-dimensional arrays. Neural networks in this framework can be built from mathematical formulas, so it can calculate derivatives of the weights in the formulas used.</p>
<p>This framework supports plugins, so it could be extended by writing custom plugins, which can then coexist along with the plugin set available out of the box (a significant set of plugins is currently available in terms of models, algorithms, hyperparameters, calculation features, and so on).</p>
<p>DeepLearning.scala applications can run as standalone on the JVM, as Jupyter (<a href="http://jupyter.org/">http://jupyter.org/</a>) notebooks, or as scripts in Ammonite (<a href="http://ammonite.io/">http://ammonite.io/</a>).</p>
<p>Numerical computing happens through ND4J, the same as for DL4J.</p>
<p>It doesn't have support for Python, nor facilities to import models implemented through Python DL frameworks.</p>
<p>One big difference between this framework and others, such as DL4J and BigDL, is the following: the structure of the neural networks is dynamically determined at runtime. All the Scala language features (functions, expressions, control flows, and so on) are available for implementation. Neural networks are Scala Monads, so they can be created by composing higher order functions, but that's not the only option in DeepLearning.scala; the framework also provides a type class called <kbd>Applicative</kbd> (through the Scalaz library, <a href="http://eed3si9n.com/learning-scalaz/Applicative.html">http://eed3si9n.com/learning-scalaz/Applicative.html</a>), which allows multiple calculations in parallel.</p>
<p>No native support for Spark or Hadoop was available for this framework at the time this chapter was written.</p>
<p>DeepLearning.scala can be a good alternative to DL4J in those contexts where there's no need for Apache Spark distributed training, and where you want to implement things in pure Scala. In terms of APIs for this programming language, it is more observant of the principles of pure Scala programming than DL4J, which has targeted all of the languages that run on the JVM (starting from Java, then extending to Scala, Clojure, and others, including Android).</p>
<p>The initial visions for these two frameworks are also different: DL4J started to target software engineers, while DeepLearning.scala has an approach more oriented toward <span>data scientists</span>. Still to be verified is its level of stability and performance in production, as it is younger than DL4J and has a smaller number of adopters in real use cases. The lack of support to import existing models from Python frameworks could also be a limitation, because you would need to build and train your model from scratch and can't rely on existing Python models that may be an excellent fit for your specific use case. In terms of community and releases, at present it can't <span>of course</span><span> </span><span>compare with DL4J and BigDL (even if there is the chance that it could grow in the very near future). Last but not least, the official documentation and examples are limited and not yet as mature and comprehensive as they are for DL4J. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, some concepts to think about when moving DL4J to production have been discussed. In particular, we understood how heap and off-heap memory management should be set up, looked at extra considerations on GPUs setup, saw how to prepare job JARs to be submitted to Spark for training, and also saw how it is possible to import and integrate Python models into an existing DL4J JVM infrastructure. Finally, a comparison between DL4J and two other DL frameworks for Scala (BigDL and DeepLearning.scala) was presented, and the reasons why DL4J could be a better choice from a production perspective were detailed.</p>
<p>In the next chapter, the core concepts of Natural Language Processing (NLP) will be explained, and a complete Scala implementation of NLP using Apache Spark and its MLLib (Machine Learning Library) will be detailed. We will go through the potential limitations of this approach, before in <a href="2bff1c2a-d984-49a0-aa22-03bafeb05fbc.xhtml" target="_blank">Chapter 12</a>, <em>Textual Analysis and Deep Learning</em>, presenting the same solution using DL4J and/or Keras/TensorFlow.</p>


            </article>

            
        </section>
    </body></html>