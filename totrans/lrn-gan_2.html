<html><head></head><body><div id="book-columns"><div id="book-inner"><div class="chapter" title="Chapter 2. Unsupervised Learning with GAN"><div class="titlepage"><div><div><h1 class="title"><a id="ch02"/><span class="koboSpan" id="kobo.1.1">Chapter 2. Unsupervised Learning with GAN</span></h1></div></div></div><p><span class="koboSpan" id="kobo.2.1">Recently, with the progress of generative models, neural networks can not only recognize images but they can be used to generate audio and realistic images as well.</span></p><p><span class="koboSpan" id="kobo.3.1">In this chapter, we will deep dive into the creative nature of deep learning through the latest state of the art algorithm of </span><span class="strong"><strong><span class="koboSpan" id="kobo.4.1">Generative Adversarial Network</span></strong></span><span class="koboSpan" id="kobo.5.1">, commonly known as </span><span class="strong"><strong><span class="koboSpan" id="kobo.6.1">GAN</span></strong></span><span class="koboSpan" id="kobo.7.1">. </span><span class="koboSpan" id="kobo.7.2">You will learn through hands-on examples to use the generative ability of the neural networks in</span><a id="id47" class="indexterm"/><span class="koboSpan" id="kobo.8.1"> generating realistic images from various real-world datasets (such as </span><code class="literal"><span class="koboSpan" id="kobo.9.1">MNIST</span></code><span class="koboSpan" id="kobo.10.1"> and </span><code class="literal"><span class="koboSpan" id="kobo.11.1">CIFAR</span></code><span class="koboSpan" id="kobo.12.1">). </span><span class="koboSpan" id="kobo.12.2">Also, you will understand how to overcome the major challenge of unsupervised learning with deep networks using semi-supervised approach and apply it to your own problem domain. </span><span class="koboSpan" id="kobo.12.3">In the final section of this chapter, you will learn some of the training obstacles followed by practical tips and tricks of working with GAN models.</span></p><p><span class="koboSpan" id="kobo.13.1">We will cover the following topics in this chapter:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.14.1">What is GAN? </span><span class="koboSpan" id="kobo.14.2">its application, tips, and tricks</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.15.1">Explaining the concept of GAN through two-layer neural network image generation with TensorFlow</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.16.1">Image generation</span><a id="id48" class="indexterm"/><span class="koboSpan" id="kobo.17.1"> with </span><span class="strong"><strong><span class="koboSpan" id="kobo.18.1">Deep Convolutional GAN</span></strong></span><span class="koboSpan" id="kobo.19.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.20.1">DCGAN</span></strong></span><span class="koboSpan" id="kobo.21.1">) using Keras</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.22.1">Implementation of semi-supervised learning using TensorFlow</span></li></ul></div><div class="section" title="Automating human tasks with deep neural networks"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec11"/><span class="koboSpan" id="kobo.23.1">Automating human tasks with deep neural networks</span></h1></div></div></div><p><span class="koboSpan" id="kobo.24.1">In the last few years, there has</span><a id="id49" class="indexterm"/><span class="koboSpan" id="kobo.25.1"> been an explosion of</span><a id="id50" class="indexterm"/><span class="koboSpan" id="kobo.26.1"> deep neural networks that can perform image classification, voice recognition, and understanding natural language with good accuracy.</span></p><p><span class="koboSpan" id="kobo.27.1">The current state of the art algorithms within the field of deep neural network are able to learn highly complex models of the patterns inherent in a set of data. </span><span class="koboSpan" id="kobo.27.2">While the capabilities are impressive, human beings are capable of doing much more than just image recognition or understanding what people are talking about and automating those tasks through machines seems </span><a id="id51" class="indexterm"/><span class="koboSpan" id="kobo.28.1">far-fetched.</span></p><p><span class="koboSpan" id="kobo.29.1">Let us see some use cases</span><a id="id52" class="indexterm"/><span class="koboSpan" id="kobo.30.1"> where we need human creativity (at least as of now):</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.31.1">Training an artificial author that can write an article and explain data science concepts to a community in a very simplistic manner by learning from past articles from Wikipedia</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.32.1">Creating an artificial painter that can paint like any famous artist by learning from his/her past collections</span></li></ul></div><p><span class="koboSpan" id="kobo.33.1">Do you believe that machines are capable of accomplishing these tasks? </span><span class="koboSpan" id="kobo.33.2">To your surprise the answer is "YES".</span></p><p><span class="koboSpan" id="kobo.34.1">Of course, these are difficult tasks to automate, but GANs have started making some of these tasks possible.</span></p><p><span class="koboSpan" id="kobo.35.1">Yann LeCun, a prominent figure in the deep learning domain (Director of Facebook AI) said that:</span></p><div class="blockquote"><blockquote class="blockquote"><p><span class="koboSpan" id="kobo.36.1">Generative Adversarial Network (GANs), and the variations that are now being proposed is the most interesting idea in the last 10 years in Machine Learning.</span></p></blockquote></div><p><span class="koboSpan" id="kobo.37.1">If you feel intimidated by the name GAN, don't worry! </span><span class="koboSpan" id="kobo.37.2">You will master this technique and apply it to real-world problems yourself by the end of this book.</span></p><div class="section" title="The purpose of GAN"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec19"/><span class="koboSpan" id="kobo.38.1">The purpose of GAN</span></h2></div></div></div><p><span class="koboSpan" id="kobo.39.1">Some generative models</span><a id="id53" class="indexterm"/><span class="koboSpan" id="kobo.40.1"> are able to generate samples from model distribution. </span><span class="koboSpan" id="kobo.40.2">GANs are an example of generative models. </span><span class="koboSpan" id="kobo.40.3">GAN focuses primarily on generating samples from distribution.</span></p><p><span class="koboSpan" id="kobo.41.1">You might be wondering why generative models are worth studying, especially generative models that are only capable of generating data rather than providing an estimate of the density function.</span></p><p><span class="koboSpan" id="kobo.42.1">Some of the reasons to study generative models are as follows:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.43.1">Sampling (or generation) is straightforward</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.44.1">Training doesn't involve maximum likelihood estimation</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.45.1">Robust to</span><a id="id54" class="indexterm"/><span class="koboSpan" id="kobo.46.1"> overfitting since the generator never sees the training data</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.47.1">GANs are good at capturing the modes of distribution</span></li></ul></div></div><div class="section" title="An analogy from the real world"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec20"/><span class="koboSpan" id="kobo.48.1">An analogy from the real world</span></h2></div></div></div><p><span class="koboSpan" id="kobo.49.1">Let's consider</span><a id="id55" class="indexterm"/><span class="koboSpan" id="kobo.50.1"> the real-world relationship between a money counterfeiting criminal and the police. </span><span class="koboSpan" id="kobo.50.2">Let's enumerate the objective of the criminal and the police in terms of money:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.51.1"><img src="graphics/B08086_02_1.jpg" alt="An analogy from the real world"/></span><div class="caption"><p><span class="koboSpan" id="kobo.52.1">Figure1a: GAN real world analogy</span></p></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.53.1">To become a successful money counterfeiter, the criminal needs to fool the police so that the police can't tell the difference between the counterfeit/fake money and real money</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.54.1">As a paragon of justice, the police want to detect fake money as effectively as possible</span></li></ul></div><p><span class="koboSpan" id="kobo.55.1">This can be modeled</span><a id="id56" class="indexterm"/><span class="koboSpan" id="kobo.56.1"> as a minimax game in game theory. </span><span class="koboSpan" id="kobo.56.2">This phenomenon is called </span><span class="strong"><strong><span class="koboSpan" id="kobo.57.1">adversarial process</span></strong></span><span class="koboSpan" id="kobo.58.1">. </span><span class="koboSpan" id="kobo.58.2">GAN, introduced by Ian Goodfellow in 2014 at </span><span class="emphasis"><em><span class="koboSpan" id="kobo.59.1">arXiv: 1406.2661</span></em></span><span class="koboSpan" id="kobo.60.1">, is a special case of an adversarial process where two neural networks compete against each other. </span><span class="koboSpan" id="kobo.60.2">The first</span><a id="id57" class="indexterm"/><span class="koboSpan" id="kobo.61.1"> network generates data and the second network tries to find the difference between the real data and the fake data generated by the first network. </span><span class="koboSpan" id="kobo.61.2">The second network will output a scalar [0, 1], which represents a probability of real data.</span></p></div><div class="section" title="The building blocks of GAN"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec21"/><span class="koboSpan" id="kobo.62.1">The building blocks of GAN</span></h2></div></div></div><p><span class="koboSpan" id="kobo.63.1">In GAN, the first </span><a id="id58" class="indexterm"/><span class="koboSpan" id="kobo.64.1">network is called</span><a id="id59" class="indexterm"/><span class="koboSpan" id="kobo.65.1"> generator and is often represented as </span><span class="emphasis"><em><span class="koboSpan" id="kobo.66.1">G(z)</span></em></span><span class="koboSpan" id="kobo.67.1"> and the second network is called discriminator and is often represented as </span><span class="emphasis"><em><span class="koboSpan" id="kobo.68.1">D(x)</span></em></span><span class="koboSpan" id="kobo.69.1">:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.70.1"><img src="graphics/B08086_02_2.png.jpg" alt="The building blocks of GAN"/></span><div class="caption"><p><span class="koboSpan" id="kobo.71.1">Figure 1b: Generative adversarial network</span></p></div></div><p><span class="koboSpan" id="kobo.72.1">At the equilibrium point, which is the optimal point in the minimax game, the first network will model the real data and the second network will output a probability of 0.5 as the output of the first network = real data:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.73.1"><img src="graphics/B08086_02_3.jpg" alt="The building blocks of GAN"/></span></div><p><span class="koboSpan" id="kobo.74.1">Sometimes the two networks eventually reach equilibrium, but this is not always guaranteed and the two networks can continue learning for a long time. </span><span class="koboSpan" id="kobo.74.2">An example of learning with both </span><a id="id60" class="indexterm"/><span class="koboSpan" id="kobo.75.1">generator and discriminator loss is shown in the following figure:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.76.1"><img src="graphics/B08086_02_4.png.jpg" alt="The building blocks of GAN"/></span><div class="caption"><p><span class="koboSpan" id="kobo.77.1">Figure 1c: Loss of two networks, generator and discriminator</span></p></div></div><div class="section" title="Generator"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec01"/><span class="koboSpan" id="kobo.78.1">Generator</span></h3></div></div></div><p><span class="koboSpan" id="kobo.79.1">The generator network</span><a id="id61" class="indexterm"/><span class="koboSpan" id="kobo.80.1"> takes as input random noise and tries to generate a sample of data. </span><span class="koboSpan" id="kobo.80.2">In the preceding figure, we </span><a id="id62" class="indexterm"/><span class="koboSpan" id="kobo.81.1">can see that generator </span><span class="emphasis"><em><span class="koboSpan" id="kobo.82.1">G(z)</span></em></span><span class="koboSpan" id="kobo.83.1"> takes an input </span><span class="emphasis"><em><span class="koboSpan" id="kobo.84.1">z</span></em></span><span class="koboSpan" id="kobo.85.1"> from probability distribution </span><span class="emphasis"><em><span class="koboSpan" id="kobo.86.1">p(z)</span></em></span><span class="koboSpan" id="kobo.87.1"> and generates data that is then fed into a discriminator network </span><span class="emphasis"><em><span class="koboSpan" id="kobo.88.1">D(x)</span></em></span><span class="koboSpan" id="kobo.89.1">.</span></p></div><div class="section" title="Discriminator"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec02"/><span class="koboSpan" id="kobo.90.1">Discriminator</span></h3></div></div></div><p><span class="koboSpan" id="kobo.91.1">The discriminator </span><a id="id63" class="indexterm"/><span class="koboSpan" id="kobo.92.1">network takes input either from the real data or from the generator's generated data and</span><a id="id64" class="indexterm"/><span class="koboSpan" id="kobo.93.1"> tries to predict whether the input is real or generated. </span><span class="koboSpan" id="kobo.93.2">It takes an input </span><span class="emphasis"><em><span class="koboSpan" id="kobo.94.1">x</span></em></span><span class="koboSpan" id="kobo.95.1"> from real data distribution </span><span class="emphasis"><em><span class="koboSpan" id="kobo.96.1">P</span></em></span>
<span class="emphasis"><em><sub><span class="koboSpan" id="kobo.97.1">data</span></sub></em></span>
<span class="emphasis"><em><span class="koboSpan" id="kobo.98.1">(x)</span></em></span><span class="koboSpan" id="kobo.99.1"> and then solves a binary classification problem giving output in the scalar range 0 to 1.</span></p><p><span class="koboSpan" id="kobo.100.1">GANs are gaining lot of popularity because of their ability to tackle the important challenge of unsupervised learning, since the amount of available unlabeled data is much larger than the</span><a id="id65" class="indexterm"/><span class="koboSpan" id="kobo.101.1"> amount of labeled data. </span><span class="koboSpan" id="kobo.101.2">Another reason for their popularity is that GANs are able to generate the most realistic images among generative models. </span><span class="koboSpan" id="kobo.101.3">Although this is subjective, it is an opinion shared by most practitioners.</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.102.1"><img src="graphics/B08086_02_5.png.jpg" alt="Discriminator"/></span><div class="caption"><p><span class="koboSpan" id="kobo.103.1">Figure-1d: Vector arithmetic in GANs</span></p></div></div><p><span class="koboSpan" id="kobo.104.1">Beside this, GAN is often very expressive: it can perform arithmetic operations in the latent space, that is the space of the z vectors, and translate into corresponding operations in feature space. </span><span class="koboSpan" id="kobo.104.2">As shown in </span><span class="emphasis"><em><span class="koboSpan" id="kobo.105.1">Figure 1d</span></em></span><span class="koboSpan" id="kobo.106.1">, if you take the representation of a man with glasses in latent space, subtract the </span><code class="literal"><span class="koboSpan" id="kobo.107.1">neutral man</span></code><span class="koboSpan" id="kobo.108.1"> vector and add back the </span><code class="literal"><span class="koboSpan" id="kobo.109.1">neutral woman</span></code><span class="koboSpan" id="kobo.110.1"> vector, you end up with a picture of a woman with glasses in feature space. </span><span class="koboSpan" id="kobo.110.2">This is truly amazing.</span></p></div></div></div></div></div></div>
<div id="book-columns"><div id="book-inner"><div class="section" title="Implementation of GAN"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec12"/><span class="koboSpan" id="kobo.1.1">Implementation of GAN</span></h1></div></div></div><p><span class="koboSpan" id="kobo.2.1">As per the </span><a id="id66" class="indexterm"/><span class="koboSpan" id="kobo.3.1">definition of GAN, we basically require two networks, be it a sophisticated network such as ConvNet or a simple two-layer neural network. </span><span class="koboSpan" id="kobo.3.2">Let's use a simple two-layer neural network with the </span><code class="literal"><span class="koboSpan" id="kobo.4.1">MNIST</span></code><span class="koboSpan" id="kobo.5.1"> dataset using TensorFlow for implementation purposes. </span><code class="literal"><span class="koboSpan" id="kobo.6.1">MNIST</span></code><span class="koboSpan" id="kobo.7.1"> is a dataset of handwritten digits where each image is gray scale of dimension 28x28 pixel:</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.8.1"># Random noise setting for Generator
Z = tf.placeholder(tf.float32, shape=[None, 100], name='Z')

#Generator parameter settings
G_W1 = tf.Variable(xavier_init([100, 128]), name='G_W1')
G_b1 = tf.Variable(tf.zeros(shape=[128]), name='G_b1')
G_W2 = tf.Variable(xavier_init([128, 784]), name='G_W2')
G_b2 = tf.Variable(tf.zeros(shape=[784]), name='G_b2')
theta_G = [G_W1, G_W2, G_b1, G_b2]


# Generator Network
def generator(z):
    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)
    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2
    G_prob = tf.nn.sigmoid(G_log_prob)

    return G_prob</span></pre></div><p><span class="koboSpan" id="kobo.9.1">The </span><code class="literal"><span class="koboSpan" id="kobo.10.1">generator(z)</span></code><span class="koboSpan" id="kobo.11.1"> takes as input a 100-dimensional vector from a random distribution (in this case we are using</span><a id="id67" class="indexterm"/><span class="koboSpan" id="kobo.12.1"> uniform distribution) and returns a 786-dimensional vector, which is a </span><code class="literal"><span class="koboSpan" id="kobo.13.1">MNIST</span></code><span class="koboSpan" id="kobo.14.1"> image (28x28). </span><span class="koboSpan" id="kobo.14.2">The </span><code class="literal"><span class="koboSpan" id="kobo.15.1">z</span></code><span class="koboSpan" id="kobo.16.1"> here is the prior for the </span><span class="emphasis"><em><span class="koboSpan" id="kobo.17.1">G(z)</span></em></span><span class="koboSpan" id="kobo.18.1">. </span><span class="koboSpan" id="kobo.18.2">In this way, it learns a mapping between the prior space to </span><span class="emphasis"><em><span class="koboSpan" id="kobo.19.1">p</span></em></span>
<sub><span class="emphasis"><em><span class="koboSpan" id="kobo.20.1">data</span></em></span></sub><span class="koboSpan" id="kobo.21.1"> (real data distribution):</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.22.1">#Input Image MNIST setting for Discriminator [28x28=784]
X = tf.placeholder(tf.float32, shape=[None, 784], name='X')

#Discriminator parameter settings
D_W1 = tf.Variable(xavier_init([784, 128]), name='D_W1')
D_b1 = tf.Variable(tf.zeros(shape=[128]), name='D_b1')
D_W2 = tf.Variable(xavier_init([128, 1]), name='D_W2')
D_b2 = tf.Variable(tf.zeros(shape=[1]), name='D_b2')
theta_D = [D_W1, D_W2, D_b1, D_b2]


# Discriminator Network
def discriminator(x):
    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)
    D_logit = tf.matmul(D_h1, D_W2) + D_b2
    D_prob = tf.nn.sigmoid(D_logit)

return D_prob, D_logit</span></pre></div><p><span class="koboSpan" id="kobo.23.1">Whereas the </span><code class="literal"><span class="koboSpan" id="kobo.24.1">discriminator(x)</span></code><span class="koboSpan" id="kobo.25.1"> takes </span><code class="literal"><span class="koboSpan" id="kobo.26.1">MNIST</span></code><span class="koboSpan" id="kobo.27.1"> image(s) as input and returns a scalar that represents a probability of real image. </span><span class="koboSpan" id="kobo.27.2">Now, let's discuss an algorithm for training GAN. </span><span class="koboSpan" id="kobo.27.3">Here's the pseudo code for</span><a id="id68" class="indexterm"/><span class="koboSpan" id="kobo.28.1"> a training algorithm from the paper </span><span class="emphasis"><em><span class="koboSpan" id="kobo.29.1">arXiv: 1406.2661, 2014</span></em></span><span class="koboSpan" id="kobo.30.1">:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.31.1"><img src="graphics/B08086_02_6.png.jpg" alt="Implementation of GAN"/></span><div class="caption"><p><span class="koboSpan" id="kobo.32.1">Figure 1e: GAN training algorithm pseudo-code</span></p></div></div><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.33.1">G_sample = generator(Z)

D_real, D_logit_real = discriminator(X)
D_fake, D_logit_fake = discriminator(G_sample)

# Loss functions according the GAN original paper
D_loss = -tf.reduce_mean(tf.log(D_real) + tf.log(1. </span><span class="koboSpan" id="kobo.33.2">- D_fake))
G_loss = -tf.reduce_mean(tf.log(D_fake))</span></pre></div><p><span class="koboSpan" id="kobo.34.1">The TensorFlow optimizer can only do minimization, so in order to maximize the </span><code class="literal"><span class="koboSpan" id="kobo.35.1">loss</span></code><span class="koboSpan" id="kobo.36.1"> function, we are using a negative sign for the loss as seen previously. </span><span class="koboSpan" id="kobo.36.2">Also, as per the paper's pseudo algorithm, it's better to maximize </span><code class="literal"><span class="koboSpan" id="kobo.37.1">tf.reduce_mean(tf.log(D_fake))</span></code><span class="koboSpan" id="kobo.38.1"> instead of minimizing </span><code class="literal"><span class="koboSpan" id="kobo.39.1">tf.reduce_mean(1 - tf.log(D_fake)</span></code><span class="koboSpan" id="kobo.40.1">. </span><span class="koboSpan" id="kobo.40.2">Then we train the networks one by one with those preceding </span><code class="literal"><span class="koboSpan" id="kobo.41.1">loss</span></code><span class="koboSpan" id="kobo.42.1"> functions:</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.43.1"># Only update D(X)'s parameters, so var_list = theta_D
D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)
# Only update G(X)'s parameters, so var_list = theta_G
G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)

def sample_Z(m, n):
    '''Uniform prior for G(Z)'''
    return np.random.uniform(-1., 1., size=[m, n])

for it in range(1000000):
    X_mb, _ = mnist.train.next_batch(mb_size)

    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_Z(mb_size, Z_dim)})
    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(mb_size, Z_dim)})</span></pre></div><p><span class="koboSpan" id="kobo.44.1">After that we start </span><a id="id69" class="indexterm"/><span class="koboSpan" id="kobo.45.1">with random noise and as the training continues, </span><code class="literal"><span class="koboSpan" id="kobo.46.1">G(Z)</span></code><span class="koboSpan" id="kobo.47.1"> starts moving towards </span><span class="emphasis"><em><span class="koboSpan" id="kobo.48.1">p</span></em></span>
<sub><span class="emphasis"><em><span class="koboSpan" id="kobo.49.1">data</span></em></span></sub><span class="koboSpan" id="kobo.50.1">. </span><span class="koboSpan" id="kobo.50.2">This is proved by the more similar samples generated by </span><code class="literal"><span class="koboSpan" id="kobo.51.1">G(Z)</span></code><span class="koboSpan" id="kobo.52.1"> compared to original MNIST images.</span></p><p><span class="koboSpan" id="kobo.53.1">Some of the output generated after 60,000 iterations is shown as follows:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.54.1"><img src="graphics/B08086_02_7.png.jpg" alt="Implementation of GAN"/></span><div class="caption"><p><span class="koboSpan" id="kobo.55.1">Figure 1f: GAN implementation of a generated output image</span></p></div></div><div class="section" title="Applications of GAN"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec22"/><span class="koboSpan" id="kobo.56.1">Applications of GAN</span></h2></div></div></div><p><span class="koboSpan" id="kobo.57.1">GAN is generating lots of excitement in a wide variety of fields. </span><span class="koboSpan" id="kobo.57.2">Some of the exciting applications of</span><a id="id70" class="indexterm"/><span class="koboSpan" id="kobo.58.1"> GAN in recent years are listed as follows:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.59.1">Translating one image to another (such as horse to zebra) with CycleGAN and performing image editing through Conditional GAN. </span><span class="koboSpan" id="kobo.59.2">Details will be covered in </span><a class="link" href="ch03.html" title="Chapter 3. Transfer Image Style Across Various Domains"><span class="koboSpan" id="kobo.60.1">Chapter 3</span></a><span class="koboSpan" id="kobo.61.1">, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.62.1">Transfer Image Style Across Various Domains</span></em></span><span class="koboSpan" id="kobo.63.1">.</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.64.1">Automatic synthesis of realistic images from a textual sentence using StackGAN. </span><span class="koboSpan" id="kobo.64.2">And</span><a id="id71" class="indexterm"/><span class="koboSpan" id="kobo.65.1"> transferring style from one domain to another domain using </span><span class="strong"><strong><span class="koboSpan" id="kobo.66.1">Discovery GAN</span></strong></span><span class="koboSpan" id="kobo.67.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.68.1">DiscoGAN</span></strong></span><span class="koboSpan" id="kobo.69.1">). </span><span class="koboSpan" id="kobo.69.2">Details will be covered in </span><a class="link" href="ch04.html" title="Chapter 4. Building Realistic Images from Your Text"><span class="koboSpan" id="kobo.70.1">Chapter 4</span></a><span class="koboSpan" id="kobo.71.1">, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.72.1">Building Realistic Images from Your Text</span></em></span><span class="koboSpan" id="kobo.73.1">.</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.74.1">Enhancing image quality and generating high resolution images with pre-trained models using SRGAN. </span><span class="koboSpan" id="kobo.74.2">Details will be covered in </span><a class="link" href="ch05.html" title="Chapter 5. Using Various Generative Models to Generate Images"><span class="koboSpan" id="kobo.75.1">Chapter 5</span></a><span class="koboSpan" id="kobo.76.1">, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.77.1">Using Various Generative Models to Generate Images</span></em></span><span class="koboSpan" id="kobo.78.1">.</span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong><span class="koboSpan" id="kobo.79.1">Generating realistic a image from attributes</span></strong></span><span class="koboSpan" id="kobo.80.1">: Let's say a burglar comes to your apartment but you don't have a picture of him/her. </span><span class="koboSpan" id="kobo.80.2">Now the system at the police station could generate a realistic image of the thief based on the description provided by you and search a database. </span><span class="koboSpan" id="kobo.80.3">For more information refer to </span><span class="emphasis"><em><span class="koboSpan" id="kobo.81.1">arXiv: 1605.05396, 2016</span></em></span><span class="koboSpan" id="kobo.82.1">.</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.83.1">Predicting the</span><a id="id72" class="indexterm"/><span class="koboSpan" id="kobo.84.1"> next frame in a video or dynamic video generation: (</span><a class="ulink" href="http://carlvondrick.com/tinyvideo/"><span class="koboSpan" id="kobo.85.1">http://carlvondrick.com/tinyvideo/</span></a><span class="koboSpan" id="kobo.86.1">).</span></li></ul></div></div><div class="section" title="Image generation with DCGAN using Keras"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec23"/><span class="koboSpan" id="kobo.87.1">Image generation with DCGAN using Keras</span></h2></div></div></div><p><span class="koboSpan" id="kobo.88.1">The </span><span class="strong"><strong><span class="koboSpan" id="kobo.89.1">Deep Convolutional Generative Adversarial Networks</span></strong></span><span class="koboSpan" id="kobo.90.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.91.1">DCGAN</span></strong></span><span class="koboSpan" id="kobo.92.1">) are introduced in the paper: </span><span class="emphasis"><em><span class="koboSpan" id="kobo.93.1">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</span></em></span><span class="koboSpan" id="kobo.94.1">, by </span><span class="emphasis"><em><span class="koboSpan" id="kobo.95.1">A. </span><span class="koboSpan" id="kobo.95.2">Radford, L. </span><span class="koboSpan" id="kobo.95.3">Metz, and S. </span><span class="koboSpan" id="kobo.95.4">Chintala, arXiv:1511.06434, 2015</span></em></span><span class="koboSpan" id="kobo.96.1">.</span></p><p><span class="koboSpan" id="kobo.97.1">The generator uses a</span><a id="id73" class="indexterm"/><span class="koboSpan" id="kobo.98.1"> 100-dimensional, uniform distribution space, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.99.1">Z</span></em></span><span class="koboSpan" id="kobo.100.1">, which is then projected into a smaller space by a series of convolution operations. </span><span class="koboSpan" id="kobo.100.2">An example is shown in the following figure:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.101.1"><img src="graphics/B08086_02_8.png.jpg" alt="Image generation with DCGAN using Keras"/></span><div class="caption"><p><span class="koboSpan" id="kobo.102.1">Figure 2: DCGAN architecture of the generator</span></p><p><span class="koboSpan" id="kobo.103.1">Source: arXiv, 1511.06434,2015</span></p></div></div><p><span class="koboSpan" id="kobo.104.1">DCGAN stabilizes the networks with the following architectural constraints:</span></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.105.1">Replace any </span><a id="id74" class="indexterm"/><span class="koboSpan" id="kobo.106.1">pooling layers with strided convolutions in the discriminator and fractional-strided convolutions in the generator</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.107.1">Use batchnorm</span><a id="id75" class="indexterm"/><span class="koboSpan" id="kobo.108.1"> in both the generator and the discriminator</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.109.1">Remove fully connected hidden layers for deeper architectures and simply use average pooling at the end</span></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.110.1">Use ReLU activation in the generator for all layers except for the output, which uses </span><code class="literal"><span class="koboSpan" id="kobo.111.1">tanh</span></code></li><li class="listitem" style="list-style-type: disc"><span class="koboSpan" id="kobo.112.1">Use leaky ReLU activation in the discriminator for all layers</span></li></ul></div><p><span class="koboSpan" id="kobo.113.1">A DCGAN generator can be</span><a id="id76" class="indexterm"/><span class="koboSpan" id="kobo.114.1"> described by the following code implemented in Keras, available at: </span><a class="ulink" href="https://github.com/jacobgil/keras-dcgan"><span class="koboSpan" id="kobo.115.1">https://github.com/jacobgil/keras-dcgan</span></a><span class="koboSpan" id="kobo.116.1">.</span></p><p><span class="koboSpan" id="kobo.117.1">Start the training/generation process with the following command:</span></p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong><span class="koboSpan" id="kobo.118.1">python dcgan.py --mode train --batch_size &lt;batch_size&gt;</span></strong></span>
<span class="strong"><strong><span class="koboSpan" id="kobo.119.1">python dcgan.py --mode generate --batch_size &lt;batch_size&gt; --nice</span></strong></span>
</pre></div><div class="mediaobject"><span class="koboSpan" id="kobo.120.1"><img src="graphics/B08086_02_9.png.jpg" alt="Image generation with DCGAN using Keras"/></span></div><p><span class="koboSpan" id="kobo.121.1">Note that the</span><a id="id77" class="indexterm"/><span class="koboSpan" id="kobo.122.1"> number of batches printed previously is calculated based on input image shape/batch size (provided).</span></p><p><span class="koboSpan" id="kobo.123.1">Now let's jump into the code. </span><span class="koboSpan" id="kobo.123.2">The generator can be described with the following:</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.124.1">def generator_model():
    model = Sequential()
    model.add(Dense(input_dim=100, output_dim=1024))
    model.add(Activation('tanh'))
    model.add(Dense(128*7*7))
    model.add(BatchNormalization())
    model.add(Activation('tanh'))
    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))
    model.add(UpSampling2D(size=(2, 2)))
    model.add(Conv2D(64, (5, 5), padding='same'))
    model.add(Activation('tanh'))
    model.add(UpSampling2D(size=(2, 2)))
    model.add(Conv2D(1, (5, 5), padding='same'))
    model.add(Activation('tanh'))
    return model</span></pre></div><p><span class="koboSpan" id="kobo.125.1">The first dense layer of the generator takes as input a vector of 100 dimensions and it produces output of 1,024 dimensions with the activation function </span><code class="literal"><span class="koboSpan" id="kobo.126.1">tanh</span></code><span class="koboSpan" id="kobo.127.1">.</span></p><p><span class="koboSpan" id="kobo.128.1">The next dense layer in the network produces data of 128 x 7 x 7 in the output using batch normalization (refer to </span><span class="emphasis"><em><span class="koboSpan" id="kobo.129.1">Batch Normalization Accelerating Deep Network Training by Reducing Internal Covariate Shift</span></em></span><span class="koboSpan" id="kobo.130.1">, by </span><span class="emphasis"><em><span class="koboSpan" id="kobo.131.1">S. </span><span class="koboSpan" id="kobo.131.2">Ioffe</span></em></span><span class="koboSpan" id="kobo.132.1"> and </span><span class="emphasis"><em><span class="koboSpan" id="kobo.133.1">C.Szegedy</span></em></span><span class="koboSpan" id="kobo.134.1">, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.135.1">arXiv: 1502.03167</span></em></span><span class="koboSpan" id="kobo.136.1">, 2014), a technique that often helps to stabilize learning by normalizing the input with zero mean and unit variance. </span><span class="koboSpan" id="kobo.136.2">Batch normalization has been empirically proven to speed up training in many situations, reduce the problems of poor initialization, and in general produce more</span><a id="id78" class="indexterm"/><span class="koboSpan" id="kobo.137.1"> accurate results. </span><span class="koboSpan" id="kobo.137.2">There is also a </span><code class="literal"><span class="koboSpan" id="kobo.138.1">Reshape()</span></code><span class="koboSpan" id="kobo.139.1"> module that produces data of 128 x 7 x 7 (128 channels, 7 width, and 7 height), </span><code class="literal"><span class="koboSpan" id="kobo.140.1">dim_ordering</span></code><span class="koboSpan" id="kobo.141.1"> to </span><code class="literal"><span class="koboSpan" id="kobo.142.1">tf</span></code><span class="koboSpan" id="kobo.143.1">, and a </span><code class="literal"><span class="koboSpan" id="kobo.144.1">UpSampling()</span></code><span class="koboSpan" id="kobo.145.1"> module that produces a repetition of each one into a 2 x 2 square. </span><span class="koboSpan" id="kobo.145.2">After that, we have a convolutional layer that produces 64 filters on 5 x 5 convolutional kernels/patches with </span><code class="literal"><span class="koboSpan" id="kobo.146.1">tanh</span></code><span class="koboSpan" id="kobo.147.1"> activation having same padding followed by a new </span><code class="literal"><span class="koboSpan" id="kobo.148.1">UpSampling()</span></code><span class="koboSpan" id="kobo.149.1"> and a final convolution with one filter, and on 5 x 5 convolutional kernels with the activation as </span><code class="literal"><span class="koboSpan" id="kobo.150.1">tanh</span></code><span class="koboSpan" id="kobo.151.1">. </span><span class="koboSpan" id="kobo.151.2">Note that there are no pooling operations in the ConvNet.</span></p><p><span class="koboSpan" id="kobo.152.1">The discriminator can be described with the following code:</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.153.1">def discriminator_model():
    model = Sequential()
    model.add(Conv2D(64, (5, 5), padding='same',input_shape=(28, 28, 1)))
    model.add(Activation('tanh'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(128, (5, 5)))
    model.add(Activation('tanh'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(1024))
    model.add(Activation('tanh'))
    model.add(Dense(1))
    model.add(Activation('sigmoid'))
    return model</span></pre></div><p><span class="koboSpan" id="kobo.154.1">The discriminator takes a standard MNIST image with the shape (</span><code class="literal"><span class="koboSpan" id="kobo.155.1">1, 28, 28</span></code><span class="koboSpan" id="kobo.156.1">) and applies a convolution with 64 filters of size 5 x 5 with </span><code class="literal"><span class="koboSpan" id="kobo.157.1">tanh</span></code><span class="koboSpan" id="kobo.158.1"> as the activation function. </span><span class="koboSpan" id="kobo.158.2">It is then followed</span><a id="id79" class="indexterm"/><span class="koboSpan" id="kobo.159.1"> by a max-pooling operation of size 2 x 2 and by a further convolution max-pooling operation. </span></p><p><span class="koboSpan" id="kobo.160.1">The last two stages are dense, with the final one being the prediction for forgery, which consists of only a single neuron with a </span><code class="literal"><span class="koboSpan" id="kobo.161.1">sigmoid</span></code><span class="koboSpan" id="kobo.162.1"> activation function. </span><span class="koboSpan" id="kobo.162.2">For a given number of epochs, the generator and discriminator are trained by using </span><code class="literal"><span class="koboSpan" id="kobo.163.1">binary_crossentropy</span></code><span class="koboSpan" id="kobo.164.1"> as a </span><code class="literal"><span class="koboSpan" id="kobo.165.1">loss</span></code><span class="koboSpan" id="kobo.166.1"> function. </span><span class="koboSpan" id="kobo.166.2">At each epoch, the generator makes a prediction of a number (for example, it creates forged MNIST images) and the discriminator tries to learn after mixing the prediction with real MNIST images. </span><span class="koboSpan" id="kobo.166.3">After a few epochs, the generator automatically learns to forge this set of handwritten numbers:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.167.1"><img src="graphics/B08086_02_10.png.jpg" alt="Image generation with DCGAN using Keras"/></span><div class="caption"><p><span class="koboSpan" id="kobo.168.1">Figure-3: Deep convolutional GAN generated handwritten digit output</span></p></div></div><p><span class="koboSpan" id="kobo.169.1">Note that training GANs could be very difficult because it is necessary to find the equilibrium</span><a id="id80" class="indexterm"/><span class="koboSpan" id="kobo.170.1"> between two players and hence some of the valuable techniques and tips used by practitioners are given in the final section of this chapter.</span></p></div><div class="section" title="Implementing SSGAN using TensorFlow"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec24"/><span class="koboSpan" id="kobo.171.1">Implementing SSGAN using TensorFlow</span></h2></div></div></div><p><span class="koboSpan" id="kobo.172.1">The basic</span><a id="id81" class="indexterm"/><span class="koboSpan" id="kobo.173.1"> intuition of </span><span class="strong"><strong><span class="koboSpan" id="kobo.174.1">Semi-Supervised Learning Generative Adversarial Network</span></strong></span><span class="koboSpan" id="kobo.175.1"> (</span><span class="strong"><strong><span class="koboSpan" id="kobo.176.1">SSGAN</span></strong></span><span class="koboSpan" id="kobo.177.1">) is to exploit the samples generated by generators to enhance the performance of image classification</span><a id="id82" class="indexterm"/><span class="koboSpan" id="kobo.178.1"> tasks of the discriminator by improving generalization. </span><span class="koboSpan" id="kobo.178.2">The key idea is to train one of the networks as both image classifier and discriminator (to identify generated images from real images).</span></p><p><span class="koboSpan" id="kobo.179.1">For a dataset having </span><span class="emphasis"><em><span class="koboSpan" id="kobo.180.1">n</span></em></span><span class="koboSpan" id="kobo.181.1"> classes, the dual trained (discriminator/classifier) network will take an image as input and classify the real images into the first </span><span class="emphasis"><em><span class="koboSpan" id="kobo.182.1">n</span></em></span><span class="koboSpan" id="kobo.183.1"> classes and generated images into the </span><span class="emphasis"><em><span class="koboSpan" id="kobo.184.1">n+1-th</span></em></span><span class="koboSpan" id="kobo.185.1"> class, as shown in the following figure:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.186.1"><img src="graphics/B08086_02_11.png.jpg" alt="Implementing SSGAN using TensorFlow"/></span><div class="caption"><p><span class="koboSpan" id="kobo.187.1">Source: </span><a class="ulink" href="https://github.com/gitlimlab/SSGAN-Tensorflow/blob/master/figure/ssgan.png"><span class="koboSpan" id="kobo.188.1">https://github.com/gitlimlab/SSGAN-Tensorflow/blob/master/figure/ssgan.png</span></a>
</p></div></div><p><span class="koboSpan" id="kobo.189.1">This multi-tasking learning framework consists of two losses, first the supervised loss:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.190.1"><img src="graphics/B08086_02_12.jpg" alt="Implementing SSGAN using TensorFlow"/></span></div><p><span class="koboSpan" id="kobo.191.1">and second the GAN loss of a discriminator:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.192.1"><img src="graphics/B08086_02_13.jpg" alt="Implementing SSGAN using TensorFlow"/></span></div><p><span class="koboSpan" id="kobo.193.1">During the</span><a id="id83" class="indexterm"/><span class="koboSpan" id="kobo.194.1"> training phase, both these losses are jointly minimized.</span></p><div class="section" title="Setting up the environment"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec03"/><span class="koboSpan" id="kobo.195.1">Setting up the environment</span></h3></div></div></div><p><span class="koboSpan" id="kobo.196.1">Perform the following steps to execute SSGAN on Cifar-10 datasets:</span></p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem"><span class="koboSpan" id="kobo.197.1">Clone</span><a id="id84" class="indexterm"/><span class="koboSpan" id="kobo.198.1"> the </span><code class="literal"><span class="koboSpan" id="kobo.199.1">git</span></code><span class="koboSpan" id="kobo.200.1"> repo: </span><a class="ulink" href="https://github.com/gitlimlab/SSGAN-Tensorflow"><span class="koboSpan" id="kobo.201.1">https://github.com/gitlimlab/SSGAN-Tensorflow</span></a><span class="koboSpan" id="kobo.202.1">:</span><div class="mediaobject"><span class="koboSpan" id="kobo.203.1"><img src="graphics/B08086_02_14.png.jpg" alt="Setting up the environment"/></span></div></li><li class="listitem"><span class="koboSpan" id="kobo.204.1">Change</span><a id="id85" class="indexterm"/><span class="koboSpan" id="kobo.205.1"> the directory:</span><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong><span class="koboSpan" id="kobo.206.1">cd SSGAN-Tensorflow/</span></strong></span>
</pre></div></li><li class="listitem"><span class="koboSpan" id="kobo.207.1">Download the </span><code class="literal"><span class="koboSpan" id="kobo.208.1">CIFAR-10</span></code><span class="koboSpan" id="kobo.209.1"> dataset:</span><div class="mediaobject"><span class="koboSpan" id="kobo.210.1"><img src="graphics/B08086_02_15.png.jpg" alt="Setting up the environment"/></span></div></li><li class="listitem"><span class="koboSpan" id="kobo.211.1">Train the model:</span><div class="mediaobject"><span class="koboSpan" id="kobo.212.1"><img src="graphics/B08086_02_16.png.jpg" alt="Setting up the environment"/></span></div></li><li class="listitem"><span class="koboSpan" id="kobo.213.1">Test or evaluate the model:</span><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong><span class="koboSpan" id="kobo.214.1">python evaler.py --dataset CIFAR10 --checkpoint ckpt_dir</span></strong></span>
</pre></div></li></ol></div><p><span class="koboSpan" id="kobo.215.1">Now let's dive</span><a id="id86" class="indexterm"/><span class="koboSpan" id="kobo.216.1"> into the code. </span><span class="koboSpan" id="kobo.216.2">The generator takes random noise from the uniform distribution:</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.217.1">z = tf.random_uniform([self.batch_size, n_z], minval=-1, maxval=1, dtype=tf.float32)</span></pre></div><p><span class="koboSpan" id="kobo.218.1">Then the generator model flattens the input noise to 1 dimensional vector using the </span><code class="literal"><span class="koboSpan" id="kobo.219.1">reshape</span></code><span class="koboSpan" id="kobo.220.1"> method. </span><span class="koboSpan" id="kobo.220.2">It then applies three layers of deconvolution on the input noise having </span><code class="literal"><span class="koboSpan" id="kobo.221.1">ReLU</span></code><span class="koboSpan" id="kobo.222.1"> activation and then applies one more deconvolution with </span><code class="literal"><span class="koboSpan" id="kobo.223.1">tanh</span></code><span class="koboSpan" id="kobo.224.1"> activation to generate the output image of dimension [</span><span class="emphasis"><em><span class="koboSpan" id="kobo.225.1">h</span></em></span><span class="koboSpan" id="kobo.226.1">=height, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.227.1">w</span></em></span><span class="koboSpan" id="kobo.228.1">=width, </span><span class="emphasis"><em><span class="koboSpan" id="kobo.229.1">c</span></em></span><span class="koboSpan" id="kobo.230.1">], where </span><span class="emphasis"><em><span class="koboSpan" id="kobo.231.1">c</span></em></span><span class="koboSpan" id="kobo.232.1"> is the number of channels (grayscale images: 1, color images: 3):</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.233.1"># Generator model function
        def G(z, scope='Generator'):
            with tf.variable_scope(scope) as scope:
                print ('\033[93m'+scope.name+'\033[0m')
                z = tf.reshape(z, [self.batch_size, 1, 1, -1])
                g_1 = deconv2d(z, deconv_info[0], is_train, name='g_1_deconv') 
                print (scope.name, g_1)
                g_2 = deconv2d(g_1, deconv_info[1], is_train, name='g_2_deconv')
                print (scope.name, g_2)
                g_3 = deconv2d(g_2, deconv_info[2], is_train, name='g_3_deconv')
                print (scope.name, g_3)
                g_4 = deconv2d(g_3, deconv_info[3], is_train, name='g_4_deconv', activation_fn='tanh')
                print (scope.name, g_4)
                output = g_4
                assert output.get_shape().as_list() == self.image.get_shape().as_list(), output.get_shape().as_list()
            return output

# Deconvolution method
def deconv2d(input, deconv_info, is_train, name="deconv2d", stddev=0.02,activation_fn='relu'):
    with tf.variable_scope(name):
        output_shape = deconv_info[0]
        k = deconv_info[1]
        s = deconv_info[2]
        deconv = layers.conv2d_transpose(input,
            num_outputs=output_shape,
            weights_initializer=tf.truncated_normal_initializer(stddev=stddev),
            biases_initializer=tf.zeros_initializer(),
            kernel_size=[k, k], stride=[s, s], padding='VALID')
        if activation_fn == 'relu':
            deconv = tf.nn.relu(deconv)
            bn = tf.contrib.layers.batch_norm(deconv, center=True, scale=True, 
                decay=0.9, is_training=is_train, updates_collections=None)
        elif activation_fn == 'tanh':
            deconv = tf.nn.tanh(deconv)
        else:
            raise ValueError('Invalid activation function.')
        return deconv</span></pre></div><p><span class="koboSpan" id="kobo.234.1">The</span><a id="id87" class="indexterm"/><span class="koboSpan" id="kobo.235.1"> discriminator takes images as input and tries to output into a </span><code class="literal"><span class="koboSpan" id="kobo.236.1">n+1</span></code><span class="koboSpan" id="kobo.237.1"> class label. </span><span class="koboSpan" id="kobo.237.2">It applies some layers of convolution having leaky ReLU with batch normalization, followed </span><a id="id88" class="indexterm"/><span class="koboSpan" id="kobo.238.1">by dropout on the input images, and finally outputs the class </span><code class="literal"><span class="koboSpan" id="kobo.239.1">label</span></code><span class="koboSpan" id="kobo.240.1"> using the </span><code class="literal"><span class="koboSpan" id="kobo.241.1">softmax</span></code><span class="koboSpan" id="kobo.242.1"> function:</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.243.1"># Discriminator model function
        def D(img, scope='Discriminator', reuse=True):
            with tf.variable_scope(scope, reuse=reuse) as scope:
                if not reuse: print ('\033[93m'+scope.name+'\033[0m')
                d_1 = conv2d(img, conv_info[0], is_train, name='d_1_conv')
                d_1 = slim.dropout(d_1, keep_prob=0.5, is_training=is_train, scope='d_1_conv/')
                if not reuse: print (scope.name, d_1)
                d_2 = conv2d(d_1, conv_info[1], is_train, name='d_2_conv')
                d_2 = slim.dropout(d_2, keep_prob=0.5, is_training=is_train, scope='d_2_conv/')
                if not reuse: print (scope.name, d_2)
                d_3 = conv2d(d_2, conv_info[2], is_train, name='d_3_conv')
                d_3 = slim.dropout(d_3, keep_prob=0.5, is_training=is_train, scope='d_3_conv/')
                if not reuse: print (scope.name, d_3)
                d_4 = slim.fully_connected(
                    tf.reshape(d_3, [self.batch_size, -1]), n+1, scope='d_4_fc', activation_fn=None)
                if not reuse: print (scope.name, d_4)
                output = d_4
                assert output.get_shape().as_list() == [self.batch_size, n+1]
                return tf.nn.softmax(output), output


# Convolution method with dropout
def conv2d(input, output_shape, is_train, k_h=5, k_w=5, stddev=0.02, name="conv2d"):
    with tf.variable_scope(name):
        w = tf.get_variable('w', [k_h, k_w, input.get_shape()[-1], output_shape],
                initializer=tf.truncated_normal_initializer(stddev=stddev))
        conv = tf.nn.conv2d(input, w, strides=[1, 2, 2, 1], padding='SAME')

        biases = tf.get_variable('biases', [output_shape], initializer=tf.constant_initializer(0.0))
        conv = lrelu(tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape()))
        bn = tf.contrib.layers.batch_norm(conv, center=True, scale=True, 
            decay=0.9, is_training=is_train, updates_collections=None)
    return bn

# Leaky Relu method
def lrelu(x, leak=0.2, name="lrelu"):
   with tf.variable_scope(name):
   f1 = 0.5 * (1 + leak)
   f2 = 0.5 * (1 - leak)
return f1 * x + f2 * abs(x)</span></pre></div><p><span class="koboSpan" id="kobo.244.1">The discriminator network has two </span><code class="literal"><span class="koboSpan" id="kobo.245.1">loss</span></code><span class="koboSpan" id="kobo.246.1"> functions, one (</span><code class="literal"><span class="koboSpan" id="kobo.247.1">s_loss</span></code><span class="koboSpan" id="kobo.248.1">) for the supervise classification </span><a id="id89" class="indexterm"/><span class="koboSpan" id="kobo.249.1">of real data from CIFAR-10 images using huber loss (Huber loss is robust to outliers compared to squared error loss) and the other (</span><code class="literal"><span class="koboSpan" id="kobo.250.1">d_loss</span></code><span class="koboSpan" id="kobo.251.1">) loss to classify the generated images by the generator as real/fake in scalar form using </span><code class="literal"><span class="koboSpan" id="kobo.252.1">softmax</span></code><span class="koboSpan" id="kobo.253.1"> function with cross entropy:</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.254.1"># Discriminator/classifier loss
s_loss = tf.reduce_mean(huber_loss(label, d_real[:, :-1]))</span></pre></div><div class="mediaobject"><span class="koboSpan" id="kobo.255.1"><img src="graphics/B08086_02_17.png.jpg" alt="Setting up the environment"/></span><div class="caption"><p><span class="koboSpan" id="kobo.256.1">Figure: 4a: Supervise loss of discriminator</span></p></div></div><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.257.1">d_loss_real = tf.nn.softmax_cross_entropy_with_logits(logits=d_real_logits, labels=real_label)
 d_loss_fake = tf.nn.softmax_cross_entropy_with_logits(logits=d_fake_logits, labels=fake_label)
d_loss = tf.reduce_mean(d_loss_real + d_loss_fake)</span></pre></div><div class="mediaobject"><span class="koboSpan" id="kobo.258.1"><img src="graphics/B08086_02_18.png.jpg" alt="Setting up the environment"/></span><div class="caption"><p><span class="koboSpan" id="kobo.259.1">Figure: 4b: Total discriminator loss (real + fake loss)</span></p></div></div><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.260.1">
# Huber loss
def huber_loss(labels, predictions, delta=1.0):
    residual = tf.abs(predictions - labels)
    condition = tf.less(residual, delta)
    small_res = 0.5 * tf.square(residual)
    large_res = delta * residual - 0.5 * tf.square(delta)
    return tf.where(condition, small_res, large_res)


# Generator loss
g_loss = tf.reduce_mean(tf.log(d_fake[:, -1]))

g_loss += tf.reduce_mean(huber_loss(real_image, fake_image)) * self.recon_weight</span></pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note02"/><span class="koboSpan" id="kobo.261.1">Note</span></h3><p><span class="koboSpan" id="kobo.262.1">Note: Weight </span><a id="id90" class="indexterm"/><span class="koboSpan" id="kobo.263.1">annealing is done as an auxiliary loss to help the generator get rid of the initial local minimum.</span></p></div></div><div class="mediaobject"><span class="koboSpan" id="kobo.264.1"><img src="graphics/B08086_02_19.png.jpg" alt="Setting up the environment"/></span><div class="caption"><p><span class="koboSpan" id="kobo.265.1">Figure: 4c: Generator loss</span></p></div></div><p><span class="koboSpan" id="kobo.266.1">The </span><code class="literal"><span class="koboSpan" id="kobo.267.1">loss</span></code><span class="koboSpan" id="kobo.268.1"> function of both the generator and discriminator network is optimized with </span><code class="literal"><span class="koboSpan" id="kobo.269.1">AdamOptimizer</span></code><span class="koboSpan" id="kobo.270.1"> and </span><a id="id91" class="indexterm"/><span class="koboSpan" id="kobo.271.1">gradient clipping (</span><code class="literal"><span class="koboSpan" id="kobo.272.1">clip_gradients</span></code><span class="koboSpan" id="kobo.273.1">) is applied with it to stabilize the training:</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.274.1"># Optimizer for discriminator
self.d_optimizer = tf.contrib.layers.optimize_loss(
loss=self.model.d_loss,
global_step=self.global_step,
learning_rate=self.learning_rate*0.5,
optimizer=tf.train.AdamOptimizer(beta1=0.5),
clip_gradients=20.0,
name='d_optimize_loss',
variables=d_var
)


# Optimizer for generator
self.g_optimizer = tf.contrib.layers.optimize_loss(
loss=self.model.g_loss,
global_step=self.global_step,
learning_rate=self.learning_rate,
optimizer=tf.train.AdamOptimizer(beta1=0.5),
clip_gradients=20.0,
name='g_optimize_loss',
variables=g_var
)</span></pre></div><p><span class="koboSpan" id="kobo.275.1">Finally, both the supervised loss (</span><code class="literal"><span class="koboSpan" id="kobo.276.1">s_loss</span></code><span class="koboSpan" id="kobo.277.1">) and generative adversarial loss (which is the combination</span><a id="id92" class="indexterm"/><span class="koboSpan" id="kobo.278.1"> of discriminator loss (</span><code class="literal"><span class="koboSpan" id="kobo.279.1">d_loss</span></code><span class="koboSpan" id="kobo.280.1">) and generator loss (</span><code class="literal"><span class="koboSpan" id="kobo.281.1">g_loss</span></code><span class="koboSpan" id="kobo.282.1">)) are trained jointly to minimize the total loss:</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.283.1">for s in xrange(max_steps):
             step, accuracy, summary, d_loss, g_loss, s_loss, step_time, prediction_train, gt_train, g_img = \
               self.run_single_step(self.batch_train, step=s, is_train=True)</span></pre></div><p><span class="koboSpan" id="kobo.284.1">The output of generated samples after 150 epochs is as follows:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.285.1"><img src="graphics/B08086_02_20.png.jpg" alt="Setting up the environment"/></span></div></div></div></div></div></div>
<div id="book-columns"><div id="book-inner"><div class="section" title="Challenges of GAN models"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec13"/><span class="koboSpan" id="kobo.1.1">Challenges of GAN models</span></h1></div></div></div><p><span class="koboSpan" id="kobo.2.1">Training a GAN</span><a id="id93" class="indexterm"/><span class="koboSpan" id="kobo.3.1"> is basically about two networks, generator </span><span class="emphasis"><em><span class="koboSpan" id="kobo.4.1">G(z)</span></em></span><span class="koboSpan" id="kobo.5.1"> and discriminator </span><span class="emphasis"><em><span class="koboSpan" id="kobo.6.1">D(z)</span></em></span><span class="koboSpan" id="kobo.7.1">, trying to race against each other and trying to reach an optimum, more specifically a nash equilibrium. </span><span class="koboSpan" id="kobo.7.2">The definition of</span><a id="id94" class="indexterm"/><span class="koboSpan" id="kobo.8.1"> nash equilibrium as per Wikipedia (in economics and game theory) is a stable state of a system involving the interaction of different participants, in which no participant can gain by a unilateral change of strategy if the strategies of the others remain unchanged.</span></p><div class="section" title="Setting up failure and bad initialization"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec25"/><span class="koboSpan" id="kobo.9.1">Setting up failure and bad initialization</span></h2></div></div></div><p><span class="koboSpan" id="kobo.10.1">If you think </span><a id="id95" class="indexterm"/><span class="koboSpan" id="kobo.11.1">about it, this is exactly what GAN is trying to do; the generator and discriminator reach a state where they cannot improve any further given the other is kept unchanged. </span><span class="koboSpan" id="kobo.11.2">Now the setup of gradient descent is to take a step in a direction that reduces the loss measure defined on the problem—but we are by no means enforcing the networks to reach Nash equilibrium in GAN, which have non-convex objective with continuous high dimensional parameters. </span><span class="koboSpan" id="kobo.11.3">The networks try to take successive steps to minimize a non-convex objective and end up in an oscillating process rather than decreasing the underlying true objective.</span></p><p><span class="koboSpan" id="kobo.12.1">In most cases, when your discriminator attains a loss very close to zero, then right away you can figure out something is wrong with your model. </span><span class="koboSpan" id="kobo.12.2">But the biggest difficulty is figuring out what is wrong.</span></p><p><span class="koboSpan" id="kobo.13.1">Another practical thing done during the training of GAN is to purposefully make one of the networks stall or learn slower, so that the other network can catch up. </span><span class="koboSpan" id="kobo.13.2">And in most scenarios, it's the generator that lags behind so we usually let the discriminator wait. </span><span class="koboSpan" id="kobo.13.3">This might be fine to some extent, but remember that for the generator to get better, it requires a good discriminator and vice versa. </span><span class="koboSpan" id="kobo.13.4">Ideally the system would want both the networks to learn at a rate where both get better over time. </span><span class="koboSpan" id="kobo.13.5">The ideal minimum loss for the discriminator is close to 0.5— this is where the generated images are indistinguishable from the real images from the perspective of the discriminator.</span></p></div><div class="section" title="Mode collapse"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec26"/><span class="koboSpan" id="kobo.14.1">Mode collapse</span></h2></div></div></div><p><span class="koboSpan" id="kobo.15.1">One of the</span><a id="id96" class="indexterm"/><span class="koboSpan" id="kobo.16.1"> main failure modes with training a generative adversarial network is called mode collapse or sometimes the helvetica scenario. </span><span class="koboSpan" id="kobo.16.2">The basic idea is that the generator can accidentally start to produce several copies of exactly the same image, so the reason is related to the game theory setup. </span><span class="koboSpan" id="kobo.16.3">We can think of the way that we train generative adversarial networks as first maximizing with respect to the discriminator and then minimizing with respect to the generator. </span><span class="koboSpan" id="kobo.16.4">If we fully maximize with respect to the discriminator </span><a id="id97" class="indexterm"/><span class="koboSpan" id="kobo.17.1">before we start to minimize with respect to the generator, everything works out just fine. </span><span class="koboSpan" id="kobo.17.2">But if we go the other way around and we minimize with respect to the generator and then maximize with respect to the discriminator, everything will actually break and the reason is that if we hold the discriminator constant, it will describe a single region in space as being the point that is most likely to be real rather than fake and then the generator will choose to map all noise input values to that same most likely to be real point.</span></p></div><div class="section" title="Problems with counting"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec27"/><span class="koboSpan" id="kobo.18.1">Problems with counting</span></h2></div></div></div><p><span class="koboSpan" id="kobo.19.1">GANs can </span><a id="id98" class="indexterm"/><span class="koboSpan" id="kobo.20.1">sometimes be far-sighted and fail to differentiate the number of particular objects that should occur at a location. </span><span class="koboSpan" id="kobo.20.2">As we can see, it gives more numbers of eyes in the head than originally present:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.21.1"><img src="graphics/B08086_02_21.png.jpg" alt="Problems with counting"/></span><div class="caption"><p><span class="koboSpan" id="kobo.22.1">Source: NIPS 2016- arXiv: 1701.00160, 2017</span></p></div></div></div><div class="section" title="Problems with perspective"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec28"/><span class="koboSpan" id="kobo.23.1">Problems with perspective</span></h2></div></div></div><p><span class="koboSpan" id="kobo.24.1">GANs</span><a id="id99" class="indexterm"/><span class="koboSpan" id="kobo.25.1"> sometimes are not capable of differentiating between front and back view and hence fail to adapt well with 3D objects while generating 2D representations from it, as follows:</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.26.1"><img src="graphics/B08086_02_22.png.jpg" alt="Problems with perspective"/></span><div class="caption"><p><span class="koboSpan" id="kobo.27.1">Source: NIPS 2016- </span><span class="emphasis"><em><span class="koboSpan" id="kobo.28.1">arXiv: 1701.00160, 2017</span></em></span>
</p></div></div></div><div class="section" title="Problems with global structures"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec29"/><span class="koboSpan" id="kobo.29.1">Problems with global structures</span></h2></div></div></div><p><span class="koboSpan" id="kobo.30.1">GANs do</span><a id="id100" class="indexterm"/><span class="koboSpan" id="kobo.31.1"> not understand holistic structures, similar to problems with perspective. </span><span class="koboSpan" id="kobo.31.2">For example, in the bottom left image, it generates an image of a quadruple cow, that is, a cow standing on its hind legs and simultaneously on all four legs. </span><span class="koboSpan" id="kobo.31.3">That is definitely unrealistic and not possible in real life!</span></p><div class="mediaobject"><span class="koboSpan" id="kobo.32.1"><img src="graphics/B08086_02_23.png.jpg" alt="Problems with global structures"/></span><div class="caption"><p><span class="koboSpan" id="kobo.33.1">Source: NIPS 2016- </span><span class="emphasis"><em><span class="koboSpan" id="kobo.34.1">arXiv: 1701</span></em></span>
<span class="emphasis"><em><span class="koboSpan" id="kobo.35.1">.00160, 2017</span></em></span>
</p></div></div></div></div></div></div>
<div id="book-columns"><div id="book-inner"><div class="section" title="Improved training approaches and tips for GAN"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec14"/><span class="koboSpan" id="kobo.1.1">Improved training approaches and tips for GAN</span></h1></div></div></div><p><span class="koboSpan" id="kobo.2.1">In order to</span><a id="id101" class="indexterm"/><span class="koboSpan" id="kobo.3.1"> overcome the difficulties of GAN models, deep learning practitioners carry out various hacks depending on the nature of the problem. </span><span class="koboSpan" id="kobo.3.2">Some of the improvisation</span><a id="id102" class="indexterm"/><span class="koboSpan" id="kobo.4.1"> techniques are mentioned in the following sections.</span></p><div class="section" title="Feature matching"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec30"/><span class="koboSpan" id="kobo.5.1">Feature matching</span></h2></div></div></div><p><span class="koboSpan" id="kobo.6.1">The instability of GANs is addressed by specifying a new objective for the generator that prevents it from</span><a id="id103" class="indexterm"/><span class="koboSpan" id="kobo.7.1">  overtraining on the current discriminator.</span></p><p><span class="koboSpan" id="kobo.8.1">The idea is to use the features at the intermediate layers in the discriminator to match for real and fake images and make this as a supervisory signal to train the generator.</span></p><p><span class="koboSpan" id="kobo.9.1">Specifically, we train the generator to generate data that matches the statistics of the real data, and match the expected value of the features on an intermediate layer of the discriminator. </span><span class="koboSpan" id="kobo.9.2">By</span><a id="id104" class="indexterm"/><span class="koboSpan" id="kobo.10.1"> training the discriminator, we ask it to find those features that are most discriminative of real data versus data generated by the current model.</span></p></div><div class="section" title="Mini batch"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec31"/><span class="koboSpan" id="kobo.11.1">Mini batch</span></h2></div></div></div><p><span class="koboSpan" id="kobo.12.1">The problem of mode </span><a id="id105" class="indexterm"/><span class="koboSpan" id="kobo.13.1">collapse can be addressed by adding some extra features to the discriminator where the discriminator actually looks at an entire "mini batch of samples" at a time rather than looking at a single sample. </span><span class="koboSpan" id="kobo.13.2">If those features measure things such as distance to other samples, then the discriminator can detect if the generator is starting to collapse in this way instead of encouraging every sample from the generator to move towards the single most likely point. </span><span class="koboSpan" id="kobo.13.3">The mini batch as a whole has to look realistic and have the correct amount of spacing between different samples.</span></p></div><div class="section" title="Historical averaging"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec32"/><span class="koboSpan" id="kobo.14.1">Historical averaging</span></h2></div></div></div><p><span class="koboSpan" id="kobo.15.1">The idea of historical</span><a id="id106" class="indexterm"/><span class="koboSpan" id="kobo.16.1"> averaging is to add a penalty term that punishes weights that are rather far away from their historical average values. </span><span class="koboSpan" id="kobo.16.2">For example, the cost is:</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.17.1">distance (current parameters, average of parameters over the last t batches)</span></pre></div></div><div class="section" title="One-sided label smoothing"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec33"/><span class="koboSpan" id="kobo.18.1">One-sided label smoothing</span></h2></div></div></div><p><span class="koboSpan" id="kobo.19.1">Usually one would use</span><a id="id107" class="indexterm"/><span class="koboSpan" id="kobo.20.1"> the labels 0 (image is real) and 1 (image is fake). </span><span class="koboSpan" id="kobo.20.2">Instead using some smoother labels (0.1 and 0.9) seems to make networks more resistant to adversarial examples.</span></p></div><div class="section" title="Normalizing the inputs"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec34"/><span class="koboSpan" id="kobo.21.1">Normalizing the inputs</span></h2></div></div></div><p><span class="koboSpan" id="kobo.22.1">Most of the time</span><a id="id108" class="indexterm"/><span class="koboSpan" id="kobo.23.1"> it is good to normalize the images between -1 and 1 and use </span><code class="literal"><span class="koboSpan" id="kobo.24.1">tanh</span></code><span class="koboSpan" id="kobo.25.1"> as the last layer of the generator output.</span></p></div><div class="section" title="Batch norm"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec35"/><span class="koboSpan" id="kobo.26.1">Batch norm</span></h2></div></div></div><p><span class="koboSpan" id="kobo.27.1">The idea is to</span><a id="id109" class="indexterm"/><span class="koboSpan" id="kobo.28.1"> construct different mini batches for real and fake, that is, each mini batch needs to contain only all real images or all generated images. </span><span class="koboSpan" id="kobo.28.2">But when batch norm is not an option, you can use instance normalization (for each sample, subtract mean and divide by standard deviation).</span></p></div><div class="section" title="Avoiding sparse gradients with ReLU, MaxPool"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec36"/><span class="koboSpan" id="kobo.29.1">Avoiding sparse gradients with ReLU, MaxPool</span></h2></div></div></div><p><span class="koboSpan" id="kobo.30.1">The stability </span><a id="id110" class="indexterm"/><span class="koboSpan" id="kobo.31.1">of the GAN game suffers if you have sparse gradients. </span><span class="koboSpan" id="kobo.31.2">Leaky ReLU is a good fit for both generator and discriminator.</span></p><p><span class="koboSpan" id="kobo.32.1">In case of down-sampling, use</span><a id="id111" class="indexterm"/><span class="koboSpan" id="kobo.33.1"> a combination of average pooling, </span><code class="literal"><span class="koboSpan" id="kobo.34.1">Conv2d + stride</span></code><span class="koboSpan" id="kobo.35.1">, whereas for up-sampling, use the combination of </span><code class="literal"><span class="koboSpan" id="kobo.36.1">PixelShuffle</span></code><span class="koboSpan" id="kobo.37.1">, </span><code class="literal"><span class="koboSpan" id="kobo.38.1">ConvTranspose2d + stride</span></code><span class="koboSpan" id="kobo.39.1">:</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.40.1">PixelShuffle- arXiv: 1609.05158, 2016 </span></pre></div></div><div class="section" title="Optimizer and noise"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec37"/><span class="koboSpan" id="kobo.41.1">Optimizer and noise</span></h2></div></div></div><p><span class="koboSpan" id="kobo.42.1">Use the ADAM optimizer</span><a id="id112" class="indexterm"/><span class="koboSpan" id="kobo.43.1"> for generators and SGD for discriminators. </span><span class="koboSpan" id="kobo.43.2">And provide noise in the form of dropout to several layers</span><a id="id113" class="indexterm"/><span class="koboSpan" id="kobo.44.1"> of generator.</span></p></div><div class="section" title="Don't balance loss through statistics only"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec38"/><span class="koboSpan" id="kobo.45.1">Don't balance loss through statistics only </span></h2></div></div></div><p><span class="koboSpan" id="kobo.46.1">Instead have a </span><a id="id114" class="indexterm"/><span class="koboSpan" id="kobo.47.1">principled approach to it, rather than intuition:</span></p><div class="informalexample"><pre class="programlisting"><span class="koboSpan" id="kobo.48.1">while lossD &gt; A:
  train D
while lossG &gt; B:
  train G</span></pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note03"/><span class="koboSpan" id="kobo.49.1">Note</span></h3><p><span class="koboSpan" id="kobo.50.1">Note: Despite all these tips and training enhancement steps, the Generative Adversarial model is still relatively new in the field of AI and deep learning and so like any other fast growing field, it too requires a lot of improvement.</span></p></div></div></div></div></div></div>
<div id="book-columns"><div id="book-inner"><div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec15"/><span class="koboSpan" id="kobo.1.1">Summary</span></h1></div></div></div><p><span class="koboSpan" id="kobo.2.1">So far you have learned how deep learning made its progress into the unsupervised arena through the concepts of GAN. </span><span class="koboSpan" id="kobo.2.2">You have already generated some realistic images such as handwritten digits, airplanes, cars, birds, and so on using </span><code class="literal"><span class="koboSpan" id="kobo.3.1">MNIST</span></code><span class="koboSpan" id="kobo.4.1">, </span><code class="literal"><span class="koboSpan" id="kobo.5.1">CIFAR</span></code><span class="koboSpan" id="kobo.6.1"> datasets. </span><span class="koboSpan" id="kobo.6.2">Also, you have understood various challenges related to Generative Adversarial Network and how to overcome it with practical tuning tips.</span></p><p><span class="koboSpan" id="kobo.7.1">In the next few chapters, we will continue our journey with a different variety of GAN-based architecture to perform some magnificent tasks with real datasets.</span></p></div></div></div></body></html>