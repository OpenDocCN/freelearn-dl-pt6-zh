- en: Building a Deep Learning Gaming Chatbot
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Chatbots**, or conversational agents, are an exploding trend in AI and are
    seen as the next human interface with the computer. From Siri, Alexa, and Google
    Home, there has been an explosion of commercial growth in this area, and you most
    likely already have interfaced with a computer in this manner. Therefore, it only
    seems natural that we cover how to build conversational agents for games. For
    our purposes, however, we are going to look at the class of bots called **neural
    conversational agents**. Their name follows from the fact that they are developed
    with neural networks. Now, chatbots don''t have to just chat; we will also look
    at other ways conversational bots can be used in gaming.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we learn how to build neural conversational agents and how
    to apply these techniques to games. The following is a summary of the main topics
    we will cover:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Neural conversational agents
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequence-to-sequence learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DeepPavlov
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building the bot server
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running the bot in Unity
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercises
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will now start building more practical real-world working examples of the
    projects. While not all of your training is complete, it is time we started to
    build pieces you can use. This means we will begin working with Unity in this
    chapter and things may start to get complicated quickly. Just remember to take
    your time and, if you need to, go over the material a few times. Again, the exercises
    at the end of the chapter are an excellent resource for additional learning.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we explore the basics of neural conversational agents.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Neural conversational agents
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The concept of communicating with a computer via natural language first became
    popular as far back as Star Trek (1966 to 1969). In the series, we can often see
    Kirk, Scotty, and the gang issuing commands to the computer. Since then, many
    attempts have been made to build chatbots that can converse naturally with a human.
    During this often unsuccessful journey over the years, several linguistic methods
    have been developed. These methods are often grouped together and referred to
    as **natural language processing**, or **NLP**. Now, NLP still is the foundation
    for most chatbots, including the deep learning variety we will get to shortly.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'We often group conversational agents by purpose or task. Currently, we categorize
    chatbots into two main types:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '**Goal-oriented**:These bots are the kind Kirk would use or the ones you likely
    communicate with on a daily basis, and a good example is Siri or Alexa.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**General conversationalist**: These chatbots are designed to converse with
    people regarding a wide range of topics, and a good example would be **Microsoft
    Tay**. Unfortunately, the Tay bot was perhaps a little too impressionable and
    picked up bad language, much like a two-year-old does.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gaming is certainly no stranger to chatbots, and attempts have been made to
    use both forms with varying success. While you may think goal-oriented bots make
    perfect sense, in reality the vocal/text is too slow and tedious for most repetitive
    gaming tasks. Even simple vocal commands (grunts or groans) are just too slow,
    at least currently. Therefore, we will look at the often under utilized conversational
    chatbots and how they can be used in gaming.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a summary of the gaming tasks these bots could undertake:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '**Non-player characters** (**NPCs**): This is an obvious first choice. NPCs
    are often scripted and become repetitive. How about an NPC that can converse naturally
    about a topic, perhaps revealing information when the right combination of words
    or phrases are used? The possibilities are endless here, and some NLP is already
    used in gaming for this matter.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Player character**: How about a game where you could converse with yourself?
    Perhaps the character has amnesia and is trying to remember information or learn
    a backstory.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Promotion**/**hints**: Perhaps as a way to promote your game, you build a
    bot that can hint at how to complete some difficult tasks or just as a way to
    talk about your game.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MMO virtual character**: What if, while you were away from your favorite
    MMO game, your character stayed in the game, unable to do actions, but still able
    to converse as you? This is the example we will look at in this chapter, and we
    will get to the action part later, when we explore **reinforcement learning**.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are likely dozens more uses that will evolve over time, but for now the
    preceding list should give you some great ideas regarding how to use chatbots
    in gaming. In the next section, we get into the background of what makes a conversationalist
    bot.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: General conversational models
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Conversational chatbots can be broken down further into two main forms: **generative**
    and **selective**. The method we will look at is called generative. Generative
    models learn by being fed a sequence of words and dialog in context/reply pairs.
    Internally, these models use RNN (LSTM) layers to learn and predict those sequences
    back to the conversant. An example of how this system works is as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/79642a34-900d-4645-8724-247d67950d08.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: Example of the generative conversational model
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Note that each block in the diagram represents one LSTM cell. Each cell then
    remembers the sequence that text was part of. What may not be clear from the preceding
    diagram is that both sides of the conversation text were fed into the model before
    training. Thus, this model is not unlike the GANs we covered in [Chapter 3](cb51d15b-9855-47e2-8e45-f74a115ebfa8.xhtml)*, GAN
    for Games*. In the next section, we will get into the details of setting up this
    type of model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Sequence-to-sequence learning
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we saw a high-level overview of our network model.
    In this section, we want to look at a Keras implementation of a generative conversational
    model that uses sequence-to-sequence learning. Before we get into the theory of
    this form of generative model, let's get the sample running, since it can take
    a while. The sample we will explore is the Keras reference sample for sequence-to-sequence
    machine translation. It is currently configured to do English-to-French translation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到我们的网络模型的概述。在这一节中，我们将介绍一个使用序列到序列学习的生成式对话模型的 Keras 实现。在我们深入探讨这种生成模型的理论之前，让我们先运行一个示例，因为这可能需要一些时间。我们将探索的示例是
    Keras 提供的序列到序列机器翻译的参考示例。它当前配置为执行英法翻译。
- en: 'Open up the `Chapter_4_1.py` sample code listing and get it running using these
    steps:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 `Chapter_4_1.py` 示例代码并按照以下步骤运行：
- en: 'Open up a shell or Anaconda window. Then run the following command:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个 shell 或 Anaconda 窗口。然后运行以下命令：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This will run the sample, and it may take several hours to run. The sample
    can also consume a substantial amount of memory and this may force memory paging
    on lower memory systems. Paging memory to disk will take additional time to train,
    especially if you are not running an SSD. If you find that you are unable to complete
    training on this sample, reduce the number of `epochs` and/or `num_samples` parameters
    as follows:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将运行示例，可能需要几个小时才能完成。该示例还可能消耗大量内存，这可能会导致低内存系统进行内存分页。将内存分页到磁盘将花费额外的训练时间，特别是如果你没有使用
    SSD。如果你发现无法完成这个示例的训练，可以减少 `epochs` 和/或 `num_samples` 参数，如下所示：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Decrease the `epochs` or `num_samples` parameters if you are unable to train
    on the original values.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你无法使用原始值进行训练，可以减少 `epochs` 或 `num_samples` 参数。
- en: After the sample has completed training, it will run through a test set of data.
    As it does so, it will output the results and you can see how well it is translating
    from English to French.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当示例完成训练后，它将运行一个测试数据集。在此过程中，它会输出结果，你可以看到它从英语翻译到法语的效果如何。
- en: Open the `fra-eng` folder located in the chapter source code.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开位于章节源代码中的 `fra-eng` 文件夹。
- en: 'Open the `fra.txt` file and the top few lines are as follows:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 `fra.txt` 文件，前几行如下：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Notice how the training text (English/French) is split on punctuation and spaces.
    Also, note how the sequences vary in length. The sequences we input do not have
    to match the length of the output, and vice versa.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意训练文本（英语/法语）是如何根据标点符号和空格进行拆分的。同时，也要注意序列的长度是如何变化的。我们输入的序列不必与输出的长度匹配，反之亦然。
- en: The sample we just looked at uses sequence-to-sequence character encoding to
    translate text from English to French. Typically, chat generation is done with
    word-to-word encoding, but this sample uses a finer-grained character-to-character
    model. This has an advantage in games because the language we attempt to generate
    may not always be human. Keep in mind that while we are only generating translated
    text in this sample, the text paired with an input could be any response you deem
    appropriate. In the next section, we will break down the code and understand in
    some detail how this sample works.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才看的示例使用了序列到序列字符编码将文本从英语翻译成法语。通常，聊天生成是通过逐词编码完成的，但这个示例使用了更细粒度的字符到字符模型。这在游戏中有一个优势，因为我们尝试生成的语言不一定总是人类语言。请记住，尽管在这个示例中我们只是生成翻译文本，任何与输入配对的文本都可以是你认为合适的任何响应。在下一节中，我们将逐步解析代码，深入理解这个示例的工作原理。
- en: Breaking down the code
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逐步解析代码
- en: 'As we progress through the book, we will begin to only focus on important sections
    of code, sections that help us understand a concept or how a method is implemented.
    This will make it more important for you to open up the code and at least pursue
    it on your own. In the next exercise, we take a look at the important sections
    of the sample code:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续深入本书，我们将开始只专注于重要的代码部分，这些部分有助于我们理解一个概念或方法是如何实现的。这样，你需要更重视自己打开代码并至少独立进行探索。在下一个练习中，我们将关注示例代码中的重要部分：
- en: 'Open `Chapter_4_1.py` and scroll down to the comment `Vectorize the data`,
    as follows:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 `Chapter_4_1.py` 并向下滚动到注释 `Vectorize the data`，如下所示：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This section of code inputs the training data and encodes it into the character
    sequences it uses to vectorize. Note how the `num_encoder_tokens` and `num_decoder_tokens`
    parameters being set here are dependent on the number of characters in each set
    and not the number of samples. Finally, the maximum length of the encoding and
    decoding sequences are set on the maximum length of the encoded characters in
    both.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we want to take a look at the vectorization of the input data. Vectorization
    of the data reduces the number of characters for each response match and is also
    the memory-intensive part, except, when we align this data, we want to keep the
    responses or targets to be one step ahead of the original input. This subtle difference
    allows our sequence-learning LSTM layers to predict the next patterns in the sequence.
    A diagram of how this works follows:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/24d3cbdd-04c1-443a-899b-083e3443bd54.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: Sequence-to-sequence model
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: In the diagram, we can see how the start of the text **HELLO** is being translated
    one step behind the response phrase **SALUT** (*hello* in French). Pay attention
    to how this works in the preceding code.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We then build the layers that will map to our network model with the code as
    follows:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Note how we are creating encoder and decoder inputs along with decoder outputs.
    This code builds and trains the `model` and then saves it for later use in inference.
    We use the term *inference* to mean that a model is inferring or generating an
    answer or response to some input. A diagram of this sequence-to-sequence model
    in layer architecture follows:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/12795ffb-7a9e-46ca-a40a-668fcc1467e3.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: Encoder/decoder inference model
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'This model is quite complex and there is a lot going on here. We have just
    covered the first part of the model. Next, we need to cover the building of the
    thought vector and generating the sampling models. The final code to do this follows:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Look over this code and see whether you can understand the structure. We are
    still missing a critical piece of the puzzle and we will cover that in the next
    section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Thought vectors
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the middle of the encoding and decoding text process is the generation of
    a thought vector. The **thought vector**, popularized by the godfather himself,
    Dr. Geoffrey Hinton, represents a vector that shows the context of one element
    in relation to many other elements.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: For instance, the word *hello *could have a high relational context to many
    words or phrases, such as *hi*, *how are you?*, *hey*, *goodbye*, and so on. Likewise,
    words such as* red, blue, fire,* and *old* would have a low context when associated
    with the word *hello*, *at* least in regular day-to-day speech. The word or character
    contexts are based on the pairings we have in the machine translation file. In
    this example, we are using the French translation pairings, but the pairings could
    be anything.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: 'This process takes place as part of the first encoding model into the thought
    vector or, in this case, a vector of probabilities. The LSTM layer calculates
    the probability or context of how the words/characters are related. You will often
    come across the following equation, which describes this transformation:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bdbd394e-5e98-4223-9edf-54a2cce63f6d.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
- en: 'Consider the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/25c0b6a5-acb5-430e-99f6-5fd59f56313c.png)= output sequence'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/3d1c7405-9215-42e5-90fc-ae7c618d0549.png) = input sequence'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/c3d20d3e-814a-4d58-baa8-d853a83e2572.png)= Vector representation'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ![](img/63dfa677-e45e-441c-a9ea-28c0a85f887b.png) represents the multiplication
    form of sigma (![](img/b107c7b6-9f98-40a1-b8c9-ebe14b24cffd.png)) and is used
    to pool the probabilities into the thought vector. This is a big simplification
    of the whole process, and the interested reader is encouraged to Google more about
    sequence-to-sequence learning on their own. For our purposes, the critical thing
    to remember is that each word/character has a probability or context that relates
    it to another. Generating this thought vector can be time consuming and memory-intensive,
    as you may have already noticed. Therefore, for our purposes, we will look at
    a more comprehensive set of natural language tools in order to create a neural
    conversational bot in the next section.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: DeepPavlov
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**DeepPavlov** is a comprehensive open source framework for building chatbots
    and other conversational agents for a variety of purposes and tasks. While this
    bot is designed for more goal-oriented bots, it will suit us well, as it is full-featured
    and includes several sequence-to-sequence model variations. Let''s take a look
    at how to build a simple pattern (sequence-to-sequence) recognition model in the
    following steps:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'Up until now, we have kept our Python environment loose, but that has to change.
    We now want to isolate our development environment so that we can easily replicate
    it to other systems later. The best way to do this is working with Python virtual
    environments. Create a new environment and then activate it with the following
    commands at an Anaconda window:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If you don''t use Anaconda, the process is a bit more involved, as follows:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then we need to install DeepPavlov with the following command at a shell or
    an Anaconda window:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This framework will attempt to install several libraries and may disrupt any
    existing Python environments. This is the other reason we are now using virtual
    environments.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For our purposes, we are just going to look at the basic `Hello World` sample
    that is very simple to follow now that we have covered the background. We first
    do our imports as per standard as follows:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now, DeepPavlov is based on Keras, but as you can see, the types we are using
    here wrap the functionality of a sequence-to-sequence pattern-matching model.
    The `PatternMatchingSkill` represents the sequence-to-sequence model we want to
    give our chatbot agent. Next, we import the `DefaultAgent` type, which is just
    the basic agent. After that, we introduce a confidence selector called `HighestConfidenceSelector`.
    Remember that the thought vector we generate is a vector of probabilities. The
    `HighestConfidenceSelector` selector always chooses the highest value relation
    or context that matches the corresponding word.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we generate three sets of patterns with corresponding responses, shown
    in the following code:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Each `PatternMatchingSkill` represents a set of pattern/response-contextual
    pairs. Note how there may be multiple responses and patterns for each. The other
    great thing about this framework is the ability to interchange and add skills.
    In this case, we are using just pattern matching, but there are plenty of other
    skills the reader is encouraged to explore.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, we build the agent and run it by simply printing the results with
    the final bit of code:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This last section of code creates a `DefaultAgent` with the three skills (`hello`,
    `bye`, and `fallback`) using the `HighestConfidenceSelector`. Then it runs the
    agent by feeding a set of three inputs nested inside the `print` statement.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the code as you normally would and look at the output. Is it what you expected?
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The simplicity of DeepPavlov makes it an excellent tool to build up various
    conversational chatbots for your games or other purposes if you so choose. The
    framework itself is very broad-featured and provides multiple natural language
    processing tools for a variety of tasks, including goal-oriented chatbots. Whole
    books could and probably should be written about Pavlov; if you have an interest
    in this, look more for NLP and DeepPavlov.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: With our new tool in hand, we now need a platform in which to serve up our bots
    with great conversational abilities. In the next section, we explore how to build
    a server for our bot.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Building the chatbot server
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python is a great framework and it provides a number of great tools for game
    development. However, we are going to focus on using Unity for our purposes. Unity
    is an excellent and very user-friendly game engine that will make setting up complex
    examples in later chapters a breeze. Don't worry if you don't know C#, the language
    of Unity, since we will be manipulating the engine through Python in many cases.
    This means we want the ability to run our Python code outside Unity and we want
    to do it on a server.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: If you are developing your game in Python, using a server then becomes optional,
    except that there are very compelling reasons to set up your AI bots as services
    or microservices. Microservices are self-contained succinct applications or services
    that only interface through some form of well-known communication protocol. **AI
    Microservices** or **AI as a Service** (**AIaaS**) are quickly outpacing other
    forms of SaaS, and it will only be a matter of time untill this same business
    model converts to gaming as well. In any case, for now, the benefit we gain from
    creating our chatbot as a microservice is **decoupling**. Decoupling will allow
    you to easily convert this bot to other platforms in the future.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Microservices also introduce a new communication pattern into the mix. Typically,
    when a client app connects to a server, the communication is direct and immediate.
    But what if your connection is broken or the communication needs to be filtered,
    duplicated, or stored for later analysis or reuse? Then using a direct communication
    protocol becomes burdened by adding these additional functions, when it doesn't
    need to be. Instead, microservices introduce the concept of a **message hub**.
    This is essentially a container or post office where all the message traffic passes
    through. This allows for incredible flexibility and offlines the need for our
    communication protocol to manage extra tasks. We will take a look at how to install
    a very easy-to-use message hub in the next section.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Message hubs (RabbitMQ)
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you have never come across the concept of microservices or message hubs
    before, you may be somewhat daunted by what is coming next. Don''t be. Message
    hubs and microservices are designed to make it easier to connect, route, and troubleshoot
    issues with multiple services that need to talk to one another. As such, these
    systems are designed to be easy to set up, and easier to use. Let''s see how easy
    it is to set up an excellent message queue platform called RabbitMQ in the next
    exercise:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Navigate your browser over to [https://www.rabbitmq.com/#getstarted](https://www.rabbitmq.com/#getstarted).
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Download and install RabbitMQ for your platform. There is typically a download
    button near the top of the page. You may be prompted to install Erlang, as follows:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/fd935c3c-eba2-4cd0-bb68-5ba1c950a390.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: Erlang warning dialog
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Erlang is a concurrent functional programming language and perfect for writing
    messaging hubs. If you don't have it on your system, just download and install
    it, again for your platform; next, restart the RabbitMQ installation.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For the most part, follow the installation choosing the defaults, except for
    the installation path. Make sure to keep the installation path short and memorable,
    as we will want to find it later. An example of setting the path in the installer
    for Windows as follows:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a76e19d5-3010-4f8f-bb1f-adb38f4e34f6.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
- en: Example of setting the installation path on Windows
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: RabbitMQ will install itself as a service on your platform. Depending on your
    system, you may get a number of security prompts requesting firewall or admin
    access. Just allow all these exceptions, as the hub needs full access. When the
    installation completes, RabbitMQ should be running on your system. Be sure to
    check the documentation for your platform if you have any concerns on the configuration
    or setup. RabbitMQ is designed to use secure communication but keeps itself fairly
    open for development. Please avoid installing the hub in a production system,
    and expect to do some security configuration.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we want to activate the RabbitMQ management tool so that we can get a
    good overview of how the hub works. Open up a Command Prompt and navigate to the
    `RabbitMQ` installation server folder (the one marked server). Then navigate to
    the `sbin` folder. When you are there, run the following command to install the
    management plugin (Windows or macOS):'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'An example of how this looks in a Windows Command Prompt follows:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1293acf7-062f-45f3-8703-9d4fdb597da8.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: Installing the RabbitMQ management plugin
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: That completes the installation of the hub on your system. In the next section,
    we will see how to inspect the hub with the management interface.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Managing RabbitMQ
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: RabbitMQ is a full-featured message hub that is very powerful and flexible in
    what it can do. There is a lot to RabbitMQ and it may be intimidating to some
    users less familiar with networking. Fortunately, we only need to use a few pieces
    right now, and in the future we will explore more functionality.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, though, open up a browser and follow along these steps to explore
    the hub''s management interface:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Navigate your browser to `http://localhost:15672/` and you should see a login
    dialog.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the username as `guest` and the password as `guest`. These are the default
    credentials and should work unless you've configured it otherwise.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After you log in, you will see the RabbitMQ interface:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/143641f0-db67-4da2-bb79-7fd03f000024.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
- en: RabbitMQ management interface
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: There is a lot going on here, so for now just click around and explore the various
    options. Avoid changing any settings, at least for now and until requested to
    do so. RabbitMQ is very powerful, but we all know that with great power comes
    great responsibility.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, currently, your message queue is empty, so you won't see a lot of activity,
    but we will soon resolve that in the next section, where we learn how to send
    and receive messages to and from the queue.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Sending and receiving to/from the MQ
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: RabbitMQ uses a protocol called **Advanced Message Queuing Protocol** (**AMQP**)for
    communication, which is a standard for all messaging middleware. This means that
    we can effectively swap out RabbitMQ for a more robust system, such as Kafka,
    in the future. This also means that, for the most part, all of the concepts we
    cover here will likely apply to similar messaging systems.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we will do is put a message on the queue from a very simple
    Python client. Open up the source file `Chapter_4_3.py` and follow these steps:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the source code file and take a look:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The code is taken from the RabbitMQ reference tutorial and shows how to connect.
    It first connects to the hub and opens a `queue` called `hello`. A queue is like
    a mailbox or stack of messages. A hub may have several different queues. Then
    the code publishes a message to the `hello` queue with the body of `Hello World!`.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Before we can run the sample, we first need to install `Pika`. Pika is an AMQP
    connection library and can be installed with the following command:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Then run the code file as you normally would and watch the output. It's not
    very exciting, is it?
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Go to the RabbitMQ management interface again at `http://localhost:15672/`
    and see that we now have a single message in the hub, as follows:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d9bffaeb-5bcf-47ac-bedf-9795061ae826.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
- en: RabbitMQ interface showing the addition of a message
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: The message we just sent will stay on the hub until we collect it later. This
    single feature will allow us to run individual services and make sure they are
    communicating correctly without having to worry about other consumers or publishers.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For the purposes of RabbitMQ, we just wrote a publisher. In some cases, you
    many want a service or app to just publish messages, while in others you may want
    them to consume them. In the next exercise, `Chapter_4_4_py`, we will write a
    hub consumer or client:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the source file `Chapter_4_4.py` and look at the code:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The preceding code is almost identical to the previous example, except that
    this time it only consumes from the queue using an internal `callback` function
    to receive the response. In this example, also note how the script blocks itself
    and waits for the message. In most cases, the client will register a callback
    with the queue in order to register an event. That event is triggered when a new
    message enters the particular queue.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the code as you normally would and watch the first `Hello World` message
    get pulled from the queue and output on the client window.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Keep the client running and run another instance of the `Chapter_4_3.py` (publish)
    script and note how the client quickly consumes it and outputs it to the window.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This completes the simple send and receive communication to/from the message
    hub. As you can see, the code is fairly straightforward and the configuration
    works out of the box, for the most part. If you do experience any issues with
    this setup, be sure to consult the RabbitMQ tutorials, which are an additional
    excellent resource for extra help. In the next section, we look at how to build
    the working chatbot server example.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Writing the message queue chatbot
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The chatbot server we want to create is essentially a combination of the three
    previous examples. Open up `Chapter_4_5.py` and follow the next exercise:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'The complete server code as follows:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We essentially have a complete working `Hello World` chatbot server in fewer
    than 25 lines of code. Of course, the functionality is still limited, but by now
    you can certainly understand how to add other pattern-matching skills to the bot.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The important thing to note here is that we are consuming from a queue called
    `chatin` and publishing to a queue called `chatout`. These queues are now wrapped
    in an exchange called `chat`. You can think of an exchange as a routing service.
    Exchanges provide for additional functionality around queues, and the great thing
    is that they are optional. For use, though, we want to use exchanges, because
    they provide us with better global control of our services. There are four types
    of exchanges used in RabbitMQ and they are summarized here:'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Direct**: Messages are sent directly to the queue marked in the message transmission.'
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fanout**: Duplicate the message to all queues wrapped by the exchange. This
    is great when you want to add logging or historical archiving.'
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Topic**: This allows you to send messages to queues identified by matching
    the message queue. For instance, you could send a message to the queue `chat`
    and any queue wrapped in the same exchange containing the word *chat* receives
    the message. The topic exchange allows you to group like messages.'
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Headers**: This works similar to the topic exchange but instead filters based
    on the headers in the message itself. This is a great exchange to use for dynamic
    routing of messages with the appropriate headers.'
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the `Chapter_4_5.py` server example and keep it running.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, open the `Chapter_4_6.py` file and look at the code shown:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The preceding code is just a sample client we can use to test the chatbot server.
    Note how the message variable `chat` is set to `'boo'`. When you run the code,
    check the output window of the chatbot server; this is the `Chapter_4_5.py` file
    we ran earlier. You should see a response message logged in the window that is
    appropriate to the chat message we just sent.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point, you could write a full chat client that could communicate with
    our chatbot in Python. However, we want to connect our bot up to Unity and see
    how we can use our bot as a microservice in the next section.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Running the chatbot in Unity
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Unity** is quickly becoming the standard game engine for learning to develop
    games, virtual reality, and augmented reality applications. Now it is quickly
    becoming the standard platform for developing AI and ML applications as well,
    partly due to the excellent reinforcement learning platform the team at Unity
    has built. This Unity ML platform is a key component in our desire to use the
    tool, since it currently is at the cutting edge of advanced AI for games.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: The AI team at Unity, led by Dr. Danny Lange and their senior developer Dr.
    Arthur Juliani, have made numerous suggestions and contributions to ideas for
    content in this book, both directly and indirectly. This, of course, has had a
    huge impact on using Unity for major portions of this book.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: 'Installing Unity is quite straightforward, but we want to make sure we get
    the installation just right the first time. Therefore, follow these steps to install
    a version of Unity on your system:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Navigate your browser to [https://store.unity.com/download](https://store.unity.com/download)
    and accept the terms, and then download the Unity Download Assistant. This is
    the tool that downloads and installs the pieces we need.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the Download Assistant and select the following minimum components to install,
    as shown in the dialog as follows:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a18fa234-6ec2-42f3-98e2-702f88ccff5a.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
- en: Selecting the installation components for Unity
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Just be sure to install the latest version of Unity and select the components
    that match your preferred OS, as shown in the preceding screenshot. You may, of
    course, select other components at your discretion, but those are the minimum
    you will need for this book.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, set the path to install Unity to a well-known folder. A good choice is
    to set the folder name equal to the version. This allows you to have multiple
    versions of Unity on the same system that you can easily find. The following screenshot
    shows how you may do this on Windows:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/56789132-7359-4d00-90b2-3fd856a3199b.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
- en: Setting the installation path to Unity
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Those are the only critical parts to the installation and you can continue installing
    the software using the defaults.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Launch the Unity editor after it installs and you will be prompted to log in.
    Unity requires you to have an account, regardless of whether you are using the
    free version. Go back to [unity.com](http://unity.com) and just create an account.
    After you are done setting up the account, go back in and log in to the editor.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After you log in, create a empty project called `Chatbot` and let the editor
    open to a blank scene.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Unity is a full-featured game engine and may be intimidating if this is your
    first visit. There are plenty of online tutorials and videos that can get you
    up to speed on the interface. We will do our best to demonstrate concepts simply,
    but if you get lost, just take your time and work through the exercise a few times.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: With Unity installed, we now have to install the components or assets that will
    allow us to easily connect to the chatbot server we just created. In the next
    section, we install the AMQP asset for Unity.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Installing AMQP for Unity
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'RabbitMQ has an excellent resource for plenty of cross-platform libraries that
    allow you to connect to the hub with ease. The library for C# does work well outside
    Unity but is problematic to set up. Fortunately, the good folks at Cymantic Labs
    have built and open sourced a version for Unity on GitHub. Let''s see how to install
    this code in the next exercise:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: 'Download and unpack the code using `git` or as a ZIP file from [https://github.com/CymaticLabs/Unity3D.Amqp](https://github.com/CymaticLabs/Unity3D.Amqp.git):'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Switch to Unity from the menu, and select File | Open Project and navigate to
    the `Unity3D.Amqp\unity\CymaticLabs.UnityAmqp` folder where you installed the
    code. This will open the asset in its own project. Wait for the project to load.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `Assets/CymanticLabs/Amqp/Scenes` folder in the Project window (typically
    at the bottom).
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Double-click on the **AmqpDemo** scene to open it in the editor.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Press the Play button at the top of the editor to run the scene. After you
    run the scene, you should see the following:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0f86dbe5-62dd-4302-8d5d-6fbce169709a.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
- en: Setting the Amqp connection and sending a message
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Press the Connect button to connect to the local RabbitMQ.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, under Subscriptions, set the exchange to chat, and the queue to chatout,
    and click Subscribe. This will subscribe to the queue so we can see any return
    message in the Unity console window.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, under Publish, set the exchange to chat, and the queue to chatin, and
    type a message such as `hello`. Click the Send button and you should see a response
    from the bot in the console window.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That sets up our working chatbot. Of course, this is just the start of what
    is possible and the reader is certainly encouraged to explore further, but keep
    in mind we will revisit this code later and make use of it in a later section
    of the book.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: That completes this chapter, and now you can take advantage of it for further
    learning in the next section.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Use the following exercises to expand your learning and get more confident
    with the material in this chapter:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Go back to the first exercise and load another set of translations. Train the
    bot on those and see what responses are generated after training. There are plenty
    of other language files available for training.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set up your own conversational training file using the English/French translation
    one as an example. Remember, the matching responses can be anything and not just
    translated text.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add additional pattern-matching skills to the DeepPavlov bot. Either the simple
    test one and/or the chatbot server.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The DeepPavlov chatbot uses a highest-value selection criteria for selecting
    a response. DeepPavlov does have a random selector as well. Change the response
    selector on the chatbot to use random.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the exchange type in the example to use Fanout and create a log queue
    to log messages.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Change the exchange type to Topic and see how you can group messages. Warning:
    this will likely break the example; see whether you can fix it.'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a RabbitMQ publisher in Python that publishes to one or more different
    types of queues.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an entire set of conversation skills using the pattern-matching skill.
    Then, see how well your bot converses with you.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add additional skills of other types to the chatbot server. This may require
    some additional homework on your part.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write or run two chatbots over RabbitMQ and watch them converse with each other.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Work through at least two or three of these exercises.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at building chatbots or neural conversational agents
    using neural networks and deep learning. We first saw what makes a chatbot and
    the main forms in use today: goal-oriented and conversational bots. Then we looked
    at how to build a basic machine translation conversational chatbot that used sequence-to-sequence
    learning.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: After getting a background in sequence learning, we looked at the open source
    tool DeepPavlov. DeepPavlov is a powerful chat platform built on top of Keras
    and designed for many forms of neural agent conversation and tasks. This made
    it ideal for us to use the chatbot server as a base. Then we installed RabbitMQ,
    a microservices message hub platform that will allow our bot and all manner of
    other services to talk together later on.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we installed Unity and then quickly installed the AMQP plugin asset
    and connected to our chatbot server.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: This completes our introductory section to deep learning, and, in the next section,
    we begin to get more into game AI by diving into **deep reinforcement learning**.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
