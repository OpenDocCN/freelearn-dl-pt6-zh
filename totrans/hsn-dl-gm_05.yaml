- en: Building a Deep Learning Gaming Chatbot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Chatbots**, or conversational agents, are an exploding trend in AI and are
    seen as the next human interface with the computer. From Siri, Alexa, and Google
    Home, there has been an explosion of commercial growth in this area, and you most
    likely already have interfaced with a computer in this manner. Therefore, it only
    seems natural that we cover how to build conversational agents for games. For
    our purposes, however, we are going to look at the class of bots called **neural
    conversational agents**. Their name follows from the fact that they are developed
    with neural networks. Now, chatbots don''t have to just chat; we will also look
    at other ways conversational bots can be used in gaming.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we learn how to build neural conversational agents and how
    to apply these techniques to games. The following is a summary of the main topics
    we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Neural conversational agents
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequence-to-sequence learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DeepPavlov
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building the bot server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running the bot in Unity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will now start building more practical real-world working examples of the
    projects. While not all of your training is complete, it is time we started to
    build pieces you can use. This means we will begin working with Unity in this
    chapter and things may start to get complicated quickly. Just remember to take
    your time and, if you need to, go over the material a few times. Again, the exercises
    at the end of the chapter are an excellent resource for additional learning.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we explore the basics of neural conversational agents.
  prefs: []
  type: TYPE_NORMAL
- en: Neural conversational agents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The concept of communicating with a computer via natural language first became
    popular as far back as Star Trek (1966 to 1969). In the series, we can often see
    Kirk, Scotty, and the gang issuing commands to the computer. Since then, many
    attempts have been made to build chatbots that can converse naturally with a human.
    During this often unsuccessful journey over the years, several linguistic methods
    have been developed. These methods are often grouped together and referred to
    as **natural language processing**, or **NLP**. Now, NLP still is the foundation
    for most chatbots, including the deep learning variety we will get to shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'We often group conversational agents by purpose or task. Currently, we categorize
    chatbots into two main types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Goal-oriented**:These bots are the kind Kirk would use or the ones you likely
    communicate with on a daily basis, and a good example is Siri or Alexa.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**General conversationalist**: These chatbots are designed to converse with
    people regarding a wide range of topics, and a good example would be **Microsoft
    Tay**. Unfortunately, the Tay bot was perhaps a little too impressionable and
    picked up bad language, much like a two-year-old does.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gaming is certainly no stranger to chatbots, and attempts have been made to
    use both forms with varying success. While you may think goal-oriented bots make
    perfect sense, in reality the vocal/text is too slow and tedious for most repetitive
    gaming tasks. Even simple vocal commands (grunts or groans) are just too slow,
    at least currently. Therefore, we will look at the often under utilized conversational
    chatbots and how they can be used in gaming.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a summary of the gaming tasks these bots could undertake:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Non-player characters** (**NPCs**): This is an obvious first choice. NPCs
    are often scripted and become repetitive. How about an NPC that can converse naturally
    about a topic, perhaps revealing information when the right combination of words
    or phrases are used? The possibilities are endless here, and some NLP is already
    used in gaming for this matter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Player character**: How about a game where you could converse with yourself?
    Perhaps the character has amnesia and is trying to remember information or learn
    a backstory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Promotion**/**hints**: Perhaps as a way to promote your game, you build a
    bot that can hint at how to complete some difficult tasks or just as a way to
    talk about your game.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MMO virtual character**: What if, while you were away from your favorite
    MMO game, your character stayed in the game, unable to do actions, but still able
    to converse as you? This is the example we will look at in this chapter, and we
    will get to the action part later, when we explore **reinforcement learning**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are likely dozens more uses that will evolve over time, but for now the
    preceding list should give you some great ideas regarding how to use chatbots
    in gaming. In the next section, we get into the background of what makes a conversationalist
    bot.
  prefs: []
  type: TYPE_NORMAL
- en: General conversational models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Conversational chatbots can be broken down further into two main forms: **generative**
    and **selective**. The method we will look at is called generative. Generative
    models learn by being fed a sequence of words and dialog in context/reply pairs.
    Internally, these models use RNN (LSTM) layers to learn and predict those sequences
    back to the conversant. An example of how this system works is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/79642a34-900d-4645-8724-247d67950d08.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of the generative conversational model
  prefs: []
  type: TYPE_NORMAL
- en: Note that each block in the diagram represents one LSTM cell. Each cell then
    remembers the sequence that text was part of. What may not be clear from the preceding
    diagram is that both sides of the conversation text were fed into the model before
    training. Thus, this model is not unlike the GANs we covered in [Chapter 3](cb51d15b-9855-47e2-8e45-f74a115ebfa8.xhtml)*, GAN
    for Games*. In the next section, we will get into the details of setting up this
    type of model.
  prefs: []
  type: TYPE_NORMAL
- en: Sequence-to-sequence learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we saw a high-level overview of our network model.
    In this section, we want to look at a Keras implementation of a generative conversational
    model that uses sequence-to-sequence learning. Before we get into the theory of
    this form of generative model, let's get the sample running, since it can take
    a while. The sample we will explore is the Keras reference sample for sequence-to-sequence
    machine translation. It is currently configured to do English-to-French translation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open up the `Chapter_4_1.py` sample code listing and get it running using these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open up a shell or Anaconda window. Then run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This will run the sample, and it may take several hours to run. The sample
    can also consume a substantial amount of memory and this may force memory paging
    on lower memory systems. Paging memory to disk will take additional time to train,
    especially if you are not running an SSD. If you find that you are unable to complete
    training on this sample, reduce the number of `epochs` and/or `num_samples` parameters
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Decrease the `epochs` or `num_samples` parameters if you are unable to train
    on the original values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After the sample has completed training, it will run through a test set of data.
    As it does so, it will output the results and you can see how well it is translating
    from English to French.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `fra-eng` folder located in the chapter source code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open the `fra.txt` file and the top few lines are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Notice how the training text (English/French) is split on punctuation and spaces.
    Also, note how the sequences vary in length. The sequences we input do not have
    to match the length of the output, and vice versa.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The sample we just looked at uses sequence-to-sequence character encoding to
    translate text from English to French. Typically, chat generation is done with
    word-to-word encoding, but this sample uses a finer-grained character-to-character
    model. This has an advantage in games because the language we attempt to generate
    may not always be human. Keep in mind that while we are only generating translated
    text in this sample, the text paired with an input could be any response you deem
    appropriate. In the next section, we will break down the code and understand in
    some detail how this sample works.
  prefs: []
  type: TYPE_NORMAL
- en: Breaking down the code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we progress through the book, we will begin to only focus on important sections
    of code, sections that help us understand a concept or how a method is implemented.
    This will make it more important for you to open up the code and at least pursue
    it on your own. In the next exercise, we take a look at the important sections
    of the sample code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open `Chapter_4_1.py` and scroll down to the comment `Vectorize the data`,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This section of code inputs the training data and encodes it into the character
    sequences it uses to vectorize. Note how the `num_encoder_tokens` and `num_decoder_tokens`
    parameters being set here are dependent on the number of characters in each set
    and not the number of samples. Finally, the maximum length of the encoding and
    decoding sequences are set on the maximum length of the encoded characters in
    both.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we want to take a look at the vectorization of the input data. Vectorization
    of the data reduces the number of characters for each response match and is also
    the memory-intensive part, except, when we align this data, we want to keep the
    responses or targets to be one step ahead of the original input. This subtle difference
    allows our sequence-learning LSTM layers to predict the next patterns in the sequence.
    A diagram of how this works follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/24d3cbdd-04c1-443a-899b-083e3443bd54.png)'
  prefs: []
  type: TYPE_IMG
- en: Sequence-to-sequence model
  prefs: []
  type: TYPE_NORMAL
- en: In the diagram, we can see how the start of the text **HELLO** is being translated
    one step behind the response phrase **SALUT** (*hello* in French). Pay attention
    to how this works in the preceding code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We then build the layers that will map to our network model with the code as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Note how we are creating encoder and decoder inputs along with decoder outputs.
    This code builds and trains the `model` and then saves it for later use in inference.
    We use the term *inference* to mean that a model is inferring or generating an
    answer or response to some input. A diagram of this sequence-to-sequence model
    in layer architecture follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/12795ffb-7a9e-46ca-a40a-668fcc1467e3.png)'
  prefs: []
  type: TYPE_IMG
- en: Encoder/decoder inference model
  prefs: []
  type: TYPE_NORMAL
- en: 'This model is quite complex and there is a lot going on here. We have just
    covered the first part of the model. Next, we need to cover the building of the
    thought vector and generating the sampling models. The final code to do this follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Look over this code and see whether you can understand the structure. We are
    still missing a critical piece of the puzzle and we will cover that in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Thought vectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the middle of the encoding and decoding text process is the generation of
    a thought vector. The **thought vector**, popularized by the godfather himself,
    Dr. Geoffrey Hinton, represents a vector that shows the context of one element
    in relation to many other elements.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, the word *hello *could have a high relational context to many
    words or phrases, such as *hi*, *how are you?*, *hey*, *goodbye*, and so on. Likewise,
    words such as* red, blue, fire,* and *old* would have a low context when associated
    with the word *hello*, *at* least in regular day-to-day speech. The word or character
    contexts are based on the pairings we have in the machine translation file. In
    this example, we are using the French translation pairings, but the pairings could
    be anything.
  prefs: []
  type: TYPE_NORMAL
- en: 'This process takes place as part of the first encoding model into the thought
    vector or, in this case, a vector of probabilities. The LSTM layer calculates
    the probability or context of how the words/characters are related. You will often
    come across the following equation, which describes this transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bdbd394e-5e98-4223-9edf-54a2cce63f6d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/25c0b6a5-acb5-430e-99f6-5fd59f56313c.png)= output sequence'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/3d1c7405-9215-42e5-90fc-ae7c618d0549.png) = input sequence'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/c3d20d3e-814a-4d58-baa8-d853a83e2572.png)= Vector representation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ![](img/63dfa677-e45e-441c-a9ea-28c0a85f887b.png) represents the multiplication
    form of sigma (![](img/b107c7b6-9f98-40a1-b8c9-ebe14b24cffd.png)) and is used
    to pool the probabilities into the thought vector. This is a big simplification
    of the whole process, and the interested reader is encouraged to Google more about
    sequence-to-sequence learning on their own. For our purposes, the critical thing
    to remember is that each word/character has a probability or context that relates
    it to another. Generating this thought vector can be time consuming and memory-intensive,
    as you may have already noticed. Therefore, for our purposes, we will look at
    a more comprehensive set of natural language tools in order to create a neural
    conversational bot in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: DeepPavlov
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**DeepPavlov** is a comprehensive open source framework for building chatbots
    and other conversational agents for a variety of purposes and tasks. While this
    bot is designed for more goal-oriented bots, it will suit us well, as it is full-featured
    and includes several sequence-to-sequence model variations. Let''s take a look
    at how to build a simple pattern (sequence-to-sequence) recognition model in the
    following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Up until now, we have kept our Python environment loose, but that has to change.
    We now want to isolate our development environment so that we can easily replicate
    it to other systems later. The best way to do this is working with Python virtual
    environments. Create a new environment and then activate it with the following
    commands at an Anaconda window:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If you don''t use Anaconda, the process is a bit more involved, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we need to install DeepPavlov with the following command at a shell or
    an Anaconda window:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This framework will attempt to install several libraries and may disrupt any
    existing Python environments. This is the other reason we are now using virtual
    environments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For our purposes, we are just going to look at the basic `Hello World` sample
    that is very simple to follow now that we have covered the background. We first
    do our imports as per standard as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Now, DeepPavlov is based on Keras, but as you can see, the types we are using
    here wrap the functionality of a sequence-to-sequence pattern-matching model.
    The `PatternMatchingSkill` represents the sequence-to-sequence model we want to
    give our chatbot agent. Next, we import the `DefaultAgent` type, which is just
    the basic agent. After that, we introduce a confidence selector called `HighestConfidenceSelector`.
    Remember that the thought vector we generate is a vector of probabilities. The
    `HighestConfidenceSelector` selector always chooses the highest value relation
    or context that matches the corresponding word.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we generate three sets of patterns with corresponding responses, shown
    in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Each `PatternMatchingSkill` represents a set of pattern/response-contextual
    pairs. Note how there may be multiple responses and patterns for each. The other
    great thing about this framework is the ability to interchange and add skills.
    In this case, we are using just pattern matching, but there are plenty of other
    skills the reader is encouraged to explore.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, we build the agent and run it by simply printing the results with
    the final bit of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This last section of code creates a `DefaultAgent` with the three skills (`hello`,
    `bye`, and `fallback`) using the `HighestConfidenceSelector`. Then it runs the
    agent by feeding a set of three inputs nested inside the `print` statement.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the code as you normally would and look at the output. Is it what you expected?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The simplicity of DeepPavlov makes it an excellent tool to build up various
    conversational chatbots for your games or other purposes if you so choose. The
    framework itself is very broad-featured and provides multiple natural language
    processing tools for a variety of tasks, including goal-oriented chatbots. Whole
    books could and probably should be written about Pavlov; if you have an interest
    in this, look more for NLP and DeepPavlov.
  prefs: []
  type: TYPE_NORMAL
- en: With our new tool in hand, we now need a platform in which to serve up our bots
    with great conversational abilities. In the next section, we explore how to build
    a server for our bot.
  prefs: []
  type: TYPE_NORMAL
- en: Building the chatbot server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python is a great framework and it provides a number of great tools for game
    development. However, we are going to focus on using Unity for our purposes. Unity
    is an excellent and very user-friendly game engine that will make setting up complex
    examples in later chapters a breeze. Don't worry if you don't know C#, the language
    of Unity, since we will be manipulating the engine through Python in many cases.
    This means we want the ability to run our Python code outside Unity and we want
    to do it on a server.
  prefs: []
  type: TYPE_NORMAL
- en: If you are developing your game in Python, using a server then becomes optional,
    except that there are very compelling reasons to set up your AI bots as services
    or microservices. Microservices are self-contained succinct applications or services
    that only interface through some form of well-known communication protocol. **AI
    Microservices** or **AI as a Service** (**AIaaS**) are quickly outpacing other
    forms of SaaS, and it will only be a matter of time untill this same business
    model converts to gaming as well. In any case, for now, the benefit we gain from
    creating our chatbot as a microservice is **decoupling**. Decoupling will allow
    you to easily convert this bot to other platforms in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices also introduce a new communication pattern into the mix. Typically,
    when a client app connects to a server, the communication is direct and immediate.
    But what if your connection is broken or the communication needs to be filtered,
    duplicated, or stored for later analysis or reuse? Then using a direct communication
    protocol becomes burdened by adding these additional functions, when it doesn't
    need to be. Instead, microservices introduce the concept of a **message hub**.
    This is essentially a container or post office where all the message traffic passes
    through. This allows for incredible flexibility and offlines the need for our
    communication protocol to manage extra tasks. We will take a look at how to install
    a very easy-to-use message hub in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Message hubs (RabbitMQ)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you have never come across the concept of microservices or message hubs
    before, you may be somewhat daunted by what is coming next. Don''t be. Message
    hubs and microservices are designed to make it easier to connect, route, and troubleshoot
    issues with multiple services that need to talk to one another. As such, these
    systems are designed to be easy to set up, and easier to use. Let''s see how easy
    it is to set up an excellent message queue platform called RabbitMQ in the next
    exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate your browser over to [https://www.rabbitmq.com/#getstarted](https://www.rabbitmq.com/#getstarted).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Download and install RabbitMQ for your platform. There is typically a download
    button near the top of the page. You may be prompted to install Erlang, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/fd935c3c-eba2-4cd0-bb68-5ba1c950a390.png)'
  prefs: []
  type: TYPE_IMG
- en: Erlang warning dialog
  prefs: []
  type: TYPE_NORMAL
- en: Erlang is a concurrent functional programming language and perfect for writing
    messaging hubs. If you don't have it on your system, just download and install
    it, again for your platform; next, restart the RabbitMQ installation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For the most part, follow the installation choosing the defaults, except for
    the installation path. Make sure to keep the installation path short and memorable,
    as we will want to find it later. An example of setting the path in the installer
    for Windows as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a76e19d5-3010-4f8f-bb1f-adb38f4e34f6.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of setting the installation path on Windows
  prefs: []
  type: TYPE_NORMAL
- en: RabbitMQ will install itself as a service on your platform. Depending on your
    system, you may get a number of security prompts requesting firewall or admin
    access. Just allow all these exceptions, as the hub needs full access. When the
    installation completes, RabbitMQ should be running on your system. Be sure to
    check the documentation for your platform if you have any concerns on the configuration
    or setup. RabbitMQ is designed to use secure communication but keeps itself fairly
    open for development. Please avoid installing the hub in a production system,
    and expect to do some security configuration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we want to activate the RabbitMQ management tool so that we can get a
    good overview of how the hub works. Open up a Command Prompt and navigate to the
    `RabbitMQ` installation server folder (the one marked server). Then navigate to
    the `sbin` folder. When you are there, run the following command to install the
    management plugin (Windows or macOS):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'An example of how this looks in a Windows Command Prompt follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1293acf7-062f-45f3-8703-9d4fdb597da8.png)'
  prefs: []
  type: TYPE_IMG
- en: Installing the RabbitMQ management plugin
  prefs: []
  type: TYPE_NORMAL
- en: That completes the installation of the hub on your system. In the next section,
    we will see how to inspect the hub with the management interface.
  prefs: []
  type: TYPE_NORMAL
- en: Managing RabbitMQ
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: RabbitMQ is a full-featured message hub that is very powerful and flexible in
    what it can do. There is a lot to RabbitMQ and it may be intimidating to some
    users less familiar with networking. Fortunately, we only need to use a few pieces
    right now, and in the future we will explore more functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, though, open up a browser and follow along these steps to explore
    the hub''s management interface:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate your browser to `http://localhost:15672/` and you should see a login
    dialog.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the username as `guest` and the password as `guest`. These are the default
    credentials and should work unless you've configured it otherwise.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After you log in, you will see the RabbitMQ interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/143641f0-db67-4da2-bb79-7fd03f000024.png)'
  prefs: []
  type: TYPE_IMG
- en: RabbitMQ management interface
  prefs: []
  type: TYPE_NORMAL
- en: There is a lot going on here, so for now just click around and explore the various
    options. Avoid changing any settings, at least for now and until requested to
    do so. RabbitMQ is very powerful, but we all know that with great power comes
    great responsibility.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, currently, your message queue is empty, so you won't see a lot of activity,
    but we will soon resolve that in the next section, where we learn how to send
    and receive messages to and from the queue.
  prefs: []
  type: TYPE_NORMAL
- en: Sending and receiving to/from the MQ
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: RabbitMQ uses a protocol called **Advanced Message Queuing Protocol** (**AMQP**)for
    communication, which is a standard for all messaging middleware. This means that
    we can effectively swap out RabbitMQ for a more robust system, such as Kafka,
    in the future. This also means that, for the most part, all of the concepts we
    cover here will likely apply to similar messaging systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we will do is put a message on the queue from a very simple
    Python client. Open up the source file `Chapter_4_3.py` and follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the source code file and take a look:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The code is taken from the RabbitMQ reference tutorial and shows how to connect.
    It first connects to the hub and opens a `queue` called `hello`. A queue is like
    a mailbox or stack of messages. A hub may have several different queues. Then
    the code publishes a message to the `hello` queue with the body of `Hello World!`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Before we can run the sample, we first need to install `Pika`. Pika is an AMQP
    connection library and can be installed with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Then run the code file as you normally would and watch the output. It's not
    very exciting, is it?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Go to the RabbitMQ management interface again at `http://localhost:15672/`
    and see that we now have a single message in the hub, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d9bffaeb-5bcf-47ac-bedf-9795061ae826.png)'
  prefs: []
  type: TYPE_IMG
- en: RabbitMQ interface showing the addition of a message
  prefs: []
  type: TYPE_NORMAL
- en: The message we just sent will stay on the hub until we collect it later. This
    single feature will allow us to run individual services and make sure they are
    communicating correctly without having to worry about other consumers or publishers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For the purposes of RabbitMQ, we just wrote a publisher. In some cases, you
    many want a service or app to just publish messages, while in others you may want
    them to consume them. In the next exercise, `Chapter_4_4_py`, we will write a
    hub consumer or client:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the source file `Chapter_4_4.py` and look at the code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code is almost identical to the previous example, except that
    this time it only consumes from the queue using an internal `callback` function
    to receive the response. In this example, also note how the script blocks itself
    and waits for the message. In most cases, the client will register a callback
    with the queue in order to register an event. That event is triggered when a new
    message enters the particular queue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the code as you normally would and watch the first `Hello World` message
    get pulled from the queue and output on the client window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Keep the client running and run another instance of the `Chapter_4_3.py` (publish)
    script and note how the client quickly consumes it and outputs it to the window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This completes the simple send and receive communication to/from the message
    hub. As you can see, the code is fairly straightforward and the configuration
    works out of the box, for the most part. If you do experience any issues with
    this setup, be sure to consult the RabbitMQ tutorials, which are an additional
    excellent resource for extra help. In the next section, we look at how to build
    the working chatbot server example.
  prefs: []
  type: TYPE_NORMAL
- en: Writing the message queue chatbot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The chatbot server we want to create is essentially a combination of the three
    previous examples. Open up `Chapter_4_5.py` and follow the next exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The complete server code as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We essentially have a complete working `Hello World` chatbot server in fewer
    than 25 lines of code. Of course, the functionality is still limited, but by now
    you can certainly understand how to add other pattern-matching skills to the bot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The important thing to note here is that we are consuming from a queue called
    `chatin` and publishing to a queue called `chatout`. These queues are now wrapped
    in an exchange called `chat`. You can think of an exchange as a routing service.
    Exchanges provide for additional functionality around queues, and the great thing
    is that they are optional. For use, though, we want to use exchanges, because
    they provide us with better global control of our services. There are four types
    of exchanges used in RabbitMQ and they are summarized here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Direct**: Messages are sent directly to the queue marked in the message transmission.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fanout**: Duplicate the message to all queues wrapped by the exchange. This
    is great when you want to add logging or historical archiving.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Topic**: This allows you to send messages to queues identified by matching
    the message queue. For instance, you could send a message to the queue `chat`
    and any queue wrapped in the same exchange containing the word *chat* receives
    the message. The topic exchange allows you to group like messages.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Headers**: This works similar to the topic exchange but instead filters based
    on the headers in the message itself. This is a great exchange to use for dynamic
    routing of messages with the appropriate headers.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the `Chapter_4_5.py` server example and keep it running.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, open the `Chapter_4_6.py` file and look at the code shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code is just a sample client we can use to test the chatbot server.
    Note how the message variable `chat` is set to `'boo'`. When you run the code,
    check the output window of the chatbot server; this is the `Chapter_4_5.py` file
    we ran earlier. You should see a response message logged in the window that is
    appropriate to the chat message we just sent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point, you could write a full chat client that could communicate with
    our chatbot in Python. However, we want to connect our bot up to Unity and see
    how we can use our bot as a microservice in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Running the chatbot in Unity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Unity** is quickly becoming the standard game engine for learning to develop
    games, virtual reality, and augmented reality applications. Now it is quickly
    becoming the standard platform for developing AI and ML applications as well,
    partly due to the excellent reinforcement learning platform the team at Unity
    has built. This Unity ML platform is a key component in our desire to use the
    tool, since it currently is at the cutting edge of advanced AI for games.'
  prefs: []
  type: TYPE_NORMAL
- en: The AI team at Unity, led by Dr. Danny Lange and their senior developer Dr.
    Arthur Juliani, have made numerous suggestions and contributions to ideas for
    content in this book, both directly and indirectly. This, of course, has had a
    huge impact on using Unity for major portions of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Installing Unity is quite straightforward, but we want to make sure we get
    the installation just right the first time. Therefore, follow these steps to install
    a version of Unity on your system:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate your browser to [https://store.unity.com/download](https://store.unity.com/download)
    and accept the terms, and then download the Unity Download Assistant. This is
    the tool that downloads and installs the pieces we need.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the Download Assistant and select the following minimum components to install,
    as shown in the dialog as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a18fa234-6ec2-42f3-98e2-702f88ccff5a.png)'
  prefs: []
  type: TYPE_IMG
- en: Selecting the installation components for Unity
  prefs: []
  type: TYPE_NORMAL
- en: Just be sure to install the latest version of Unity and select the components
    that match your preferred OS, as shown in the preceding screenshot. You may, of
    course, select other components at your discretion, but those are the minimum
    you will need for this book.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, set the path to install Unity to a well-known folder. A good choice is
    to set the folder name equal to the version. This allows you to have multiple
    versions of Unity on the same system that you can easily find. The following screenshot
    shows how you may do this on Windows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/56789132-7359-4d00-90b2-3fd856a3199b.png)'
  prefs: []
  type: TYPE_IMG
- en: Setting the installation path to Unity
  prefs: []
  type: TYPE_NORMAL
- en: Those are the only critical parts to the installation and you can continue installing
    the software using the defaults.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Launch the Unity editor after it installs and you will be prompted to log in.
    Unity requires you to have an account, regardless of whether you are using the
    free version. Go back to [unity.com](http://unity.com) and just create an account.
    After you are done setting up the account, go back in and log in to the editor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After you log in, create a empty project called `Chatbot` and let the editor
    open to a blank scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Unity is a full-featured game engine and may be intimidating if this is your
    first visit. There are plenty of online tutorials and videos that can get you
    up to speed on the interface. We will do our best to demonstrate concepts simply,
    but if you get lost, just take your time and work through the exercise a few times.
  prefs: []
  type: TYPE_NORMAL
- en: With Unity installed, we now have to install the components or assets that will
    allow us to easily connect to the chatbot server we just created. In the next
    section, we install the AMQP asset for Unity.
  prefs: []
  type: TYPE_NORMAL
- en: Installing AMQP for Unity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'RabbitMQ has an excellent resource for plenty of cross-platform libraries that
    allow you to connect to the hub with ease. The library for C# does work well outside
    Unity but is problematic to set up. Fortunately, the good folks at Cymantic Labs
    have built and open sourced a version for Unity on GitHub. Let''s see how to install
    this code in the next exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download and unpack the code using `git` or as a ZIP file from [https://github.com/CymaticLabs/Unity3D.Amqp](https://github.com/CymaticLabs/Unity3D.Amqp.git):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Switch to Unity from the menu, and select File | Open Project and navigate to
    the `Unity3D.Amqp\unity\CymaticLabs.UnityAmqp` folder where you installed the
    code. This will open the asset in its own project. Wait for the project to load.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `Assets/CymanticLabs/Amqp/Scenes` folder in the Project window (typically
    at the bottom).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Double-click on the **AmqpDemo** scene to open it in the editor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Press the Play button at the top of the editor to run the scene. After you
    run the scene, you should see the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0f86dbe5-62dd-4302-8d5d-6fbce169709a.png)'
  prefs: []
  type: TYPE_IMG
- en: Setting the Amqp connection and sending a message
  prefs: []
  type: TYPE_NORMAL
- en: Press the Connect button to connect to the local RabbitMQ.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, under Subscriptions, set the exchange to chat, and the queue to chatout,
    and click Subscribe. This will subscribe to the queue so we can see any return
    message in the Unity console window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, under Publish, set the exchange to chat, and the queue to chatin, and
    type a message such as `hello`. Click the Send button and you should see a response
    from the bot in the console window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That sets up our working chatbot. Of course, this is just the start of what
    is possible and the reader is certainly encouraged to explore further, but keep
    in mind we will revisit this code later and make use of it in a later section
    of the book.
  prefs: []
  type: TYPE_NORMAL
- en: That completes this chapter, and now you can take advantage of it for further
    learning in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Use the following exercises to expand your learning and get more confident
    with the material in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Go back to the first exercise and load another set of translations. Train the
    bot on those and see what responses are generated after training. There are plenty
    of other language files available for training.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set up your own conversational training file using the English/French translation
    one as an example. Remember, the matching responses can be anything and not just
    translated text.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add additional pattern-matching skills to the DeepPavlov bot. Either the simple
    test one and/or the chatbot server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The DeepPavlov chatbot uses a highest-value selection criteria for selecting
    a response. DeepPavlov does have a random selector as well. Change the response
    selector on the chatbot to use random.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the exchange type in the example to use Fanout and create a log queue
    to log messages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Change the exchange type to Topic and see how you can group messages. Warning:
    this will likely break the example; see whether you can fix it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a RabbitMQ publisher in Python that publishes to one or more different
    types of queues.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an entire set of conversation skills using the pattern-matching skill.
    Then, see how well your bot converses with you.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add additional skills of other types to the chatbot server. This may require
    some additional homework on your part.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write or run two chatbots over RabbitMQ and watch them converse with each other.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Work through at least two or three of these exercises.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at building chatbots or neural conversational agents
    using neural networks and deep learning. We first saw what makes a chatbot and
    the main forms in use today: goal-oriented and conversational bots. Then we looked
    at how to build a basic machine translation conversational chatbot that used sequence-to-sequence
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: After getting a background in sequence learning, we looked at the open source
    tool DeepPavlov. DeepPavlov is a powerful chat platform built on top of Keras
    and designed for many forms of neural agent conversation and tasks. This made
    it ideal for us to use the chatbot server as a base. Then we installed RabbitMQ,
    a microservices message hub platform that will allow our bot and all manner of
    other services to talk together later on.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we installed Unity and then quickly installed the AMQP plugin asset
    and connected to our chatbot server.
  prefs: []
  type: TYPE_NORMAL
- en: This completes our introductory section to deep learning, and, in the next section,
    we begin to get more into game AI by diving into **deep reinforcement learning**.
  prefs: []
  type: TYPE_NORMAL
