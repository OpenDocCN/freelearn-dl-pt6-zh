- en: Sentiment Analysis Using Word2Vec and LSTM Network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sentiment analysis is a systematic way to identify, extract, quantify, and study
    effective states and subjective information. This is widely used in **natural
    language processing** (**NLP**), text analytics, and computational linguistics.
    This chapter demonstrates how to implement and deploy a hands-on deep learning
    project that classifies review texts as either positive or negative based on the
    words they contain. A large-scale movie review dataset that contains 50k reviews
    (training plus testing) will be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'A combined approach using Word2Vec (that is, a widely used word embedding technique
    in NLP) and the **Long Short-Term Memory** (**LSTM**) network for modeling will
    be applied: the pre-trained Google news vector model will be used as the neural
    word embeddings. Then, the training vectors, along with the labels, will be fed
    into the LSTM network to classify them as negative or positive sentiments. Finally,
    it evaluates the trained model on the test set.'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, it shows how to apply text preprocessing techniques such as tokenizer,
    stop words removal, and **term frequency-inverse document frequency** (**TF-IDF**),
    and word-embedding operations in **Deeplearning4j** (**DL4J**).
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, it also shows how to save the trained DL4J model. Later on, the
    saved model will be restored from disk to make sentiment prediction on other small-scale
    review texts from Amazon cell, Yelp, and IMDb. Finally, it has answers to some
    frequently asked questions related to the projects and possible outlook.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered throughout this end-to-end project:'
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis in NLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Word2Vec for neural word embeddings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset collection and description
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saving and restoring pre-trained models with DL4J
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing a sentiment-analyzing model using Word2Vec and LSTM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequently asked questions (FAQs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis is a challenging task
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Text analytics in NLP is all about processing and analyzing large-scale structured
    and unstructured text to discover hidden patterns and themes and derive contextual
    meaning and relationships. Text analytics has so many potential use cases, such
    as sentiment analysis, topic modeling, TF-IDF, named entity recognition, and event
    extraction.
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis includes many example use cases, such as analyzing the political
    opinions of people on Facebook, Twitter, and other social media. Similarly, analyzing
    the reviews of restaurants on Yelp is also another great example of Sentiment
    Analysis. NLP frameworks and libraries such as OpenNLP and Stanford NLP are typically
    used to implement sentiment analysis.
  prefs: []
  type: TYPE_NORMAL
- en: However, for analyzing sentiments using text, particularly unstructured texts,
    we must find a robust and efficient way of feature engineering to convert the
    text into numbers. However, several stages of transformation of data are possible
    before a model is trained, and then subsequently deployed and finally performing
    predictive analytics. Moreover, we should expect the refinement of the features
    and model attributes. We could even explore a completely different algorithm,
    repeating the entire sequence of tasks as part of a new workflow.
  prefs: []
  type: TYPE_NORMAL
- en: When you look at a line of text, we see sentences, phrases, words, nouns, verbs,
    punctuation, and so on, which, when put together, have a meaning and purpose.
    Humans are very good at understanding sentences, words, slang, annotations, and
    context extremely well. This comes from years of practice and learning how to
    read/write proper grammar, punctuation, exclamations, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the two sentences: *DL4J makes predictive analytics easy*, and
    *Predictive analytics makes DL4J easy*, might result in the same sentence vector
    having the same length equal to the size of our vocabulary that we pick. The second
    drawback is that the words "is" and "DL4J" have the same numerical index value
    of one, but our intuition says that the word "is" isn''t important compared to
    "DL4J". Let''s take a look at the second example: when your search string is *hotels
    in Berlin* in Google, we want results pertaining to *bnb*, *motel*, *lodging*,
    and *accommodation* in Berlin, too.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When layman terms come to the party, natural language learning becomes more
    complicated. Take the word bank as an example. This has several connections with
    a financial institution and land alongside a body of water. Now, if a natural
    sentence contains the term "bank" in conjunction with words such as finance, money,
    treasury, and interest rates, we can understand that its intended meaning is the
    former. However, if the neighboring words are water, shore, river, and lake, and
    so on, the case is the latter. Now, the question would be: can we exploit this
    concept to deal with polysemy and synonyms and make our model learn better?'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f620eb24-b4e5-4a8d-9a95-ef5685415cd2.png)'
  prefs: []
  type: TYPE_IMG
- en: Classical machine learning versus deep learning-based NPL
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, natural language sentences also contain vague words, slang, trivial
    words, and special characters, and all of these make the overall understanding
    and machine learning troublesome.
  prefs: []
  type: TYPE_NORMAL
- en: We have already seen how to use one-hot encoding or StringIndexer techniques
    to convert categorical variables (or even words) into numeric form. However, this
    kind of program often fails to interpret the semantics in a complex sentence,
    especially for lengthy sentences or even words. Consequently, human words have
    no natural notion of similarity. Thus, we naturally won't try to replicate this
    kind of capability, right?
  prefs: []
  type: TYPE_NORMAL
- en: How can we build a simple, scalable, faster way to deal with the regular texts
    or sentences and derive relations between a word and its contextual words, and
    then embed them in billions of words that will produce exceedingly good word representations
    into numeric vector space so that the machine learning models can consume them?
    Let's look at the Word2Vec model to find the answer to this.
  prefs: []
  type: TYPE_NORMAL
- en: Using Word2Vec for neural word embeddings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Word2Vec is a two-layer neural network that processes texts and turns them
    into numerical features. This way, the output of the Word2Vec is a vocabulary
    in which each word is embedded in vector space. The resulting vector can then
    be fed into a neural network for better understanding of natural languages. The
    novelist EL Doctorow has expressed this idea quite poetically in his book *Billy
    Bathgate*:'
  prefs: []
  type: TYPE_NORMAL
- en: '"It''s like numbers are language, like all the letters in the language are
    turned into numbers, and so it''s something that everyone understands the same
    way. You lose the sounds of the letters and whether they click or pop or touch
    the palate, or go ooh or aah, and anything that can be misread or con you with
    its music or the pictures it puts in your mind, all of that is gone, along with
    the accent, and you have a new understanding entirely, a language of numbers,
    and everything becomes as clear to everyone as the writing on the wall. So as
    I say there comes a certain time for the reading of the numbers."'
  prefs: []
  type: TYPE_NORMAL
- en: 'While using BOW and TF-IDF, all words are projected into the same position
    and their vectors are averaged: we address the word importance without considering
    the importance of word order in a collection of documents or in a single document.'
  prefs: []
  type: TYPE_NORMAL
- en: As the order of words in the history does not influence the projection, both
    BOW and TF-IDF have no such features that can take care of this issue. Word2Vec
    encodes each word into a vector by using either context to predict a target word
    using a **continuous bag-of-words** (**CBOW**) or using a word to predict a target
    context, which is called **continuous skip-gram**.
  prefs: []
  type: TYPE_NORMAL
- en: '**N-gram versus skip-gram**: Words are read into vectors one at a time and
    scanned back and forth within a certain range'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CBOW**: The CBOW technique uses a continuously distributed representation
    of the context'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous skip-gram**: Unlike CBOW, this method tries to maximize classification
    of a word based on another word in the same sentence'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I have experienced that an increase in the range improves the quality of the
    resulting word vectors, but it also increases the computational complexity. Since
    more distant words are usually less related to the current word than those close
    to it are, we give less weight to the distant words by sampling less from those
    words in our training examples. Because of the model building and prediction,
    times also increase.
  prefs: []
  type: TYPE_NORMAL
- en: 'A comparative analysis from the architecture''s point of view can be seen in
    the following diagram, where the architecture predicts the current word based
    on the context, and the skip-gram predicts the surrounding words given the current
    word:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bba3319f-913c-4a4d-af80-de53f74b9cfd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'CBOW versus skip-gram (source: Tomas Mikolov et al., Efficient Estimation of
    Word Representations in Vector Space, https://arxiv.org/pdf/1301.3781.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: Datasets and pre-trained model description
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are going to use the Large Movie Review dataset for training and testing
    the mode. Additionally, we will be using the Sentiment labeled Sentences dataset
    for making a single prediction on reviews on products, movies, and restaurants.
  prefs: []
  type: TYPE_NORMAL
- en: Large Movie Review dataset for training and testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The former one is a dataset for binary sentiment classification containing substantially
    more data than previous benchmark datasets. The dataset can be downloaded from
    [http://ai.stanford.edu/~amaas/data/sentiment/](http://ai.stanford.edu/~amaas/data/sentiment/).
    Alternatively, I have utilized a Java method that comes from DL4J examples that
    also downloads and extracts this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'I would like to acknowledge the following publications: Andrew L. Maas, Raymond
    E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011),
    *Learning Word Vectors for Sentiment Analysis*, The 49^(th) Annual Meeting of
    the Association for Computational Linguistics (ACL 2011).'
  prefs: []
  type: TYPE_NORMAL
- en: This dataset contains 50,000 movie reviews along with their associated binary
    sentiment polarity labels. The reviews are split evenly into 25,000 for both train
    and test sets. The overall distribution of labels is balanced (25,000 positive
    and 25,000 negative). We also include an additional 50 thousand unlabeled documents
    for unsupervised learning. In the labeled train/test sets, if a reviews has a
    score <= 4 out of 10, it is treated as a negative review, but having a score >=
    7 out of 10 is treated as a positive review. Nevertheless, reviews with more neutral
    ratings are not included in the datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Folder structure of the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two folders, namely `train` and `test` for the training and test
    sets, respectively. Each folder has two separate subfolders called `pos` and `neg`,
    which contain reviews with binary labels (pos, neg). Reviews are stored in text
    files having the name `id_rating.txt`, where `id` is a unique ID and `rating`
    is the star rating on a 1-10 scale. Take a look at the following diagram to get
    a clearer view on the directory''s structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3c758053-b424-4acf-b7d1-76fa4dcc7225.png)'
  prefs: []
  type: TYPE_IMG
- en: Folder structure in Large Movie Review Dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the `test/pos/200_8.txt` file is the text for a positive-labeled
    test set example with a unique ID of 200 and a star rating of 8/10 from IMDb.
    The `train/unsup/` directory has zero for all ratings because the ratings are
    omitted for this portion of the dataset. Let''s look at a sample positive review
    from IMDb:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Bromwell High is a cartoon comedy. It ran at the same time as some other programs
    about school life, such as "Teachers". My 35 years in the teaching profession
    lead me to believe that Bromwell High''s satire is much closer to reality than
    is "Teachers". The scramble to survive financially, the insightful students who
    can see right through their pathetic teachers'' pomp, the pettiness of the whole
    situation, all remind me of the schools I knew and their students. When I saw
    the episode in which a student repeatedly tried to burn down the school, I immediately
    recalled ......... at .......... High. A classic line: INSPECTOR: I''m here to
    sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many
    adults of my age think that Bromwell High is far-fetched. What a pity that it
    isn''t!"'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, from the preceding review text, we can understand that the respective
    audience gave Bromwell High (a British-Canadian adult animated series about a
    British high school in South London, which you can see more of at [https://en.wikipedia.org/wiki/Bromwell_High](https://en.wikipedia.org/wiki/Bromwell_High))
    a positive review, that is, a positive sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: Description of the sentiment labeled dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The sentiment labeled sentences dataset was downloaded from the UCI machine
    learning repository at [http://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences](http://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences).
    This dataset was a research outcome by Kotzias and is used in the following publication:
    *From Group to Individual Labels using Deep Features*, Kotzias et. al, KDD'' 2015.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset contains sentences labeled with a positive or negative sentiment,
    extracted from reviews of products, movies, and restaurants. The review is a tab-delimited
    review having review sentences and a score of either 1 (for positive) or 0 (for
    negative). Let''s look at a sample review from Yelp with an associated label:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"I was disgusted because I was pretty sure that was human hair."*'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding review text, the score is 0, so it is a negative review and
    it expresses a negative sentiment on the part of the customer. On the other hand,
    there are 500 positive and 500 negative sentences.
  prefs: []
  type: TYPE_NORMAL
- en: 'Those were selected at random for larger datasets of reviews. The author has
    attempted to select sentences that have a clearly positive or negative connotation;
    the goal was for no neutral sentences to be selected. The review sentences are
    collected from three different websites/fields, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.imdb.com/](https://www.imdb.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.amazon.com/](https://www.amazon.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.yelp.com/](https://www.yelp.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Word2Vec pre-trained model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Instead of generating a new Word2Vec model from scratch, Google's pre-trained
    news word vector model can be used, which provides an efficient implementation
    of the CBOW and skip-gram architectures for computing vector representations of
    words. These representations can subsequently be used in many NLP applications
    and further research.
  prefs: []
  type: TYPE_NORMAL
- en: The model can be downloaded from [https://code.google.com/p/word2vec/](https://code.google.com/p/word2vec/)
    manually. The Word2Vec model takes a text corpus as input and produces the word
    vectors as output. It first constructs a vocabulary from the training text data
    and then learns vector representation of words.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways to achieve a Word2Vec model: by using continuous bag-of-words
    and continuous skip-gram. Skip-gram is slower, but better for infrequent words,
    although CBOW is faster.'
  prefs: []
  type: TYPE_NORMAL
- en: The resulting word vector file can be used as a feature in many natural language
    processing and machine learning applications.
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis using Word2Vec and LSTM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, let''s define the problem. Given a movie review (raw text), we have
    to classify that movie review as either positive or negative based on the words
    it contains, that is, sentiment. We do this by combining the Word2Vec model and
    LSTM: each word in a review is vectorized using the Word2Vec model and fed into
    an LSTM net. As stated earlier, we will train data in the Large Movie Review dataset.
    Now, here is the workflow of the overall project:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we download the movie/product reviews dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we create or reuse an existing Word2Vec model (for example, Google News
    word vectors)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we load each review text and convert words to vectors and reviews to sequences
    of vectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we create and train the LSTM network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we save the trained model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we evaluate the model on the test set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we restore the trained model and evaluate a sample review text from the
    sentiment labeled dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at what the `main()` method would look like if we go
    with the preceding workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Let's break the preceding steps down into smaller steps. We'll start with dataset
    preparation using the Word2Vec model.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the train and test set using the Word2Vec model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, to prepare the dataset for training and testing, first, we have to download
    three files, which are outlined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A Google-trained Word2Vec model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A large Movie Review dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A sentiment labeled dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The pre-trained Word2Vec is downloaded from [https://code.google.com/p/word2vec/](https://code.google.com/p/word2vec/)
    and then we can set the location for the Google News vectors manually:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Then, we will download and extract the Large Movie Review dataset from the following
    URL.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s set the location to save and extract the training/testing data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can either manually download or extract the dataset in our preferred
    location or, alternatively, the following method does it in an automated way.
    Note that I have slightly modified the original DL4J implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding method, download the dataset from the URL I mentioned using
    HTTP protocol. Then, extract the dataset to the location we mentioned. For this,
    I have used the `TarArchiveEntry`, `TarArchiveInputStream`, and `GzipCompressorInputStream`
    utilities from Apache Commons. Interested readers can find more details at [http://commons.apache.org/](http://commons.apache.org/).
  prefs: []
  type: TYPE_NORMAL
- en: In short, I have provided a class named `DataUtilities.java` that has two methods,
    `downloadFile()` and `extractTarGz()`, that are used for downloading and extracting
    the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the `downloadFile()` method takes the remote URL (that is, the URL of
    the remote file) and the local path (that is, where to download the file) as parameters
    and downloads a remote file if it doesn''t exist. Now, let''s see what the signature
    looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Second, the `extractTarGz()` method takes an input path (the `ism` input file
    path) and the output path (that is, the output directory path) as parameters and
    extracts the `tar.gz` file to a local folder. Now, let''s see what the signature
    looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to utilize the preceding methods, you have to import the following packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: By the way, Apache Commons is an Apache project focused on all aspects of reusable
    Java components. See more at [https://commons.apache.org/](https://commons.apache.org/).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the sentiment labeled dataset can be downloaded from [https://archive.ics.uci.edu/ml/machine-learning-databases/00331/](https://archive.ics.uci.edu/ml/machine-learning-databases/00331/).
    Once you have finished these steps, the next task will be to prepare the training
    and testing set. For this, I have written a class named `SentimentDatasetIterator`,
    which is a `DataSetIterator` that is specialized for the IMDb review dataset used
    in our project. However, this can also be applied to any text dataset for text
    analytics in NLP. This class is a slight extension of the `SentimentExampleIterator.java`
    class, which is provided by the DL4J example. Thanks to the DL4J folks for making
    our life easier.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `SentimentDatasetIterator` class takes either the train or test set from
    the sentiment labeled dataset and Google pre-trained Word2Vec and generates training
    data sets. On the other hand, a single class (negative or positive) is used as
    the label to predict the final time step of each review. Additionally, since we
    are dealing with reviews of different lengths and only one output at the final
    time step, we use padding arrays. In short, our training dataset should contain
    the following items, that is, the 4D object:'
  prefs: []
  type: TYPE_NORMAL
- en: Features from each review text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labels in either 1 or 0 (that is, for positive and negative, respectively)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature masks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Label masks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, let''s get started with the following constructor, which is used for the
    following purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding signature of the constructor, we used the following purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: To keep track of the positive and negative review files in the directory of
    the IMDb review data set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To tokenize the review texts to words with stop words and unknown words removed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the longest review exceeds `truncateLength`, only take the first `truncateLength`
    words
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Word2Vec object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The batch size, which is the size of each minibatch for training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once initialization is complete, we load each review test as a string. Then,
    we alternate between positive and negative reviews:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we tokenize the reviews and filter out unknown words (that is, words
    that are not included in the pre-trained Word2Vec model, for example, stop words):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, if the longest review exceeds the threshold `truncateLength`, we only
    take the first `truncateLength` words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create data for training. Here, we have `reviews.size()` examples
    of varying lengths since we have two labels, positive or negative:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we are dealing with reviews of different lengths and only one output
    at the final time step, we use padding arrays, where the mask arrays contain 1
    if data is present at that time step for that example, or 0 if the data is just
    padding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: It is to be noted that creating the mask arrays for the features and labels
    are optional and may be null too. Then, we get the truncated sequence length of
    the *i*^(th) document, obtain all the word vectors for the current document, and
    transpose them to fit the second and third feature shape.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the word vectors ready, we put them into the features array at
    three indices, which is equal to `NDArrayIndex.interval(0, vectorSize)` having
    all elements between 0 and the length of the current sequence. Then, we assign
    1 to each position where a feature is present, that is, at the interval of 0 and
    the sequence length.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, when it comes to label encoding, we set [0, 1] for a negative review text
    and [1, 0] for a positive review text. Finally, we specify that an output exists
    at the final time step for this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Note that the main problem hindering dropout in NLP has been that it could not
    be applied to recurrent connections, as the aggregating dropout masks would effectively
    zero out embeddings over time—hence, feature masking has been used in the preceding
    code block.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, up to this point, all the required elements are prepared so finally, we
    return the dataset as an `NDArray` (that is, 4D) containing the features, labels,
    `featuresMask`, and `labelsMask`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: More elaborately, using `DataSet`, we will create a dataset with the specified
    input `INDArray` and labels (output) `INDArray`, and (optionally) mask arrays
    for the features and labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, our training set will be at hand using the following invocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Fantastic! Now we can create our neural networks by specifying the layers and
    hyperparameters in the next step.
  prefs: []
  type: TYPE_NORMAL
- en: Network construction, training, and saving the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in the Titanic survival prediction section, again, everything starts
    with `MultiLayerConfiguration`, which organizes those layers and their hyperparameters.
    Our LSTM network consists of five layers. The input layer is followed by three
    LSTM layers. Then, the last layer is an RNN layer, which is also the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: More technically, the first layer is the input layer, and then three layers
    are placed as LSTM layers. For the LSTM layers, we initialize the weights using
    Xavier, we use SGD as the optimization algorithm with the Adam updater, and we
    use Tanh as the activation function. Finally, the RNN output layer has a softmax
    activation function that gives us a probability distribution over classes (that
    is, it outputs the sum to 1.0) and MCXENT, which is the multiclass cross entropy
    loss function.
  prefs: []
  type: TYPE_NORMAL
- en: 'For creating LSTM layers, DL4J provides both LSTM and `GravesLSTM` classes.
    The latter is an LSTM recurrent net, which is based on Graves, but comes up without
    CUDA support: supervised sequence labelling with RNN (see more at [http://www.cs.toronto.edu/~graves/phd.pdf](http://www.cs.toronto.edu/~graves/phd.pdf)).
    Now, before we start creating the network, first let''s define the required hyperparameters
    such as the number of input/hidden/output nodes (that is, neurons):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now create a network configuration and conduct network training. With
    DL4J, you add a layer by calling a layer on the `NeuralNetConfiguration.Builder()`,
    specifying its place in the order of layers (the zero-indexed layer in the following
    code is the input layer):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we also specify that we do not need to do any pre-training (which
    is typically needed in a deep belief network or stacked auto-encoders). Then,
    we initialize the network and start the training on the training set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Typically, this type of network has lots of hyperparameters. Let''s print the
    number of parameters in the network (and for each layer):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As I said, our network has 1 million parameters, which is huge. This also imposes
    a great challenge while tuning hyperparameters. However, we will see some tricks
    in the FAQ section.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Once the training has been completed, we can save the trained model for model
    persistence and subsequent reuse. For that, DL4J provides support for the trained
    model sterilization using the `writeModel()` method from the `ModelSerializer`
    class. Additionally, it provides the functionality for restoring the saved model
    using the `restoreMultiLayerNetwork()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will see more in the following step. Nevertheless, we can also save the
    network updater too, that is, the state for momentum, RMSProp, Adagrad, and so
    on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Restoring the trained model and evaluating it on the test set
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the training has been completed, the next task will be to evaluate the
    model. We will evaluate the model's performance on the test set. For the evaluation,
    we will be using `Evaluation()`, which creates an evaluation object with two possible
    classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s iterate the evaluation on every test sample and get the network''s
    prediction from the trained model. Finally, the `eval()` method checks the prediction
    against the true class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The predictive accuracy for the sentiment analysis using LSTM is about 87%,
    which is good considering that we have not focused on hyperparameter tuning! Now,
    let''s see how the classifier predicts across each class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to [Chapter 2](e27fb252-7892-4659-81e2-2289de8ce570.xhtml), *Cancer
    Types Prediction Using Recurrent Type Networks*, we will now compute another metric
    called Matthews''s correlation coefficient for this binary classification problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This shows a weakly positive relationship, showing that our model performs quite
    well. Up next, we will use the trained model for inferencing, that is, we will
    perform predictions on sample review texts.
  prefs: []
  type: TYPE_NORMAL
- en: Making predictions on sample review texts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at how our trained model generalizes, that is, how
    it performs on unseen review texts from the sentiment labeled sentences dataset.
    First, we need to restore the trained model from the disk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can randomly extract two review texts from IMDb, Amazon, and Yelp,
    where the first one expresses a positive sentiment, and the second one expresses
    a negative sentiment (according to the known labels). Then, we can create a HashMap
    containing both the review strings and labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create an array of the preceding strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we iterate over the map and do the sample evaluation using the pre-trained
    model as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: If you look at the preceding code block carefully, you can see that we converted
    each review text as a time series by extracting features. Then, we computed the
    network output (that is, probability). Then, we compare the probability, that
    is, if the probability is that of it being a positive sentiment, we set a flag
    as true, or false otherwise. This way, we then take a decision on the final class
    prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have also utilized the `loadFeaturesFromString()` method in the preceding
    code block, which converts a review string to features in `INDArray` format. It
    takes two parameters, `reviewContents`, which is the content of the review to
    vectorize, and `maxLength`, which is the maximum length of the review text. Finally,
    it returns a `features` array for the given input string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: If you don't want to truncate, simply use `Integer.MAX_VALUE`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s go back to our original discussion. Hilariously, we made it more
    human, that is, without utilizing an activation function. Finally, we print the
    result for each review text and its associated label:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: So, our trained model has made 50% incorrect predictions, especially since it
    always predicts a positive review as a negative. In short, it is not that good
    at generalizing to unknown texts, which can be seen with an accuracy of 50%.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, a stupid question might come to mind. Did our network underfit? Is there
    any way to observe how the training went? In other words, the question would be:
    Why didn''t our LSTM net neural show higher accuracy? We will try to answer these
    questions in the next section. So stay with me!'
  prefs: []
  type: TYPE_NORMAL
- en: Frequently asked questions (FAQs)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have solved the sentiment analysis problem with an acceptable level
    of accuracy, there are other practical aspects of this problem and overall deep
    learning phenomena that need to be considered too. In this section, we will see
    some frequently asked questions that might already be on your mind. Answers to
    these questions can be found in Appendix A:'
  prefs: []
  type: TYPE_NORMAL
- en: I understand that the predictive accuracy of sentiment analysis using LSTM is
    still reasonable. However, it does not perform well on the Sentiment labeled dataset.
    Did our network overfit? Is there any way to observe how the training went?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Considering a huge number of review texts, can we perform the training on the
    GPU?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In relation to question 2, can we even undertake the whole process using Spark?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Where can I get more training datasets for sentiment analysis?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Instead of downloading the training data in `.zip` format manually, can we use
    the `extractTarGz()` method?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: My machine has limited memory. Give me a clue as to how memory management and
    garbage collection work in DL4J.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we have seen how to implement and deploy a hands-on deep learning
    project that classifies review texts as either positive or negative based on the
    words they contain. We have used a large-scale movie review dataset that contains
    50,000 reviews (training plus testing). A combined approach using Word2Vec (that
    is, a widely used word embedding technique in NLP) and the LSTM network for modeling
    was applied: the pre-trained Google news vector model was used as the neural word
    embeddings.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, the training vectors, along with the labels, were fed into the LSTM network,
    which successfully classified them as negative or positive sentiments. Then, it
    evaluated the trained model on the test set. Additionally, we have also seen how
    to apply text-based preprocessing techniques such as tokenizer, stop words removal
    and TF-IDF, as well as word-embedding operations in DL4J.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see a complete example of how to develop a deep
    learning project to classify images using the DL4J transfer learning API. Through
    this application, users will be able to modify the architecture of an existing
    model, fine-tune learning configurations of an existing model, and hold parameters
    of a specified layer constantly during training, which is also referred to as
    frozen.
  prefs: []
  type: TYPE_NORMAL
- en: Answers to questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Answer to question 1**: We have seen that our trained model performs pretty
    well on the test set with an accuracy of 87%. Now, if we see the model versus
    iteration score and other parameters from the following graph, then we can see
    that our model was not overfitted:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/45849f1d-1af8-415e-ba55-2557cb8acf40.png)'
  prefs: []
  type: TYPE_IMG
- en: Model versus iteration score and other parameters of the LSTM sentiment analyzer
  prefs: []
  type: TYPE_NORMAL
- en: Now, for the sentiment labeled sentences, the trained model did not perform
    well. There could be several reasons for that. For example, our model is trained
    with only the movie review dataset, but here, we try to force our model to perform
    on different types of datasets too, for example, Amazon and Yelp. Nevertheless,
    we have not tuned the hyperparameters carefully.
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer to question 2**: Yes, in fact, this will be very helpful. For this,
    we have to make sure that our programming environment is ready. In other words,
    first, we have to configure CUDA and cuDNN on our machine.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, make sure that your machine has a NVIDIA GPU installed and configured
    with sufficient memory and CUDA compute capability. If you do not know how to
    configure such prerequisites, refer to this URL at [https://docs.nvidia.com/deeplearning/sdk/cudnn-install/](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/).
    Once your machine has CUDA/cuDNN installed, in the `pom.xml` file, you have to
    add two entries:'
  prefs: []
  type: TYPE_NORMAL
- en: Backend in the project properties
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CUDA as the platform dependency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For step 1, the properties should now look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, for step 2, add the following dependency in the `pop.xml` file (that is,
    inside the dependencies tag):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, update the Maven project, and the required dependencies will be downloaded
    automatically. Now, unless we perform the training on multiple GPUs, we do not
    need to make any changes. However, just run the same script again to perform the
    training. Then, you will experience the following logs on the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Nevertheless, in [Chapter 8](a59fb1f2-b585-44f5-a467-903b8c25867b.xhtml), *Distributed
    Deep Learning – Video Classification Using Convolutional LSTM Networks*, we will
    see how to make everything faster and scalable overall on multiple GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Aswer** **to question 3**: Yes, in fact, this will be very helpful. For this,
    we have to make sure that our programming environment is ready. In other words,
    first, we have to configure Spark on our machine. Once your machine has CUDA/cuDNN
    installed, we just want to configure Spark. In the `pom.xml` file, you have to
    add two entries:'
  prefs: []
  type: TYPE_NORMAL
- en: Backend in the project properties
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spark dependency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For step 1, the properties should now look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, for step 2, add the following dependency in the `pop.xml` file (that is,
    inside the dependencies tag):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Then, update the Maven project, and the required dependencies will be downloaded
    automatically. Now, unless we perform the training on multiple GPUs, we do not
    need to make any changes. However, we need to convert the training/testing dataset
    into a Spark-compatible JavaRDD.
  prefs: []
  type: TYPE_NORMAL
- en: 'I have written all of the steps in the `SentimentAnalyzerSparkGPU.java` file
    that can be used to see how the overall steps work. A general warning is that
    if you perform the training on Spark, the DL4J UI will not work because of cross-dependencies
    on the Jackson library. For that, we must first create the `JavaSparkContext`
    using the `sparkSession()` method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we have to convert the sentiment training dataset iterator to JavaRDD
    of the dataset. First, we create a list of datasets and then add each training
    sample to the list as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create a `JavaSparkContext` by invoking the `sparkSession()` method
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we utilize the `parallelize()` method of Spark to create the JavaRDD
    of the dataset, which can then be used to perform the training using Spark:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the Spark `TrainingMaster` uses the `ParameterAveragingTrainingMaster`,
    which helps perform the training using Spark. Please refer to [Chapter 8](a59fb1f2-b585-44f5-a467-903b8c25867b.xhtml),
    *Distributed Deep Learning – Video Classification Using Convolutional LSTM Networks*,
    for more details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create the `SparkDl4jMultiLayer` instead of just the `MultilayerNetwork`
    as we did previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create a training listener that records the score of each iteration
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we start the training as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'However, using this approach, there is a drawback, that is, we cannot save
    the trained model directly like this but first, we have to fit the network using
    the training data and collect the output as the `MultiLayerNetwork` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '**Answer to question 4**: There are many sources where you can get a sentiment
    analysis dataset. A few of them are listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The huge n-grams dataset from Google: [storage.googleapis.com/books/ngrams/books/datasetsv2.html](http://storage.googleapis.com/books/ngrams/books/datasetsv2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Twitter sentiment: [http://www.sananalytics.com/lab/twitter-sentiment/](http://www.sananalytics.com/lab/twitter-sentiment/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'UMICH SI650—sentiment classification dataset on Kaggle: [http://inclass.kaggle.com/c/si650winter11/data](http://inclass.kaggle.com/c/si650winter11/data)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Multi-domain sentiment dataset: [http://www.cs.jhu.edu/~mdredze/datasets/sentiment/](http://www.cs.jhu.edu/~mdredze/datasets/sentiment/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Answer to question 5**: The answer is no, but with a little effort we can
    make it work. For that, we can use the `ZipArchiveInputStream` and `GzipCompressorInputStream`
    classes from Apache commons as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '**Answer to question 6**: Well, this is really only a concern if your machine
    doesn''t have enough memory. For this application, I did not face any OOP type
    issue while running this project as my laptop has 32 GB of RAM.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from this step, we can also choose DL4J garbage collection, especially
    because memory is constrained on your end. DL4J provides a method called `getMemoryManager()`
    that returns a backend-specific `MemoryManager` implementation for low-level memory
    management. Additionally, we have to enable the periodic `System.gc()` calls with
    the windowsills minimal time in milliseconds between calls. Let''s see an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: However, simply set `windowMillis` to `0` to disable this option.
  prefs: []
  type: TYPE_NORMAL
