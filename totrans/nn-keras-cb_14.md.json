["```py\ndef extract_img(img):\n     target = np.ones((32,128))*255\n     new_shape1 = 32/img.shape[0]\n     new_shape2 = 128/img.shape[1]\n     final_shape = min(new_shape1, new_shape2)\n     new_x = int(img.shape[0]*final_shape)\n     new_y = int(img.shape[1]*final_shape)\n     img2 = cv2.resize(img, (new_y,new_x ))\n     target[:new_x,:new_y] = img2[:,:,0]\n     target[new_x:,new_y:]=255\n     return 255-target\n```", "```py\nfilepath = '/content/words.txt'\nf = open(filepath)\nimport cv2\ncount = 0\nx = []\ny = []\nx_new = []\nchars = set()\nfor line in f:\n     if not line or line[0]=='#':\n         continue\n     try:\n         lineSplit = line.strip().split(' ')\n         fileNameSplit = lineSplit[0].split('-')\n         img_path = '/content/'+fileNameSplit[0]+'/'+fileNameSplit[0] + '-' +              fileNameSplit[1]+'/'+lineSplit[0]+'.png'\n         img_word = lineSplit[-1]\n         img = cv2.imread(img_path)\n         img2 = extract_img(img)\n         x_new.append(img2)\n         x.append(img)\n         y.append(img_word)\n         count+=1\n     except:\n         continue\n```", "```py\nimport itertools\nlist2d = y\ncharList = list(set(list(itertools.chain(*list2d))))\n```", "```py\nnum_images = 50000\n\nimport numpy as np\ny2 = []\ninput_lengths = np.ones((num_images,1))*32\nlabel_lengths = np.zeros((num_images,1))\nfor i in range(num_images):\n     val = list(map(lambda x: charList.index(x), y[i]))\n     while len(val)<32:\n         val.append(79)\n     y2.append(val)\n     label_lengths[i] = len(y[i])\n     input_lengths[i] = 32\n```", "```py\nx = np.asarray(x_new[:num_images])\ny2 = np.asarray(y2)\nx= x.reshape(x.shape[0], x.shape[1], x.shape[2],1)\n```", "```py\noutputs = {'ctc': np.zeros([32])}\n```", "```py\ndef ctc_loss(args):\n     y_pred, labels, input_length, label_length = args\n     return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n```", "```py\ninput_data = Input(name='the_input', shape = (32, 128,1), dtype='float32')\n\ninner = Conv2D(32, (3,3), padding='same')(input_data)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2,2),name='max1')(inner)\ninner = Conv2D(64, (3,3), padding='same')(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2,2),name='max2')(inner)\ninner = Conv2D(128, (3,3), padding='same')(input_data)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2,2),name='max3')(inner)\ninner = Conv2D(128, (3,3), padding='same')(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2,2),name='max4')(inner)\ninner = Conv2D(256, (3,3), padding='same')(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(4,2),name='max5')(inner)\ninner = Reshape(target_shape = ((32,256)), name='reshape')(inner)\n```", "```py\ngru_1 = GRU(256, return_sequences = True, name = 'gru_1')(inner)\ngru_2 = GRU(256, return_sequences = True, go_backwards = True, name = 'gru_2')(inner)\nmix_1 = add([gru_1, gru_2])\ngru_3 = GRU(256, return_sequences = True, name = 'gru_3')(inner)\ngru_4 = GRU(256, return_sequences = True, go_backwards = True, name = 'gru_4')(inner)\n```", "```py\nmerged = concatenate([gru_3, gru_4])\n```", "```py\ndense = TimeDistributed(Dense(80))(merged)\ny_pred = TimeDistributed(Activation('softmax', name='softmax'))(dense)\n```", "```py\nfrom keras.optimizers import Adam\nOptimizer = Adam()\nlabels = Input(name = 'the_labels', shape=[32], dtype='float32')\ninput_length = Input(name='input_length', shape=[1],dtype='int64')\nlabel_length = Input(name='label_length',shape=[1],dtype='int64')\noutput = Lambda(ctc_loss, output_shape=(1,),name='ctc')([y_pred, labels, input_length, label_length])\n```", "```py\nmodel = Model(inputs = [input_data, labels, input_length, label_length], outputs= output)\nmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = Optimizer)\n```", "```py\nx2 = 1-np.array(x_new[:num_images])/255\nx2 = x2.reshape(x2.shape[0],x2.shape[1],x2.shape[2],1)\ny2 = np.array(y2[:num_images])\ninput_lengths = input_lengths[:num_images]\nlabel_lengths = label_lengths[:num_images]\n```", "```py\nimport random\n\nfor i in range(100):\n     samp=random.sample(range(x2.shape[0]-100),32)\n     x3=[x2[i] for i in samp]\n     x3 = np.array(x3)\n     y3 = [y2[i] for i in samp]\n     y3 = np.array(y3)\n     input_lengths2 = [input_lengths[i] for i in samp]\n     label_lengths2 = [label_lengths[i] for i in samp]\n     input_lengths2 = np.array(input_lengths2)\n     label_lengths2 = np.array(label_lengths2)\n     inputs = {\n     'the_input': x3,\n     'the_labels': y3,\n     'input_length': input_lengths2,\n     'label_length': label_lengths2,\n     }\n     outputs = {'ctc': np.zeros([32])}\n     model.fit(inputs, outputs,batch_size = 32, epochs=1, verbose =2)\n```", "```py\nmodel2 = Model(inputs = input_data, outputs = y_pred)\npred = model2.predict(x2[-5].reshape(1,32,128,1))\n\npred2 = np.argmax(pred[0,:],axis=1)\nout = \"\"\nfor i in pred2:\n  if(i==79):\n    continue\n  else:\n    out += charList[i]\nplt.imshow(x2[k].reshape(32,128))\nplt.title('Predicted word: '+out)\nplt.grid('off')\n```", "```py\nimport glob\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pickle\nfrom tqdm import tqdm\nimport pandas as pd\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector, merge, Activation, Flatten\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.layers.wrappers import Bidirectional\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.preprocessing import image\nimport nltk\n```", "```py\ncaption_file = '...'\ncaptions = open(caption_file, 'r').read().strip().split('\\n')\nd = {}\nfor i, row in enumerate(captions):\n     row = row.split('\\t')\n     row[0] = row[0][:len(row[0])-2]\n     if row[0] in d:\n         d[row[0]].append(row[1])\n     else:\n         d[row[0]] = [row[1]]\ntotal_images = list(d.keys())\n```", "```py\nimage_path = '...'\nfrom keras.applications.vgg16 import VGG16\nvgg16=VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n\nimport cv2\nx = []\ny = []\nx2 = []\ntot_images = ''\nfor i in range(len(d.keys())):\n     for j in range(len(d[total_images[i]])):\n         img_path = image_path+total_images[i]\n         img = cv2.imread(img_path)\n         try:\n             img2 = cv2.resize(img, (224, 224))/255\n             img3 = vgg16.predict(img2.reshape(1,224,224,3))\n             x.append(img3)\n             y.append(d[total_images[i]][j])\n             tot_images = tot_images + ' '+total_images[i]\n         except:\n             continue\n```", "```py\nx = np.array(x)\nx = x.reshape(x.shape[0],7,7,512)\n```", "```py\ndef preprocess(text):\n     text=text.lower()\n     text=re.sub('[^0-9a-zA-Z]+',' ',text)\n     words = text.split()\n     words2 = words\n     words4=' '.join(words2)\n     return(words4)\n```", "```py\ncaps = []\nfor key, val in d.items():\n     if(key in img_path2):\n         for i in val:\n             i = preprocess(i)\n             caps.append('<start> ' + i + ' <end>')\n```", "```py\ncaps2 = []\nx2 = []\nimg_path3 = []\nfor i in range(len(caps)):\n     if (('girl') in caps[i]):\n         caps2.append(caps[i])\n         x2.append(x[i])\n         img_path2.append(img_path[i])\n     elif 'dog' in caps[i]:\n         caps2.append(caps[i])\n         x2.append(x[i])\n         img_path2.append(img_path[i])\n     else:\n         continue\n```", "```py\nwords = [i.split() for i in caps2]\nunique = []\nfor i in words:\n     unique.extend(i)\nunique = list(set(unique))\nvocab_size = len(unique)\n```", "```py\nword2idx = {val:(index+1) for index, val in enumerate(unique)}\nidx2word = {(index+1):val for index, val in enumerate(unique)}\n```", "```py\nmax_len = 0\nfor c in caps:\n     c = c.split()\n     if len(c) > max_len:\n         max_len = len(c)\n```", "```py\nn = np.zeros(vocab_size+1)\ny = []\ny2 = []\nfor k in range(len(caps2)):\n     t= [word2idx[i] for i in caps2[k].split()]\n     y.append(len(t))\n     while(len(t)<max_len):\n         t.append(word2idx['<end>'])\n     y2.append(t)\n```", "```py\nfrom keras.layers import Input\nembedding_size = 300\ninp = Input(shape=(7,7,512))\ninp1 = Conv2D(512, (3,3), activation='relu')(inp)\ninp11 = MaxPooling2D(pool_size=(2, 2))(inp1)\ninp2 = Flatten()(inp11)\nimg_emb = Dense(embedding_size, activation='relu') (inp2)\nimg_emb2 = RepeatVector(max_len)(img_emb)\n```", "```py\ninp2 = Input(shape=(max_len,))\ncap_emb = Embedding((vocab_size+1), embedding_size, input_length=max_len) (inp2)\ncap_emb2 = LSTM(256, return_sequences=True)(cap_emb)\ncap_emb3 = TimeDistributed(Dense(300)) (cap_emb2)\n```", "```py\nfinal1 = concatenate([img_emb2, cap_emb3])\nfinal2 = Bidirectional(LSTM(256, return_sequences=False))(final1)\nfinal3 = Dense(vocab_size+1)(final2)\nfinal4 = Activation('softmax')(final3)\n\nfinal_model = Model([inp, inp2], final4)\n```", "```py\nfrom keras.optimizers import Adam\nadam = Adam(lr = 0.0001)\nfinal_model.compile(loss='categorical_crossentropy', optimizer = adam, metrics=['accuracy'])\n```", "```py\nfor i in range(500):\n     x3 = []\n     x3_sent = []\n     y3 = []\n     shortlist_y = random.sample(range(len(y)-100),32)\n     for j in range(len(shortlist_y)):\n         for k in range(y[shortlist_y[j]]-1):\n             n = np.zeros(vocab_size+1) \n             x3.append(x2[shortlist_y[j]])\n             pad_sent = pad_sequences([y2[shortlist_y[j]][:(k+1)]], maxlen=max_len, padding='post')\n             x3_sent.append(pad_sent)\n             n[y2[shortlist_y[j]][(k+1)]] = 1\n             y3.append(n)\n             x3 = np.array(x3)\n             x3_sent =np.array(x3_sent)\n             x3_sent = x3_sent.reshape(x3_sent.shape[0], x3_sent.shape[2])\n             y3 = np.array(y3) \n             final_model.fit([x3/12, x3_sent], y3, batch_size = 32, epochs = 3, verbose = 1)\n```", "```py\nl=-25\nim_path = image_path+ img_path3[l]\nimg1 = cv2.imread(im_path)\nplt.imshow(img1)\n```", "```py\np = np.zeros(max_len)\np[0] = word2idx['<start>']\nfor i in range(max_len-1):\n     pred= final_model.predict([x33[l].reshape(1,7,7,512)/12, p.reshape(1,max_len)])\n     pred2 = np.argmax(pred)\n     print(idx2word[pred2])\n     p[i+1] = pred2\n     if(idx2word[pred2]=='<end>'):\n         break\n```", "```py\nbeamsize = 3\ndef get_top3(img, string_with_conf):\n     tokens, confidence = string_with_conf\n     p = np.zeros((1, max_len))\n     p[0, :len(tokens)] = np.array(tokens)\n     pred = final_model.predict([img.reshape(1,7,7,512)/12, p])\n     best_pred = list(np.argsort(pred)[0][-beamsize:])\n     best_confs = list(pred[0,best_pred])\n     top_best = [(tokens + list([best_pred[i]]), confidence*best_confs[i]) for i in range(beamsize)]\n     return top_best\n```", "```py\nstart_token = word2idx['<start>']\nbest_strings = [([start_token], 1)]\nfor i in range(max_len):\n     new_best_strings = []\n     for string in best_strings:\n         strings = get_top3(x33[l], string)\n         new_best_strings.extend(strings) \n         best_strings = sorted(new_best_strings, key=lambda x: x[1], reverse=True)[:beamsize]\n```", "```py\nfor i in range(3):\n     string = best_strings[i][0]\n     print('============')\n     for j in string:\n         print(idx2word[j])\n         if(idx2word[j]=='<end>'):\n             break\n```"]