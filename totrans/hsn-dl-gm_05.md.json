["```py\npython3 Chapter_4_1.py\n```", "```py\nbatch_size = 64 # Batch size for training.\nepochs = 100 # Number of epochs to train for.\nlatent_dim = 256 # Latent dimensionality of the encoding space.\nnum_samples = 10000 # Number of samples to train on.\n```", "```py\nGo. Va !\nHi. Salut !\nRun! Cours !\nRun! Courez !\nWow! Ça alors !\nFire! Au feu !\nHelp! À l'aide !\nJump. Saute.\nStop! Ça suffit !\nStop! Stop !\nStop! Arrête-toi !\nWait! Attends !\nWait! Attendez !\nGo on. Poursuis.\nGo on. Continuez.\nGo on. Poursuivez.\nHello! Bonjour !\nHello! Salut !\n```", "```py\n# Vectorize the data.\ninput_texts = []\ntarget_texts = []\ninput_characters = set()\ntarget_characters = set()\nwith open(data_path, 'r', encoding='utf-8') as f:\n    lines = f.read().split('\\n')\nfor line in lines[: min(num_samples, len(lines) - 1)]:\n    input_text, target_text = line.split('\\t')\n    # We use \"tab\" as the \"start sequence\" character\n    # for the targets, and \"\\n\" as \"end sequence\" character.\n    target_text = '\\t' + target_text + '\\n'\n    input_texts.append(input_text)\n    target_texts.append(target_text)\n    for char in input_text:\n        if char not in input_characters:\n            input_characters.add(char)\n    for char in target_text:\n        if char not in target_characters:\n            target_characters.add(char)\n\ninput_characters = sorted(list(input_characters))\ntarget_characters = sorted(list(target_characters))\nnum_encoder_tokens = len(input_characters)\nnum_decoder_tokens = len(target_characters)\nmax_encoder_seq_length = max([len(txt) for txt in input_texts])\nmax_decoder_seq_length = max([len(txt) for txt in target_texts])\n\nprint('Number of samples:', len(input_texts))\nprint('Number of unique input tokens:', num_encoder_tokens)\nprint('Number of unique output tokens:', num_decoder_tokens)\nprint('Max sequence length for inputs:', max_encoder_seq_length)\nprint('Max sequence length for outputs:', max_decoder_seq_length)\n```", "```py\n# Define an input sequence and process it.\nencoder_inputs = Input(shape=(None, num_encoder_tokens))\nencoder = LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]\n\n# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None, num_decoder_tokens))\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don't use the\n# return states in the training model, but we will use them in inference.\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n                                     initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n# Run training\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\nmodel.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_split=0.2)\n# Save model\nmodel.save('s2s.h5')\n```", "```py\nencoder_model = Model(encoder_inputs, encoder_states)\n\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\ndecoder_outputs, state_h, state_c = decoder_lstm(\n    decoder_inputs, initial_state=decoder_states_inputs)\ndecoder_states = [state_h, state_c]\ndecoder_outputs = decoder_dense(decoder_outputs)\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs] + decoder_states)\n\n# Reverse-lookup token index to decode sequences back to\n# something readable.\nreverse_input_char_index = dict(\n    (i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict(\n    (i, char) for char, i in target_token_index.items())\n```", "```py\n#Anaconda virtual environment\nconda create --name dlgames\n#when prompted choose yes\nactivate dlgames\n```", "```py\n#Python virtual environment\npip install virtualenv\nvirutalenv dlgames\n\n#on Mac\nsource dlgames/bin/activate\n\n#on Windows\ndlgames\\Scripts\\activate\n```", "```py\npip install deeppavlov\n```", "```py\nfrom deeppavlov.skills.pattern_matching_skill import PatternMatchingSkill\nfrom deeppavlov.agents.default_agent.default_agent import DefaultAgent \nfrom deeppavlov.agents.processors.highest_confidence_selector import HighestConfidenceSelector\n```", "```py\nhello = PatternMatchingSkill(responses=['Hello world!'], patterns=[\"hi\", \"hello\", \"good day\"])\nbye = PatternMatchingSkill(['Goodbye world!', 'See you around'], patterns=[\"bye\", \"ciao\", \"see you\"])\nfallback = PatternMatchingSkill([\"I don't understand, sorry\", 'I can say \"Hello world!\"'])\n```", "```py\nHelloBot = DefaultAgent([hello, bye, fallback], skills_selector=HighestConfidenceSelector())\n\nprint(HelloBot(['Hello!', 'Boo...', 'Bye.']))\n```", "```py\nrabbitmq-plugins enable rabbitmq_management\n```", "```py\nimport pika\n\nconnection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost'))\nchannel = connection.channel()\nchannel.queue_declare(queue='hello')\nchannel.basic_publish(exchange='',\n                      routing_key='hello',\n                      body='Hello World!')\nprint(\" [x] Sent 'Hello World!'\")\nconnection.close()\n```", "```py\npip install pika\n```", "```py\nimport pika\n\nconnection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost'))\nchannel = connection.channel()\n\nchannel.queue_declare(queue='hello')\n\ndef callback(ch, method, properties, body):\n    print(\" [x] Received %r\" % body)\n\nchannel.basic_consume(callback,\n                      queue='hello',\n                      no_ack=True)\n\nprint(' [*] Waiting for messages. To exit press CTRL+C')\nchannel.start_consuming()\n```", "```py\nimport pika\nfrom deeppavlov.skills.pattern_matching_skill import PatternMatchingSkill\nfrom deeppavlov.agents.default_agent.default_agent import DefaultAgent \nfrom deeppavlov.agents.processors.highest_confidence_selector import HighestConfidenceSelector\n\nhello = PatternMatchingSkill(responses=['Hello world!'], patterns=[\"hi\", \"hello\", \"good day\"])\nbye = PatternMatchingSkill(['Goodbye world!', 'See you around'], patterns=[\"bye\", \"chao\", \"see you\"])\nfallback = PatternMatchingSkill([\"I don't understand, sorry\", 'I can say \"Hello world!\"'])\n\nHelloBot = DefaultAgent([hello, bye, fallback], skills_selector=HighestConfidenceSelector())\n\nconnection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost'))\nchannelin = connection.channel()\nchannelin.exchange_declare(exchange='chat', exchange_type='direct', durable=True)\nchannelin.queue_bind(exchange='chat', queue='chatin')\n\nchannelout = connection.channel()\nchannelout.exchange_declare(exchange='chat', durable=True)\n\ndef callback(ch, method, properties, body):\n    global HelloBot, channelout\n    response = HelloBot([str(body)])[0].encode()\n    print(body,response)\n    channelout.basic_publish(exchange='chat',\n                      routing_key='chatout',\n                      body=response)\n    print(\" [x] Sent response %r\" % response)\n\nchannelin.basic_consume(callback, \n                      queue='chatin',\n                      no_ack=True)\n\nprint(' [*] Waiting for messages. To exit press CTRL+C')\nchannelin.start_consuming()\n```", "```py\nimport pika\n\nconnection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost'))\nchannelin = connection.channel()\n\nchannelin.exchange_declare(exchange='chat')\n\nchat = 'boo'\n\nchannelin.basic_publish(exchange='chat',\n                      routing_key='chatin',\n                      body=chat)\nprint(\" [x] Sent '{0}'\".format(chat))\nconnection.close()\n```", "```py\ngit clone https://github.com/CymaticLabs/Unity3D.Amqp.git\n```"]