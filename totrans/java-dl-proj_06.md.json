["```py\nDeep Convolutional Neural Networks (DCNN) have been used in computer visionâ€”for example, image classification, image feature extraction, object detection, and semantic segmentation. Despite such successes of state-of-the-art approaches for object detection from still images, detecting objects in a video is not an easy job.\n```", "```py\n<dependency>\n  <groupId>org.deeplearning4j</groupId>\n  <artifactId>deeplearning4j-zoo</artifactId>\n  <version>${dl4j.version}</version>\n</dependency>\n```", "```py\n<dependency>\n  <groupId>org.nd4j</groupId>\n  <artifactId>nd4j-cuda-9.0-platform</artifactId>\n  <version>${nd4j.version}</version>\n</dependency>\n<dependency>\n  <groupId>org.deeplearning4j</groupId>\n  <artifactId>deeplearning4j-cuda-9.0</artifactId>\n  <version>${dl4j.version}</version>\n</dependency>\n```", "```py\nprivate ComputationGraph model; \nprivate TinyYoloModel() { \n        try { \n            model = (ComputationGraph) new TinyYOLO().initPretrained(); \n            createObjectLabels(); \n        } catch (IOException e) { \n            throw new RuntimeException(e); \n        } \n    }  \n```", "```py\nprivate HashMap<Integer, String> labels;  \nvoid createObjectLabels() { \n        if (labels == null) { \n            String label = \"aeroplanen\" + \"bicyclen\" + \"birdn\" + \"boatn\" + \"bottlen\" + \"busn\" + \"carn\" + \n                    \"catn\" + \"chairn\" + \"cown\" + \"diningtablen\" + \"dogn\" + \"horsen\" + \"motorbiken\" + \n                    \"personn\" + \"pottedplantn\" + \"sheepn\" + \"sofan\" + \"trainn\" + \"tvmonitor\"; \n            String[] split = label.split(\"\\n\"); \n            int i = 0; \n            labels = new HashMap<>(); \n            for(String label1 : split) { \n                labels.put(i++, label1); \n            } \n        } \n    } \n```", "```py\n static final TinyYoloModel yolo = new TinyYoloModel(); \n    public static TinyYoloModel getPretrainedModel() { \n        return yolo; \n    } \n```", "```py\nTinyYoloModel model = TinyYoloModel.getPretrainedModel(); \nSystem.out.println(TinyYoloModel.getSummary()); \n```", "```py\n<dependency>\n  <groupId>org.bytedeco</groupId>\n  <artifactId>javacv-platform</artifactId>\n  <version>1.4.1</version>\n</dependency>\n```", "```py\nString videoPath = \"data/SelfDrivingCar_Day.mp4\"; \nFFmpegFrameGrabber frameGrabber = new FFmpegFrameGrabber(videoPath); \nframeGrabber.start(); \n\nFrame frame; \ndouble frameRate = frameGrabber.getFrameRate(); \nSystem.out.println(\"The inputted video clip has \" + frameGrabber.getLengthInFrames() + \" frames\"); \nSystem.out.println(\"Frame rate \" + framerate + \"fps\"); \n>>>\n The inputted video clip has 1802 frames.\n The inputted video clip has frame rate of 29.97002997002997.\n```", "```py\nJava2DFrameConverter converter = new Java2DFrameConverter(); \n// grab the first frame \nframeGrabber.setFrameNumber(1); \nframe = frameGrabber.grab(); \nBufferedImage bufferedImage = converter.convert(frame); \nSystem.out.println(\"First Frame\" + \", Width: \" + bufferedImage.getWidth() + \", Height: \" + bufferedImage.getHeight()); \n\n// grab the second frame \nframeGrabber.setFrameNumber(2); \nframe = frameGrabber.grab(); \nbufferedImage = converter.convert(frame); \nSystem.out.println(\"Second Frame\" + \", Width: \" + bufferedImage.getWidth() + \", Height: \" + bufferedImage.getHeight()); \n>>>\n First Frame: Width-640, Height-360\n Second Frame: Width-640, Height-360\n```", "```py\nprivate volatile Mat[] v = new Mat[1]; \nprivate String windowName = \"Object Detection from Video\"; \ntry { \n    for(int i = 1; i < frameGrabber.getLengthInFrames();     \n    i+ = (int)frameRate) { \n                frameGrabber.setFrameNumber(i); \n                frame = frameGrabber.grab(); \n                v[0] = new OpenCVFrameConverter.ToMat().convert(frame); \n                model.markObjectWithBoundingBox(v[0], frame.imageWidth, \n                                               frame.imageHeight, true, windowName); \n                imshow(windowName, v[0]); \n\n                char key = (char) waitKey(20); \n                // Exit on escape: \n                if (key == 27) { \n                    destroyAllWindows(); \n                    break; \n                } \n            } \n        } catch (IOException e) { \n            e.printStackTrace(); \n        } finally { \n            frameGrabber.stop(); \n        } \n        frameGrabber.close(); \n```", "```py\npublic void markObjectWithBoundingBox(Mat file, int imageWidth, int imageHeight, boolean newBoundingBOx,\n                                      String winName) throws Exception { \n        // parameters matching the pretrained TinyYOLO model\n        int W = 416; // width of the video frame  \n        int H = 416; // Height of the video frame \n        int gW = 13; // Grid width \n        int gH = 13; // Grid Height \n        double dT = 0.5; // Detection threshold \n\n        Yolo2OutputLayer outputLayer = (Yolo2OutputLayer) model.getOutputLayer(0); \n        if (newBoundingBOx) { \n            INDArray indArray = prepareImage(file, W, H); \n            INDArray results = model.outputSingle(indArray); \n            predictedObjects = outputLayer.getPredictedObjects(results, dT); \n            System.out.println(\"results = \" + predictedObjects); \n            markWithBoundingBox(file, gW, gH, imageWidth, imageHeight); \n        } else { \n            markWithBoundingBox(file, gW, gH, imageWidth, imageHeight); \n        } \n        imshow(winName, file); \n    }\n```", "```py\nINDArray prepareImage(Mat file, int width, int height) throws IOException { \n        NativeImageLoader loader = new NativeImageLoader(height, width, 3); \n        ImagePreProcessingScaler imagePreProcessingScaler = new ImagePreProcessingScaler(0, 1); \n        INDArray indArray = loader.asMatrix(file); \n        imagePreProcessingScaler.transform(indArray); \n        return indArray; \n    } \n```", "```py\nvoid markObjectWithBoundingBox(Mat file, int gridWidth, int gridHeight, int w, int h, DetectedObject obj) {  \n        double[] xy1 = obj.getTopLeftXY(); \n        double[] xy2 = obj.getBottomRightXY(); \n        int predictedClass = obj.getPredictedClass(); \n        int x1 = (int) Math.round(w * xy1[0] / gridWidth); \n        int y1 = (int) Math.round(h * xy1[1] / gridHeight); \n        int x2 = (int) Math.round(w * xy2[0] / gridWidth); \n        int y2 = (int) Math.round(h * xy2[1] / gridHeight); \n        rectangle(file, new Point(x1, y1), new Point(x2, y2), Scalar.RED); \n        putText(file, labels.get(predictedClass), new Point(x1 + 2, y2 - 2), \n                                 FONT_HERSHEY_DUPLEX, 1, Scalar.GREEN); \n    } \n```", "```py\nstatic void removeObjectsIntersectingWithMax(ArrayList<DetectedObject> detectedObjects, \n                                             DetectedObject maxObjectDetect) { \n        double[] bottomRightXY1 = maxObjectDetect.getBottomRightXY(); \n        double[] topLeftXY1 = maxObjectDetect.getTopLeftXY(); \n        List<DetectedObject> removeIntersectingObjects = new ArrayList<>(); \n        for(DetectedObject detectedObject : detectedObjects) { \n            double[] topLeftXY = detectedObject.getTopLeftXY(); \n            double[] bottomRightXY = detectedObject.getBottomRightXY(); \n            double iox1 = Math.max(topLeftXY[0], topLeftXY1[0]); \n            double ioy1 = Math.max(topLeftXY[1], topLeftXY1[1]); \n\n            double iox2 = Math.min(bottomRightXY[0], bottomRightXY1[0]); \n            double ioy2 = Math.min(bottomRightXY[1], bottomRightXY1[1]); \n\n            double inter_area = (ioy2 - ioy1) * (iox2 - iox1); \n\n            double box1_area = (bottomRightXY1[1] - topLeftXY1[1]) * (bottomRightXY1[0] - topLeftXY1[0]); \n            double box2_area = (bottomRightXY[1] - topLeftXY[1]) * (bottomRightXY[0] - topLeftXY[0]); \n\n            double union_area = box1_area + box2_area - inter_area; \n            double iou = inter_area / union_area;  \n\n            if(iou > 0.5) { \n                removeIntersectingObjects.add(detectedObject); \n            } \n        } \n        detectedObjects.removeAll(removeIntersectingObjects); \n    } \n```", "```py\n[4.6233e-11]], predictedClass=6),\nDetectedObject(exampleNumber=0,\ncenterX=3.5445247292518616, centerY=7.621537864208221,\nwidth=2.2568163871765137, height=1.9423424005508423,\nconfidence=0.7954192161560059,\nclassPredictions=[[ 1.5034e-7], [ 3.3064e-9]...\n```", "```py\n// ObjectDetectorFromVideo.java\npublic class ObjectDetectorFromVideo{ \n    private volatile Mat[] v = new Mat[1]; \n    private String windowName; \n\n    public static void main(String[] args) throws java.lang.Exception { \n        String videoPath = \"data/SelfDrivingCar_Day.mp4\"; \n        TinyYoloModel model = TinyYoloModel.getPretrainedModel(); \n\n        System.out.println(TinyYoloModel.getSummary()); \n        new ObjectDetectionFromVideo().startRealTimeVideoDetection(videoPath, model); \n    } \n\n    public void startRealTimeVideoDetection(String videoFileName, TinyYoloModel model) \n           throws java.lang.Exception { \n        windowName = \"Object Detection from Video\"; \n        FFmpegFrameGrabber frameGrabber = new FFmpegFrameGrabber(videoFileName); \n        frameGrabber.start(); \n\n        Frame frame; \n        double frameRate = frameGrabber.getFrameRate(); \n        System.out.println(\"The inputted video clip has \" + frameGrabber.getLengthInFrames() + \" frames\"); \n        System.out.println(\"The inputted video clip has frame rate of \" + frameRate); \n\n        try { \n            for(int i = 1; i < frameGrabber.getLengthInFrames(); i+ = (int)frameRate) { \n                frameGrabber.setFrameNumber(i); \n                frame = frameGrabber.grab(); \n                v[0] = new OpenCVFrameConverter.ToMat().convert(frame); \n                model.markObjectWithBoundingBox(v[0], frame.imageWidth, frame.imageHeight, \n                                                true, windowName); \n                imshow(windowName, v[0]); \n\n                char key = (char) waitKey(20); \n                // Exit on escape: \n                if(key == 27) { \n                    destroyAllWindows(); \n                    break; \n                } \n            } \n        } catch (IOException e) { \n            e.printStackTrace(); \n        } finally { \n            frameGrabber.stop(); \n        } \n        frameGrabber.close(); \n    } \n} \n```", "```py\nString videoPath = \"data/SelfDrivingCar_Night.mp4\";\n```"]