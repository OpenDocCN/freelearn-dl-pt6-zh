["```py\n$sudo apt-get install pyqt5-dev-tools\n$sudo pip3 install -r requirements/requirements-linux-python3.txt\n$make qt5py3\n$python3 labelImg.py\n```", "```py\n$brew install qt  # will install qt-5.x.x\n$brew install libxml2\n$make qt5py3\n$python3 labelImg.py\n```", "```py\n$pip install selectivesearch\n```", "```py\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport selectivesearch\nimport cv2\n```", "```py\nimg = cv2.imread('/content/Hemanvi.jpeg')\n```", "```py\nimg_lbl, regions = selectivesearch.selective_search(img, scale=100, min_size=2000)\n```", "```py\nprint(len(regions))\ncandidates = set()\nfor r in regions:\n     if r['rect'] in candidates:\n         continue\n # excluding regions smaller than 2000 pixels\n     if r['size'] < 2000:\n         continue\n     x, y, w, h = r['rect']\n candidates.add(r['rect'])\n```", "```py\nimport matplotlib.patches as mpatches\nfig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 6))\nax.imshow(img)\nfor x, y, w, h in candidates:\n    rect = mpatches.Rectangle(\n        (x, y), w, h, fill=False, edgecolor='red', linewidth=1)\n    ax.add_patch(rect)\nplt.axis('off')\nplt.show()\n```", "```py\nfrom copy import deepcopy\nimport numpy as np\ndef extract_iou(candidate, current_y,img_shape):\n     boxA = deepcopy(candidate)\n     boxB = deepcopy(current_y)\n\n     img1 = np.zeros(img_shape)\n     img1[boxA[1]:boxA[3],boxA[0]:boxA[2]]=1\n\n     img2 = np.zeros(img_shape)\n     img2[int(boxB[1]):int(boxB[3]),int(boxB[0]):int(boxB[2])]=1\n\n     iou = np.sum(img1*img2)/(np.sum(img1)+np.sum(img2)- np.sum(img1*img2))\n     return iou\n```", "```py\nimg = cv2.imread('/content/Hemanvi.jpeg')\n```", "```py\nplt.imshow(img)\nplt.grid('off')\n```", "```py\nimg_lbl, regions = selectivesearch.selective_search(img, scale=100, min_size=2000)\n```", "```py\nregions =list(candidates)\nactual_bb = [50,50,290,500]\niou = []\nfor i in range(len(regions)):\n     candidate = list(regions[i])\n     candidate[2] += candidate[0]\n     iou.append(extract_iou(candidate, actual_bb, img.shape))\n```", "```py\nnp.argmax(iou)\n```", "```py\nmax_region = list(regions[np.argmax(iou)])\nmax_region[2] -= max_region[0]\nmax_region[3] -= max_region[1]\n\nactual_bb[2] -= actual_bb[0]\nactual_bb[3] -= actual_bb[1]\n```", "```py\nmaxcandidate_actual = [max_region,actual_bb]\n```", "```py\nimport matplotlib.patches as mpatches\nfig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 6))\nax.imshow(img)\nfor i,(x, y, w, h) in enumerate(maxcandidate_actual):\n if(i==0):\n rect = mpatches.Rectangle(\n (x, y), w, h, fill=False, edgecolor='blue', linewidth=2)\n ax.add_patch(rect)\n else:\n rect = mpatches.Rectangle(\n (x, y), w, h, fill=False, edgecolor='red', linewidth=5)\n ax.add_patch(rect)\nplt.axis('off')\nplt.show()\n```", "```py\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf, selectivesearch\nimport json, scipy, os, numpy as np,argparse,time, sys, gc, cv2, xmltodict\nfrom copy import deepcopy\n```", "```py\ndef extract_iou2(candidate, current_y,img_shape):\n     boxA = deepcopy(candidate)\n     boxB = deepcopy(current_y)\n     boxA[2] += boxA[0]\n     boxA[3] += boxA[1]\n     iou_img1 = np.zeros(img_shape)\n     iou_img1[boxA[1]:boxA[3],boxA[0]:boxA[2]]=1\n     iou_img2 = np.zeros(img_shape)\n     iou_img2[int(boxB[1]):int(boxB[3]),int(boxB[0]):int(boxB[2])]=1\n     iou = np.sum(iou_img1*iou_img2)/(np.sum(iou_img1)+np.sum(iou_img2)-np.sum(iou_img1*iou_img2))\n     return iou\n```", "```py\ndef extract_candidates(img):\n     img_lbl, regions = selectivesearch.selective_search(img, scale=100, min_size=100)\n     img_area = img.shape[0]*img.shape[1]\n     candidates = []\n     for r in regions:\n         if r['rect'] in candidates:\n             continue\n         if r['size'] < (0.05*img_area):\n             continue\n         x, y, w, h = r['rect']\n         candidates.append(list(r['rect']))\n     return candidates\n```", "```py\nfrom keras.applications import vgg16\nfrom keras.utils.vis_utils import plot_model\nvgg16_model = vgg16.VGG16(include_top=False, weights='imagenet')\n```", "```py\ntraining_data_size = N = 1000\n\nfinal_cls = []\nfinal_delta = []\niou_list = []\nimgs = []\n```", "```py\nfor ix, xml in enumerate(XMLs[:N]):\n    print('Extracted data from {} xmls...'.format(ix), end='\\r')\n    xml_file = annotations + xml\n    fname = xml.split('.')[0]\n    with open(xml_file, \"rb\") as f: # notice the \"rb\" mode\n        xml = xmltodict.parse(f, xml_attribs=True)\n        l = []        \n        if isinstance(xml[\"annotation\"][\"object\"], list):\n            #'let us ignore cases with multiple objects...'\n            continue\n```", "```py\n        bndbox = xml['annotation']['object']['bndbox']\n        for key in bndbox:\n              bndbox[key] = float(bndbox[key])\n        x1, x2, y1, y2 = [bndbox[key] for key in ['xmin', 'xmax', 'ymin', 'ymax']]\n\n        img_size = xml['annotation']['size']\n        for key in img_size:\n              img_size[key] = float(img_size[key])\n        w, h = img_size['width'], img_size['height']\n\n        #'converting pixel values from bndbox to fractions...'\n        x1 /= w; x2 /= w; y1 /= h; y2 /= h\n        label = xml['annotation']['object']['name']\n\n        y = [x1, y1, x2-x1, y2-y1, label]  # top-left x & y, width and height\n```", "```py\n         filename = jpegs+fname+'.jpg' # Path to jpg files here\n         img = cv2.resize(cv2.imread(filename), (224,224)) # since VGG's input shape is 224x224\n         candidates = extract_candidates(img)\n```", "```py\n         for jx, candidate in enumerate(candidates):\n                current_y2 = [int(i*224) for i in [x1,y1,x2,y2]] # [int(x1*224), int(y1*224), int(x2*224), int(y2*224)]\n                iou = extract_iou2(candidate, current_y2, (224, 224))\n                candidate_region_coordinates = c_x1, c_y1, c_w, c_h = np.array(candidate)/224\n\n                dx = c_x1 - x1 \n                dy = c_y1 - y1 \n                dw = c_w - (x2-x1)\n                dh = c_h - (y2-y1)\n\n                final_delta.append([dx,dy,dw,dh]) \n```", "```py\n               if(iou>0.3): \n                    final_cls.append(label)\n               else:\n                    final_cls.append('background')\n\n            #\"We'll predict our candidate crop using VGG\"\n               l = int(c_x1 * 224)\n               r = int((c_x1 + c_w) * 224)\n               t = int(c_y1 * 224)\n               b = int((c_y1 + c_h) * 224)\n\n               img2 = img[t:b,l:r,:3]\n               img3 = cv2.resize(img2,(224,224))/255\n               img4 = vgg16_model.predict(img3.reshape(1,224,224,3))\n               imgs.append(img4)\n```", "```py\ntargets = pd.DataFrame(final_cls, columns=['label'])\nlabels = pd.get_dummies(targets['label']).columns\ny_train = pd.get_dummies(targets['label']).values.astype(float)\n```", "```py\nx_train = np.array(imgs)\nx_train = x_train.reshape(x_train.shape[0],x_train.shape[2],x_train.shape[3],x_train.shape[4])\n```", "```py\nmodel = Sequential()\nmodel.add(Flatten(input_shape=((7,7,512))))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(all_classes.shape[1],activation='softmax'))\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n```", "```py\nmodel.fit(xtrain3/x_train.max(),y_train,validation_split = 0.1, epochs=5, batch_size=32, verbose=1)\n```", "```py\nimport matplotlib.patches as mpatches\nix = np.random.randint(N, len(XMLs))\nfilename = jpegs + XMLs[ix].replace('xml', 'jpg')\n```", "```py\ndef test_predictions(filename):\n     img = cv2.resize(cv2.imread(filename), (224,224))\n     candidates = extract_candidates(img)\n```", "```py\n    _, ax = plt.subplots(1, 2)\n    ax[0].imshow(img)\n    ax[0].grid('off')\n    ax[0].set_title(filename.split('/')[-1])\n    pred = []\n    pred_class = []\n```", "```py\n    for ix, candidate in enumerate(candidates):\n        l, t, w, h = np.array(candidate).astype(int)\n        img2 = img[t:t+h,l:l+w,:3]\n        img3 = cv2.resize(img2,(224,224))/255\n        img4 = vgg16_model.predict(img3.reshape(1,224,224,3))\n        final_pred = model.predict(img4/x_train.max())\n        pred.append(np.max(final_pred))\n        pred_class.append(np.argmax(final_pred))\n```", "```py\n    pred = np.array(pred)\n    pred_class = np.array(pred_class)\n    pred2 = pred[pred_class!=1]\n    pred_class2 = pred_class[pred_class!=1]\n    candidates2 = np.array(candidates)[pred_class!=1]\n    x, y, w, h = candidates2[np.argmax(pred2)]\n```", "```py\n   ax[1].set_title(labels[pred_class2[np.argmax(pred2)]])\n   ax[1].imshow(img)\n   ax[1].grid('off')\n   rect = mpatches.Rectangle((x, y), w, h, fill=False, edgecolor='red', linewidth=1)\n   ax[1].add_patch(rect)\n```", "```py\nfilename = '...' #Path to new image\ntest_predictions(filename)\n```", "```py\nmodel2 = Sequential()\nmodel2.add(Flatten(input_shape=((7,7,512))))\nmodel2.add(Dense(512, activation='relu'))\nmodel2.add(Dense(4,activation='linear'))\n\nmodel2.compile(loss='mean_absolute_error',optimizer='adam')\n```", "```py\nfor i in range(1000):\n     samp=random.sample(range(len(x_train)),500)\n     x_train2=[x_train[i] for i in samp if pred_class[i]!=1]\n     x_train2 = np.array(x_train2)\n     final_delta2 = [final_delta[i] for i in samp if pred_class[i]!=1]\n     model2.fit(x_train2/x_train.max(), np.array(final_delta2), validation_split = 0.1, epochs=1, batch_size=32, verbose=0)\n```", "```py\n'TESTING'\nimport matplotlib.patches as mpatches\ndef test_predictions2(filename):\n     img = cv2.resize(cv2.imread(filename), (224,224))\n     candidates = extract_candidates(img)\n     _, ax = plt.subplots(1, 2)\n     ax[0].imshow(img)\n     ax[0].grid('off')\n     ax[0].set_title(filename.split('/')[-1])\n     pred = []\n     pred_class = []\n     del_new = []\n     for ix, candidate in enumerate(candidates):\n        l, t, w, h = np.array(candidate).astype(int)\n        img2 = img[t:t+h,l:l+w,:3]\n        img3 = cv2.resize(img2,(224,224))/255\n        img4 = vgg16_model.predict(img3.reshape(1,224,224,3)) \n        final_pred = model.predict(img4/x_train.max())\n        delta_new = model2.predict(img4/x_train.max())[0] \n        pred.append(np.max(final_pred))\n        pred_class.append(np.argmax(final_pred))\n        del_new.append(delta_new) \n     pred = np.array(pred)\n     pred_class = np.array(pred_class)\n     non_bgs = (pred_class!=1)\n     pred = pred[non_bgs]\n     pred_class = pred_class[non_bgs] \n     del_new = np.array(del_new)\n     del_new = del_new[non_bgs]\n     del_pred = del_new*224\n     candidates = C = np.array(candidates)[non_bgs]\n     C = np.clip(C, 0, 224)\n     C[:,2] += C[:,0]\n     C[:,3] += C[:,1]\n     bbs_pred = candidates - del_pred\n     bbs_pred = np.clip(bbs_pred, 0, 224) \n     bbs_pred[:,2] -= bbs_pred[:,0]\n     bbs_pred[:,3] -= bbs_pred[:,1]\n     final_bbs_pred = bbs_pred[np.argmax(pred)]\n     x, y, w, h = final_bbs_pred\n     ax[1].imshow(img)\n     ax[1].grid('off')\n     rect = mpatches.Rectangle((x, y), w, h, fill=False, edgecolor='red', linewidth=1)\n     ax[1].add_patch(rect)\n     ax[1].set_title(labels[pred_class[np.argmax(pred)]])\n```", "```py\nsingle_object_images = []\nfor ix, xml in enumerate(XMLs[N:]):\n     xml_file = annotations + xml\n     fname = xml.split('.')[0]\n     with open(xml_file, \"rb\") as f: # notice the \"rb\" mode\n         xml = xmltodict.parse(f, xml_attribs=True)\n         l = []\n         if isinstance(xml[\"annotation\"][\"object\"], list):\n             continue\n         single_object_images.append(xml[\"annotation\"]['filename'])\n         if(ix>100):\n             break\n```", "```py\ntest_predictions2(filename)\n```", "```py\nfilename = jpegs + single_object_images[ix]\nimg = cv2.imread(filename)\nimg = cv2.resize(img,(224,224))\nimg_area = img.shape[0]*img.shape[1]\ncandidates = extract_candidates(img)\nplt.imshow(img)\nplt.grid('off')\n```", "```py\npred = []\npred_class = []\ndel_new = []\n\nfor ix, candidate in enumerate(candidates):\n    l, t, w, h = np.array(candidate).astype(int)\n    img2 = img[t:t+h,l:l+w,:3]\n    img3 = cv2.resize(img2,(224,224))/255\n    img4 = vgg16_model.predict(img3.reshape(1,224,224,3)) \n    final_pred = model.predict(img4/x_train.max())\n    delta_new = model2.predict(img4/x_train.max())[0]\n    pred.append(np.max(final_pred))\n    pred_class.append(np.argmax(final_pred))\n    del_new.append(delta_new)\npred = np.array(pred)\npred_class = np.array(pred_class)\n```", "```py\nnon_bgs = ((pred_class!=1))\npred = pred[non_bgs]\npred_class = pred_class[non_bgs]\n\ndel_new = np.array(del_new)\ndel_new = del_new[non_bgs]\ndel_pred = del_new*224\n```", "```py\ncandidates = C = np.array(candidates)[non_bgs]\nC = np.clip(C, 0, 224)\nC[:,2] += C[:,0]\nC[:,3] += C[:,1]\n\nbbs_pred = candidates - del_pred\nbbs_pred = np.clip(bbs_pred, 0, 224)\n```", "```py\nbbs_pred[:,2] -= bbs_pred[:,0]\nbbs_pred[:,3] -= bbs_pred[:,1]\nbbs_pred = np.clip(bbs_pred, 0, 224)\n\nbbs_pred2 = bbs_pred[(bbs_pred[:,2]>0) & (bbs_pred[:,3]>0)]\npred = pred[(bbs_pred[:,2]>0) & (bbs_pred[:,3]>0)]\npred_class = pred_class[(bbs_pred[:,2]>0) & (bbs_pred[:,3]>0)]\n```", "```py\nimport matplotlib.patches as mpatches\nfig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 6))\nax.imshow(img)\nfor ix, (x, y, w, h) in enumerate(bbs_pred2):\n    rect = mpatches.Rectangle(\n        (x, y), w, h, fill=False, edgecolor='red', linewidth=1)\n    ax.add_patch(rect)\n\nplt.axis('off')\nplt.show()\n```", "```py\ndef nms_boxes(threshold, boxes, scores):\n     x = boxes[:, 0]\n     y = boxes[:, 1]\n     w = boxes[:, 2]\n     h = boxes[:, 3]\n     areas = w * h\n     order = scores.argsort()[::-1]\n```", "```py\n     keep = []\n     while order.size > 0:\n         i = order[0]\n         keep.append(i)\n         xx1 = np.maximum(x[i], x[order[1:]])\n         yy1 = np.maximum(y[i], y[order[1:]])\n         xx2 = np.minimum(x[i] + w[i], x[order[1:]] + w[order[1:]])\n         yy2 = np.minimum(y[i] + h[i], y[order[1:]] + h[order[1:]])\n         w1 = np.maximum(0.0, xx2 - xx1 + 1)\n         h1 = np.maximum(0.0, yy2 - yy1 + 1)\n         inter = w1 * h1\n         iou = inter / (areas[i] + areas[order[1:]] - inter)\n```", "```py\n        inds = np.where(ovr <= threshold)[0]\n        order = order[inds + 1]\n```", "```py\n    keep = np.array(keep)\n    return keep\n```", "```py\nkeep_box_ixs = nms_boxes(0.3, bbs_pred2, pred)\n```", "```py\nimport matplotlib.patches as mpatches\nfig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 6))\nax.imshow(img)\nfor ix, (x, y, w, h) in enumerate(bbs_pred2):\n     if ix not in keep_box_ixs:\n         continue\n     rect = mpatches.Rectangle((x, y), w, h, fill=False, edgecolor='red', linewidth=1)\n     ax.add_patch(rect)\n     centerx = x + w/2\n     centery = y + h - 10\n     plt.text(centerx, centery,labels[pred_class[ix]]+\" \"+str(round(pred[ix],2)),fontsize = 20,color='red')\nplt.axis('off')\nplt.show()\n```", "```py\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf, selectivesearch\nimport json, scipy, os, numpy as np,argparse,time, sys, gc, cv2, xmltodict\nfrom copy import deepcopy\n```", "```py\ndef extract_iou2(candidate, current_y,img_shape):\n     boxA = deepcopy(candidate)\n     boxB = deepcopy(current_y)\n     boxA[2] += boxA[0]\n     boxA[3] += boxA[1]\n     iou_img1 = np.zeros(img_shape)\n     iou_img1[boxA[1]:boxA[3],boxA[0]:boxA[2]]=1\n     iou_img2 = np.zeros(img_shape)\n     iou_img2[int(boxB[1]):int(boxB[3]),int(boxB[0]):int(boxB[2])]=1\n     iou = np.sum(iou_img1*iou_img2)/(np.sum(iou_img1)+np.sum(iou_img2)-np.sum(iou_img1*iou_img2))\n     return iou\n```", "```py\ny_train = []\n\nfor i in mylist[:10000]:\n     xml_file = xml_filepath +i\n     arg1=i.split('.')[0]\n     with open(xml_file, \"rb\") as f: # notice the \"rb\" mode\n         d = xmltodict.parse(f, xml_attribs=True)\n         l=[]\n         if type(d[\"annotation\"][\"object\"]) == type(l):\n             discard=1\n         else:\n             x1=((float(d['annotation']['object']\n             ['bndbox']['xmin'])))/(float(d['annotation']['size']['width']))\n             x2=((float(d['annotation']['object']\n             ['bndbox']['xmax'])))/(float(d['annotation']['size']['width']))\n             y1=((float(d['annotation']['object']\n             ['bndbox']['ymin'])))/(float(d['annotation']['size']['height']))\n             y2=((float(d['annotation']['object']\n             ['bndbox']['ymax'])))/(float(d['annotation']['size']['height']))\n             cls=d['annotation']['object']['name']\n             if(cls == 'person'):\n                 y_train.append([x2-x1, y2-y1])\n```", "```py\ny_train = np.array(y_train)\nfrom sklearn.cluster import KMeans\nkm = KMeans(n_clusters=5)\nkm.fit(y_train)\nkm.cluster_centers_\n```", "```py\nanchors = [[[0.84638352, 0.90412013],        \n            [0.28036872, 0.58073186],        \n            [0.45700897, 0.87035502],        \n            [0.15685545, 0.29256264],        \n            [0.59814951, 0.64789503]]]\n\n```", "```py\nk=-1\npre_xtrain = []\ny_train = []\ncls = []\nxtrain=[]\nfinal_cls = []\ndx = []\ndy = []\ndw= []\ndh = []\nfinal_delta = []\nav = 0\nx_train = []\nimg_paths = []\nlabel_coords = []\ny_delta = []\nanc = []\n```", "```py\nfor i in mylist[:10000]:\n     xml_file = xml_filepath +i\n     arg1=i.split('.')[0]\n     discard=0\n     with open(xml_file, \"rb\") as f: # notice the \"rb\" mode\n         d = xmltodict.parse(f, xml_attribs=True)\n         l=[]\n         if type(d[\"annotation\"][\"object\"]) == type(l):\n             discard=1\n         else:\n             coords={arg1:[]}\n             pre_xtrain.append(arg1)\n             m=pre_xtrain[(k+1)]\n             k = k+1\n             if(discard==0):\n                 x1=((float(d['annotation']['object']['bndbox']['xmin'])))/(float(d['annotation']['size']['width']))\n                 x2=((float(d['annotation']['object']['bndbox']['xmax'])))/(float(d['annotation']['size']['width']))\n                 y1=((float(d['annotation']['object']['bndbox']['ymin'])))/(float(d['annotation']['size']['height']))\n                 y2=((float(d['annotation']['object']['bndbox']['ymax'])))/(float(d['annotation']['size']['height']))\n                 cls=d['annotation']['object']['name']\n                 if(cls == 'person'):\n                     coords[arg1].append(x1)\n                     coords[arg1].append(y1)\n                     coords[arg1].append(x2)\n                     coords[arg1].append(y2)\n                     coords[arg1].append(cls)\n```", "```py\n                     filename = base_dir+m+'.jpg'\n                     # reference to jpg files here\n                     img = filename\n                     img_size=224\n                     img = cv2.imread(filename)\n                     img2 = cv2.resize(img,(img_size,img_size))\n                     img2 = img2/255\n```", "```py\n                    current_y = [int(x1*224), int(y1*224), int(x2*224), int(y2*224)]\n                    current_y2 = [float(d['annotation']['object']['bndbox']['xmin']), float(d['annotation']['object']['bndbox']['ymin']),\n float(d['annotation']['object']['bndbox']['xmax'])-float(d['annotation']['object']['bndbox']['xmin']),\n float(d['annotation']['object']['bndbox']['ymax'])-float(d['annotation']['object']['bndbox']['ymin'])]\n\n                    label_center = [(current_y[0]+current_y[2])/2,(current_y[1]+current_y[3])/2] \n                    label = current_y\n```", "```py\n            vgg_predict =vgg16_model.predict(img2.reshape(1,img_size,img_size,3))\n            x_train.append(vgg_predict)\n```", "```py\n            target_class = np.zeros((num_grids,num_grids,5))\n            target_delta = np.zeros((num_grids,num_grids,20))\n```", "```py\ndef positive_grid_cell(label,img_width = 224, img_height = 224): \n     label_center = [(label[0]+label[2])/(2),(label[1]+label[3])/(2)] \n     a = int(label_center[0]/(img_width/num_grids)) \n     b = int(label_center[1]/(img_height/num_grids)) \n     return a, b\n```", "```py\n            a,b = positive_grid_cell(label)\n```", "```py\ndef find_closest_anchor(label,img_width, img_height):\n     label_width = (label[2]-label[0])/img_width\n     label_height = (label[3]-label[1])/img_height \n     label_width_height_array = np.array([label_width, label_height]) \n     distance = np.sum(np.square(np.array(anchors) - label_width_height_array), axis=1) \n     closest_anchor = anchors[np.argmin(distance)] \n     return closest_anchor\n```", "```py\ndef closest_anchor_corrections(a, b, anchor, label, img_width, img_height): \n     label_center = [(label[0]+label[2])/(2),(label[1]+label[3])/(2)] \n     anchor_center = [a*img_width/num_grids , b*img_height/num_grids ] \n     dx = (label_center[0] - anchor_center[0])/img_width \n     dy = (label_center[1] - anchor_center[1])/img_height\n     dw = ((label[2] - label[0])/img_width) / (anchor[0])\n     dh = ((label[3] - label[1])/img_height) / (anchor[1]) \n     return dx, dy, dw, dh \n```", "```py\nfor a2 in range(num_grids):\n     for b2 in range(num_grids):\n         for m in range(len(anchors)):\n             dx, dy, dw, dh = closest_anchor_corrections(a2, b2, anchors[m], label, 224, 224)\n             target_class[a2,b2,m] = 0\n             target_delta[a2,b2,((4*m)):((4*m)+4)] = [dx, dy, dw, dh]\n             anc.append(anchors[m])\n             if((anchors[m] == find_closest_anchor(label,224, 224)) & (a2 == a) & (b2 == b)):\n                 target_class[a2,b2,m] = 1\n```", "```py\n            y_train.append(target_class.flatten())\n            y_delta.append(target_delta)\n```", "```py\nfrom keras.optimizers import Adam\noptimizer = Adam(lr=0.001)\nfrom keras.layers import BatchNormalization\nfrom keras import regularizers\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(7,7,512)))\nmodel.add(Conv2D(1024, (3,3), activation='relu',padding='valid'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(5, (1,1), activation='relu',padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(125, activation='sigmoid'))\nmodel.summary()\n```", "```py\ny_train = np.array(y_train)\nx_train = np.array(x_train)\nx_train = x_train.reshape(x_train.shape[0],7,7,512)\n```", "```py\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer)\n\nmodel.fit(x_train/np.max(x_train), y_train, epochs=5, batch_size = 32, validation_split = 0.1, verbose = 1)\n```", "```py\ndelta_x = []\ndelta_y = []\nfor i in range(len(x_train)):\n     delta_x.append(x_train[i])\n     delta = y_delta[i].flatten()\n     coord = np.argmax(model.predict(x_train[i].reshape(1,7,7,512)/12))\n     delta_y.append(delta[(coord*4):((coord*4)+4)])\n```", "```py\ndelta_x = np.array(delta_x)\ndelta_y = np.array(delta_y)\n\nmax_y = np.max(delta_y, axis=0)\ndelta_y2 = deltay/max_y\n```", "```py\nmodel2 = Sequential()\nmodel2.add(BatchNormalization(input_shape=(7,7,512)))\nmodel2.add(Conv2D(1024, (3,3), activation='relu',padding='valid'))\nmodel2.add(BatchNormalization())\nmodel2.add(Conv2D(5, (1,1), activation='relu',padding='same'))\nmodel2.add(Flatten())\nmodel2.add(Dense(2, activation='linear'))\n```", "```py\nmodel2.compile(loss = 'mean_absolute_error', optimizer = optimizer)\nmodel2.fit(delta_x/np.max(x_train), delta_y2, epochs = 10, batch_size = 32, verbose = 1, validation_split = 0.1)\n```", "```py\nimg = cv2.imread('/content/Hemanvi.jpg')\nimg = cv2.resize(img,(224,224))\nimg = img/255\nimg2 = vgg16_model.predict(img.reshape(1,224,224,3))\narg = np.argmax(model.predict(img2/np.max(x_train)))\n```", "```py\ncount = 0\nfor a in range(num_grids):\n     for b in range(num_grids):\n         for c in range(len(anchors)):\n             if(count == arg):\n                 a2 = a\n                 b2 = b\n                 c2 = c \n             count+=1\n```", "```py\npred = model2.predict(img2/np.max(delta_x))[0]\n```", "```py\npred1 = pred*max_y\n```", "```py\nxmin = pred1[0]*224+a2*224/num_grids - (anchors[c2][0]*pred1[2] * 224)/2\nymin = pred1[1]*224+b2*224/num_grids - (anchors[c2][1]*pred1[3] * 224)/2\n\nw = anchors[c2][0]*pred1[2] * 224\nh = anchors[c2][1]*pred1[3] * 224\n```", "```py\nimport matplotlib.patches as mpatches\ncand = [xmin, ymin, w, h]\ncand = np.clip(cand, 1, 223)\nfig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 6))\nax.imshow(img)\nrect = mpatches.Rectangle(\n(cand[0], cand[1]), cand[2], cand[3], fill=False, edgecolor='red', linewidth=1)\nax.add_patch(rect)\nplt.grid('off')\nplt.show()\n```"]