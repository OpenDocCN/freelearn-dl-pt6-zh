["```py\nfrom keras.datasets import mnist\nfrom keras.layers import Flatten, Dense\nfrom keras.models import Sequential\nimport matplotlib.pyplot as plt\n%matplotlib inline\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n```", "```py\nX_train1 = X_train[y_train==1]\n```", "```py\nnum_pixels = X_train.shape[1] * X_train.shape[2]\nX_train = X_train.reshape(X_train.shape[0],num_pixels).astype('float32')\nX_test = X_test.reshape(X_test.shape[0],num_pixels).astype('float32')\nX_train = X_train / 255\nX_test = X_test / 255\n```", "```py\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\nnum_classes = y_train.shape[1]\n```", "```py\nmodel = Sequential()\nmodel.add(Dense(1000, input_dim=num_pixels, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test),epochs=5, batch_size=1024, verbose=1)\n```", "```py\npic=np.zeros((28,28))\npic2=np.copy(pic)\nfor i in range(X_train1.shape[0]):\n    pic2=X_train1[i,:,:]\n    pic=pic+pic2\npic=(pic/X_train1.shape[0])\nplt.imshow(pic)\n```", "```py\nfor i in range(pic.shape[0]):\n     if i<20:\n         pic[:,i]=pic[:,i+1]\n     plt.imshow(pic)\n```", "```py\nmodel.predict(pic.reshape(1,784)/255)\n```", "```py\npic=np.zeros((28,28))\npic2=np.copy(pic)\nfor i in range(X_train1.shape[0]):\n    pic2=X_train1[i,:,:]\n    pic=pic+pic2\npic=(pic/X_train1.shape[0])\npic2=np.copy(pic)\nfor i in range(pic.shape[0]):\n    if ((i>6) and (i<26)):\n    pic[:,i]=pic2[:,(i-1)]\nplt.imshow(pic)\n```", "```py\nmodel.predict(pic.reshape(1,784)/255)\n```", "```py\nimport numpy as np\nX_train=np.array([[[1,2,3,4],[2,3,4,5],[5,6,7,8],[1,3,4,5]],\n[[-1,2,3,-4],[2,-3,4,5],[-5,6,-7,8],[-1,-3,-4,-5]]])\ny_train=np.array([0,1])\n```", "```py\nX_train = X_train / 8\n```", "```py\nX_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[1],1 ).astype('float32')\n```", "```py\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom keras.models import Sequential\nmodel = Sequential()\n```", "```py\nmodel.add(Conv2D(1, (3,3), input_shape=(4,4,1),activation='relu'))\n```", "```py\nmodel.add(MaxPooling2D(pool_size=(2, 2))) \n```", "```py\nmodel.add(Flatten())\n```", "```py\nmodel.add(Dense(1, activation='sigmoid'))\n```", "```py\nmodel.summary()\n```", "```py\nmodel.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n```", "```py\nmodel.fit(X_train, y_train, epochs = 500)\n```", "```py\nmodel.weights\n```", "```py\nmodel.get_weights()\n```", "```py\nmodel.predict(X_train[0].reshape(1,4,4,1))\n```", "```py\nsumprod = []\nfor i in range(X_train[0].shape[0]-model.get_weights()[0].shape[0]+1):\n     for j in range(X_train[0].shape[0]-model.get_weights()[0].shape[0]+1):\n         img_subset = np.array(X_train[0,i:(i+3),j:(j+3),0])\n         filter = model.get_weights()[0].reshape(3,3)\n         val = np.sum(img_subset*filter) + model.get_weights()[1]\n         sumprod.append(val)\n```", "```py\nsumprod= np.array(sumprod).reshape(2,2,1)\n```", "```py\nsumprod = np.where(sumprod>0,sumprod,0)\n```", "```py\npooling_layer_output = np.max(sumprod)\n```", "```py\nintermediate_output_value = pooling_layer_output*model.get_weights()[2]+model.get_weights()[3]\n```", "```py\n1/(1+np.exp(-intermediate_output_value))\n```", "```py\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[1],1 ).astype('float32')\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[1],1).astype('float32')\n\nX_train = X_train / 255\nX_test = X_test / 255\n\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\n\nnum_classes = y_test.shape[1]\n```", "```py\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom keras.models import Sequential\nmodel = Sequential()\nmodel.add(Conv2D(10, (3,3), input_shape=(28, 28,1),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(1000, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n```", "```py\nmodel.summary()\n```", "```py\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test),epochs=5, batch_size=1024, verbose=1)\n```", "```py\nX_test1 = X_test[y_test[:,1]==1]\n```", "```py\nimport numpy as np\npic=np.zeros((28,28))\npic2=np.copy(pic)\nfor i in range(X_test1.shape[0]):\n     pic2=X_test1[i,:,:,0]\n     pic=pic+pic2\npic=(pic/X_test1.shape[0])\n```", "```py\nfor i in range(pic.shape[0]):\n     if i<20:\n         pic[:,i]=pic[:,i+1]\n```", "```py\nmodel.predict(pic.reshape(1,28,28,1))\n```", "```py\n$ wget https://d1p17r2m4rzlbo.cloudfront.net/wp-content/uploads/2017/04/a943287.csv\n```", "```py\nimport pandas as pd, numpy as np\nfrom skimage import io\n# Location of file is /content/a943287.csv\n# be sure to change to location of downloaded file on your machine\ndata = pd.read_csv('/content/a943287.csv')\ndata.head() \n```", "```py\ndata_male = data[data['please_select_the_gender_of_the_person_in_the_picture']==\"male\"].reset_index(drop='index')\ndata_female = data[data['please_select_the_gender_of_the_person_in_the_picture']==\"female\"].reset_index(drop='index')\nfinal_data = pd.concat([data_male[:1000],data_female[:1000]],axis=0).reset_index(drop='index')\n```", "```py\nx = []\ny = []\nfor i in range(final_data.shape[0]):\n     try:\n         image = io.imread(final_data.loc[i]['image_url'])\n         if(image.shape==(300,300,3)):\n             x.append(image)\n             y.append(final_data.loc[i]['please_select_the_gender_of_the_person_in_the_picture'])\n     except:\n         continue\n```", "```py\nx2 = []\ny2 = []\nfor i in range(len(x)):\n      img = cv2.cvtColor(x[i], cv2.COLOR_BGR2GRAY)\n      img2 = cv2.resize(img,(50,50))\n      x2.append(img2)\n      img_label = np.where(y[i]==\"male\",1,0)\n      y2.append(img_label)\n```", "```py\nx2 = np.array(x2)\nx2 = x2.reshape(x2.shape[0],x2.shape[1],x2.shape[2],1)\nY = np.array(y2)\n```", "```py\nX = np.array(x2)/255\nY = np.array(y2)\n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.1, random_state=42)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n```", "```py\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom keras.models import Sequential\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu',input_shape=(50,50,1)))\nmodel.add(MaxPooling2D(pool_size=(5, 5)))\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(512, kernel_size=(3, 3), activation='relu',padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n```", "```py\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n```", "```py\nhistory = model.fit(X_train, y_train, batch_size=32, epochs=50,verbose=1,validation_data = (X_test, y_test))\n```", "```py\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport numpy as np\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import regularizers\n\nfrom keras.datasets import cifar10\n(X_train, y_train), (X_val, y_val) = cifar10.load_data()\n```", "```py\nX_train = X_train.astype('float32')/255.\nX_val = X_val.astype('float32')/255.\n\nn_classes = 10\ny_train = np_utils.to_categorical(y_train, n_classes)\ny_val = np_utils.to_categorical(y_val, n_classes)\n```", "```py\ninput_shape = X_train[0].shape\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2)) \nmodel.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3)) \nmodel.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4)) \nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))\n\nfrom keras.optimizers import Adam\nadam = Adam(lr = 0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=adam,metrics=['accuracy'])\n```", "```py\nmodel.fit(X_train, y_train, batch_size=32,epochs=10, verbose=1, validation_data=(X_val, y_val))\n```", "```py\nfrom keras.preprocessing.image import ImageDataGenerator \ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0,\n    height_shift_range=0,\n    fill_mode = 'nearest')\n\ndatagen.fit(X_train)\n```", "```py\nbatch_size = 32\nmodel = Sequential()\nmodel.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2)) \nmodel.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3)) \nmodel.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4)) \nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))\nfrom keras.optimizers import Adam\nadam = Adam(lr = 0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n```", "```py\nmodel.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),steps_per_epoch=X_train.shape[0] // batch_size, epochs=10,validation_data=(X_val,y_val))\n```"]