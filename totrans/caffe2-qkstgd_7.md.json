["```py\n$ ssh pi@<IP address of Pi>\n```", "```py\n$ sudo apt update\n$ sudo apt upgrade\n```", "```py\n$ git clone --recursive https://github.com/pytorch/pytorch.git\n$ cd pytorch\n$ git submodule update --init\n```", "```py\n$ rm -rf .git\n```", "```py\n$ cd ..\n$ tar zcvf pytorch.tar.gz pytorch\n$ scp pytorch.tar.gz pi@<IP address of Pi>:/home/pi\n```", "```py\n$ tar xvf pytorch.tar.gz\n$ cd pytorch\n```", "```py\n$ sudo apt install python-future python-typing python-yaml\n$ sudo pip install -U protobuf\n```", "```py\n$ cd scripts\n$ ./build_raspbian.sh\n```", "```py\n$ cd ../build\n$ sudo make install\n$ python -c \"from caffe2.python import core\"\n```", "```py\n$ sudo adduser myusername docker\n```", "```py\n$ docker run hello-world\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1\\. The Docker client contacted the Docker daemon.\n 2\\. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n (amd64)\n 3\\. The Docker daemon created a new container from that image which \n    runs the executable that produces the output you are currently \n    reading.\n 4\\. The Docker daemon streamed that output to the Docker client, \n    which sent it to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n```", "```py\n$ docker run --rm -it ubuntu bash\n```", "```py\n$ curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - distribution=$(. /etc/os-release;echo $ID$VERSION_ID)\n$ curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list\n$ sudo apt-get update\n```", "```py\n$ sudo apt-get install -y nvidia-docker2\n```", "```py\n$ sudo pkill -SIGHUP dockerd\n```", "```py\n$ docker run --runtime=nvidia --rm nvidia/cuda:9.0-base nvidia-smi\n```", "```py\n$ nvidia-docker run --rm nvidia/cuda:9.0-base nvidia-smi\n```", "```py\n$ docker run --rm -ti caffe2ai/caffe2:c2v0.8.1.cpu.min.ubuntu16.04\nroot@13588569ad8f:/# python -c \"from caffe2.python import core\"\nWARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n```", "```py\n$ nvidia-docker run --rm -ti caffe2ai/caffe2:c2v0.8.1.cuda8.cudnn7.ubuntu16.04\nroot@9dd026974563:/# python -c \"from caffe2.python import core\"\n```", "```py\n$ docker run --rm -ti -v /home/joe/caffe2_apps:/joe_caffe2_apps caffe2ai/caffe2:c2v0.8.1.cpu.min.ubuntu16.04\n```", "```py\n$ python net_drawer.py --input /path/to/bvlc_alexnet/predict_net.pb --rankdir TB\n```", "```py\n$ python net_drawer.py --help\nusage: net_drawer.py [-h] --input INPUT [--output_prefix OUTPUT_PREFIX]\n [--minimal] [--minimal_dependency] [--\n                     append_output]\n [--rankdir RANKDIR]\n\nCaffe2 net drawer.\n\noptional arguments:\n -h, --help            show this help message and exit\n --input INPUT         The input protobuf file.\n --output_prefix OUTPUT_PREFIX\n The prefix to be added to the output filename.\n --minimal             If set, produce a minimal visualization.\n --minimal_dependency  If set, only draw minimal dependency.\n --append_output       If set, append the output blobs to the operator \n                        names.\n --rankdir RANKDIR     The rank direction of the pydot graph.\n```", "```py\n$ pip3 install --user netron\n```", "```py\n$ netron -b /path/to/predict_net.pb\n```"]