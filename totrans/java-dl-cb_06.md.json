["```py\nnew NumberedFileInputSplit(FEATURE_DIR+\"/%d.csv\",0,3199);\n```", "```py\nnew NumberedFileInputSplit(LABEL_DIR+\"/%d.csv\",0,3199);\n```", "```py\nSequenceRecordReader trainFeaturesReader = new CSVSequenceRecordReader(1, \",\");\n trainFeaturesReader.initialize(new NumberedFileInputSplit(FEATURE_DIR+\"/%d.csv\",0,3199));\n SequenceRecordReader trainLabelsReader = new CSVSequenceRecordReader();\n trainLabelsReader.initialize(new NumberedFileInputSplit(LABEL_DIR+\"/%d.csv\",0,3199));\n```", "```py\nSequenceRecordReader trainFeaturesReader = new CSVSequenceRecordReader(1, \",\");\n```", "```py\nDataSetIterator trainDataSetIterator = new SequenceRecordReaderDataSetIterator(trainFeaturesReader,trainLabelsReader,batchSize,numberOfLabels,false, SequenceRecordReaderDataSetIterator.AlignmentMode.ALIGN_END);\n```", "```py\nDataSetIterator testDataSetIterator = new SequenceRecordReaderDataSetIterator(testFeaturesReader,testLabelsReader,batchSize,numberOfLabels,false, SequenceRecordReaderDataSetIterator.AlignmentMode.ALIGN_END);\n```", "```py\nDataSetIterator testDataSetIterator = new SequenceRecordReaderDataSetIterator(testFeaturesReader,testLabelsReader,batchSize,numberOfLabels,false, SequenceRecordReaderDataSetIterator.AlignmentMode.ALIGN_END);\n```", "```py\nComputationGraphConfiguration.GraphBuilder builder = new NeuralNetConfiguration.Builder()\n .seed(RANDOM_SEED)\n .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n .weightInit(WeightInit.XAVIER)\n .updater(new Adam())\n .dropOut(0.9)\n .graphBuilder()\n .addInputs(\"trainFeatures\");\n```", "```py\nnew LSTM.Builder()\n .nIn(INPUTS)\n .nOut(LSTM_LAYER_SIZE)\n .forgetGateBiasInit(1)\n .activation(Activation.TANH)\n .build(),\"trainFeatures\");\n```", "```py\nbuilder.addLayer(\"L1\", new LSTM.Builder()\n .nIn(86)\n .nOut(200)\n .forgetGateBiasInit(1)\n .activation(Activation.TANH)\n .build(),\"trainFeatures\");\n```", "```py\nbuilder.addInputs(\"trainFeatures\");\n```", "```py\nbuilder.addLayer(\"L1\", new LSTM.Builder()\n     .nIn(INPUTS)\n     .nOut(LSTM_LAYER_SIZE)\n     .forgetGateBiasInit(1)\n     .activation(Activation.TANH)\n     .build(),\"trainFeatures\");\n```", "```py\nnew RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT)\n .activation(Activation.SOFTMAX)\n .nIn(LSTM_LAYER_SIZE).nOut(labelCount).build()\n```", "```py\nbuilder.addLayer(\"predictMortality\", new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT)\n .activation(Activation.SOFTMAX)\n .nIn(LSTM_LAYER_SIZE).nOut(labelCount).build(),\"L1\");\n```", "```py\nbuilder.addLayer(\"predictMortality\", new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT)\n .activation(Activation.SOFTMAX)\n .nIn(LSTM_LAYER_SIZE).nOut(labelCount).build(),\"L1\")\n```", "```py\nComputationGraphConfiguration configuration = builder.build();\n   ComputationGraph model = new ComputationGraph(configuration);\n```", "```py\nfor(int i=0;i<epochs;i++){\n   model.fit(trainDataSetIterator);\n }\n```", "```py\nmodel.fit(trainDataSetIterator,epochs);\n```", "```py\nROC evaluation = new ROC(thresholdSteps);\n```", "```py\nDataSet batch = testDataSetIterator.next();\n INDArray[] output = model.output(batch.getFeatures());\n```", "```py\nINDArray actuals = batch.getLabels();\n   INDArray predictions = output[0]\n   evaluation.evalTimeSeries(actuals, predictions);\n```", "```py\nSystem.out.println(evaluation.calculateAUC());\n\n```", "```py\nevaluation.calculateAUC();\n```"]