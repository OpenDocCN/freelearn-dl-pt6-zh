- en: Analyzing and Predicting Telecommunication Churn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will develop a **machine learning** (**ML**) project to
    analyze and predict whether a customer is likely to cancel the subscription to
    his telecommunication contract or not. In addition, we'll do some preliminary
    analysis of the data and take a closer look at what types of customer features
    are typically responsible for such a churn.
  prefs: []
  type: TYPE_NORMAL
- en: Widely used classification algorithms, such as decision trees, random forest,
    logistic regression, and **Support Vector Machines** (**SVMs**) will be used for
    analyzing and making the prediction. By the end, readers will be able to choose
    the best model to use for a production-ready environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a nutshell, we will learn the following topics throughout this end-to-end
    project:'
  prefs: []
  type: TYPE_NORMAL
- en: Why, and how, do we do churn prediction?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic regression-based churn prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SVM-based churn prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision tree-based churn prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random forest-based churn prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting the best model for deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why do we perform churn analysis, and how do we do it?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Customer churn** is the loss of clients or customers (also known as **customer
    attrition**, customer turnover, or customer defection). This concept was initially
    used within the telecommunications industry when many subscribers switched to
    other service providers. However, it has become a very important issue in other
    areas of business, such as banks, internet service providers, insurance companies,
    and so on. Well, two of the primary reasons for churn are customer dissatisfaction
    and cheaper and/or better offers from the competition.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in *Figure 1*, there are four possible contracts with the customer
    in a business industry: contractual, non-contractual, voluntary, and involuntary.
    The full cost of customer churn includes both the lost revenue and the (tele-)
    marketing costs involved with replacing those customers with new ones. However,
    this type of loss can cause a huge loss to a business. Think back to a decade
    ago, when Nokia was the dominator of the cell phone market. All of a sudden, Apple
    announced iPhone 3G, and that was a revolution in the smartphone era. Then, around
    10 to 12% of customers stopped using Nokia and switched to iPhone. Although later
    on, Nokia also tried to release a smartphone, eventually, they could not compete
    with Apple:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cc26a83d-61b4-4cf0-b673-1e91438ec329.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Four types of possible contracts with the customers'
  prefs: []
  type: TYPE_NORMAL
- en: Churn prediction is fundamental to businesses, as it allows them to detect customers
    who are likely to cancel a subscription, product, or service. It can also minimize
    customer defection. It does so by predicting which customers are likely to cancel
    a subscription to a service. Then, the respective business can have a special
    offer or plan for those customers (who might cancel the subscription). This way,
    a business can reduce the churn ratio. This should be a key business goal of every
    online business.
  prefs: []
  type: TYPE_NORMAL
- en: 'When it comes to employee churn prediction, the typical task is to determine
    what factors predict an employee leaving his/her job. These types of prediction
    processes are heavily data-driven and are often required to utilize advanced ML
    techniques. In this chapter, however, we will mainly focus on customer churn prediction
    and analysis. For this, a number of factors should be analyzed in order to understand
    the customer''s behavior, including but not limited to:'
  prefs: []
  type: TYPE_NORMAL
- en: Customer's demographic data, such as age, marital status, and so on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer's sentiment analysis of social media
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Browsing behavior from clickstream logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Historical data that shows patterns of behavior that suggest churn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer's usage patterns and geographical usage trends
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calling-circle data and support call center statistics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing a churn analytics pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In ML, we observe an algorithm''s performance in two stages: learning and inference.
    The ultimate target of the learning stage is to prepare and describe the available
    data, also called the **feature vector**, which is used to train the model.'
  prefs: []
  type: TYPE_NORMAL
- en: The learning stage is one of the most important stages, but it is also truly
    time-consuming. It involves preparing a list of vectors, also called **feature
    vectors** (vectors of numbers representing the value of each feature), from the
    training data after transformation so that we can feed them to the learning algorithms.
    On the other hand, training data also sometimes contains impure information that
    needs some pre-processing, such as cleaning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have the feature vectors, the next step in this stage is preparing
    (or writing/reusing) the learning algorithm. The next important step is training
    the algorithm to prepare the predictive model. Typically, (and of course based
    on data size), running an algorithm may take hours (or even days) so that the
    features converge into a useful model, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f458d39c-885d-4161-b766-251ea56c1efb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Learning and training a predictive model - it shows how to generate
    the feature vectors from the training data to train the learning algorithm that
    produces a predictive model'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second most important stage is the inference that is used for making an
    intelligent use of the model, such as predicting from the never-before-seen data,
    making recommendations, deducing future rules, and so on. Typically, it takes
    less time compared to the learning stage, and is sometimes even in real time.
    Thus, inferencing is all about testing the model against new (that is, unobserved)
    data and evaluating the performance of the model itself, as shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7e917a27-ffcf-43d6-8794-a16d48bd0fed.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Inferencing from an existing model towards predictive analytics (feature
    vectors are generated from unknown data for making predictions)'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, during the whole process and for making the predictive model a successful
    one, data acts as the first-class citizen in all ML tasks. Keeping all this in
    mind, the following figure shows an analytics pipeline that can be used by telecommunication
    companies:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9abacbdc-9ed4-4ab4-938f-54ee24efcc24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Churn analytics pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: With this kind of analysis, telecom companies can discern how to predict and
    enhance the customer experience, which can, in turn, prevent churn and tailor
    marketing campaigns. In practice, often these business assessments are used in
    order to retain the customers most likely to leave, as opposed to those who are
    likely to stay.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we need to develop a predictive model so that it ensures that our model
    is sensitive to the `Churn = True` samples—that is, a binary classification problem.
    We will see more details in upcoming sections.
  prefs: []
  type: TYPE_NORMAL
- en: Description of the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **Orange Telecom''s Churn Dataset**, which consists of cleaned customer
    activity data (features), along with a churn label specifying whether a customer
    canceled the subscription, will be used to develop our predictive model. The churn-80
    and churn-20 datasets can be downloaded from the following links, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://bml-data.s3.amazonaws.com/churn-bigml-80.csv](https://bml-data.s3.amazonaws.com/churn-bigml-80.csv)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://bml-data.s3.amazonaws.com/churn-bigml-20.csv](https://bml-data.s3.amazonaws.com/churn-bigml-20.csv)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, as more data is often desirable for developing ML models, let's use
    the larger set (that is, churn-80) for training and cross-validation purposes,
    and the smaller set (that is, churn-20) for final testing and model performance
    evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the latter set is only used to evaluate the model (that is for demonstration
    purposes). For a production ready environment, telecommunication companies can
    use their own dataset with necessary preprocessing and feature engineering. The
    dataset has the following schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '**State**: `String`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Account length**: `Integer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Area code**: `Integer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**International plan**: `String`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Voicemail plan**: `String`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number email messages**: `Integer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total day minutes**: `Double`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total day calls**: `Integer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total day charge**: `Double`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total eve minutes**: `Double`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total eve calls**: `Integer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total eve charge**: `Double`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total night minutes**: `Double`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total night calls**: `Integer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total night charge**: `Double`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total intl minutes**: `Double`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total intl calls**: `Integer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total intl charge**: `Double`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Customer service calls**: `Integer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploratory analysis and feature engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this sub-section, we will see some EDA of the dataset before we start preprocessing
    and feature engineering. Only then creation of an analytics pipeline makes sense.
    At first, let''s import necessary packages and libraries as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Then, let's specify the data source and schema for the dataset to be processed.
    When loading the data into a DataFrame, we can specify the schema. This specification
    provides optimized performance compared to the pre-Spark 2.x schema inference.
  prefs: []
  type: TYPE_NORMAL
- en: 'At first, let''s create a Scala case class with all the fields specified. The
    variable names are self-explanatory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s create a custom schema having a structure similar to our already
    created data source, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create a Spark session and import the `implicit._` that enables us to
    specify a DataFrame operation, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s create the training set. We read the CSV file with Spark''s recommended
    format, `com.databricks.spark.csv`. We don''t need any explicit schema inference,
    making the infer Schema false, but instead, we need our own schema we just created
    previously. Then, we load the data file from our desired location, and finally,
    specify our data source so that our DataFrame looks exactly the same as we specified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s see what the schema looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/489ed265-308b-4a22-82c2-127c473bd023.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Excellent! It looks exactly the same as the data structure. Now let''s see
    some sample data using the `show()` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following figure, column names are made shorter for visibility on the
    picture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/601a7523-4f1b-45d2-9481-d0f868bca26d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also see related statistics of the training set using the `describe()`
    method from Spark:'
  prefs: []
  type: TYPE_NORMAL
- en: The `describe()` method is a Spark DataFrame's built-in method for statistical
    processing. It applies summary statistics calculations on all numeric columns.
    Finally, it returns the computed values as a single DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/fe307ce5-7904-41fd-b30b-63a24fee94e5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If this dataset can be fit into RAM, we can cache it for quick and repeated
    access using the `cache()` method from Spark:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see some useful properties, such as variable correlation with churn.
    For example, let''s see how the churn is related to the total number of international
    calls:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see how the churn is related to the total international call charges:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we also need to have the test set prepared to evaluate the model,
    let''s prepare the same set, similar to the train set, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s cache them for faster access for further manipulation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s see some related properties of the training set to understand its
    suitableness for our purposes. At first, let''s create a temp view for persistence
    for this session. We can create a catalog as an interface that can be used to
    create, drop, alter, or query underlying databases, tables, functions, and many
    more:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Grouping the data by the churn label and calculating the number of instances
    in each group demonstrates that there are around six times more false churn samples
    as true churn samples. Let''s verify this statement with the following line of
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also see the previous statement, verified using Apache Zeppelin (see
    more details on how to configure and getting started in [Chapter 8](3e09dbd3-a9bb-4451-97f1-1a961d28b4a0.xhtml),
    *Using Deep Belief Networks in Bank Marketing*), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/b933288d-c96b-4772-888f-b1930c1c0593.png)'
  prefs: []
  type: TYPE_IMG
- en: As we have already stated, in most cases the target is to retain the customers
    who are most likely to leave, as opposed to those who are likely to stay or are
    staying. This also signifies that we should prepare our training set such that
    it ensures that our ML model is sensitive to the true churn samples—that is, having
    churn label true.
  prefs: []
  type: TYPE_NORMAL
- en: We can also observe that the preceding training set is highly unbalanced. Therefore,
    it would be feasible to put two sample types on the same footing using stratified
    sampling. The `sampleBy()` method can be used to do so when provided with fractions
    of each sample type to be returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we''re keeping all instances of the `True` churn class, but downsampling
    the `False` churn class to a fraction of *388/2278*, which is about `0.1675`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This way, we are also mapping only `True` churn samples. Now, let''s create
    a new DataFrame for the training set containing only downsampled ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The third parameter is the seed used for the reproducibility purpose. Now let''s
    see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s see how the variables are related to each other. Let''s see how
    the day, night, evening, and international voice calls contribute to the `churn`
    class. Just execute the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/5a0af826-28e0-463e-b042-50b3498f37b0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'On Apache Zeppelin, the preceding result can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a764a0a5-e3c5-4867-b495-2d5952c8407d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, let''s see how many minutes of day, night, evening, and international
    voice calls have contributed to the preceding total charge to the `churn` class.
    Just execute the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/548bee1c-eb4e-40dc-b02c-e58b1729a683.png)'
  prefs: []
  type: TYPE_IMG
- en: 'On Apache Zeppelin, the preceding result can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aa00e9d2-c314-4459-8e51-135748fb243d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From the preceding two graphs and tables, it is clear that total day minutes
    and total day charge are a highly correlated feature in this training set, which
    is not beneficial for our ML model training. Therefore, it would be better to
    remove them altogether. Moreover, the following graph shows all possible correlations
    (plotted in PySpark, though):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7aea33d2-92d3-4c01-8b74-aba1b5cb883e.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Correlation matrix, including all the features'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s drop one column of each pair of correlated fields, along with the **State**
    and **Area code** columns, too, since those will not be used either:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Excellent. Finally, we have our training DataFrame that can be used for better
    predictive modeling. Let''s take a look at some columns of the resulting DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/a90814fb-81d6-440c-bc2a-226ee24a1bd0.png)'
  prefs: []
  type: TYPE_IMG
- en: However, we are not done yet; the current DataFrame cannot be fed to the model
    as an estimator. As we described, the Spark ML API needs our data to be converted
    in a Spark DataFrame format, consisting of a label (in Double) and features (in
    Vector).
  prefs: []
  type: TYPE_NORMAL
- en: Now, we need to create a pipeline to pass the data through and chain several
    transformers and estimators. The pipeline then works as a feature extractor. More
    specifically, we have prepared two `StringIndexer` transformers and a `VectorAssembler`.
  prefs: []
  type: TYPE_NORMAL
- en: '`StringIndexer` encodes a categorical column of labels to a column of label
    indices (that is, numerical). If the input column is numeric, we have to cast
    it into a string and index the string values. Other Spark pipeline components,
    such as Estimator or Transformer, make use of this string-indexed label. In order
    to do this, the input column of the component must be set to this string-indexed
    column name. In many cases, you can set the input column with `setInputCol`. Interested
    readers should refer to this [https://spark.apache.org/docs/latest/ml-features.html](https://spark.apache.org/docs/latest/ml-features.html) for
    more details.'
  prefs: []
  type: TYPE_NORMAL
- en: The first `StringIndexer` converts the String categorical feature `international_plan`
    and labels into number indices. The second `StringIndexer` converts the categorical
    label (that is, `churn`) to numeric. This way, indexing categorical features enables
    decision trees and random forest-like classifiers to treat categorical features
    appropriately, hence improving performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, add the following lines of code, index labels, and metadata to the label
    column. Fit on the whole dataset to include all labels in the index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we need to extract the most important features that contribute to the classification.
    Since we have dropped some columns already, the resulting column set consists
    of the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'As we have already converted categorical labels into numeric using `StringIndexer`,
    the next task is to extract the features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s transform the features into feature vectors, which are vectors
    of numbers representing the value for each feature. In our case, we will use `VectorAssembler`.
    It takes all the `featureCols` and combines/transforms them into a single column
    called **features**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have the real training set consisting of labels and feature vectors
    ready, the next task is to create an estimator—the third element of a pipeline.
    We start with a very simple but powerful Logistic Regressionclassifier.
  prefs: []
  type: TYPE_NORMAL
- en: LR for churn prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'LR is one of the most widely used classifiers to predict a binary response.
    It is a linear ML method, as described in [Chapter 1](4b0be2d2-f313-471f-83fe-830931fc8af9.xhtml),
    *Analyzing Insurance Severity Claim*. The `loss` function is the formulation given
    by the logistic loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/58d1cdb4-4e46-48ce-8051-bf44e2fbf31c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For the LR model, the `loss` function is the logistic loss. For a binary classification
    problem, the algorithm outputs a binary LR model such that, for a given new data
    point, denoted by *x*, the model makes predictions by applying the logistic function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a34028da-b03e-4cb1-a247-c08dd7e7d7ce.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding equation, *z = W^TX* and if *f(W^TX)>0.5*, the outcome is positive;
    otherwise, it is negative.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the raw output of the LR model, *f(z)*, has a probabilistic interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: Note that compared to linear regression, logistic regression provides you with
    a higher classification accuracy. Moreover, it is a flexible way to regularize
    a model for custom adjustment, and overall, the model responses are measures of
    probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most importantly, whereas linear regression can predict only continuous values,
    linear regression can still be generalized enough to make it predict discrete
    values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Now that we already know linear regression's working principle, let's start
    using the Spark-based implementation of linear regression. Let's start by importing
    the required packages and libraries.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create a Spark session and import implicit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We now need to define some hyperparameters to train an linear regression-based
    pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The `RegParam` is a scalar that helps adjust the strength of the constraints:
    a small value implies a soft margin, so naturally, a large value implies a hard
    margin, and being an infinity is the hardest margin.'
  prefs: []
  type: TYPE_NORMAL
- en: By default, LR performs an L2 regularization with the regularization parameter
    set to 1.0\. The same model performs an L1 regularized variant of LR with the
    regularization parameter (that is, `RegParam`) set to 0.10\. Elastic Net is a
    combination of L1 and L2 regularization.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, the `Tol` parameter is used for the convergence tolerance
    for iterative algorithms such as logistic regression or linear SVM. Now, once
    we have the hyperparameters defined and initialized, the next task is to instantiate
    an linear regression estimator, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have three transformers and an estimator ready, the next task is
    to chain in a single pipeline—that is, each of them acts as a stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to perform such a grid search over the hyperparameter space, we need
    to define it first. Here, the functional programming properties of Scala are quite
    handy, because we just add function pointers and the respective parameters to
    be evaluated to the parameter grid, where you set up the parameters to test, and
    a cross-validation evaluator, to construct a model selection workflow. This searches
    through linear regression''s max iteration, regularization param, tolerance, and
    Elastic Net for the best model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Note that the hyperparameters form an n-dimensional space where *n* is the number
    of hyperparameters. Every point in this space is one particular hyperparameter
    configuration, which is a hyperparameter vector. Of course, we can't explore every
    point in this space, so what we basically do is a grid search over a (hopefully
    evenly distributed) subset in that space.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then need to define a `BinaryClassificationEvaluator` evaluator, since this
    is a binary classification problem. Using this evaluator, the model will be evaluated
    according to a precision metric by comparing the test label column with the test
    prediction column. The default metrics are an area under the precision-recall
    curve and an area under the **receiver operating characteristic** (**ROC**) curve:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We use a `CrossValidator` for best model selection. The `CrossValidator` uses
    the Estimator Pipeline, the Parameter Grid, and the Classification Evaluator.
    The `CrossValidator` uses the `ParamGridBuilder` to iterate through the max iteration,
    regression param, and tolerance and Elastic Net parameters of linear regression,
    and then evaluates the models, repeating 10 times per parameter value for reliable
    results—that is, 10-fold cross-validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code is meant to perform cross-validation. The validator itself
    uses the `BinaryClassificationEvaluator` estimator for evaluating the training
    in the progressive grid space on each fold and makes sure that there's no overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although there is so much stuff going on behind the scenes, the interface to
    our `CrossValidator` object stays slim and well-known, as `CrossValidator` also
    extends from Estimator and supports the fit method. This means that, after calling
    fit, the complete predefined pipeline, including all feature preprocessing and
    the LR classifier, is executed multiple times—each time with a different hyperparameter
    vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now it''s time to evaluate the predictive power of the LR model we created
    using the test dataset, which has not been used for any training or cross-validation
    so far—that is, unseen data to the model. As a first step, we need to transform
    the test set to the model pipeline, which will map the features according to the
    same mechanism we described in the preceding feature engineering step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/b2101733-4336-453c-9d7e-2bf2fb7c7f1a.png)'
  prefs: []
  type: TYPE_IMG
- en: The prediction probabilities can also be very useful in ranking customers according
    to their likeliness to imperfection. This way, a limited number of resources can
    be utilized in a telecommunication business for withholding but can be focused
    to the most valuable customers.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, seeing the previous prediction DataFrame, it is really difficult to
    guess the classification accuracy. In the second step, the evaluator evaluates
    itself using `BinaryClassificationEvaluator`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: So, we get about 77% of classification accuracy from our binary classification
    model. Now using the accuracy for the binary classifier does not make enough sense.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, researchers often recommend other performance metrics, such as area
    under the precision-recall curve and area under the ROC curve. However, for this
    we need to construct an RDD containing the raw scores on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the preceding RDD can be used to compute the two previously-mentioned
    performance metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the evaluation returns 77% accuracy, but only 58% precision.
    In the following, we calculate some more metrics; for example, false and true
    positive and negative predictions are also useful to evaluate the model''s performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True positive**: How often the model correctly predicted subscription canceling'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False positive**: How often the model incorrectly predicted subscription
    canceling'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**True negative**: How often the model correctly predicted no canceling at
    all'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False negative**: How often the model incorrectly predicted no canceling'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/16371f9d-cf39-4676-98fc-4407d4fba749.png)'
  prefs: []
  type: TYPE_IMG
- en: Yet, we have not received good accuracy, so let's continue trying other classifiers,
    such as SMV. This time, we will use the linear SVM implementation from the Apache
    Spark ML package.
  prefs: []
  type: TYPE_NORMAL
- en: SVM for churn prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'SVM is also used widely for large-scale classification (that is, binary as
    well as multinomial) tasks. Besides, it is also a linear ML method, as described
    in [Chapter 1](4b0be2d2-f313-471f-83fe-830931fc8af9.xhtml), *Analyzing Insurance
    Severity Claim*. The linear SVM algorithm outputs an SVM model, where the loss
    function used by SVM can be defined using the hinge loss, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*L(**w**;**x**,y):=max{0,1−y**w**^T**x**}*'
  prefs: []
  type: TYPE_NORMAL
- en: The linear SVMs in Spark are trained with an L2 regularization, by default.
    However, it also supports L1 regularization, by which the problem itself becomes
    a linear program.
  prefs: []
  type: TYPE_NORMAL
- en: Now, suppose we have a set of new data points *x*; the model makes predictions
    based on the value of ***w**^T**x***. By default, if ***w****^T****x**≥0*, then
    the outcome is positive, and negative otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we already know the SVMs working principle, let''s start using the
    Spark-based implementation of SVM. Let''s start by importing the required packages
    and libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s create a Spark session and import implicit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We now need to define some hyperparameters to train an LR-based pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, once we have the hyperparameters defined and initialized, the next task
    is to instantiate an LR estimator, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have three transformers and an estimator ready, the next task is
    to chain in a single pipeline—that is, each of them acts as a stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define the `paramGrid` to perform such a grid search over the hyperparameter
    space. This searches through SVM''s max iteration, regularization param, tolerance,
    and Elastic Net for the best model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define a `BinaryClassificationEvaluator` evaluator to evaluate the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'We use a `CrossValidator` for performing 10-fold cross-validation for best
    model selection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now call the `fit` method so that the complete predefined pipeline,
    including all feature preprocessing and the LR classifier, is executed multiple
    times—each time with a different hyperparameter vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Now it''s time to evaluate the predictive power of the SVM model on the test
    dataset. As a first step, we need to transform the test set with the model pipeline,
    which will map the features according to the same mechanism we described in the
    preceding feature engineering step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/ad85dba1-6541-44bf-bf6c-560e0d867804.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However, seeing the previous prediction DataFrame, it is really difficult to
    guess the classification accuracy. In the second step, the evaluator evaluates
    itself using `BinaryClassificationEvaluator`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: So we get about 75% of classification accuracy from our binary classification
    model. Now, using the accuracy for the binary classifier does not make enough
    sense.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, researchers often recommend other performance metrics, such as area
    under the precision-recall curve and area under the ROC curve. However, for this
    we need to construct an RDD containing the raw scores on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the preceding RDD can be used to compute the two previously-mentioned performance
    metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the evaluation returns 75% accuracy but only 55% precision. In
    the following, we again calculate some more metrics; for example, false and true
    positive and negative predictions are also useful to evaluate the model''s performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/6d30c141-8fcc-4bda-8273-b5fc3c4f9a3d.png)'
  prefs: []
  type: TYPE_IMG
- en: Yet, we have not received good accuracy using SVM. Moreover, there is no option
    to select the most suitable features, which would help us train our model with
    the most appropriate features. This time , we will again use a more robust classifier,
    such as the **decision trees** (**DTs**) implementation from the Apache Spark
    ML package.
  prefs: []
  type: TYPE_NORMAL
- en: DTs for churn prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DTs are commonly considered a supervised learning technique used for solving
    classification and regression tasks.
  prefs: []
  type: TYPE_NORMAL
- en: More technically, each branch in a DT represents a possible decision, occurrence,
    or reaction, in terms of statistical probability. Compared to naive Bayes, DTs
    are a far more robust classification technique. The reason is that at first, the
    DT splits the features into training and test sets. Then, it produces a good generalization
    to infer the predicted labels or classes. Most interestingly, a DT algorithm can
    handle both binary and multiclass classification problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, in the following example figure, DTs learn from the admission
    data to approximate a sine curve with a set of **if...else** decision rules. The
    dataset contains the record of each student who applied for admission, say, to
    an American university. Each record contains the graduate record exam score, CGPA
    score, and the rank of the column. Now we will have to predict who is competent
    based on these three features (variables). DTs can be used to solve this kind
    of problem after training the DT model and pruning unwanted branches of the tree.
    In general, a deeper tree signifies more complex decision rules and a better-fitted
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fa48fbd9-4b1f-4e97-abd1-fe85ca6be6d4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Decision tree for university admission data'
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the deeper the tree, the more complex the decision rules and the
    more fitted the model is. Now let''s see some pros and cons of DTs:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Pros** | **Cons** | **Better at** |'
  prefs: []
  type: TYPE_TB
- en: '| **Decision trees (DTs)** | -Simple to implement, train, and interpret-Trees
    can be visualized-Requires little data preparation-Less model building and prediction
    time-Can handle both numeric and categorical data-Possibility of validating the
    model using the statistical tests-Robust against noise and missing values-High
    accuracy | -Interpretation is hard with large and complex trees-Duplication may
    occur within the same sub-tree-Possible issues with diagonal decision boundaries-Decision
    tree learners can create over-complex trees that do not generalize the data well-Sometimes
    DTs can be unstable because of small variants in the data-Learning the DT itself
    is an NP-complete problem-DT learners create biased trees if some classes dominate
    | -Targeting highly accurate classification-Medical diagnosis and prognosis-Credit
    risk analytics |'
  prefs: []
  type: TYPE_TB
- en: 'Now, that we already know the working principle of DTs, let''s start using
    the Spark-based implementation of DTs. Let''s start by importing required packages
    and libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s create a Spark session and import implicit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, once we have the hyperparameters defined and initialized, the next task
    is to instantiate a `DecisionTreeClassifier` estimator, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have three transformers and an estimator ready, the next task is
    to chain in a single pipeline—that is, each of them acts as a stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define the paramgrid to perform such a grid search over the hyperparameter
    space. This search is through DT''s impurity, max bins, and max depth for the
    best model. Maximum depth of the tree: depth 0 means 1 leaf node; depth 1 means
    1 internal node + 2 leaf nodes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, the maximum number of bins is used for separate continuous
    features and for choosing how to split on features at each node. More bins give
    higher granularity. In short, we search through decision tree''s `maxDepth` and
    `maxBins` parameters for the best model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code segment, we're creating a progressive paramgrid through
    sequence format. That means we are creating the grid space with different hyperparameter
    combinations. This will help us provide the best model that consists of the most
    optimal hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s define a `BinaryClassificationEvaluator` evaluator to evaluate the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We use a `CrossValidator` for performing 10-fold cross-validation for best
    model selection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now call the `fit` method so that the complete predefined pipeline,
    including all feature preprocessing and the DT classifier, is executed multiple
    times—each time with a different hyperparameter vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Now it''s time to evaluate the predictive power of the DT model on the test
    dataset. As a first step, we need to transform the test set with the model pipeline,
    which will map the features according to the same mechanism we described in the
    previous feature engineering step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/7ecce996-69f6-4412-b021-7588816d89d6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However, seeing the preceding prediction DataFrame, it is really difficult
    to guess the classification accuracy. In the second step, in the evaluation is
    the evaluate itself using `BinaryClassificationEvaluator`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we get about 87% of classification accuracy from our binary classification
    model. Now, similar to SVM and LR, we will observe the area under the precision-recall
    curve and the area under the ROC curve based on the following RDD containing the
    raw scores on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the preceding RDD can be used to compute the two previously-mentioned performance
    metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the evaluation returns 87% accuracy but only 73% precision, which
    is much better than that of SVM and LR. In the following, we again calculate some
    more metrics; for example, false and true positive and negative predictions are
    also useful to evaluate the model''s performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/e919b818-4fc3-4bd9-8bde-c1e4974f3518.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fantastic; we achieved 87% accuracy, but for what factors? Well, it can be
    debugged to get the decision tree constructed during the classification. But first,
    let''s see at what level we achieved the best model after the cross-validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The Best Model and Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'That means we achieved the best tree model at depth 5 having 53 nodes. Now
    let''s extract those moves (that is, decisions) taken during tree construction
    by showing the tree. This tree helps us to find the most valuable features in
    our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Learned classification tree model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding output, the `toDebugString()` function prints the tree''s
    decision nodes and the final prediction comes out at the end leaves. It is also
    clearly seen that features 11 and 3 are used for decision making; they are the
    two most important reasons why a customer is likely to churn. But what are those
    two features? Let''s see them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: So the customer service calls and total day minutes are selected by the decision
    trees, since it provides an automated mechanism for determining the most important
    features.
  prefs: []
  type: TYPE_NORMAL
- en: Wait! We are not finished yet. Last but not least, we will use an ensemble technique,
    RF, which is considered a more robust classifier than DTs. Again, let's use the
    Random Forest implementation from the Apache Spark ML package.
  prefs: []
  type: TYPE_NORMAL
- en: Random Forest for churn prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As described in [Chapter 1](4b0be2d2-f313-471f-83fe-830931fc8af9.xhtml), *Analyzing
    Insurance Severity Claim*, Random Forest is an ensemble technique that takes a
    subset of observations and a subset of variables to build decision trees—that
    is, an ensemble of DTs. More technically, it builds several decision trees and
    integrates them together to get a more accurate and stable prediction.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5cc25b68-25d8-404b-8419-01ce7bd71ce4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Random forest and its assembling technique explained'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a direct consequence, since by maximum voting from a panel of independent
    juries, we get the final prediction better than the best jury (see the preceding
    figure). Now that we already know the working principle of RF, let''s start using
    the Spark-based implementation of RF. Let''s start by importing the required packages
    and libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s create Spark session and import implicit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, once we have the hyperparameters defined and initialized, the next task
    is to instantiate a `DecisionTreeClassifier` estimator, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have three transformers and an estimator ready, the next task is
    to chain in a single pipeline—that is, each of them acts as a stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define the paramgrid to perform such a grid search over the hyperparameter
    space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define a `BinaryClassificationEvaluator` evaluator to evaluate the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'We use a `CrossValidator` for performing 10-fold cross-validation for best
    model selection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now call the `fit` method so that the complete, predefined pipeline,
    including all feature preprocessing and the DT classifier, is executed multiple
    times—each time with a different hyperparameter vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Now it''s time to evaluate the predictive power of the DT model on the test
    dataset. As a first step, we need to transform the test set to the model pipeline,
    which will map the features according to the same mechanism we described in the
    previous feature engineering step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/3c3565fc-44f6-4bf0-a838-72fae88c09e3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However, seeing the preceding prediction DataFrame, it is really difficult
    to guess the classification accuracy. In the second step, in the evaluation is
    the evaluate itself using `BinaryClassificationEvaluator`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we get about 87% of classification accuracy from our binary classification
    model. Now, similar to SVM and LR, we will observe the area under the precision-recall
    curve and the area under the ROC curve based on the following RDD containing the
    raw scores on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the preceding RDD can be used to compute the two previously-mentioned performance
    metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the evaluation returns 87% accuracy but only 73% precision, which
    is much better than that of SVM and LR. In the following, we again calculate some
    more metrics; for example, false and true positive and negative predictions are
    also useful to evaluate the model''s performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'We will get the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c1a146a-2390-4b0e-b71e-af399d8e61b3.png)'
  prefs: []
  type: TYPE_IMG
- en: Fantastic; we achieved 91% accuracy, but for what factors? Well, similar to
    DT, Random Forest can be debugged to get the decision tree that was constructed
    during the classification. For the tree to be printed and the most important features
    selected, try the last few lines of code in the DT, and you're done.
  prefs: []
  type: TYPE_NORMAL
- en: 'Can you now guess how many different models were trained? Well, we have 10-folds
    on CrossValidation and five-dimensional hyperparameter space cardinalities between
    2 and 7\. Now let''s do some simple math: 10 * 7 * 5 * 2 * 3 * 6 = 12600 models!'
  prefs: []
  type: TYPE_NORMAL
- en: Note that we still make the hyperparameter space confined, with `numTrees`,
    `maxBins`, and `maxDepth` limited to 7\. Also, remember that bigger trees will
    most likely perform better. Therefore, feel free to play around with this code
    and add features, and also use a bigger hyperparameter space, say, bigger trees.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting the best model for deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From the preceding results, it can be seen that LR and SVM models have the
    same but higher false positive rate compared to Random Forest and DT. So we can
    say that DT and Random Forest have better accuracy overall in terms of true positive
    counts. Let''s see the validity of the preceding statement with prediction distributions
    on pie charts for each model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e0108be2-f86e-40ab-9f3f-00e341dda8df.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, it's worth mentioning that using random forest, we are actually getting
    high accuracy, but it's a very resource, as well as time-consuming job; the training,
    especially, takes a considerably longer time as compared to LR and SVM.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, if you don't have higher memory or computing power, it is recommended
    to increase the Java heap space prior to running this code to avoid OOM errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, if you want to deploy the best model (that is, Random Forest in our
    case), it is recommended to save the cross-validated model immediately after the
    `fit()` method invocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'Your trained model will be saved to that location. The directory will include:'
  prefs: []
  type: TYPE_NORMAL
- en: The best model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The metadata of the training itself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now the next task will be restoring the same model, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we need to transform the test set to the model pipeline that maps
    the features according to the same mechanism we described in the preceding feature
    engineering step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we evaluate the restored model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'You will receive the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5cb2c2c5-1984-4919-a0c1-8d433a22c386.png)'
  prefs: []
  type: TYPE_IMG
- en: Well, done! We have managed to reuse the model and do the same prediction. But,
    probably due to the randomness of data, we observed slightly different predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen how to develop an ML project to predict whether
    a customer is likely to cancel their subscription or not, and then used it to
    develop a real-life predictive model. We have developed predictive models using
    LR, SVMs, DTs, and Random Forest. We have also analyzed what types of customer
    data are typically used to do preliminary analysis of the data. Finally, we have
    seen how to choose which model to use for a production-ready environment.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how to develop a real-life project that collects
    historical and live **Bitcoin** data and predicts the price for an upcoming week,
    month, and so on. In addition to this, we will see how to generate a simple signal
    for online cryptocurrency trading.
  prefs: []
  type: TYPE_NORMAL
