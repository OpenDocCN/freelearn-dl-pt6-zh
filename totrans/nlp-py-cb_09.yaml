- en: Applications of Deep Learning in NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Classification of emails using deep neural networks after generating TF-IDF
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IMDB sentiment classification using convolutional networks CNN 1D
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IMDB sentiment classification using bidirectional LSTM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualization of high-dimensional words in 2D with neural word vector visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In recent times, deep learning has become very prominent in the application
    of text, voice, and image data to obtain state-of-the-art results, which are primarily
    used in the creation of applications in the field of artificial intelligence.
    However, these models turn out to be producing such results in all the fields
    of application. In this chapter, we will be covering various applications in NLP/text
    processing.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional neural networks and recurrent neural networks are central themes
    in deep learning that you will keep meeting across the domain.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CNNs are primarily used in image processing to classify images into a fixed
    set of categories and so on. CNN''s working principle has been described in the
    following diagram, wherein a filter of size 3 x 3 convolves over the original
    matrix of size 5 x 5, which produces an output of size 3 x 3\. The filter can
    stride horizontally by a step size of 1 or any value greater than 1 also. For
    cell (1, 1) the value obtained is 3, which is a product of the underlying matrix
    value and filter values. In this way, the filter will hover across the original
    5 x 5 matrix to create convolved features of 3 x 3, also known as activation maps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1f0de83f-8f28-4815-8546-e0291f2381ed.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The advantages of using convolutions:'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of a fixed size, fully connected layers save the number of neurons and
    hence the computational power requirement of the machine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Only a small size of filter weights is used to hover across the matrix, rather
    than each pixel connected to the next layers. So this is a better way of summarization
    of the input image into the next layers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: During backpropagation, only the weights of the filter need to be updated based
    on the backpropagated errors, hence the higher efficiency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CNNs perform mappings between spatially/temporally distributed arrays in arbitrary
    dimensions. They appear to be suitable for application to time series, images,
    or videos. CNNs are characterized by:'
  prefs: []
  type: TYPE_NORMAL
- en: Translation invariance (neural weights are fixed with respect to spatial translation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Local connectivity (neural connections exist only between spatially local regions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An optional progressive decrease in spatial resolution (as the number of features
    is gradually increased)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After convolution, the convolved feature/activation map needs to be reduced
    based on the most important features, as the same operation reduces the number
    of points and improves computational efficiency. Pooling is an operation typically
    performed to reduce unnecessary representations. Brief details about pooling operations
    are given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pooling**: Pooling makes the activation representation (obtained from convolving
    the filter over the input combination of input and weight values) smaller and
    more manageable. It operates over each activation map independently. Pooling applies
    to the width and breadth of the layer, and the depth will remain the same during
    the pooling stage. In the following diagram, a pooling operation of 2 x 2 is explained.
    Every original 4 x 4 matrix has been reduced by half. In the first four cell values
    of 2, 4, 5, and 8, the maximum is extracted, which is 8:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/3170d0b6-f394-4a6e-892a-e4cfa2098e20.png)'
  prefs: []
  type: TYPE_IMG
- en: Due to the operation of convolution, it is natural that the size of pixels/input
    data size reduces over the stages. But in some cases, we would really like to
    maintain the size across operations. A hacky way to achieve this is padding with
    zeros at the top layer accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: '**Padding**: The following diagram (its width and breadth) will be shrunk consecutively;
    this is undesirable in deep networks, and padding keeps the size of the picture
    constant or controllable in size throughout the network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/06710dbf-06c0-4d56-83ef-24aa6b2c386b.png)'
  prefs: []
  type: TYPE_IMG
- en: A simple equation for calculating the activation map size based on given input
    width, filter size, padding, and stride is shown as follows. This equation gives
    an idea of how much computational power is needed, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '**Calculation of activation map size**: In the following formula, the size
    of the activation map obtained from the convolutional layer is:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/ed1eab2b-75be-4e81-9f68-bebb519fda72.png)'
  prefs: []
  type: TYPE_IMG
- en: Where, *W* is the width of original image, *F* is the filter size, *P* is padding
    size (*1* for a single layer of padding, *2* for a double layer of padding, and
    so on), *S* is stride length
  prefs: []
  type: TYPE_NORMAL
- en: For example, consider an input image of size 224 x 224 x 3 (3 indicates Red,
    Green, and Blue channels), with a filter size of 11 x 11 and number of filters
    as 96\. The stride length is 4 and there is no padding. What is the activation
    map size generated out from these filters?
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6267bd0f-60a3-4992-914d-1a5380ac7ce1.png)![](img/184c95da-33a8-4650-b17d-def9e96dd982.png)'
  prefs: []
  type: TYPE_IMG
- en: The activation map dimensions would be 55 x 55 x 96\. Using the preceding formula,
    only width and depth can be computed, but the depth depends on the number of filters
    used. In fact, this is what was obtained in step 1 after convolution stage in
    AlexNet, which we will describe now.
  prefs: []
  type: TYPE_NORMAL
- en: '**AlexNet used in ImageNet competition during 2012**: The following image describes
    AlexNet, developed to win the ImageNet competition during 2012\. It produced significantly
    more accuracy compared with other competitors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/28456fad-7aea-4783-949f-e3bd0ec3dc14.png)'
  prefs: []
  type: TYPE_IMG
- en: In AlexNet, all techniques such as convolution, pooling, and padding have been
    used, and finally get connected with the fully connected layer.
  prefs: []
  type: TYPE_NORMAL
- en: Applications of CNNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CNNs are used in various applications, a few of them are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image classification**: Compared with other methods, CNNs achieve higher
    accuracy on large-scale images of data size. In image classification, CNNs are
    used at the initial stage, and once enough features are extracted using pooling
    layers, followed by other CNNs and so on, will be finally connected with the fully
    connected layers to classify them into the number of given classes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Face recognition**: CNNs are invariant to position, brightness, and so on, which
    will recognize faces from images and process them despite bad lighting, a face
    looking sideways, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scene labeling**: Each pixel is labeled with the category of the object it
    belongs to in scene labeling. CNNs are utilized here to combine pixels in a hierarchical
    manner.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NLP**: In NLP, CNNs are used similarly with bag-of-words, in which the sequence
    of words does not play a critical role in identifying the final class of email/text
    and so on. CNNs are used on matrices, which are represented by sentences in vector
    format. Subsequently, filters are applied but CNNs are one-dimensional, in which
    width is constant, and filters traverse only across height (the height is 2 for
    bi-grams, 3 for tri-grams, and so on).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recurrent neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A recurrent neural network is used to process a sequence of vectors X by applying
    a recurrence formula at every time step. In convolutional neural networks, we
    assume all inputs are independent of each other. But in some tasks, inputs are
    dependent on each other, for example, time series forecasting data, or predicting
    the next word in a sentence depending on past words, and so on, which needs to
    be modeled by considering dependency of past sequences. These types of problems
    are modeled with RNNs as they provide better accuracy, In theory, RNNs can make
    use of information in arbitrarily long sequences, but in practice, they are limited
    to looking back only for a few steps. The next formula explains the RNN functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6c951b2a-f3cd-4761-895c-174e48adebef.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/3d3b30c1-c0b3-4000-91be-d2499713d1c4.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/ebc6d56d-0880-4b8f-ba97-517c5726551c.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/dbcf9f07-3081-48ae-b330-7d04b13bd121.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/db890bd1-2148-4e01-96c4-2cb3ca05aad3.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/d39ddee4-9fdf-44bd-8c93-072018b21b35.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/5a7099c1-83bd-4c00-a499-c47d03cbc953.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Vanishing or exploding the gradient problem in RNNs**: Gradients does vanish
    quickly with the more number of layers and this issue is severe with RNNs as at
    each layer there are many time steps which also do occur and recurrent weights
    are multiplicative in nature, hence gradients either explode or vanish quickly,
    which makes neural networks untrainable. Exploding gradients can be limited by
    using a gradient clipping technique, in which an upper limit will be set to explode
    the gradients, but however vanishing gradient problem still does exists. This
    issue can be overcome by using **long short-term memory** (**LSTM**) networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LSTM**: LSTM is an artificial neural network contains LSTM blocks in addition
    to regular network units. LSTM blocks contain gates that determine when the input
    is significant enough to remember, when it should continue to remember or when
    it should forget the value, and when it should output the value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/71294f9c-1aff-473a-8966-8cb7616da3d4.png)![](img/b706152e-fc50-47a8-b1df-d695e7c5ab26.png)'
  prefs: []
  type: TYPE_IMG
- en: Vanishing and exploding gradient problems do not occur in LSTM as the same is
    an additive model rather than multiplicative model which is the case with RNN.
  prefs: []
  type: TYPE_NORMAL
- en: Application of RNNs in NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: RNNs have shown great success in many NLP tasks. The most commonly used variant
    of RNN is LSTM due to overcoming the issue of vanishing/exploding gradients.
  prefs: []
  type: TYPE_NORMAL
- en: '**Language modeling**: Given a sequence of words, the task is to predict the
    next probable word'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text generation**: To generate text from the writings of some authors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Machine translation**: To convert one language into other language (English
    to Chinese and so on.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chat bot**: This application is very much like machine translation; however
    question and answer pairs are used to train the model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generating an image description**: By training together with CNNs, RNNs can
    be used to generate a caption/description of the image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classification of emails using deep neural networks after generating TF-IDF
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will use deep neural networks to classify emails into one
    of the 20 pre-trained categories based on the words present in each email. This
    is the simple model to start with to understand the subject of deep learning and
    its applications on NLP.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The 20 newsgroups dataset from scikit-learn have been utilized to illustrate
    the concept. Number of observations/emails considered for analysis are 18,846
    (train observations - 11,314 and test observations - 7,532) and its corresponding
    classes/categories are 20, which are shown in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the following screenshot, a sample first data observation and target class
    category has been shown. From the first observation or email we can infer that
    the email is talking about a two-door sports car, which we can classify manually
    into autos category which is `8`.
  prefs: []
  type: TYPE_NORMAL
- en: Target value is `7` due to the indexing starts from `0`), which is validating
    our understanding with actual target class `7`
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1afe5527-7747-4d8e-9cce-291ed16337a9.png)'
  prefs: []
  type: TYPE_IMG
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using NLP techniques, we have pre-processed the data for obtaining finalized
    word vectors to map with final outcomes spam or ham. Major steps involved are:'
  prefs: []
  type: TYPE_NORMAL
- en: Pre-processing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Removal of punctuations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Word tokenization.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Converting words into lowercase.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stop word removal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Keeping words of length of at least 3.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stemming words.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: POS tagging.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Lemmatization of words:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: TF-IDF vector conversion.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep learning model training and testing.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Model evaluation and results discussion.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The NLTK package has been utilized for all the pre-processing steps, as it
    consists of all the necessary NLP functionality under one single roof:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The function written (pre-processing) consists of all the steps for convenience.
    However, we will be explaining all the steps in each section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following line of the code splits the word and checks each character to
    see if it contains any standard punctuations, if so it will be replaced with a
    blank or else it just don''t replace with blank:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code tokenizes the sentences into words based on whitespaces
    and puts them together as a list for applying further steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Converting all the cases (upper, lower and proper) into lower case reduces
    duplicates in corpus:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As mentioned earlier, Stop words are the words that do not carry much of weight
    in understanding the sentence; they are used for connecting words and so on. We
    have removed them with the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Keeping only the words with length greater than `3` in the following code for
    removing small words which hardly consists of much of a meaning to carry;
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Stemming applied on the words using Porter stemmer which stems the extra suffixes
    from the words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: POS tagging is a prerequisite for lemmatization, based on whether word is noun
    or verb or and so on. it will reduce it to the root word
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '`pos_tag` function returns the part of speed in four formats for Noun and six
    formats for verb. NN - (noun, common, singular), NNP - (noun, proper, singular),
    NNPS - (noun, proper, plural), NNS - (noun, common, plural), VB - (verb, base
    form), VBD - (verb, past tense), VBG - (verb, present participle), VBN - (verb,
    past participle), VBP - (verb, present tense, not 3rd person singular), VBZ -
    (verb, present tense, third person singular)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following function, `prat_lemmatize`, has been created only for the reasons
    of mismatch between the `pos_tag` function and intake values of `lemmatize` function.
    If the tag for any word falls under the respective noun or verb tags category,
    `n` or `v` will be applied accordingly in `lemmatize` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'After performing tokenization and applied all the various operations, we need
    to join it back to form stings and the following function performs the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Applying pre-processing on train and test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'After the pre-processing step has been completed, processed TF-IDF vectors
    have to be sent to the following deep learning code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The following image produces the output after firing up the preceding Keras
    code. Keras has been installed on Theano, which eventually works on Python. A
    GPU with 6 GB memory has been installed with additional libraries (CuDNN and CNMeM)
    for four to five times faster execution, with a choking of around 20% memory;
    hence only 80% memory out of 6 GB is available;
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/32236634-34b3-4191-891e-e41530804966.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following code explains the central part of the deep learning model. The
    code is self-explanatory, with the number of classes considered `20`, batch size
    `64`, and number of epochs to train, `20`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code converts the `20` categories into one-hot encoding vectors
    in which `20` columns are created and the values against the respective classes
    are given as `1`. All other classes are given as `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following building blocks of Keras code, three hidden layers (`1000`,
    `500`, and `50` neurons in each layer respectively) are used, with dropout as
    50% for each layer with Adam as an optimizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The architecture is shown as follows and describes the flow of the data from
    a start of 10,000 as input. Then there are `1000`, `500`, `50`, and `20` neurons
    to classify the given email into one of the `20` categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/665d79f4-cae5-4110-a960-1eccd8cd3b6f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The model is trained as per the given metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The model has been fitted with 20 epochs, in which each epoch took about 2
    seconds. The loss has been minimized from `1.9281` to `0.0241`. By using CPU hardware,
    the time required for training each epoch may increase as a GPU massively parallelizes
    the computation with thousands of threads/cores:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0566ec9a-9f67-4733-b22d-a199c949fecb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, predictions are made on the train and test datasets to determine the
    accuracy, precision, and recall values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/072cd7f7-a8ef-4989-a480-3b3a80a27faa.png)'
  prefs: []
  type: TYPE_IMG
- en: It appears that the classifier is giving a good 99.9% accuracy on the train
    dataset and 80.7% on the test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: IMDB sentiment classification using convolutional networks CNN 1D
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will use the Keras IMDB movie review sentiment data, which
    has labeled its sentiment (positive/negative). Reviews are pre-processed, and
    each review is already encoded as a sequence of word indexes (integers). However,
    we have decoded it to show a you sample in the following code.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The IMDB dataset from Keras has a set of words and its respective sentiment.
    The following is the pre-processing of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In this set of parameters, we did put maximum features or number of words to
    be extracted are 6,000 with maximum length of an individual sentence as 400 words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The dataset has an equal number of train and test observations, in which we
    will build a model on 25,000 observations and test the trained model on the test
    data with 25,000 data observations. A sample of data can be seen in this screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f07abcac-0aa8-4375-8d77-43dc55726312.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following code is used to create the dictionary mapping of a word and its
    respective integer index value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We see the first observation as a set of numbers rather than any English word,
    because the computer can only understand and work with numbers rather than characters,
    words, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/75264b5f-29a6-4688-a678-f98f27f46e03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Decoding using a created dictionary of inverse mapping is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot describes the stage after converting a number mapping
    into textual format. Here, dictionaries are utilized to reverse a map from integer
    format to text format:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f4e42ef6-d95d-464b-b523-d4c8cba3a207.png)'
  prefs: []
  type: TYPE_IMG
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The major steps involved are described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Pre-processing, during this stage, we do pad sequences to bring all observations
    into one fixed dimension, which enhances speed and enables computation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: CNN 1D model development and validation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model evaluation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following code does perform padding operation for adding extra sentences
    which can make up to maximum length of 400 words. By doing this, data will become
    even and easier to perform computation using neural networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/70c9e3df-a73e-4654-8ead-dab9d254c9eb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following deep learning code describes the application of Keras code to
    create a CNN 1D model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following screenshot, the entire model summary has been displayed, indicating
    the number of dimensions and its respective number of neurons utilized. These
    directly impact the number of parameters that will be utilized in computation
    from input data into the final target variable, whether it is `0` or `1`. Hence
    a dense layer has been utilized at the last layer of the network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/abdfbfd6-1fb3-465f-ad18-578f32ee6107.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following code performs model fitting operation on training data in which
    both `X` and `Y` variables are used to train data by batch wise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The model has been trained for three epochs, in which each epoch consumes 5
    seconds on the GPU. But if we observe the following iterations, even though the
    train accuracy is moving up, validation accuracy is decreasing. This phenomenon
    can be identified as model overfitting. This indicates that we need to try some
    other ways to improve the model accuracy rather than just increase the number
    of epochs. Other ways we probably should look at are increasing the architecture
    size and so on. Readers are encouraged to experiment with various combinations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3c7a82dc-aec0-440f-9207-4bbf0a3b3420.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following code is used for prediction of classes for both train and test
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot describes various measurable metrics to judge the
    model performance. From the result, the train accuracy seems significantly high
    at 96%; however, the test accuracy is at a somewhat lower value of 88.2 %. This
    could be due to model overfitting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/89ab2d00-affb-4a62-8f93-a38cde3ef341.png)'
  prefs: []
  type: TYPE_IMG
- en: IMDB sentiment classification using bidirectional LSTM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we are using same IMDB sentiment data to show the difference
    between CNN and RNN methodology in terms of accuracies and so on. Data pre-processing
    steps remain the same; only the architecture of the model varies.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The IMDB dataset from Keras has set of words and its respective sentiment.
    Here is the pre-processing of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The major steps involved are described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Pre-processing, during this stage, we do pad sequences to bring all the observations
    into one fixed dimension, which enhances speed and enables computation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: LSTM model development and validation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model evaluation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The following deep learning code describes the application of Keras code to
    create a bidirectional LSTM model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bidirectional LSTMs have a connection from both forward and backward, which
    enables them to fill in the middle words to get connected well with left and right
    words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the architecture of the model. The embedding layer has been used to
    reduce the dimensions to `128`, followed by bidirectional LSTM, ending up with
    a dense layer for modeling sentiment either zero or one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/72079ae1-a362-4078-8f09-a01ad6a0affa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following code is used for training the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'LSTM models take longer than CNNs because LSTMs are not easily parallelizable
    with GPU (4x to 5x), whereas CNNs (100x) are massively parallelizable. One important
    observation: even after an increase in the training accuracy, the validation accuracy
    was decreasing. This situation indicates overfitting.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9887f540-5eb9-4a05-95e8-09a1df5f0d30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following code has been used for predicting the class for both train and
    test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/89f3a771-4199-4c30-9edb-5f571e93abb6.png)'
  prefs: []
  type: TYPE_IMG
- en: It appears that LSTM did provide slightly less test accuracy compared with CNN;
    however, with careful tuning of the model parameters, we can obtain better accuracies
    in RNNs compared with CNNs.
  prefs: []
  type: TYPE_NORMAL
- en: Visualization of high-dimensional words in 2D with neural word vector visualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will use deep neural networks to visualize words from a high-dimensional
    space in a two-dimensional space.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The *Alice in Wonderland* dataset has been used to extract words and create
    a visualization using the dense network made to be like the encoder-decoder architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The major steps involved are described here:'
  prefs: []
  type: TYPE_NORMAL
- en: Pre-processing, creation of skip-grams and using the middle word to predict
    either the left or the right word.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application of one-hot encoding for feature engineering.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model building using encoder-decoder architecture.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extraction of the encoder architecture to create two-dimensional features for
    visualization from test data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following code creates dictionary, which is a mapping of word to index
    and index to word (vice versa). As we knew, models simply do not work on character/word
    input. Hence, we will be converting words into numeric equivalents (particularly
    integer mapping), and once the computation has been performed using the neural
    network model, the reverse of the mapping (index to word) will be applied to visualize
    them. The counter from the `collections` library has been used for efficient creation
    of dictionaries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code applies word-to-integer mapping and extracts the tri-grams
    from the embedding. Skip-gram is the methodology in which the central word is
    connected to both left and right adjacent words for training, and if during testing
    phase if it predicts correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The following code describes that the length of the dictionary is the vocabulary
    size. Nonetheless, based on user specification, any custom vocabulary size can
    be chosen. Here, we are considering all words though!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on vocabulary size, all independent and dependent variables are transformed
    into vector representations with the following code, in which the number of rows
    would be the number of words and the number of columns would be the vocabulary
    size. The neural network model basically maps the input and output variables over
    the vector space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Out of total 13,868 observations, train and test are split into 70% and 30%,
    which are created as 9,707 and 4,161 respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e9c7b361-7274-4cdb-ba36-da1b08448548.png)'
  prefs: []
  type: TYPE_IMG
- en: The central part of the model is described in the following few lines of deep
    learning code using Keras software. It is a convergent-divergent code, in which
    initially the dimensions of all input words are squeezed to achieve the output
    format.
  prefs: []
  type: TYPE_NORMAL
- en: 'While doing so, the dimensions are reduced to 2D in the second layer. After
    training the model, we will extract up to the second layer for predictions on
    test data. This literally works similar to the conventional encoder-decoder architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code is used to train the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: By carefully observing the accuracy on both the training and validation datasets,
    we can find that the best accuracy values are not even crossing 6%. This happens
    due to limited data and architecture of deep learning models. In order to make
    this really work, we need at least gigabytes of data and large architectures.
    Models too need to be trained for very long. Due to practical constraints and
    illustration purposes, we have just trained for 20 iterations. However, readers
    are encouraged to try various combinations to improve the accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/088aa145-de48-42fd-a671-3b2224d6ec9e.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The following image describes the visualization of the words in two-dimensional
    space. Some words are closer to each other than other words, which indicates closeness
    and relationships with nearby words. For example, words such as `never`, `ever`,
    and `ask` are very close to each other.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7bbb0dc1-8d24-4db3-878c-330052d9f83c.png)'
  prefs: []
  type: TYPE_IMG
