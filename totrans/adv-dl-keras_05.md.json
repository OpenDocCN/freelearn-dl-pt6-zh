["```py\ndef wasserstein_loss(y_label, y_pred):\n    return -K.mean(y_label * y_pred)\n```", "```py\ndiscriminator = gan.discriminator(inputs, activation='linear')\n```", "```py\ngenerator = gan.generator(inputs, image_size)\n```", "```py\ndef build_and_train_models():\n    # load MNIST dataset\n    (x_train, _), (_, _) = mnist.load_data()\n\n    # reshape data for CNN as (28, 28, 1) and normalize\n    image_size = x_train.shape[1]\n    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n    x_train = x_train.astype('float32') / 255\n\n    model_name = \"wgan_mnist\"\n    # network parameters\n    # the latent or z vector is 100-dim\n    latent_size = 100\n # hyper parameters from WGAN paper [2]\n n_critic = 5\n clip_value = 0.01\n    batch_size = 64\n    lr = 5e-5\n    train_steps = 40000\n    input_shape = (image_size, image_size, 1)\n\n    # build discriminator model\n    inputs = Input(shape=input_shape, name='discriminator_input')\n # WGAN uses linear activation in paper [2]\n discriminator = gan.discriminator(inputs, activation='linear')\n optimizer = RMSprop(lr=lr)\n # WGAN discriminator uses wassertein loss\n discriminator.compile(loss=wasserstein_loss,\n optimizer=optimizer,\n metrics=['accuracy'])\n    discriminator.summary()\n\n    # build generator model\n    input_shape = (latent_size, )\n    inputs = Input(shape=input_shape, name='z_input')\n    generator = gan.generator(inputs, image_size)\n    generator.summary()\n\n    # build adversarial model = generator + discriminator\n    # freeze the weights of discriminator \n    # during adversarial training\n    discriminator.trainable = False\n    adversarial = Model(inputs,\n                        discriminator(generator(inputs)),\n                        name=model_name)\n adversarial.compile(loss=wasserstein_loss,\n optimizer=optimizer,\n metrics=['accuracy'])\n    adversarial.summary()\n\n    # train discriminator and adversarial networks\n    models = (generator, discriminator, adversarial)\n    params = (batch_size,\n              latent_size,\n              n_critic,\n              clip_value,\n              train_steps,\n              model_name)\n    train(models, x_train, params)\n```", "```py\ndef train(models, x_train, params):\n    \"\"\"Train the Discriminator and Adversarial Networks\n\n    Alternately train Discriminator and Adversarial networks by batch.\n    Discriminator is trained first with properly labeled real and fake images\n    for n_critic times.\n    Discriminator weights are clipped as a requirement of Lipschitz constraint.\n    Generator is trained next (via Adversarial) with fake images\n    pretending to be real.\n    Generate sample images per save_interval\n\n    # Arguments\n        models (list): Generator, Discriminator, Adversarial models\n        x_train (tensor): Train images\n        params (list) : Networks parameters\n\n    \"\"\"\n    # the GAN models\n    generator, discriminator, adversarial = models\n    # network parameters\n    (batch_size, latent_size, n_critic,\n            clip_value, train_steps, model_name) = params\n    # the generator image is saved every 500 steps\n    save_interval = 500\n    # noise vector to see how the generator output \n    # evolves during training\n    noise_input = np.random.uniform(-1.0, 1.0, size=[16,    \n                                    latent_size])\n    # number of elements in train dataset\n    train_size = x_train.shape[0]\n    # labels for real data\n    real_labels = np.ones((batch_size, 1))\n    for i in range(train_steps):\n        # train discriminator n_critic times\n        loss = 0\n        acc = 0\n        for _ in range(n_critic):\n            # train the discriminator for 1 batch\n            # 1 batch of real (label=1.0) and \n            # fake images (label=-1.0)\n            # randomly pick real images from dataset\n            rand_indexes = np.random.randint(0,\n                                             train_size,         \n                                             size=batch_size)\n            real_images = x_train[rand_indexes]\n            # generate fake images from noise using generator\n            # generate noise using uniform distribution\n            noise = np.random.uniform(-1.0,\n                                      1.0,\n                                      size=[batch_size,                    \n                                      latent_size])\n            fake_images = generator.predict(noise)\n\n            # train the discriminator network\n            # real data label=1, fake data label=-1\n            # instead of 1 combined batch of real and fake images,\n            # train with 1 batch of real data first, then 1 batch\n            # of fake images.\n            # this tweak prevents the gradient from vanishing \n            # due to opposite signs of real and\n            # fake data labels (i.e. +1 and -1) and\n            # small magnitude of weights due to clipping.\n            real_loss, real_acc =                      \n                         discriminator.train_on_batch(real_images,                                   \n                                                      real_labels)\n            fake_loss, fake_acc = \n                         discriminator.train_on_batch(fake_images,\n                                                      real_labels)\n            # accumulate average loss and accuracy\n            loss += 0.5 * (real_loss + fake_loss)\n            acc += 0.5 * (real_acc + fake_acc)\n\n            # clip discriminator weights to satisfy \n            # Lipschitz constraint\n            for layer in discriminator.layers:\n                weights = layer.get_weights()\n                weights = [np.clip(weight,\n                                   -clip_value,\n                                   clip_value) for weight in weights]\n                layer.set_weights(weights)\n\n        # average loss and accuracy per n_critic \n        # training iterations\n        loss /= n_critic\n        acc /= n_critic\n        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n\n        # train the adversarial network for 1 batch\n        # 1 batch of fake images with label=1.0\n        # since the discriminator weights are \n        # frozen in adversarial network\n        # only the generator is trained\n        # generate noise using uniform distribution\n        noise = np.random.uniform(-1.0, 1.0, \n                                  size=[batch_size, latent_size])\n        # train the adversarial network\n        # note that unlike in discriminator training,\n        # we do not save the fake images in a variable\n        # the fake images go to the discriminator input \n        # of the adversarial for classification\n        # fake images are labelled as real\n        # log the loss and accuracy\n        loss, acc = adversarial.train_on_batch(noise, real_labels)\n        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n        print(log)\n        if (i + 1) % save_interval == 0:\n            if (i + 1) == train_steps:\n                show = True\n            else:\n                show = False\n\n            # plot generator images on a periodic basis\n            gan.plot_images(generator,\n                            noise_input=noise_input,\n                            show=show,\n                            step=(i + 1),\n                            model_name=model_name)\n\n    # save the model after training the generator\n    # the trained generator can be reloaded for future \n    # MNIST digit generation\n    generator.save(model_name + \".h5\")\n```", "```py\npython3 wgan-mnist-5.1.2.py --generator=wgan_mnist.h5\n\n```", "```py\ndiscriminator = gan.discriminator(inputs, activation=None)\n```", "```py\ngenerator = gan.generator(inputs, image_size)\n```", "```py\ngan.train(models, x_train, params)\n```", "```py\ndef build_and_train_models():\n    # MNIST dataset\n    (x_train, _), (_, _) = mnist.load_data()\n\n    # reshape data for CNN as (28, 28, 1) and normalize\n    image_size = x_train.shape[1]\n    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n    x_train = x_train.astype('float32') / 255\n\n    model_name = \"lsgan_mnist\"\n    # network parameters\n    # the latent or z vector is 100-dim\n    latent_size = 100\n    input_shape = (image_size, image_size, 1)\n    batch_size = 64\n    lr = 2e-4\n    decay = 6e-8\n    train_steps = 40000\n\n    # build discriminator model\n    inputs = Input(shape=input_shape, name='discriminator_input')\n discriminator = gan.discriminator(inputs, activation=None)\n    # [1] uses Adam, but discriminator converges \n    # easily with RMSprop\n    optimizer = RMSprop(lr=lr, decay=decay)\n # LSGAN uses MSE loss [2]\n discriminator.compile(loss='mse',\n optimizer=optimizer,\n metrics=['accuracy'])\n    discriminator.summary()\n\n    # build generator model\n    input_shape = (latent_size, )\n    inputs = Input(shape=input_shape, name='z_input')\n    generator = gan.generator(inputs, image_size)\n    generator.summary()\n\n    # build adversarial model = generator + discriminator\n    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n    # freeze the weights of discriminator \n    # during adversarial training\n    discriminator.trainable = False\n    adversarial = Model(inputs,\n                        discriminator(generator(inputs)),\n                        name=model_name)\n # LSGAN uses MSE loss [2]\n adversarial.compile(loss='mse',\n optimizer=optimizer,\n metrics=['accuracy'])\n    adversarial.summary()\n\n    # train discriminator and adversarial networks\n    models = (generator, discriminator, adversarial)\n    params = (batch_size, latent_size, train_steps, model_name)\n gan.train(models, x_train, params)\n\n```", "```py\npython3 lsgan-mnist-5.2.1.py --generator=lsgan_mnist.h5\n\n```", "```py\ndef discriminator(inputs,\n                  activation='sigmoid',\n                  num_labels=None,\n                  num_codes=None):\n    \"\"\"Build a Discriminator Model\n\n    Stack of LeakyReLU-Conv2D to discriminate real from fake\n    The network does not converge with BN  so it is not used here\n    unlike in [1]\n\n    # Arguments\n        inputs (Layer): Input layer of the discriminator (the image)\n        activation (string): Name of output activation layer\n        num_labels (int): Dimension of one-hot labels for ACGAN & InfoGAN\n        num_codes (int): num_codes-dim Q network as output \n                    if StackedGAN or 2 Q networks if InfoGAN\n\n    # Returns\n        Model: Discriminator Model\n    \"\"\"\n    kernel_size = 5\n    layer_filters = [32, 64, 128, 256]\n\n    x = inputs\n    for filters in layer_filters:\n        # first 3 convolution layers use strides = 2\n        # last one uses strides = 1\n        if filters == layer_filters[-1]:\n            strides = 1\n        else:\n            strides = 2\n        x = LeakyReLU(alpha=0.2)(x)\n        x = Conv2D(filters=filters,\n                   kernel_size=kernel_size,\n                   strides=strides,\n                   padding='same')(x)\n\n    x = Flatten()(x)\n    # default output is probability that the image is real\n    outputs = Dense(1)(x)\n    if activation is not None:\n        print(activation)\n        outputs = Activation(activation)(outputs)\n\n if num_labels:\n # ACGAN and InfoGAN have 2nd output\n # 2nd output is 10-dim one-hot vector of label\n layer = Dense(layer_filters[-2])(x)\n labels = Dense(num_labels)(layer)\n labels = Activation('softmax', name='label')(labels)\n if num_codes is None:\n outputs = [outputs, labels]\n        else:\n            # InfoGAN have 3rd and 4th outputs\n            # 3rd output is 1-dim continous Q of 1st c given x\n            code1 = Dense(1)(layer)\n            code1 = Activation('sigmoid', name='code1')(code1)\n\n            # 4th output is 1-dim continuous Q of 2nd c given x\n            code2 = Dense(1)(layer)\n            code2 = Activation('sigmoid', name='code2')(code2)\n\n            outputs = [outputs, labels, code1, code2]\n    elif num_codes is not None:\n        # z0_recon is reconstruction of z0 normal distribution\n        z0_recon =  Dense(num_codes)(x)\n        z0_recon = Activation('tanh', name='z0')(z0_recon)\n        outputs = [outputs, z0_recon]\n\n    return Model(inputs, outputs, name='discriminator')\n```", "```py\ndiscriminator = gan.discriminator(inputs, num_labels=num_labels)\n```", "```py\ndef generator(inputs,\n              image_size,\n              activation='sigmoid',\n              labels=None,\n              codes=None):\n    \"\"\"Build a Generator Model\n\n    Stack of BN-ReLU-Conv2DTranpose to generate fake images.\n    Output activation is sigmoid instead of tanh in [1].\n    Sigmoid converges easily.\n\n    # Arguments\n        inputs (Layer): Input layer of the generator (the z-vector)\n        image_size (int): Target size of one side (assuming square image)\n        activation (string): Name of output activation layer\n        labels (tensor): Input labels\n        codes (list): 2-dim disentangled codes for InfoGAN\n\n    # Returns\n        Model: Generator Model\n    \"\"\"\n    image_resize = image_size // 4\n    # network parameters\n    kernel_size = 5\n    layer_filters = [128, 64, 32, 1]\n\n if labels is not None:\n if codes is None:\n # ACGAN labels\n # concatenate z noise vector and one-hot labels\n inputs = [inputs, labels]\n        else:\n            # infoGAN codes\n            # concatenate z noise vector, one-hot labels \n            # and codes 1 & 2\n            inputs = [inputs, labels] + codes\n        x = concatenate(inputs, axis=1)\n    elif codes is not None:\n        # generator 0 of StackedGAN\n        inputs = [inputs, codes]\n        x = concatenate(inputs, axis=1)\n    else:\n        # default input is just 100-dim noise (z-code)\n        x = inputs\n\n    x = Dense(image_resize * image_resize * layer_filters[0])(x)\n    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n\n    for filters in layer_filters:\n        # first two convolution layers use strides = 2\n        # the last two use strides = 1\n        if filters > layer_filters[-2]:\n            strides = 2\n        else:\n            strides = 1\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(filters=filters,\n                            kernel_size=kernel_size,\n                            strides=strides,\n                            padding='same')(x)\n\n    if activation is not None:\n        x = Activation(activation)(x)\n\n    # generator output is the synthesized image x\n    return Model(inputs, x, name='generator')\n```", "```py\ngenerator = gan.generator(inputs, image_size, labels=labels)\n```", "```py\ndef build_and_train_models():\n    # load MNIST dataset\n    (x_train, y_train), (_, _) = mnist.load_data()\n\n    # reshape data for CNN as (28, 28, 1) and normalize\n    image_size = x_train.shape[1]\n    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n    x_train = x_train.astype('float32') / 255\n\n    # train labels\n    num_labels = len(np.unique(y_train))\n    y_train = to_categorical(y_train)\n\n    model_name = \"acgan_mnist\"\n    # network parameters\n    latent_size = 100\n    batch_size = 64\n    train_steps = 40000\n    lr = 2e-4\n    decay = 6e-8\n    input_shape = (image_size, image_size, 1)\n    label_shape = (num_labels, )\n\n    # build discriminator Model\n    inputs = Input(shape=input_shape, name='discriminator_input')\n    # call discriminator builder with 2 outputs, \n    # pred source and labels\n discriminator = gan.discriminator(inputs, num_labels=num_labels)\n # [1] uses Adam, but discriminator converges easily with RMSprop\n optimizer = RMSprop(lr=lr, decay=decay)\n # 2 loss fuctions: 1) probability image is real\n # 2) class label of the image\n loss = ['binary_crossentropy', 'categorical_crossentropy']\n discriminator.compile(loss=loss,\n optimizer=optimizer,\n metrics=['accuracy'])\n    discriminator.summary()\n\n    # build generator model\n    input_shape = (latent_size, )\n    inputs = Input(shape=input_shape, name='z_input')\n    labels = Input(shape=label_shape, name='labels')\n    # call generator builder with input labels\n    generator = gan.generator(inputs, image_size, labels=labels)\n    generator.summary()\n\n    # build adversarial model = generator + discriminator\n    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n    # freeze the weights of discriminator \n    # during adversarial training\n    discriminator.trainable = False\n adversarial = Model([inputs, labels],\n discriminator(generator([inputs, labels])),\n name=model_name)\n # same 2 loss fuctions: 1) probability image is real\n # 2) class label of the image\n adversarial.compile(loss=loss,\n optimizer=optimizer,\n metrics=['accuracy'])\n    adversarial.summary()\n\n    # train discriminator and adversarial networks\n    models = (generator, discriminator, adversarial)\n    data = (x_train, y_train)\n    params = (batch_size, latent_size, train_steps, num_labels, model_name)\n    train(models, data, params)\n```", "```py\ndef train(models, data, params):\n    \"\"\"Train the discriminator and adversarial Networks\n\n    Alternately train discriminator and adversarial networks by batch.\n    Discriminator is trained first with real and fake images and\n    corresponding one-hot labels.\n    Adversarial is trained next with fake images pretending to be real and \n    corresponding one-hot labels.\n    Generate sample images per save_interval.\n\n    # Arguments\n        models (list): Generator, Discriminator, Adversarial models\n        data (list): x_train, y_train data\n        params (list): Network parameters\n\n    \"\"\"\n    # the GAN models\n    generator, discriminator, adversarial = models\n    # images and their one-hot labels\n    x_train, y_train = data\n    # network parameters\n    batch_size, latent_size, train_steps, num_labels, model_name = params\n    # the generator image is saved every 500 steps\n    save_interval = 500\n    # noise vector to see how the generator output \n    # evolves during training\n    noise_input = np.random.uniform(-1.0, \n                                    1.0,\n                                    size=[16, latent_size])\n # class labels are 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5\n # the generator must produce these MNIST digits\n noise_label = np.eye(num_labels)[np.arange(0, 16) % num_labels]\n    # number of elements in train dataset\n    train_size = x_train.shape[0]\n    print(model_name,\n          \"Labels for generated images: \",\n          np.argmax(noise_label, axis=1))\n\n    for i in range(train_steps):\n        # train the discriminator for 1 batch\n        # 1 batch of real (label=1.0) and fake images (label=0.0)\n        # randomly pick real images and corresponding labels \n        # from dataset \n        rand_indexes = np.random.randint(0, \n                                         train_size, \n                                         size=batch_size)\n        real_images = x_train[rand_indexes]\n real_labels = y_train[rand_indexes]\n        # generate fake images from noise using generator\n        # generate noise using uniform distribution\n        noise = np.random.uniform(-1.0,\n                                  1.0,\n                                  size=[batch_size, latent_size])\n # randomly pick one-hot labels\n fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n batch_size)]\n        # generate fake images\n        fake_images = generator.predict([noise, fake_labels])\n        # real + fake images = 1 batch of train data\n        x = np.concatenate((real_images, fake_images))\n # real + fake labels = 1 batch of train data labels\n labels = np.concatenate((real_labels, fake_labels))\n        # label real and fake images\n        # real images label is 1.0\n        y = np.ones([2 * batch_size, 1])\n        # fake images label is 0.0\n        y[batch_size:, :] = 0\n        # train discriminator network, log the loss and accuracy\n        # ['loss', 'activation_1_loss', 'label_loss', \n        # 'activation_1_acc', 'label_acc']\n metrics  = discriminator.train_on_batch(x, [y, labels])\n fmt = \"%d: [disc loss: %f, srcloss: %f, lblloss: %f, srcacc: %f, lblacc: %f]\"\n log = fmt % (i, metrics[0], metrics[1], metrics[2], metrics[3], metrics[4])\n\n        # train the adversarial network for 1 batch\n        # 1 batch of fake images with label=1.0 and\n        # corresponding one-hot label or class \n        # since the discriminator weights are frozen \n        # in adversarial network\n        # only the generator is trained\n        # generate noise using uniform distribution\n        noise = np.random.uniform(-1.0,\n                                  1.0,\n                                  size=[batch_size, latent_size])\n # randomly pick one-hot labels\n fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n batch_size)]\n        # label fake images as real\n        y = np.ones([batch_size, 1])\n        # train the adversarial network \n        # note that unlike in discriminator training, \n        # we do not save the fake images in a variable\n        # the fake images go to the discriminator input \n        # of the adversarial\n        # for classification\n        # log the loss and accuracy\n metrics  = adversarial.train_on_batch([noise, fake_labels],\n [y, fake_labels])\n fmt = \"%s [advr loss: %f, srcloss: %f, lblloss: %f, srcacc: %f, lblacc: %f]\"\n log = fmt % (log, metrics[0], metrics[1], metrics[2], metrics[3], metrics[4])\n        print(log)\n        if (i + 1) % save_interval == 0:\n            if (i + 1) == train_steps:\n                show = True\n            else:\n                show = False\n\n            # plot generator images on a periodic basis\n            gan.plot_images(generator,\n                        noise_input=noise_input,\n                        noise_label=noise_label,\n                        show=show,\n                        step=(i + 1),\n                        model_name=model_name)\n\n    # save the model after training the generator\n    # the trained generator can be reloaded for \n    # future MNIST digit generation\n    generator.save(model_name + \".h5\")\n```", "```py\n[0 1 2 3 \n 4 5 6 7 \n 8 9 0 1 \n 2 3 4 5]\n\n```", "```py\npython3 acgan-mnist-5.3.1.py --generator=acgan_mnist.h5\n\n```", "```py\npython3 acgan-mnist-5.3.1.py --generator=acgan_mnist.h5 --digit=3\n\n```"]