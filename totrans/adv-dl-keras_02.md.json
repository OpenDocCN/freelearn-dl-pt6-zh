["```py\ny = Conv2D(32)(x)\n```", "```py\nimport numpy as np\nfrom keras.layers import Dense, Dropout, Input\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten\nfrom keras.models import Model\nfrom keras.datasets import mnist\nfrom keras.utils import to_categorical\n\n# compute the number of labels\nnum_labels = len(np.unique(y_train))\n\n# convert to one-hot vector\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# reshape and normalize input images\nimage_size = x_train.shape[1]\nx_train = np.reshape(x_train,[-1, image_size, image_size, 1])\nx_test = np.reshape(x_test,[-1, image_size, image_size, 1])\nx_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\n\n# network parameters\n# image is processed as is (square grayscale)\ninput_shape = (image_size, image_size, 1)\nbatch_size = 128\nkernel_size = 3\nfilters = 64 \ndropout = 0.3 \n\n# use functional API to build cnn layers\ninputs = Input(shape=input_shape)\ny = Conv2D(filters=filters,\n           kernel_size=kernel_size,\n           activation='relu')(inputs)\ny = MaxPooling2D()(y)\ny = Conv2D(filters=filters,\n           kernel_size=kernel_size,\n           activation='relu')(y)\ny = MaxPooling2D()(y)\ny = Conv2D(filters=filters,\n           kernel_size=kernel_size,\n           activation='relu')(y)\n# image to vector before connecting to dense layer\ny = Flatten()(y)\n# dropout regularization\ny = Dropout(dropout)(y)\noutputs = Dense(num_labels, activation='softmax')(y)\n\n# build the model by supplying inputs/outputs\nmodel = Model(inputs=inputs, outputs=outputs)\n# network model in text\nmodel.summary()\n\n# classifier loss, Adam optimizer, classifier accuracy\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# train the model with input images and labels\nmodel.fit(x_train,\n          y_train,\n          validation_data=(x_test, y_test),\n          epochs=20,\n          batch_size=batch_size)\n\n# model accuracy on test dataset\nscore = model.evaluate(x_test, y_test, batch_size=batch_size)\nprint(\"\\nTest accuracy: %.1f%%\" % (100.0 * score[1]))\n```", "```py\nimport numpy as np\n\nfrom keras.layers import Dense, Dropout, Input\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten\nfrom keras.models import Model\nfrom keras.layers.merge import concatenate\nfrom keras.datasets import mnist\nfrom keras.utils import to_categorical\nfrom keras.utils import plot_model\n\n# load MNIST dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n   # compute the number of labels\n   num_labels = len(np.unique(y_train))\n\n   # convert to one-hot vector\n   y_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# reshape and normalize input images\nimage_size = x_train.shape[1]\nx_train = np.reshape(x_train,[-1, image_size, image_size, 1])\nx_test = np.reshape(x_test,[-1, image_size, image_size, 1])\nx_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\n\n# network parameters\ninput_shape = (image_size, image_size, 1)\nbatch_size = 32\nkernel_size = 3\ndropout = 0.4\nn_filters = 32\n\n# left branch of Y network\nleft_inputs = Input(shape=input_shape)\nx = left_inputs\nfilters = n_filters\n# 3 layers of Conv2D-Dropout-MaxPooling2D\n# number of filters doubles after each layer (32-64-128)\nfor i in range(3):\n    x = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               padding='same',\n               activation='relu')(x)\n    x = Dropout(dropout)(x)\n    x = MaxPooling2D()(x)\n    filters *= 2\n\n# right branch of Y network\nright_inputs = Input(shape=input_shape)\ny = right_inputs\nfilters = n_filters\n# 3 layers of Conv2D-Dropout-MaxPooling2D\n# number of filters doubles after each layer (32-64-128)\nfor i in range(3):\n    y = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               padding='same',\n               activation='relu',\n               dilation_rate=2)(y)\n    y = Dropout(dropout)(y)\n    y = MaxPooling2D()(y)\n    filters *= 2\n\n# merge left and right branches outputs\ny = concatenate([x, y])\n# feature maps to vector before connecting to Dense layer\ny = Flatten()(y)\ny = Dropout(dropout)(y)\noutputs = Dense(num_labels, activation='softmax')(y)\n\n# build the model in functional API\nmodel = Model([left_inputs, right_inputs], outputs)\n# verify the model using graph\nplot_model(model, to_file='cnn-y-network.png', show_shapes=True)\n# verify the model using layer text description\nmodel.summary()\n\n# classifier loss, Adam optimizer, classifier accuracy\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# train the model with input images and labels\nmodel.fit([x_train, x_train],\n          y_train,\n          validation_data=([x_test, x_test], y_test),\n          epochs=20,\n          batch_size=batch_size)\n\n# model accuracy on test dataset\nscore = model.evaluate([x_test, x_test], y_test, batch_size=batch_size)\nprint(\"\\nTest accuracy: %.1f%%\" % (100.0 * score[1]))\n```", "```py\nfrom keras.datasets import cifar10\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n```", "```py\nn = 3\n\n# model version\n# orig paper: version = 1 (ResNet v1), \n# Improved ResNet: version = 2 (ResNet v2)\nversion = 1\n\n# computed depth from supplied model parameter n\nif version == 1:\n    depth = n * 6 + 2\nelif version == 2:\n    depth = n * 9 + 2\n…\nif version == 2:\n    model = resnet_v2(input_shape=input_shape, depth=depth)\nelse:\n    model = resnet_v1(input_shape=input_shape, depth=depth)\n```", "```py\ndef resnet_v1(input_shape, depth, num_classes=10):\n    if (depth - 2) % 6 != 0:\n        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n    # Start model definition.\n    num_filters = 16\n    num_res_blocks = int((depth - 2) / 6)\n\n    inputs = Input(shape=input_shape)\n    x = resnet_layer(inputs=inputs)\n    # Instantiate the stack of residual units\n    for stack in range(3):\n        for res_block in range(num_res_blocks):\n            strides = 1\n            if stack > 0 and res_block == 0:\n                strides = 2  # downsample\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters,\n                             strides=strides)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters,\n                             activation=None)\n            if stack > 0 and res_block == 0\n                # linear projection residual shortcut connection \n                # to match changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = add([x, y])\n            x = Activation('relu')(x)\n        num_filters *= 2\n\n    # Add classifier on top.\n    # v1 does not use BN after last shortcut connection-ReLU\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation='softmax',\n                    kernel_initializer='he_normal')(y)\n\n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n```", "```py\ndef resnet_v2(input_shape, depth, num_classes=10):\n    if (depth - 2) % 9 != 0:\n        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n    # Start model definition.\n    num_filters_in = 16\n    num_res_blocks = int((depth - 2) / 9)\n\n    inputs = Input(shape=input_shape)\n    # v2 performs Conv2D with BN-ReLU on input \n    # before splitting into 2 paths\n    x = resnet_layer(inputs=inputs,\n                     num_filters=num_filters_in,\n                     conv_first=True)\n\n    # Instantiate the stack of residual units\n    for stage in range(3):\n        for res_block in range(num_res_blocks):\n            activation = 'relu'\n            batch_normalization = True\n            strides = 1\n            if stage == 0:\n                num_filters_out = num_filters_in * 4\n                if res_block == 0:  # first layer and first stage\n                    activation = None\n                    batch_normalization = False\n            else:\n                num_filters_out = num_filters_in * 2\n                if res_block == 0:  # 1st layer but not 1st stage\n                    strides = 2    # downsample\n\n            # bottleneck residual unit\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters_in,\n                             kernel_size=1,\n                             strides=strides,\n                             activation=activation,\n                             batch_normalization=batch_normalization,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_in,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_out,\n                             kernel_size=1,\n                             conv_first=False)\n            if res_block == 0:\n                # linear projection residual shortcut connection \n                # to match changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters_out,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = add([x, y])\n\n        num_filters_in = num_filters_out\n\n    # add classifier on top.\n    # v2 has BN-ReLU before Pooling\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation='softmax',\n                    kernel_initializer='he_normal')(y)\n\n    # instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n```", "```py\nn = 12\n\n# model version\n# orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\nversion = 2\n\n# computed depth from supplied model parameter n\nif version == 1:\n    depth = n * 6 + 2\nelif version == 2:\n    depth = n * 9 + 2\n…\nif version == 2:\n    model = resnet_v2(input_shape=input_shape, depth=depth)\nelse:\n    model = resnet_v1(input_shape=input_shape, depth=depth)\n```", "```py\n# start model definition\n# densenet CNNs (composite function) are made of BN-ReLU-Conv2D\ninputs = Input(shape=input_shape)\nx = BatchNormalization()(inputs)\nx = Activation('relu')(x)\nx = Conv2D(num_filters_bef_dense_block,\n           kernel_size=3,\n           padding='same',\n           kernel_initializer='he_normal')(x)\nx = concatenate([inputs, x])\n\n# stack of dense blocks bridged by transition layers\nfor i in range(num_dense_blocks):\n    # a dense block is a stack of bottleneck layers\n    for j in range(num_bottleneck_layers):\n        y = BatchNormalization()(x)\n        y = Activation('relu')(y)\n        y = Conv2D(4 * growth_rate,\n                   kernel_size=1,\n                   padding='same',\n                   kernel_initializer='he_normal')(y)\n        if not data_augmentation:\n            y = Dropout(0.2)(y)\n        y = BatchNormalization()(y)\n        y = Activation('relu')(y)\n        y = Conv2D(growth_rate,\n                   kernel_size=3,\n                   padding='same',\n                   kernel_initializer='he_normal')(y)\n        if not data_augmentation:\n            y = Dropout(0.2)(y)\n        x = concatenate([x, y])\n\n    # no transition layer after the last dense block\n    if i == num_dense_blocks - 1:\n        continue\n\n    # transition layer compresses num of feature maps and \n    # reduces the size by 2\n    num_filters_bef_dense_block += num_bottleneck_layers * growth_rate\n    num_filters_bef_dense_block = int(num_filters_bef_dense_block * compression_factor)\n    y = BatchNormalization()(x)\n    y = Conv2D(num_filters_bef_dense_block,\n               kernel_size=1,\n               padding='same',\n               kernel_initializer='he_normal')(y)\n    if not data_augmentation:\n        y = Dropout(0.2)(y)\n    x = AveragePooling2D()(y)\n\n# add classifier on top\n# after average pooling, size of feature map is 1 x 1\nx = AveragePooling2D(pool_size=8)(x)\ny = Flatten()(x)\noutputs = Dense(num_classes,\n                kernel_initializer='he_normal',\n                activation='softmax')(y)\n\n# instantiate and compile model\n# orig paper uses SGD but RMSprop works better for DenseNet\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=RMSprop(1e-3),\n              metrics=['accuracy'])\nmodel.summary()\n```"]