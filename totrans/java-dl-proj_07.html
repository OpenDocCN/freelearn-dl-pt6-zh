<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Stock Price Prediction Using LSTM Network</h1>
                </header>
            
            <article>
                
<p>Stock market price prediction is one of the most challenging tasks. One of the major reasons is noise and the volatile features of this type of dataset. Therefore, how to predict stock price movement accurately is still an open question for the modern trading world. However classical machine learning algorithms, such as Support vector machines, decision trees, and tree ensembles (for example, random forest and gradient-boosted trees), have been used in the last decade.</p>
<p>However, stock market prices have severe volatility and a historical perspective, which make them suited for time series analysis. This also challenges those classical algorithms, since long-term dependencies cannot be availed using those algorithms. Considering these challenges and the limitations of existing algorithms, in this chapter, we will see how to develop a real-life p<span class="col-11">lain stock open or close</span> <span class="col-11">price prediction using, LSTM on top of DL4J library</span>.</p>
<p>A time series dataset generated from a real-life stock dataset will be used to train the LSTM model, which will be used to predict only one day ahead at a time. Briefly, we will learn the following topics throughout this end-to-end project:</p>
<ul>
<li>Stock price prediction and online trading</li>
<li>Data collection and description</li>
<li>Stock price prediction with LSTM</li>
<li>FAQs.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">State-of-the-art automated stock trading</h1>
                </header>
            
            <article>
                
<p>Usually, in a security exchange, exchanges maintain order book lists of all buy and sell orders with their quantity and prices, and they execute them when a match is found between somebody buying and selling. In addition, exchanges keep and provide statistics about state trading, often captured as <strong>OHCL</strong> (short for, <strong>open-high-close-low</strong>) and volume for both currencies of a trader pair.</p>
<p>By the way, bar charts are used<span>,</span> showing open, high, low, and closing prices. Unlike line charts, OHLC charts enable technical analysts to evaluate intra-day volatility and see where prices opened and closed. Take a look at this diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-746 image-border" src="assets/82d2422a-194a-432b-ba95-c5cb07a2f637.png" style=""/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">OHLC pricing model showing the open, high, low, and close <span class="embed link">prices</span> of a certain time period (source: http://en.tradimo.com/tradipedia/ohlc-chart/)</div>
<p>This data is being presented as aggregated in some periods, from seconds to days, and even months. There are dedicated servers working on collecting this data for professional traders and institutions. Although you cannot expect to have all the order data available for free, some of it is accessible to the public and can be used. The first set is historical stock trading data (OHLC), and the second contains the technical indicators of stock trading.</p>
<p>For example, Bitcoin, which is one of the first cryptocurrencies, has attracted the interest of investors and traders. This is because of the following:</p>
<ul>
<li>With Bitcoin, is possible to start trading</li>
<li>Bitcoin allows you to stay pseudo-anonymous</li>
<li>There has been, dramatic growth during <span>Bitcoin's history </span>(see the following graph for some statistics), which lures long-term investors</li>
<li>There is high volatility<span>, which </span>attracts daytraders</li>
</ul>
<p>It is hard to predict the value of Bitcoin in the long term, as the value behind Bitcoin is less tangible, and its price mostly reflects market perception and is highly dependent on news, regulations, collaboration of governments and banks, technical issues of platform, such as transactions fees and size of block, interest of institutional investors in including Bitcoin into their portfolio and so on. Take a look at this screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5ff3ea00-951a-4fdb-81e1-cff8e2922efb.jpg" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Bitcoin and its dramatic price increases until September 2017 (source: http://www.bitcoin2040.com/bitcoin-price-history/)</div>
<p>Now the question would be how to analyze this dataset in an automated way to help an investor or an online currency trader. Well, in the world of traditional securities, such as company's stocks, it used to be humans who would do the analytics, predict <span>stock </span>prices, and make the trades. Currently, the volume of Bitcoin trading is relatively low compared to traditional exchanges. Two of the reasons for this are high volatility in the stock market and regulations of cryptocurrencies. Take a look at this diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/71929ab3-01a2-46fa-8a9d-fee88f1af575.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Bitcoin buy and sell orders for the BTC/USD pair (until June 18th, 2018, source: https://cex.io/trade#)</div>
<p>So, today, people mostly buy and sell Bitcoins with all the consequences of irrational behavior connected to that, but some attempts to automate <span>Bitcoin</span> trading have been made. The most famous one was a paper by MIT and another one by Stanford researchers, published in 2014.</p>
<p>Many things have changed, and taking into account the massive Bitcoin price increase during the last three years, anyone who would just buy and hold would be satisfied enough with the results. Definitely, some traders use <strong>machine learning</strong> (<strong>ML</strong>) for trading, and such applications look promising. Up to now, a few best possible approaches.</p>
<p>For the training, use order-book data instead of derived <em>OHLC + volume data</em>. Therefore, for training and prediction, use data in the following way:</p>
<ul>
<li>Split the data into a time series of a certain size (where size is a parameter to adjust).</li>
<li>Cluster the time series data into <em>K</em> clusters, where <em>K</em> is the only parameter to tune. It is assumed that clusters with some natural trends will appear (sharp drop/rise in price and so on).</li>
<li>For each cluster, train the regression/classifier to predict the price and the price change, respectively.</li>
</ul>
<p class="CDPAlignLeft CDPAlign">For the inferencing and evaluation, this approach considers the most recent time series with the size of a specific window and trains the model. Then it classifies the data as follows:</p>
<ul>
<li>It takes the most-recent time series with window size used for training and classifies itâ€”which of the clusters does it belong to?</li>
<li>It uses the ML model to predict the clusters for the price and the price change</li>
</ul>
<p>This solution comes from 2014, but, still, it gives a certain level of robustness. By having many parameters to identify, and not having order-book historical data available, in this project, we use a simpler approach and dataset.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Developing a stock price predictive model</h1>
                </header>
            
            <article>
                
<p>As stated earlier, the stock market price has severe volatility and historical perspective, which make it suited for time analysis. This also challenges those classical algorithms, since long-term dependencies cannot be availed using those algorithms.</p>
<p>As outlined in following diagram, first we collect historical financial data. The data is then converted into a time series after the necessary preprocessing and feature engineering. The resultant time series data is then fed into the LSTM to carry out the training. The following diagram illustrates this:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-691 image-border" src="assets/f14e1f05-03e4-49e8-b51d-2cb98fb5e010.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">High-level data pipeline of the prototype used for this project</div>
<p>Therefore, we will be using LSTM not only because it outperforms classical algorithms but also <span>because we can </span>solve long-term dependencies with it. Consequently, our project will have the following steps:</p>
<ol>
<li>Load and preprocess the data, and split it into train-and-test sets</li>
<li>Train the <kbd>LSTM</kbd> model with the data</li>
<li>Evaluate the model on test data</li>
<li>Visualize the model's performance</li>
</ol>
<p>We will go into the details of each step. However, before that, knowing about the dataset is mandatory.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data collection and exploratory analysis</h1>
                </header>
            
            <article>
                
<p>As stated earlier, we will utilize historical stock data for training our LSTM network. The dataset has one minute OHLC data from 506 different securities for the period of January 2016 to December 2016. Let's take a look at the data we'll be using:</p>
<pre>//DataPreview.java<br/><strong>SparkSession</strong> spark = <strong>SparkSession</strong>.<em>builder</em>().master("local").appName("StockPricePredictor").getOrCreate();<br/>spark.conf().set("<strong>spark.sql.crossJoin.enabled</strong>", "true");//enables cross joining across Spark DataFrames<br/><br/>// load data from csv file<br/><strong>String</strong> filename = "data/prices-split-adjusted.csv"; <br/><strong>Dataset&lt;Row&gt;</strong> data = spark.read().option("inferSchema", <strong>false</strong>).option("header", <strong>true</strong>)<br/>       .format("csv").load(filename)<br/>             .withColumn("openPrice", functions.<em>col</em>("open").cast("double")).drop("open")<br/>             .withColumn("closePrice", functions.<em>col</em>("close").cast("double")).drop("close")<br/>             .withColumn("lowPrice", functions.<em>col</em>("low").cast("double")).drop("low")<br/>             .withColumn("highPrice", functions.<em>col</em>("high").cast("double")).drop("high")<br/>             .withColumn("volumeTmp", functions.<em>col</em>("volume").cast("double")).drop("volume")<br/>             .toDF("date", "symbol", "open", "close", "low", "high", "volume");<br/>data.show(10);</pre>
<p>The following snapshot shows the output from this code:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-692 image-border" src="assets/208ceae0-fcfb-426c-8b6a-9155f4a640b9.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">A snapshot of the historical dataset used in this project</div>
<p>As shown in the preceding screenshot, our dataset has seven features. They're described as follows:</p>
<ul>
<li><kbd>date</kbd>: Time elapsed between January 2016 and December 2016</li>
<li><kbd>symbol</kbd>: Ticker symbols for 506 different securities</li>
<li><kbd>open</kbd>: The price at the opening of the time interval</li>
<li><kbd>close</kbd>: The price at the closing of the time interval</li>
<li><kbd>high</kbd>: The highest price from all orders executed during the interval</li>
<li><kbd>low</kbd>: Same, but the lowest price</li>
<li><kbd>volume</kbd>: The sum of all stocks that were transferred during the time interval</li>
</ul>
<p>Now let's take a look at some ticker symbols (see more in the <kbd>securities.csv</kbd> file):</p>
<pre>data.createOrReplaceTempView("stock");<br/>spark.sql("<strong>SELECT DISTINCT symbol FROM stock GROUP BY symbol</strong>").show(10);</pre>
<p>The is snapshot shows the output from the previous code:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-693 image-border" src="assets/f37203cb-a74a-45d1-a265-b15798aa6f39.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Some symbols whose stock price data is used in this project</div>
<p>If we need to learn about securities, the following table gives us some insight into this:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-695 image-border" src="assets/3a316da5-b3f4-456e-8f19-ae25733137ce.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Some securities and their details, whose stock price data is used in this project</div>
<p>Then we decide to see the average price of four categoriesâ€”open, close, low, and high<span>â€”</span>for all individual securities. Take a look at this code:</p>
<pre>spark.sql("<strong>SELECT</strong> symbol, avg(open) as avg_open, "<br/>                + "avg(close) as avg_close, "<br/>                + "avg(low) as avg_low, "<br/>                + "avg(high) as avg_high "<br/>                + "<strong>FROM</strong> stock <strong>GROUP BY</strong> symbol")<br/>                .show(10); </pre>
<p class="mce-root">This snapshot shows the output from the previous code:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-697 image-border" src="assets/0d3ef10e-1382-4c28-925b-47e88fdf52dd.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Average prices for the open, close, low, and high categories</div>
<p>The preceding table, however, did not provide much insight, except when it came to the average prices. Therefore, knowing the minimum and maximum prices gives us an idea whether the stock market <span>really </span>has very high volatility. Take a look at this code:</p>
<pre>spark.sql("<strong>SELECT</strong> symbol, "<br/>                + "<strong>MIN</strong>(open) as min_open, <strong>MAX</strong>(open) as max_open, "<br/>                + "<strong>MIN</strong>(close) as min_close, <strong>MAX</strong>(close) as max_close, "<br/>                + "<strong>MIN</strong>(low) as min_low, <strong>MAX</strong>(low) as max_low, "<br/>                + "<strong>MIN</strong>(high) as min_high, <strong>MAX</strong>(high) as max_high "<br/>                + "<strong>FROM</strong> stock <strong>GROUP BY</strong> symbol")<br/>                .show(10);   </pre>
<p class="mce-root">This snapshot shows the code's output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/04cd7d7a-8537-4109-82b3-ad82144cae72.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Average max and min prices for the open, close, low, and high categories</div>
<p>This table shows, for example, that the minimum opening and closing prices are not significantly different. However, the maximum opening price or even the closing price is very different. This is the nature of time series data, and it motivated me to choose <kbd>LSTM</kbd> by converting the data into a time series.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Preparing the training and test sets</h1>
                </header>
            
            <article>
                
<p>One of the most important parts of the data science pipeline, after data collection (which was in a sense outsourcedâ€”we use data collected by others) is data preprocessing, that is, clearing the dataset and transforming it to suit our needs.</p>
<p>So, our goal is to predict the direction of price change from the actual price in dollars over time. To do that, we define variables such as <kbd>file</kbd>, <kbd>symbol</kbd>, <kbd>batchSize</kbd>, <kbd>splitRatio</kbd>, and <kbd>epochs</kbd>. You can see the explanation of each variable in the inline comments within this code:</p>
<pre>// StockPricePrediction.java<br/><strong>String</strong> file = "data/prices-split-adjusted.csv";<br/><strong>String</strong> symbol = "GRMN"; // stock name<br/><strong>int</strong> batchSize = 128; // mini-batch size<br/><strong>double</strong> splitRatio = 0.8; // 80% for training, 20% for testing<br/><strong>int</strong> epochs = 100; // training epochs</pre>
<p>We use the <kbd>StockDataSetIterator</kbd> constructor variable to prepare the dataset for the model. Here, we prepare the input dataset for the model as a sequence format for <kbd>category = PriceCategory.ALL</kbd>, which means we will predict all five price categories (open, close, low, high, and volume). Take a look at this code:</p>
<pre>//StockPricePrediction.java<br/>System.<strong><em>out</em></strong>.println("Creating dataSet iterator...");<br/><strong>PriceCategory</strong> category = PriceCategory.<strong><em>ALL</em></strong>; // CLOSE: predict close price<br/><br/><em>iterator</em> = <strong>new</strong> StockDataSetIterator(file, symbol, batchSize, <em>exampleLength</em>, splitRatio, category);<br/>System.<strong><em>out</em></strong>.println("Loading test dataset...");<br/><strong>List&lt;Pair&lt;INDArray, INDArray&gt;&gt;</strong> test = <em>iterator</em>.getTestDataSet();</pre>
<p>In the preceding code block, the <kbd>PriceCategory</kbd> constructor that we used has the following signature:</p>
<pre><strong>public </strong><strong>enum</strong> PriceCategory {<br/>      <strong>OPEN</strong>, <strong>CLOSE</strong>, <strong>LOW</strong>, <strong>HIGH</strong>, <strong>VOLUME</strong>, <strong>ALL<em><br/></em></strong>}</pre>
<p>In the same line, the following options are valid too:</p>
<pre><strong>PriceCategory</strong> category = PriceCategory.<strong>OPEN</strong>; // OPEN: predict open price<br/><strong>PriceCategory</strong> category = PriceCategory.<strong>CLOSE</strong>; // CLOSE: predict close price<br/><strong>PriceCategory</strong> category = PriceCategory.<strong>LOW</strong>; // LOW: predict low price<br/><strong>PriceCategory</strong> category = PriceCategory.<strong>HIGH</strong>; // HIGH: predict high price.</pre>
<p>Whereas, inside, the constructor function of the <kbd>StockDataSetIterator</kbd> class has the following functionalities:</p>
<ul>
<li>We read the stock data from the file, and for each symbol we create a list</li>
<li>We set the <kbd>miniBatchSize</kbd>, <kbd>exampleLength</kbd>, and <kbd>category</kbd> variables to class properties</li>
<li>Then the <kbd>split</kbd> variable is computed based on the <kbd>splitRation</kbd> variable</li>
<li>We separate the <kbd>stockDataList</kbd> into two parts: train and test</li>
<li>Then the stock data is split into training and test sets</li>
<li>We call the function <kbd>initializeOffsets()</kbd> to initial value for the array <kbd>exampleStartOffsets</kbd></li>
</ul>
<p>Following this, the <kbd>StockDataSetIterator()</kbd> constructor has the following signature, which generates the test dataset as a <kbd>List&lt;Pair&lt;INDArray, INDArray&gt;&gt;</kbd>:</p>
<pre>//StockDataSetIterator.java<br/>/** stock dataset for training */<br/><strong>private</strong> <strong>List&lt;StockData&gt;</strong> train;</pre>
<p>In the following code, <kbd>StockData</kbd> is a case class that provides the structure of the dataset to be extracted or prepared from the input <kbd>CSV</kbd> file:</p>
<pre>//StockData.java<br/><strong>private String</strong> date; // date<br/><strong>private String</strong> symbol; // stock name<br/><br/><strong>private double</strong> open; // open price<br/><strong>private double</strong> close; // close price<br/><strong>private double</strong> low; // low price<br/><strong>private double</strong> high; // high price<br/><strong>private double</strong> volume; // volume<br/><br/><strong>public</strong> StockData () {}<br/><br/><strong>public StockData</strong> (<strong>String</strong> date, <strong>String</strong> symbol, <strong>double</strong> open, <strong>double</strong> close, <strong>double</strong> low, <strong>double</strong> high, <strong>double</strong> volume) {<br/>       <strong> this</strong>.date = date;<br/>        <strong>this</strong>.symbol = symbol;<br/>        <strong>this</strong>.open = open;<br/>        <strong>this</strong>.close = close;<br/>        <strong>this</strong>.low = low;<br/>        <strong>this</strong>.high = high;<br/>        <strong>this</strong>.volume = volume;<br/>    }</pre>
<p>Then we have the following getter and setter methods for the aforementioned variable, which are as follows:</p>
<pre><strong>public String</strong> getDate() { <strong>return</strong> date; }<br/><strong>public void</strong> setDate(String date) { <strong>this</strong>.date = date; }<br/><br/><strong>public String</strong> getSymbol() { <strong>return</strong> symbol; }<br/><strong>public void</strong> setSymbol(String symbol) { <strong>this</strong>.symbol = symbol; }<br/><br/><strong>public double</strong> getOpen() { <strong>return</strong> open; }<br/><strong>public void</strong> setOpen(<strong>double</strong> open) { <strong>this</strong>.open = open; }<br/><br/><strong>public double</strong> getClose() { <strong>return</strong> close; }<br/><strong>public void</strong> setClose(<strong>double</strong> close) { <strong>this</strong>.close = close; }<br/><br/><strong>public double</strong> getLow() { <strong>return</strong> low; }<br/><strong>public void</strong> setLow(<strong>double</strong> low) { <strong>this</strong>.low = low; }<br/><br/><strong>public double</strong> getHigh() { <strong>return</strong> high; }<br/><strong>public void</strong> setHigh(<strong>double</strong> high) { <strong>this</strong>.high = high; }<br/><br/><strong>public double</strong> getVolume() { <strong>return</strong> volume; }<br/><strong>public void</strong> setVolume(<strong>double</strong> volume) { <strong>this</strong>.volume = volume; }</pre>
<p>Now that we have seen the signature for the <kbd>StockData.java</kbd> class, it's time to create the test dataset as <kbd>StockDataSetIterator</kbd>:</p>
<pre>/** adjusted stock dataset for testing */<br/><strong>private List&lt;Pair&lt;INDArray, INDArray&gt;&gt;</strong> test;<br/><br/><strong>public StockDataSetIterator</strong> (<strong>String</strong> filename, <strong>String</strong> symbol, <strong>int</strong> miniBatchSize, <strong>int</strong> exampleLength, <br/>        <strong>double</strong> splitRatio, <strong>PriceCategory</strong> category) {<br/>        <strong>List&lt;StockData&gt;</strong> stockDataList = readStockDataFromFile(filename, symbol);<br/><br/>        <strong>this</strong>.miniBatchSize = miniBatchSize;<br/>        <strong>this</strong>.exampleLength = exampleLength;<br/>        <strong>this</strong>.category = category;<br/><br/>        <strong>int</strong> split = (<strong>int</strong>) <strong>Math</strong>.round(stockDataList.size() * splitRatio);<br/>        train = stockDataList.subList(0, split);<br/>        test = generateTestDataSet(stockDataList.subList(split, stockDataList.size()));<br/>        initializeOffsets();<br/>    }</pre>
<p class="mce-root">In the preceding method, the <kbd>initializeOffsets()</kbd> method is invoked to initialize the mini-batch offsets:</p>
<pre class="mce-root"><strong>private void</strong> initializeOffsets() {<br/>        exampleStartOffsets.clear();<br/>        <strong>int</strong> window = exampleLength + predictLength;<br/>        <strong>for</strong>(<strong>int</strong> i = 0; i &lt; train.size() - window; i++) {<br/>              exampleStartOffsets.add(i); <br/>                }<br/>    }</pre>
<p>The actual reading is done using the <kbd>readStockDataFromFile()</kbd> method. Inside the constructor, first, we call the function <kbd>readStockDataFromFile()</kbd> to read data from the file and load it to the <kbd>stockDataList</kbd>. Then we initialize the <kbd>StockDataList</kbd> list to contain data read from the <kbd>csv</kbd> file.</p>
<p>Next, we initialize max in min arrays with <kbd>Double.MIN_VALUE</kbd> and <kbd>Double.MAX_VALUE</kbd>. Then the <kbd>CSV</kbd> file is read line by line for five values. The values are inserted subsequently into the constructor of the <kbd>StockData</kbd> object, and we add this object to <kbd>StockDataList</kbd>. Additionally, we throw if we have any exception. Finally, the method returns <kbd>StockDataList</kbd>. The signature of the method is as follows:</p>
<pre><strong>private List&lt;StockData&gt;</strong> readStockDataFromFile (String filename, String symbol) {<br/>        <strong>List&lt;StockData&gt;</strong> stockDataList = <strong>new ArrayList&lt;&gt;</strong>();<br/>        <strong>try</strong> {<br/>            <strong>for</strong>(<strong>int</strong> i = 0; i &lt; maxArray.length; i++) { // initialize max and min arrays<br/>                maxArray[i] = <strong>Double.MIN_VALUE</strong>;<br/>                minArray[i] = <strong>Double.MAX_VALUE</strong>;<br/>            }<br/>            <strong>List&lt;String[]&gt;</strong> list = <strong>new CSVReader</strong>(<strong>new FileReader</strong>(filename)).readAll();//load as a list<br/>            <strong>for</strong>(<strong>String</strong>[] arr : list) {<br/>                <strong>if</strong>(!arr[1].equals(symbol)) <strong>continue</strong>;<br/>                <strong>double</strong>[] nums = <strong>new double</strong>[VECTOR_SIZE];<br/><br/>                <strong>for</strong>(<strong>int</strong> i = 0; i &lt; arr.length - 2; i++) {<br/>                    nums[i] = <strong>Double</strong>.valueOf(arr[i + 2]);<br/><br/>                    <strong>if</strong>(nums[i] &gt; maxArray[i]) maxArray[i] = nums[i];<br/>                    <strong>if</strong>(nums[i] &lt; minArray[i]) minArray[i] = nums[i];<br/>                }<br/>                stockDataList.add(new StockData(arr[0], arr[1], nums[0], nums[1], <br/>                                  nums[2], nums[3], nums[4]));<br/>            }<br/>        } <strong>catch</strong> (<strong>IOException</strong> e) {<br/>            e.printStackTrace();<br/>        }<br/>        <strong>return</strong> stockDataList;<br/>    }</pre>
<p>Then the <kbd>generateTestDataSet()</kbd> method actually generates the features only consumable by the <kbd>LSTM</kbd> model as <kbd>List&lt;Pair&lt;INDArray, INDArray&gt;&gt;</kbd>, where the ordering is set as <kbd>f</kbd> for faster construct:</p>
<pre><strong>private List&lt;Pair&lt;INDArray, INDArray&gt;&gt;</strong> generateTestDataSet (<strong>List&lt;StockData&gt;</strong> stockDataList) {<br/>        <strong>int</strong> window = exampleLength + predictLength;<br/>        <strong>List&lt;Pair&lt;INDArray, INDArray&gt;&gt;</strong> test = new ArrayList&lt;&gt;();<br/><br/>        <strong>for</strong> (<strong>int</strong> i = 0; i &lt; stockDataList.size() - window; i++) {<br/>            <strong>INDArray</strong> input = <strong>Nd4j</strong>.create(new int[] {exampleLength, VECTOR_SIZE}, 'f');<br/><br/>            <strong>for</strong> (<strong>int</strong> j = i; j &lt; i + exampleLength; j++) {<br/>                <strong>StockData</strong> stock = stockDataList.get(j);<br/>                input.putScalar(new int[] {j - i, 0}, (stock.getOpen() - minArray[0]) / (maxArray[0] - <br/>                     minArray[0]));<br/>                input.putScalar(new int[] {j - i, 1}, (stock.getClose() - minArray[1]) / (maxArray[1] -    <br/>                     minArray[1]));<br/>                input.putScalar(new int[] {j - i, 2}, (stock.getLow() - minArray[2]) / (maxArray[2] - <br/>                     minArray[2]));<br/>                input.putScalar(new int[] {j - i, 3}, (stock.getHigh() - minArray[3]) / (maxArray[3] - <br/>                     minArray[3]));<br/>                input.putScalar(new int[] {j - i, 4}, (stock.getVolume() - minArray[4]) / (maxArray[4] - <br/>                       minArray[4]));<br/>            }<br/>            <strong>StockData</strong> stock = stockDataList.get(i + exampleLength);<br/>            <strong>INDArray</strong> label;<br/><br/>            <strong>if</strong> (category.equals(<strong>PriceCategory</strong>.<strong>ALL</strong>)) {<br/>                label = <strong>Nd4j</strong>.create(<strong>new int</strong>[]{VECTOR_SIZE}, 'f'); // ordering is set faster construct<br/>                label.putScalar(<strong>new int</strong>[] {0}, stock.getOpen());<br/>                label.putScalar(<strong>new int</strong>[] {1}, stock.getClose());<br/>                label.putScalar(<strong>new int</strong>[] {2}, stock.getLow());<br/>                label.putScalar(<strong>new int</strong>[] {3}, stock.getHigh());<br/>                label.putScalar(<strong>new int</strong>[] {4}, stock.getVolume());<br/>            } <strong>else</strong> {<br/>                label = <strong>Nd4j</strong>.create(<strong>new int</strong>[] {1}, 'f');<br/>                <strong>switch</strong> (category) {<br/>                    <strong>case</strong> <strong>OPEN</strong>: label.putScalar(<strong>new int</strong>[] {0}, stock.getOpen()); <strong>break</strong>;<br/>                    <strong>case</strong> <strong>CLOSE</strong>: label.putScalar(<strong>new int</strong>[] {0}, stock.getClose()); <strong>break</strong>;<br/>                    <strong>case</strong> <strong>LOW</strong>: label.putScalar(<strong>new int</strong>[] {0}, stock.getLow()); <strong>break</strong>;<br/>                    <strong>case</strong> <strong>HIGH</strong>: label.putScalar(<strong>new int</strong>[] {0}, stock.getHigh()); <strong>break</strong>;<br/>                    <strong>case</strong> <strong>VOLUME</strong>: label.putScalar(<strong>new int</strong>[] {0}, stock.getVolume()); <strong>break</strong>;<br/>                    <strong>default</strong>: <strong>throw new NoSuchElementException</strong>();<br/>                }<br/>            }<br/>            test.add(<strong>new Pair&lt;&gt;</strong>(input, label));<br/>        }<br/>        <strong>return</strong> test;<br/>    }</pre>
<p>In the previous code block, we save the <kbd>miniBatchSize</kbd>, <kbd>exampleLength</kbd>, and <kbd>category</kbd> variables as class properties. Then we compute the <kbd>split</kbd> variable based on the <kbd>splitRation</kbd> variable. We then separate the <kbd>stockDataList</kbd> into two parts:</p>
<ul>
<li>Indices starting from the beginning to <kbd>split</kbd> belong to train set</li>
<li>Indices starting from split+1 to the end of the list belong to test set.<br/></li>
</ul>
<p>The test data generated is quite different from the train dataset. Call the function <kbd>generatedTestDataSet()</kbd> to set up the test dataset. First, we set a window variable by the example length and the prediction length. Then we loop through from 0 to test the data length minus the window. Consider the following::</p>
<ul>
<li>Read five input variables: open price, close price, low price, high price, and volume.</li>
<li>Base on the value of <kbd>category</kbd>, read the label value. If <kbd>category</kbd> is equal to <kbd>ALL</kbd>, then read five variables such as input variables. Otherwise, read only one variable via the value of <kbd>category</kbd>.</li>
</ul>
<p>In the preceding code block, the labels are being fed using the <kbd>feedLabel()</kbd> method, which goes as follows:</p>
<pre><strong>private double</strong> feedLabel(<strong>StockData</strong> data) {<br/>        <strong>double</strong> <strong>value</strong>;<br/><br/>        <strong>switch</strong>(category) {<br/>            <strong>case</strong> <strong>OPEN</strong>: value = (data.getOpen() - minArray[0]) / (maxArray[0] - minArray[0]); <strong>break</strong>;<br/>            <strong>case</strong> <strong>CLOSE</strong>: value = (data.getClose() - minArray[1]) / (maxArray[1] - minArray[1]); <strong>break</strong>;<br/>            <strong>case</strong> <strong>LOW</strong>: value = (data.getLow() - minArray[2]) / (maxArray[2] - minArray[2]); <strong>break</strong>;<br/>            <strong>case</strong> <strong>HIGH</strong>: value = (data.getHigh() - minArray[3]) / (maxArray[3] - minArray[3]); <strong>break</strong>;<br/>            <strong>case</strong> <strong>VOLUME</strong>: value = (data.getVolume() - minArray[4]) / (maxArray[4] - minArray[4]); <strong>break</strong>;<br/>            <strong>default</strong>: <strong>throw new NoSuchElementException()</strong>;<br/>        }<br/>        <strong>return</strong> value;<br/>    }</pre>
<p>In the preceding code block, we initialize variable <kbd>value</kbd>. We then check the value of variable <kbd>category</kbd>, and the computed value of variable <kbd>value</kbd> can be seen using math notation as follows:</p>
<div class="CDPAlignCenter CDPAlign"><kbd>value = (data.getOpen() - minArray[0]) / (maxArray[0] - minArray[0])</kbd></div>
<p>Then both the features and labels are used to prepare the dataset. Take a look at this code:</p>
<pre><strong>public DataSet</strong> next(<strong>int</strong> num) {<br/>        <strong>if</strong>(exampleStartOffsets.size() == 0) <strong>throw new NoSuchElementException()</strong>;<br/>        <strong>int</strong> actualMiniBatchSize = <strong>Math</strong>.min(num, exampleStartOffsets.size());<br/><br/>        <strong>INDArray</strong> input = <strong>Nd4j</strong>.create(<strong>new</strong> <strong>int</strong>[] {actualMiniBatchSize, VECTOR_SIZE, exampleLength}, 'f');<br/>        <strong>INDArray</strong> label;<br/>        <br/>        <strong>if</strong>(category.equals(PriceCategory.ALL)) <br/>            label = <strong>Nd4j</strong>.create(<strong>new int</strong>[] {actualMiniBatchSize, VECTOR_SIZE, exampleLength}, 'f');<br/>        <strong>else</strong> <br/>            label = <strong>Nd4j</strong>.create(<strong>new</strong> <strong>int</strong>[] {actualMiniBatchSize, predictLength, exampleLength}, 'f');<br/>        <br/>        <strong>for</strong>(<strong>int</strong> index = 0; index &lt; actualMiniBatchSize; index++) {<br/>            <strong>int</strong> startIdx = exampleStartOffsets.removeFirst();<br/>            <strong>int</strong> endIdx = startIdx + exampleLength;<br/><br/>            <strong>StockData</strong> curData = train.get(startIdx);<br/>            <strong>StockData</strong> nextData;<br/><br/>            <strong>for</strong>(<strong>int</strong> i = startIdx; i &lt; endIdx; i++) {<br/>                <strong>int</strong> c = i - startIdx;<br/>                input.putScalar(<strong>new</strong> <strong>int</strong>[] {index, 0, c}, (curData.getOpen() - minArray[0]) <br/>                                 / (maxArray[0] - minArray[0]));<br/>                input.putScalar(<strong>new int</strong>[] {index, 1, c}, (curData.getClose() - minArray[1]) <br/>                                 / (maxArray[1] - minArray[1]));<br/>                input.putScalar(<strong>new int</strong>[] {index, 2, c}, (curData.getLow() - minArray[2]) <br/>                                 / (maxArray[2] - minArray[2]));<br/>                input.putScalar(<strong>new int</strong>[] {index, 3, c}, (curData.getHigh() - minArray[3]) <br/>                                 / (maxArray[3] - minArray[3]));<br/>                input.putScalar(<strong>new int</strong>[] {index, 4, c}, (curData.getVolume() - minArray[4]) <br/>                                 / (maxArray[4] - minArray[4]));<br/>                nextData = train.get(i + 1);<br/><br/>                <strong>if</strong>(category.equals(PriceCategory.<strong>ALL</strong>)) {<br/>                    label.putScalar(<strong>new int</strong>[] {index, 0, c}, (nextData.getOpen() - minArray[1]) <br/>                                    / (maxArray[1] - minArray[1]));<br/>                    label.putScalar(<strong>new int</strong>[] {index, 1, c}, (nextData.getClose() - minArray[1]) <br/>                                   / (maxArray[1] - minArray[1]));<br/>                    label.putScalar(<strong>new int</strong>[] {index, 2, c}, (nextData.getLow() - minArray[2]) <br/>                                   / (maxArray[2] - minArray[2]));<br/>                    label.putScalar(<strong>new int</strong>[] {index, 3, c}, (nextData.getHigh() - minArray[3]) <br/>                                   / (maxArray[3] - minArray[3]));<br/>                    label.putScalar(<strong>new int</strong>[] {index, 4, c}, (nextData.getVolume() - minArray[4]) <br/>                                   / (maxArray[4] - minArray[4]));<br/>                } <strong>else</strong> {<br/>                    label.putScalar(<strong>new int</strong>[]{index, 0, c}, feedLabel(nextData));<br/>                }<br/>                curData = nextData;<br/>            }<br/>            <strong>if</strong>(exampleStartOffsets.size() == 0) <strong>break</strong>;<br/>        }<br/>        <strong>return</strong> <strong>new DataSet</strong>(input, label);<br/>    }</pre>
<p>In the preceding code block, we loop through the <kbd>epochs</kbd> time, and for each time we loop until we have the data, fitting the network with a data get in function <kbd>iterator.next()</kbd>. Consider the following:</p>
<ul>
<li>We initialize two variables: <kbd>input</kbd> using <kbd>actualMinibatchSize</kbd> and <kbd>label</kbd> with <kbd>category</kbd>.</li>
<li>We then loop from 0 to <kbd>actualMiniBatchSize</kbd>. Each time, we create two <span>additional </span>variables: <kbd>curData</kbd> , which is a <kbd>StockData</kbd> point of current time. Then we put their value into the <kbd>input</kbd> list. Similarly the<kbd>nextData</kbd> variable is also a <span class="packt_screen"><kbd>StockData</kbd></span> point of the day, which is after the day of <kbd>curData</kbd> . Finally, we put the value of <kbd>nextData</kbd> to <kbd>label</kbd> list.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">LSTM network construction</h1>
                </header>
            
            <article>
                
<p>As stated earlier, I wrote a class called <kbd>RecurrentNets.java</kbd> to build an LSTM network. We create a <kbd>MultilayerNetwork</kbd> LSTM network that consists of an input layer, four LSTM layers, three dense layers, and an output layer. The input consists of sequences of genetic variants.</p>
<p>We use the <kbd>BuildBuildLstmNetworks()</kbd> method with two parametersâ€”number of input for input layers and number of output for output layers, as shown here:</p>
<pre><strong>private static</strong> final int lstmLayer1Size = 128;<br/><strong>private static</strong> final int lstmLayer2Size = 128;<br/><strong>private static</strong> final int denseLayerSize = 32;<br/><strong>private static</strong> final double dropoutRatio = 0.5;<br/><strong>private static</strong> final int truncatedBPTTLength = 22;</pre>
<p>Now, before we start creating and building the network, let's see what our model would look like:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-745 image-border" src="assets/f4bfded0-ee1e-4a5e-9966-35f85db1c7b5.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">The stock price LSTM network</div>
<p>Then, the <kbd>createAndBuildLstmNetworks()</kbd> method is used to create and build the network with the preceding parameter setting:</p>
<pre><strong>public static MultiLayerNetwork</strong> createAndBuildLstmNetworks(<strong>int</strong> nIn, <strong>int</strong> nOut) {<br/>        // Creating MultiLayerConfiguration <br/>        <strong>MultiLayerConfiguration </strong>conf = <strong>new</strong> <strong>NeuralNetConfiguration</strong>.Builder()<br/>                .seed(123456)// for the reproducibility<br/>                .optimizationAlgo(OptimizationAlgorithm.<strong>STOCHASTIC_GRADIENT_DESCENT</strong>)//optimizer<br/>                .updater(new Adam(0.001)) // Adam updater with SGD<br/>                .l2(1e-4)// l2 regularization<br/>                .weightInit(WeightInit.<strong>XAVIER</strong>)// network weight initialization<br/>                .activation(Activation.<strong>RELU</strong>)// ReLU as activation<br/>                .list()<br/>                .layer(0, new <strong>LSTM</strong>.Builder()//LSTM layer 1<br/>                        .nIn(nIn)<br/>                        .nOut(lstmLayer1Size)<br/>                        .activation(Activation.<strong>TANH</strong>)<br/>                        .gateActivationFunction(Activation.<strong>HARDSIGMOID</strong>)// Segment-wise linear       <br/>                                                                       // approximation of sigmoid<br/>                        .dropOut(dropoutRatio)// keeping drop-out ratio<br/>                        .build())<br/>                .layer(1, new <strong>LSTM</strong>.Builder()// LSTM layer 2<br/>                        .nIn(lstmLayer1Size)<br/>                        .nOut(lstmLayer2Size)<br/>                        .activation(Activation.<strong>TANH</strong>)<br/>                        .gateActivationFunction(Activation.<strong>HARDSIGMOID</strong>)<br/>                        .dropOut(dropoutRatio)//kee drop-out ratio<br/>                        .build())<br/>                .layer(2, new <strong>LSTM</strong>.Builder()//LSTM layer 3<br/>                        .nIn(lstmLayer1Size)<br/>                        .nOut(lstmLayer2Size)<br/>                        .activation(Activation.<strong>TANH</strong>)<br/>                        .gateActivationFunction(Activation.<strong>HARDSIGMOID</strong>)<br/>                        .dropOut(dropoutRatio)// keep drop-out ratio<br/>                        .build())<br/>                .layer(3, new DenseLayer.Builder()// FC layer 1<br/>                        .nIn(lstmLayer2Size)<br/>                        .nOut(denseLayerSize)<br/>                        .activation(Activation.<strong>RELU</strong>)<br/>                        .build())<br/>                .layer(4, new DenseLayer.Builder()//FC layer 2<br/>                        .nIn(denseLayerSize)<br/>                        .nOut(denseLayerSize)<br/>                        .activation(Activation.<strong>RELU</strong>)<br/>                        .build())<br/>                .layer(5, new DenseLayer.Builder()//FC layer 3<br/>                        .nIn(denseLayerSize)<br/>                        .nOut(denseLayerSize)<br/>                        .activation(Activation.<strong>RELU</strong>)<br/>                        .build())<br/>                .layer(6, new RnnOutputLayer.Builder() // RNN output layer<br/>                        .nIn(denseLayerSize)<br/>                        .nOut(nOut)<br/>                        .activation(Activation.<strong>IDENTITY</strong>)// Regression with MSE as the loss function<br/>                        .lossFunction(LossFunctions.LossFunction.<strong>MSE</strong>)<br/>                        .build())<br/>                .backpropType(BackpropType.TruncatedBPTT)// Back propagation with time<br/>                .tBPTTForwardLength(truncatedBPTTLength)<br/>                .tBPTTBackwardLength(truncatedBPTTLength)<br/>                .pretrain(false).backprop(true)//no pretraining necessary<br/>                .build();<br/><br/>        // Creating MultiLayerNetwork using the above MultiLayerConfig<br/>        <strong>MultiLayerNetwork</strong> net = <strong>new MultiLayerNetwork</strong>(conf);<br/>        net.init(); // initilize the MultiLayerNetwork<br/>        net.setListeners(new ScoreIterationListener(100));// shows score in each 100th iteration/epoch<br/>        <strong>return</strong> net; // return the MultiLayerNetwork<br/>    }</pre>
<p>Since we created and used an <kbd>LSTM</kbd> net several times in this chapter, I decided not to discuss its details. However, one important thing here is the use of the <kbd>IDENTITY</kbd> activation with <kbd>Root Means Square Errors (RMSE)</kbd>, which is used for regression problems.</p>
<p>In short, to perform regression with a neural network in DL4J, you would set up a multilayer neural network and add an output layer at the end with the following properties, as shown previously:</p>
<pre>//Create output layer<br/>    .layer()<br/>    .nIn($NumberOfInputFeatures)<br/>    .nOut(1)// regression hence, only a single output<br/>    .activation(Activation.<strong>IDENTITY</strong>)//Regression with RMSE as the loss function<br/>    .lossFunction(LossFunctions.LossFunction.RMSE)</pre>
<div class="packt_infobox">For more information on regression analysis using DL4j, interested readers can visit <a href="https://deeplearning4j.org/evaluation#Regression">https://deeplearning4j.org/evaluation#Regression</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Network training, and saving the trained model</h1>
                </header>
            
            <article>
                
<p>Now that our network as well as the training and test sets are ready, we can start training the network. For this, again we use the DL4J-provided <kbd>fit()</kbd> method. We loop through <kbd>epochs</kbd> times, for each time looping until we have the data. We fit the network with a <kbd>miniBatchSize</kbd> amount of data at each time step, as shown here:</p>
<pre>// StockPricePrediction.java<br/>System.out.println("Training LSTM network...");<br/><strong>for</strong>(<strong>int</strong> i = 0; i &lt; epochs; i++) {<br/>            <strong>while</strong>(iterator.hasNext()) net.fit(iterator.next()); // fit model using mini-batch data<br/>            iterator.reset(); // reset iterator<br/>            net.rnnClearPreviousState(); // clear previous state<br/>        }<br/><br/><br/><q>&gt;&gt;</q><br/> <span class="packt_screen">Creating dataSet iterator...<br/> Loading test dataset...<br/> Building LSTM networks...<br/> Training LSTM network...</span></pre>
<p>Once the training is completed, we save the trained model to disk (in directory <kbd>data</kbd>). Here I specified a sample name <kbd>StockPriceLSTM_+ category name + .zip</kbd> as shown here:</p>
<pre># StockPricePrediction.java<br/>System.<strong><em>out</em></strong>.println("Saving model...");<br/><strong>File</strong> locationToSave = <strong>new</strong> File("data/StockPriceLSTM_".concat(String.<em>valueOf</em>(category)).concat(".zip"));<br/><br/>// saveUpdater: i.e., state for Momentum, RMSProp, Adagrad etc. Save this to train your network in future<br/><strong>ModelSerializer</strong>.<em>writeModel</em>(net, locationToSave, <strong>true</strong>);</pre>
<p>Now let's take a look at the number of parameters at each layer:</p>
<pre>//Print the  number of parameters in the network (and for each layer)<br/><strong>Layer</strong>[] layers_before_saving = net.getLayers();<br/>              <strong>int</strong> totalNumParams_before_saving = 0;<br/><br/>              <strong>for</strong>(<strong>int</strong> i=0; i&lt;layers_before_saving.length; i++ ){<br/>                  <strong>int</strong> nParams = layers_before_saving[i].numParams();<br/>                  System.out.println("Number of parameters in layer " + i + ": " + nParams);<br/>                  totalNumParams_before_saving += nParams;<br/>              }<br/>System.out.println("Total number of network parameters: " + totalNumParams_before_saving);</pre>
<pre>&gt;&gt;&gt;<br/> <span class="packt_screen">Saving model...<br/> Number of parameters in layer 0: 68608<br/> Number of parameters in layer 1: 131584<br/> Number of parameters in layer 2: 131584<br/> Number of parameters in layer 3: 4128<br/> Number of parameters in layer 4: 1056<br/> Number of parameters in layer 5: 1056<br/> Number of parameters in layer 6: 165<br/> Total number of network parameters: 338181</span></pre>
<p>Nevertheless, we enable the DL4J UI to view the training progress and params, as shown here:</p>
<pre>//Initialize the user interface backend<br/><strong>UIServer</strong> uiServer = UIServer.<em>getInstance</em>();<br/><br/>//Configure where the network information (gradients, activations, score vs. time etc) is to be stored. //Then add the StatsListener to collect this information from the network, as it trains:<br/><strong>StatsStorage</strong> statsStorage = <strong>new</strong> <strong>InMemoryStatsStorage</strong>();<br/><br/>//Alternative: new FileStatsStorage(File) - see UIStorageExample. Attach the StatsStorage instance to the //UI: this allows the contents of the StatsStorage to be visualized:<br/>uiServer.attach(statsStorage);<br/><br/><strong>int</strong> listenerFrequency = 1;<br/>net.setListeners(<strong>new</strong> StatsListener(statsStorage, listenerFrequency));</pre>
<p>The following screenshot shows the output:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-744 image-border" src="assets/8621da6a-21ff-4d2a-b57c-51a991d9a3fa.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Network parameters on the UI</div>
<p>The graphs look as though they are not regularized, probably because we do not have enough training data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Restoring the saved model for inferencing</h1>
                </header>
            
            <article>
                
<p>Now that we have finished the training, and the trained model is at hand, we can either directly use that trained one on the fly as well as restore the saved model from disk, or start the inferencing. Take a look at this code:</p>
<pre>System.<strong><em>out</em></strong>.println("Restoring model...");<br/>net = ModelSerializer.<em>restoreMultiLayerNetwork</em>(locationToSave);<br/><br/>//print the score with every 1 iteration<br/>net.setListeners(<strong>new</strong> ScoreIterationListener(1));<br/><br/>//Print the number of parameters in the network (and for each layer)<br/><strong>Layer</strong>[] layers = net.getLayers(); <br/><br/><strong>int</strong> totalNumParams = 0;<br/><strong>for</strong>( <strong>int</strong> i=0; i&lt;layers.length; i++ ){<br/>        <strong>int</strong> nParams = layers[i].numParams(); <br/>       System.<strong><em>out</em></strong>.println("Number of parameters in layer " + i + ": " + nParams);<br/>       totalNumParams += nParams;<br/>}<br/>System.<strong><em>out</em></strong>.println("Total number of network parameters: " + totalNumParams);</pre>
<pre>&gt;&gt;&gt;<br/> <span class="packt_screen">Restoring model...<br/> Number of parameters in layer 0: 68608<br/> Number of parameters in layer 1: 131584<br/> Number of parameters in layer 2: 131584<br/> Number of parameters in layer 3: 4128<br/> Number of parameters in layer 4: 1056<br/> Number of parameters in layer 5: 1056<br/> Number of parameters in layer 6: 165<br/> Total number of network parameters: 338181</span></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Evaluating the model</h1>
                </header>
            
            <article>
                
<p>The number of parameters is the same as the one we saved on disk. This means our trained model is not contaminated, so we are safe. Next up, we start evaluating the model on the test set. But, as stated earlier, we will perform a two-way evaluation of the model. First, we predict one feature of a stock, one day ahead, as shown here:</p>
<pre>/** Predict one feature of a stock one-day ahead */<br/><strong>private static void</strong> predictPriceOneAhead (<strong>MultiLayerNetwork</strong> net, <strong>List&lt;Pair&lt;INDArray, INDArray&gt;&gt;</strong> testData, <strong>double</strong> max, <strong>double</strong> min, <strong>PriceCategory</strong> category) {<br/>        <strong>double</strong>[] predicts = new double[testData.size()];<br/>        <strong>double</strong>[] actuals = new double[testData.size()];<br/>        <br/>        <strong>for</strong> (<strong>int</strong> i = 0; i &lt; testData.size(); i++) {<br/>            predicts[i] = net.rnnTimeStep(testData.get(i).getKey()).getDouble(exampleLength - 1) <br/>                          * (max - min) + min;<br/>            actuals[i] = testData.get(i).getValue().getDouble(0);<br/>        }<br/>        <br/>        <strong>RegressionEvaluation</strong> eval = net.evaluateRegression(iterator);   <br/>        System.out.println(eval.stats());<br/>        <br/>        System.out.println("Printing predicted and actual values...");<br/>        System.out.println("Predict, Actual");<br/>        <br/>        <strong>for</strong> (<strong>int</strong> i = 0; i &lt; predicts.length; i++) <br/>            System.out.println(predicts[i] + "," + actuals[i]);<br/>        <br/>        System.out.println("Plottig...");<br/>        <strong>PlotUtil</strong>.plot(predicts, actuals, String.valueOf(category));<br/>    }</pre>
<p>In the preceding code block, we perform the training for a single category, for example, by setting any one of the following options:</p>
<pre><strong>PriceCategory</strong> category = PriceCategory.<strong>OPEN</strong>; // OPEN: predict open price<br/><strong>PriceCategory</strong> category = PriceCategory.<strong>CLOSE</strong>; // CLOSE: predict close price<br/><strong>PriceCategory</strong> category = PriceCategory.<strong>LOW</strong>; // LOW: predict low price<br/><strong>PriceCategory</strong> category = PriceCategory.<strong>HIGH</strong>; // HIGH: predict high price</pre>
<p>We can do the evaluation simultaneously for all the categories by setting <kbd>PriceCategory category = PriceCategory.<strong><em>ALL</em></strong>; // <strong>ALL</strong>: predict close price</kbd>.</p>
<p>Thus, we predict all the features (open, close, low, high prices, and volume) of a stock, one day ahead. The process of evaluation on a category is the same within case all categories. There is only one thing different: We need to loop through a number of categories using <kbd>PlotUtil</kbd> for the draw <kbd>XY</kbd> line chart, as shown here:</p>
<pre>/** Predict all the features (open, close, low, high prices and volume) of a stock one-day ahead */<br/><strong>private static void</strong> predictAllCategories (<strong>MultiLayerNetwork</strong> net, <strong>List&lt;Pair&lt;INDArray, INDArray&gt;&gt;</strong> testData, <strong>INDArray</strong> max, <strong>INDArray</strong> min) {<br/>        <strong>INDArray</strong>[] predicts = new INDArray[testData.size()];<br/>        <strong>INDArray</strong>[] actuals = new INDArray[testData.size()];<br/>        <strong>for</strong>(<strong>int</strong> i = 0; i &lt; testData.size(); i++) {<br/>            predicts[i] = net.rnnTimeStep(testData.get(i).getKey()).getRow(exampleLength - 1)<br/>                          .mul(max.sub(min)).add(min);<br/>            actuals[i] = testData.get(i).getValue();<br/>        }<br/>        <br/>        System.out.println("Printing predicted and actual values...");<br/>        System.out.println("Predict, Actual");<br/><br/>        <strong>for</strong>(<strong>int</strong> i = 0; i &lt; predicts.length; i++) <br/>            System.out.println(predicts[i] + "\t" + actuals[i]);<br/>        System.out.println("Plottig...");<br/>        <br/>        <strong>RegressionEvaluation</strong> eval = net.evaluateRegression(iterator);   <br/>        System.out.println(eval.stats());<br/>        <br/>        <strong>for</strong>(<strong>int</strong> n = 0; n &lt; 5; n++) {<br/>            <strong>double</strong>[] pred = new double[predicts.length];<br/>            <strong>double</strong>[] actu = new double[actuals.length];<br/><br/>            <strong>for</strong>(<strong>int</strong> i = 0; i &lt; predicts.length; i++) {<br/>                pred[i] = predicts[i].getDouble(n);<br/>                actu[i] = actuals[i].getDouble(n);<br/>            }<br/>            <strong>String</strong> name;<br/>            <strong>switch</strong>(n) {<br/>                <strong>case</strong> 0: name = "Stock OPEN Price"; <strong>break</strong>;<br/>                <strong>case</strong> 1: name = "Stock CLOSE Price"; <strong>break</strong>;<br/>                <strong>case</strong> 2: name = "Stock LOW Price"; <strong>break</strong>;<br/>                <strong>case</strong> 3: name = "Stock HIGH Price"; <strong>break</strong>;<br/>                <strong>case</strong> 4: name = "Stock VOLUME Amount"; <strong>break</strong>;<br/>                <strong>default</strong>: throw new NoSuchElementException();<br/>            }<br/>            <strong>PlotUtil</strong>.plot(pred, actu, name);<br/>        }<br/>    }</pre>
<p>In the preceding code block, we go to the function <kbd>predictAllCategories()</kbd> to see how evaluation goes on in all categories. Next, we create two arrays, <kbd>predicts</kbd> and <kbd>actuals</kbd>, to store the predicted result and the actual result. Then we loop over the test data. Then we do the following:</p>
<ul>
<li>Call the function <kbd>net.rnnTimeStep()</kbd> with parameter as the key of row i-th and append the result to the <kbd>predicts</kbd> list</li>
<li>Actual value gets from the value of test data row <em>i</em><sup>th</sup></li>
<li>Print the predicted value and actual values</li>
</ul>
<p>Finally, we loop through five categories; we're using the <kbd>PlotUtil.java</kbd> to draw an <em>XY</em> line chart between predicted and actual values. Consider the following:</p>
<ul>
<li>The initial two double arrays are named <kbd>pred</kbd> and <kbd>actu</kbd> with size equal to the size of the predicted length.</li>
<li>Loop through the <kbd>predicts</kbd> and <kbd>actuals</kbd> arrays and, get the double value of each element in each list.</li>
<li>With each value of <em>n</em> has four values from 0 to 4. Set the variable <kbd>name</kbd> to the ledge of the <em>Y</em> column.</li>
<li>Call the function <kbd>PlotUtil</kbd> to draw the <em>XY</em> line.</li>
</ul>
<p>By the way, the <kbd>PlotUtil.java</kbd> class is used to draw an <em>XY</em> line for predicted versus actual values, which goes as follows:</p>
<pre><strong>public static void</strong> plot(double[] predicts, double[] actuals, String name) {<br/>        <strong>double</strong>[] index = new double[predicts.length];<br/>        <strong>for</strong>(<strong>int</strong> i = 0; i &lt; predicts.length; i++)<br/>            index[i] = i;<br/>        <br/>        <strong>int</strong> min = minValue(predicts, actuals);<br/>        <strong>int</strong> max = maxValue(predicts, actuals);<br/>        <br/>        <strong>final</strong> <strong>XYSeriesCollection</strong> dataSet = new XYSeriesCollection();<br/>        addSeries(dataSet, index, predicts, "Predicted");<br/>        addSeries(dataSet, index, actuals, "Actual");<br/>        <br/>        <strong>final</strong> <strong>JFreeChart</strong> chart = ChartFactory.createXYLineChart(<br/>                "Predicted vs Actual", // chart title<br/>                "Index", // x axis label<br/>                name, // y axis label<br/>                dataSet, // data<br/>                PlotOrientation.VERTICAL,<br/>                true, // include legend<br/>                true, // tooltips<br/>                false // urls<br/>              );<br/>        <br/>        <strong>XYPlot</strong> xyPlot = chart.getXYPlot();<br/>        <br/>        // X-axis<br/>        <strong>final</strong> <strong>NumberAxis</strong> domainAxis = (NumberAxis) xyPlot.getDomainAxis();<br/>        domainAxis.setRange((int) index[0], (int) (index[index.length - 1] + 2));<br/>        domainAxis.setTickUnit(new NumberTickUnit(20));<br/>        domainAxis.setVerticalTickLabels(true);<br/>        <br/>        // Y-axis<br/>        <strong>final</strong> NumberAxis rangeAxis = (NumberAxis) xyPlot.getRangeAxis();<br/>        rangeAxis.setRange(min, max);<br/>        rangeAxis.setTickUnit(new NumberTickUnit(50));<br/>        <br/>        <strong>final</strong> <strong>ChartPanel</strong> panel = new ChartPanel(chart);<br/>        final JFrame f = new JFrame();<br/>        f.add(panel);<br/>        f.setDefaultCloseOperation(WindowConstants.EXIT_ON_CLOSE);<br/>        f.pack();<br/>        f.setVisible(true);<br/>    }</pre>
<p>In the preceding code block,the <kbd>addSeries()</kbd> method is used to add the <em>XY</em> series, which is as follows:</p>
<pre><strong>private static void</strong> addSeries (<strong>final</strong> XYSeriesCollection dataSet, <strong>double</strong>[] x, <strong>double</strong>[] y, <strong>final</strong> String label){<br/>        <strong>final</strong> XYSeries s = <strong>new XYSeries</strong>(label);<br/>        <strong>for</strong>(<strong>int</strong> j = 0; j &lt; x.length; j++ ) s.add(x[j], y[j]);<br/>        dataSet.addSeries(s);<br/>    }</pre>
<p>Apart from these, finding the min, max values of <kbd>predicted</kbd> and <kbd>actual</kbd> values that we used in the preceding code happen as follows:</p>
<ul>
<li><strong>Finding min:</strong> First, we set variable <kbd>min</kbd> as <kbd>MAX_VALUE.</kbd> Then we loop through the <kbd>predicted</kbd> and <kbd>actual</kbd> arrays, such that if <kbd>min</kbd> is greater than any element, then we reset <kbd>min</kbd> as the current element. Then we take the integer closest lower bound of value of min:</li>
</ul>
<pre style="padding-left: 60px"><strong>private static int</strong> minValue (<strong>double</strong>[] predicts, <strong>double</strong>[] actuals) {<br/>        <strong>double</strong> min = <strong>Integer</strong>.MAX_VALUE;<br/><br/>        <strong>for</strong>(<strong>int</strong> i = 0; i &lt; predicts.length; i++) {<br/>            <strong>if</strong>(min &gt; predicts[i]) min = predicts[i];<br/>            <strong>if</strong>(min &gt; actuals[i]) min = actuals[i];<br/>        }<br/>        <strong>return</strong> (<strong>int</strong>) (min * 0.98);<br/>    }</pre>
<ul>
<li><strong>Finding max:</strong> First, we set the variable <kbd>max</kbd> as <kbd>MIN_VALUE.</kbd> Then we loop through the <kbd>predicts</kbd> and <kbd>actual</kbd> arrays such that if <kbd>max</kbd> &lt; any element, we reset <kbd>max</kbd> as this element. Then we take the integer closest to the upper bound of the value of max as shown here:</li>
</ul>
<pre style="padding-left: 60px"><strong>private</strong> <strong>static</strong> <strong>int</strong> maxValue (<strong>double</strong>[] predicts, <strong>double</strong>[] actuals) {<br/>        <strong>double</strong> max = <strong>Integer</strong>.MIN_VALUE;<br/><br/>        <strong>for</strong>(<strong>int</strong> i = 0; i &lt; predicts.length; i++) {<br/>            <strong>if</strong>(max &lt; predicts[i]) max = predicts[i];<br/>            <strong>if</strong>(max &lt; actuals[i]) max = actuals[i];<br/>        }<br/>        <strong>return</strong> (<strong>int</strong>) (max * 1.02);<br/>    }</pre>
<p>Finally, we use the <kbd>addSeries()</kbd> method to add a series to dataSet while plotting the graph. Nevertheless, since the task is a regression, we perform the evaluation showing regression metrics too, such as <kbd>MSE</kbd>, <kbd>MAE</kbd>, <kbd>R2</kbd>, and so on.</p>
<p>Now, based on the preceding plans and based on the value of variable <kbd>category</kbd>, we have two methods to evaluate the model. If the category is <kbd>ALL</kbd>, then the network will predict all categories; otherwise, the network will work <span>only</span> on one category. First, for only a single category, say <kbd>OPEN</kbd>. Take a look at this code:</p>
<pre>System.out.println("Evaluating...");<br/><strong>if</strong>(category.equals(<strong>PriceCategory</strong>.OPEN)) {<br/>            <strong>INDArray</strong> max = <strong>Nd4j</strong>.create(iterator.getMaxArray());<br/>            <strong>INDArray</strong> min = <strong>Nd4j</strong>.create(iterator.getMinArray());<br/>            predictAllCategories(net, test, max, min);<br/>} <strong>else</strong> {<br/>            <strong>double</strong> max = iterator.getMaxNum(category);<br/>            <strong>double</strong> min = iterator.getMinNum(category);<br/>            predictPriceOneAhead(net, test, max, min, category);<br/> }<br/>System.out.println("Done...");</pre>
<pre><span class="packt_screen">&gt;&gt;&gt;<br/> Evaluating...<br/> Printing predicted and actual values...<br/> Predict, Actual<br/> ---------------------------------------<br/> 29.175033326034814,35.61000061035156<br/> 29.920153324534823,35.70000076293945<br/> 30.84457991629533,35.9900016784668<br/> 31.954761620513793,36.150001525878906<br/> 33.171770076832885,36.79999923706055<br/> 34.42622247035372,36.150001525878906<br/> 35.63831635695636,36.41999816894531<br/> 36.79695794284552,36.04999923706055<br/> 37.79222186089784,35.9900016784668<br/> 38.45504267616927,35.470001220703125<br/> 38.837315702846766,35.66999816894531</span></pre>
<p>Then the regression metrics will be printed as follows (you may experience slightly different result, though):</p>
<pre><span class="packt_screen">Column MSE MAE RMSE RSE PC R^2<br/> -------------------------------------------------------------------------------------------<br/> col_0 3.27134e-02 1.14001e-01 1.80868e-01 5.53901e-01 7.17285e-01 4.46100e-01</span></pre>
<p>Finally, we observe the following screenshot showing predicted versus actual <kbd>OPEN</kbd> prices:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9d1020c0-ee25-4e63-85d1-c322756232db.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Predicted versus actual prices for <kbd>OPEN</kbd> category</div>
<p>Then, for only <span>the </span><kbd><strong>ALL</strong></kbd> category, we run a similar code, except that <kbd>PriceCategory.ALL</kbd> is used as follows:</p>
<pre>System.out.println("Evaluating...");<br/><strong>if</strong>(category.equals(PriceCategory.ALL)) {<br/>            <strong>INDArray</strong> max = <strong>Nd4j</strong>.create(iterator.getMaxArray());<br/>            <strong>INDArray</strong> min = <strong>Nd4j</strong>.create(iterator.getMinArray());<br/>            predictAllCategories(net, test, max, min);<br/>} <strong>else</strong> {<br/>            <strong>double</strong> max = iterator.getMaxNum(category);<br/>            <strong>double</strong> min = iterator.getMinNum(category);<br/>            predictPriceOneAhead(net, test, max, min, category);<br/>   }<br/>System.out.println("Done...");</pre>
<pre>&gt;&gt;&gt;<br/> E<span class="packt_screen">valuating...<br/> Printing predicted and actual values...<br/> Predict, Actual<br/> ------------ ---------------------------------------------------------------<br/> [[27.8678,27.1462,27.0535,27.9431, 9.7079e5]] [[35.6100,35.8900,35.5500,36.1100, 1.5156e6]]<br/> [[28.3925,27.2648,27.2769,28.4423, 1.2579e6]] [[35.7000,35.8100,35.6500,36.1000,8.623e5]]<br/> [[29.0413,27.4402,27.6015,29.1540, 1.6014e6]] [[35.9900,36.1400,35.9000,36.3200, 1.0829e6]]<br/> [[29.9264,27.6811,28.0419,30.1133, 2.0673e6]] [[36.1500,36.7100,36.0700,36.7600, 1.0635e6]]<br/> [[30.9201,27.9385,28.5584,31.2908, 2.5381e6]] [[36.8000,36.5700,36.4600,37.1600, 1.0191e6]]<br/> [[32.0080,28.2469,29.1343,32.6514, 3.0186e6]] [[36.1500,36.2300,35.9300,36.7600, 1.8299e6]]<br/> [[33.1358,28.5809,29.7641,34.1525, 3.4644e6]] [[36.4200,36.5400,36.1800,36.8900,8.774e5]]<br/> [[45.2637,31.2634,39.5828,53.1128, 5.0282e6]] [[50.3600,49.2200,49.1700,50.4500,9.415e5]]<br/> [[45.1651,31.2336,39.5284,52.9815, 4.9879e6]] [[49.1700,49.0100,48.8100,49.4400,9.517e5]]</span></pre>
<p>Then the regression metrics will be printed as follows (you may experience slightly different result, though):</p>
<pre><span class="packt_screen">Column MSE MAE RMSE RSE PC R^2<br/> -------------------------------------------------------------------------------------------------<br/> col_0 4.52917e-02 1.35709e-01 2.12819e-01 7.49715e-01 6.60401e-01 2.50287e-01<br/> col_1 1.52875e-01 3.27669e-01 3.90993e-01 2.54384e+00 6.61151e-01 -1.54384e+00<br/> col_2 8.46744e-02 2.19064e-01 2.90989e-01 1.41381e+00 6.01910e-01 -4.13806e-01<br/> col_3 6.05071e-02 1.93558e-01 2.45982e-01 9.98581e-01 5.95618e-01 1.41977e-03<br/> col_4 2.34488e-02 1.17289e-01 1.53130e-01 9.97561e+00 5.59983e-03 -8.97561e+00</span></pre>
<p>Now take a look at the following graph, showing predicted versus actual <kbd>ALL</kbd> prices:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/8b74636f-a246-4971-b678-f266defb34f5.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Predicted versus actual prices for <kbd>ALL</kbd> categories</div>
<p>From the graph, we can see that the price for <kbd>OPEN</kbd> and <kbd>HIGH</kbd> shows a good fit, whereas <kbd>LOW</kbd> shows a somewhat good fit. Unfortunately, <kbd>CLOSE</kbd> and <kbd>VOLUME</kbd> show a very disappointing fit (see the preceding regression result table). One possible reason could be lack of data. And also, the hyperparameters used are not hypertuned at all. Nevertheless, most of the hyperparameters were chosen naively.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Frequently asked questions (FAQs)</h1>
                </header>
            
            <article>
                
<p>In this section, we will see some frequently asked questions that may be already on your mind. Answers to these questions can be found in Appendix A:</p>
<ol>
<li>Can I extend this project for Bitcoin price prediction purposes? If so, how and where can I get such datasets?</li>
<li>What happens if you take predicted values as input for the next prediction?</li>
<li>I understand that this is a regression problem, but how can I predict whether a price will go up or down?</li>
<li>I would like to extend this app and deploy a web application. How can I do that?</li>
<li>I want to extend this application not only for price prediction, but also for anomaly detection in prices. How can I do that?</li>
<li>Can I use similar technique for stock price recommendation?</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter,we saw how to develop a demo project for predicting stock prices for five categories: <kbd>OPEN</kbd>, <kbd>CLOSE</kbd>, <kbd>LOW</kbd>, <kbd>HIGH</kbd>, and <kbd>VOLUME</kbd>. However, our approach cannot generate an actual signal. Still, it gives some idea of how to use LSTM. I know there are some serious drawbacks of this approach. Nevertheless, we did not use enough data, which potentially limits the performance of such a model.</p>
<p>In the next chapter, we will see how to apply deep learning approaches to a video dataset. We will describe how to process and extract features from a large collection of video clips. Then we will make the overall pipeline scalable and faster by distributing the training on multiple devices (CPUs and GPUs), and run them in parallel.</p>
<p>We will see a complete example of how to develop a deep learning application that accurately classifies a large collection of a video dataset, such as <kbd>UCF101</kbd>, using a combined CNN-LSTM network with DL4J. It overcomes the limitations of standalone CNN or <kbd>LSTM</kbd> networks. The training will be carried out on an Amazon EC2 GPU compute cluster. Eventually, this end-to-end project can be treated as a primer for human activity recognition from video or so.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Answers to questions</h1>
                </header>
            
            <article>
                
<p><strong>Answer</strong> <strong>to question</strong> <strong>1:</strong> Some historical Bitcoin data can be downloaded from Kaggle, <span>fo</span><span>r example, </span><a href="https://www.kaggle.com/mczielinski/bitcoin-historical-data/data">https://www.kaggle.com/mczielinski/bitcoin-historical-data/data</a>.</p>
<p>Once you've downloaded the dataset, try to extract the most important features and convert the dataset into a time series so that it can be fed into an LSTM model. Then the model can be trained with the time series for each time step.</p>
<p><strong>Answer</strong> <strong>to question 2:</strong> Our sample project only calculates the stock price of those stocks whose actual stock price is given, and not the next day's stock price. It shows <kbd>actual</kbd> and <kbd>predicted</kbd>, but the next day's stock price should only contain <kbd>predicted</kbd>. This is what is happening if we take predicted values as input for the next prediction:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f9c0c769-0e8a-467d-9771-8c9d377e2565.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Predicted versus actual prices for <kbd>ALL</kbd> categories, where predicted values are input for the next prediction</div>
<p><strong>Answer</strong> <strong>to question</strong> <strong>3:</strong> Well, then the task would be a binary classification problem. To make this happen, you need to make two changes:</p>
<ul>
<li>Convert the dataset such that there will be two labels</li>
<li>Replace the <kbd>IDENTITY</kbd> activation function and <kbd>RMSE</kbd> loss with cross-entropy loss</li>
</ul>
<p><strong>Answer to question 4:</strong> That is a great idea. You can try improving the modeling by following questions 1 and 2. Then you can save the model on disk for later stage inferencing. Finally, you can serve this model as a web application, as suggested in previous chapters.</p>
<p><strong>Answer</strong> <strong>to question </strong><strong>5</strong>: Applying anomaly detection in such a dataset is very challenging, and I am not sure whether it is feasible, since the market has very high volatility. Therefore, the time series will have very many vicissitudes sometimes, which is the nature of the stock market. This helps the trained model to identify that abnormal volatility.</p>
<p>Answer <strong>to question 6:</strong> Yes, you can. You can try using <span class="heading"><strong>Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014 Data Set.</strong> This dataset can be downloaded from <kbd>UCI ML repository</kbd> at <a href="https://archive.ics.uci.edu/ml/datasets/Machine+Learning+based+ZZAlpha+Ltd.+Stock+Recommendations+2012-2014">https://archive.ics.uci.edu/ml/datasets/Machine+Learning+based+ZZAlpha+Ltd.+Stock+Recommendations+2012-2014</a>. The repository also describes the problem as well as the dataset.</span></p>


            </article>

            
        </section>
    </body></html>