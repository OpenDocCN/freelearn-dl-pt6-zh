["```py\n//DataPreview.java\nSparkSession spark = SparkSession.*builder*().master(\"local\").appName(\"StockPricePredictor\").getOrCreate();\nspark.conf().set(\"spark.sql.crossJoin.enabled\", \"true\");//enables cross joining across Spark DataFrames\n\n// load data from csv file\nString filename = \"data/prices-split-adjusted.csv\"; \nDataset<Row> data = spark.read().option(\"inferSchema\", false).option(\"header\", true)\n       .format(\"csv\").load(filename)\n             .withColumn(\"openPrice\", functions.*col*(\"open\").cast(\"double\")).drop(\"open\")\n             .withColumn(\"closePrice\", functions.*col*(\"close\").cast(\"double\")).drop(\"close\")\n             .withColumn(\"lowPrice\", functions.*col*(\"low\").cast(\"double\")).drop(\"low\")\n             .withColumn(\"highPrice\", functions.*col*(\"high\").cast(\"double\")).drop(\"high\")\n             .withColumn(\"volumeTmp\", functions.*col*(\"volume\").cast(\"double\")).drop(\"volume\")\n             .toDF(\"date\", \"symbol\", \"open\", \"close\", \"low\", \"high\", \"volume\");\ndata.show(10);\n```", "```py\ndata.createOrReplaceTempView(\"stock\");\nspark.sql(\"SELECT DISTINCT symbol FROM stock GROUP BY symbol\").show(10);\n```", "```py\nspark.sql(\"SELECT symbol, avg(open) as avg_open, \"\n                + \"avg(close) as avg_close, \"\n                + \"avg(low) as avg_low, \"\n                + \"avg(high) as avg_high \"\n                + \"FROM stock GROUP BY symbol\")\n                .show(10); \n```", "```py\nspark.sql(\"SELECT symbol, \"\n                + \"MIN(open) as min_open, MAX(open) as max_open, \"\n                + \"MIN(close) as min_close, MAX(close) as max_close, \"\n                + \"MIN(low) as min_low, MAX(low) as max_low, \"\n                + \"MIN(high) as min_high, MAX(high) as max_high \"\n                + \"FROM stock GROUP BY symbol\")\n                .show(10);   \n```", "```py\n// StockPricePrediction.java\nString file = \"data/prices-split-adjusted.csv\";\nString symbol = \"GRMN\"; // stock name\nint batchSize = 128; // mini-batch size\ndouble splitRatio = 0.8; // 80% for training, 20% for testing\nint epochs = 100; // training epochs\n```", "```py\n//StockPricePrediction.java\nSystem.*out*.println(\"Creating dataSet iterator...\");\nPriceCategory category = PriceCategory.*ALL*; // CLOSE: predict close price\n\n*iterator* = new StockDataSetIterator(file, symbol, batchSize, *exampleLength*, splitRatio, category);\nSystem.*out*.println(\"Loading test dataset...\");\nList<Pair<INDArray, INDArray>> test = *iterator*.getTestDataSet();\n```", "```py\npublic enum PriceCategory {\n      OPEN, CLOSE, LOW, HIGH, VOLUME, ALL}\n```", "```py\nPriceCategory category = PriceCategory.OPEN; // OPEN: predict open price\nPriceCategory category = PriceCategory.CLOSE; // CLOSE: predict close price\nPriceCategory category = PriceCategory.LOW; // LOW: predict low price\nPriceCategory category = PriceCategory.HIGH; // HIGH: predict high price.\n```", "```py\n//StockDataSetIterator.java\n/** stock dataset for training */\nprivate List<StockData> train;\n```", "```py\n//StockData.java\nprivate String date; // date\nprivate String symbol; // stock name\n\nprivate double open; // open price\nprivate double close; // close price\nprivate double low; // low price\nprivate double high; // high price\nprivate double volume; // volume\n\npublic StockData () {}\n\npublic StockData (String date, String symbol, double open, double close, double low, double high, double volume) {\n        this.date = date;\n        this.symbol = symbol;\n        this.open = open;\n        this.close = close;\n        this.low = low;\n        this.high = high;\n        this.volume = volume;\n    }\n```", "```py\npublic String getDate() { return date; }\npublic void setDate(String date) { this.date = date; }\n\npublic String getSymbol() { return symbol; }\npublic void setSymbol(String symbol) { this.symbol = symbol; }\n\npublic double getOpen() { return open; }\npublic void setOpen(double open) { this.open = open; }\n\npublic double getClose() { return close; }\npublic void setClose(double close) { this.close = close; }\n\npublic double getLow() { return low; }\npublic void setLow(double low) { this.low = low; }\n\npublic double getHigh() { return high; }\npublic void setHigh(double high) { this.high = high; }\n\npublic double getVolume() { return volume; }\npublic void setVolume(double volume) { this.volume = volume; }\n```", "```py\n/** adjusted stock dataset for testing */\nprivate List<Pair<INDArray, INDArray>> test;\n\npublic StockDataSetIterator (String filename, String symbol, int miniBatchSize, int exampleLength, \n        double splitRatio, PriceCategory category) {\n        List<StockData> stockDataList = readStockDataFromFile(filename, symbol);\n\n        this.miniBatchSize = miniBatchSize;\n        this.exampleLength = exampleLength;\n        this.category = category;\n\n        int split = (int) Math.round(stockDataList.size() * splitRatio);\n        train = stockDataList.subList(0, split);\n        test = generateTestDataSet(stockDataList.subList(split, stockDataList.size()));\n        initializeOffsets();\n    }\n```", "```py\nprivate void initializeOffsets() {\n        exampleStartOffsets.clear();\n        int window = exampleLength + predictLength;\n        for(int i = 0; i < train.size() - window; i++) {\n              exampleStartOffsets.add(i); \n                }\n    }\n```", "```py\nprivate List<StockData> readStockDataFromFile (String filename, String symbol) {\n        List<StockData> stockDataList = new ArrayList<>();\n        try {\n            for(int i = 0; i < maxArray.length; i++) { // initialize max and min arrays\n                maxArray[i] = Double.MIN_VALUE;\n                minArray[i] = Double.MAX_VALUE;\n            }\n            List<String[]> list = new CSVReader(new FileReader(filename)).readAll();//load as a list\n            for(String[] arr : list) {\n                if(!arr[1].equals(symbol)) continue;\n                double[] nums = new double[VECTOR_SIZE];\n\n                for(int i = 0; i < arr.length - 2; i++) {\n                    nums[i] = Double.valueOf(arr[i + 2]);\n\n                    if(nums[i] > maxArray[i]) maxArray[i] = nums[i];\n                    if(nums[i] < minArray[i]) minArray[i] = nums[i];\n                }\n                stockDataList.add(new StockData(arr[0], arr[1], nums[0], nums[1], \n                                  nums[2], nums[3], nums[4]));\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n        return stockDataList;\n    }\n```", "```py\nprivate List<Pair<INDArray, INDArray>> generateTestDataSet (List<StockData> stockDataList) {\n        int window = exampleLength + predictLength;\n        List<Pair<INDArray, INDArray>> test = new ArrayList<>();\n\n        for (int i = 0; i < stockDataList.size() - window; i++) {\n            INDArray input = Nd4j.create(new int[] {exampleLength, VECTOR_SIZE}, 'f');\n\n            for (int j = i; j < i + exampleLength; j++) {\n                StockData stock = stockDataList.get(j);\n                input.putScalar(new int[] {j - i, 0}, (stock.getOpen() - minArray[0]) / (maxArray[0] - \n                     minArray[0]));\n                input.putScalar(new int[] {j - i, 1}, (stock.getClose() - minArray[1]) / (maxArray[1] -    \n                     minArray[1]));\n                input.putScalar(new int[] {j - i, 2}, (stock.getLow() - minArray[2]) / (maxArray[2] - \n                     minArray[2]));\n                input.putScalar(new int[] {j - i, 3}, (stock.getHigh() - minArray[3]) / (maxArray[3] - \n                     minArray[3]));\n                input.putScalar(new int[] {j - i, 4}, (stock.getVolume() - minArray[4]) / (maxArray[4] - \n                       minArray[4]));\n            }\n            StockData stock = stockDataList.get(i + exampleLength);\n            INDArray label;\n\n            if (category.equals(PriceCategory.ALL)) {\n                label = Nd4j.create(new int[]{VECTOR_SIZE}, 'f'); // ordering is set faster construct\n                label.putScalar(new int[] {0}, stock.getOpen());\n                label.putScalar(new int[] {1}, stock.getClose());\n                label.putScalar(new int[] {2}, stock.getLow());\n                label.putScalar(new int[] {3}, stock.getHigh());\n                label.putScalar(new int[] {4}, stock.getVolume());\n            } else {\n                label = Nd4j.create(new int[] {1}, 'f');\n                switch (category) {\n                    case OPEN: label.putScalar(new int[] {0}, stock.getOpen()); break;\n                    case CLOSE: label.putScalar(new int[] {0}, stock.getClose()); break;\n                    case LOW: label.putScalar(new int[] {0}, stock.getLow()); break;\n                    case HIGH: label.putScalar(new int[] {0}, stock.getHigh()); break;\n                    case VOLUME: label.putScalar(new int[] {0}, stock.getVolume()); break;\n                    default: throw new NoSuchElementException();\n                }\n            }\n            test.add(new Pair<>(input, label));\n        }\n        return test;\n    }\n```", "```py\nprivate double feedLabel(StockData data) {\n        double value;\n\n        switch(category) {\n            case OPEN: value = (data.getOpen() - minArray[0]) / (maxArray[0] - minArray[0]); break;\n            case CLOSE: value = (data.getClose() - minArray[1]) / (maxArray[1] - minArray[1]); break;\n            case LOW: value = (data.getLow() - minArray[2]) / (maxArray[2] - minArray[2]); break;\n            case HIGH: value = (data.getHigh() - minArray[3]) / (maxArray[3] - minArray[3]); break;\n            case VOLUME: value = (data.getVolume() - minArray[4]) / (maxArray[4] - minArray[4]); break;\n            default: throw new NoSuchElementException();\n        }\n        return value;\n    }\n```", "```py\npublic DataSet next(int num) {\n        if(exampleStartOffsets.size() == 0) throw new NoSuchElementException();\n        int actualMiniBatchSize = Math.min(num, exampleStartOffsets.size());\n\n        INDArray input = Nd4j.create(new int[] {actualMiniBatchSize, VECTOR_SIZE, exampleLength}, 'f');\n        INDArray label;\n\n        if(category.equals(PriceCategory.ALL)) \n            label = Nd4j.create(new int[] {actualMiniBatchSize, VECTOR_SIZE, exampleLength}, 'f');\n        else \n            label = Nd4j.create(new int[] {actualMiniBatchSize, predictLength, exampleLength}, 'f');\n\n        for(int index = 0; index < actualMiniBatchSize; index++) {\n            int startIdx = exampleStartOffsets.removeFirst();\n            int endIdx = startIdx + exampleLength;\n\n            StockData curData = train.get(startIdx);\n            StockData nextData;\n\n            for(int i = startIdx; i < endIdx; i++) {\n                int c = i - startIdx;\n                input.putScalar(new int[] {index, 0, c}, (curData.getOpen() - minArray[0]) \n                                 / (maxArray[0] - minArray[0]));\n                input.putScalar(new int[] {index, 1, c}, (curData.getClose() - minArray[1]) \n                                 / (maxArray[1] - minArray[1]));\n                input.putScalar(new int[] {index, 2, c}, (curData.getLow() - minArray[2]) \n                                 / (maxArray[2] - minArray[2]));\n                input.putScalar(new int[] {index, 3, c}, (curData.getHigh() - minArray[3]) \n                                 / (maxArray[3] - minArray[3]));\n                input.putScalar(new int[] {index, 4, c}, (curData.getVolume() - minArray[4]) \n                                 / (maxArray[4] - minArray[4]));\n                nextData = train.get(i + 1);\n\n                if(category.equals(PriceCategory.ALL)) {\n                    label.putScalar(new int[] {index, 0, c}, (nextData.getOpen() - minArray[1]) \n                                    / (maxArray[1] - minArray[1]));\n                    label.putScalar(new int[] {index, 1, c}, (nextData.getClose() - minArray[1]) \n                                   / (maxArray[1] - minArray[1]));\n                    label.putScalar(new int[] {index, 2, c}, (nextData.getLow() - minArray[2]) \n                                   / (maxArray[2] - minArray[2]));\n                    label.putScalar(new int[] {index, 3, c}, (nextData.getHigh() - minArray[3]) \n                                   / (maxArray[3] - minArray[3]));\n                    label.putScalar(new int[] {index, 4, c}, (nextData.getVolume() - minArray[4]) \n                                   / (maxArray[4] - minArray[4]));\n                } else {\n                    label.putScalar(new int[]{index, 0, c}, feedLabel(nextData));\n                }\n                curData = nextData;\n            }\n            if(exampleStartOffsets.size() == 0) break;\n        }\n        return new DataSet(input, label);\n    }\n```", "```py\nprivate static final int lstmLayer1Size = 128;\nprivate static final int lstmLayer2Size = 128;\nprivate static final int denseLayerSize = 32;\nprivate static final double dropoutRatio = 0.5;\nprivate static final int truncatedBPTTLength = 22;\n```", "```py\npublic static MultiLayerNetwork createAndBuildLstmNetworks(int nIn, int nOut) {\n        // Creating MultiLayerConfiguration \n        MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()\n                .seed(123456)// for the reproducibility\n                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)//optimizer\n                .updater(new Adam(0.001)) // Adam updater with SGD\n                .l2(1e-4)// l2 regularization\n                .weightInit(WeightInit.XAVIER)// network weight initialization\n                .activation(Activation.RELU)// ReLU as activation\n                .list()\n                .layer(0, new LSTM.Builder()//LSTM layer 1\n                        .nIn(nIn)\n                        .nOut(lstmLayer1Size)\n                        .activation(Activation.TANH)\n                        .gateActivationFunction(Activation.HARDSIGMOID)// Segment-wise linear       \n                                                                       // approximation of sigmoid\n                        .dropOut(dropoutRatio)// keeping drop-out ratio\n                        .build())\n                .layer(1, new LSTM.Builder()// LSTM layer 2\n                        .nIn(lstmLayer1Size)\n                        .nOut(lstmLayer2Size)\n                        .activation(Activation.TANH)\n                        .gateActivationFunction(Activation.HARDSIGMOID)\n                        .dropOut(dropoutRatio)//kee drop-out ratio\n                        .build())\n                .layer(2, new LSTM.Builder()//LSTM layer 3\n                        .nIn(lstmLayer1Size)\n                        .nOut(lstmLayer2Size)\n                        .activation(Activation.TANH)\n                        .gateActivationFunction(Activation.HARDSIGMOID)\n                        .dropOut(dropoutRatio)// keep drop-out ratio\n                        .build())\n                .layer(3, new DenseLayer.Builder()// FC layer 1\n                        .nIn(lstmLayer2Size)\n                        .nOut(denseLayerSize)\n                        .activation(Activation.RELU)\n                        .build())\n                .layer(4, new DenseLayer.Builder()//FC layer 2\n                        .nIn(denseLayerSize)\n                        .nOut(denseLayerSize)\n                        .activation(Activation.RELU)\n                        .build())\n                .layer(5, new DenseLayer.Builder()//FC layer 3\n                        .nIn(denseLayerSize)\n                        .nOut(denseLayerSize)\n                        .activation(Activation.RELU)\n                        .build())\n                .layer(6, new RnnOutputLayer.Builder() // RNN output layer\n                        .nIn(denseLayerSize)\n                        .nOut(nOut)\n                        .activation(Activation.IDENTITY)// Regression with MSE as the loss function\n                        .lossFunction(LossFunctions.LossFunction.MSE)\n                        .build())\n                .backpropType(BackpropType.TruncatedBPTT)// Back propagation with time\n                .tBPTTForwardLength(truncatedBPTTLength)\n                .tBPTTBackwardLength(truncatedBPTTLength)\n                .pretrain(false).backprop(true)//no pretraining necessary\n                .build();\n\n        // Creating MultiLayerNetwork using the above MultiLayerConfig\n        MultiLayerNetwork net = new MultiLayerNetwork(conf);\n        net.init(); // initilize the MultiLayerNetwork\n        net.setListeners(new ScoreIterationListener(100));// shows score in each 100th iteration/epoch\n        return net; // return the MultiLayerNetwork\n    }\n```", "```py\n//Create output layer\n    .layer()\n    .nIn($NumberOfInputFeatures)\n    .nOut(1)// regression hence, only a single output\n    .activation(Activation.IDENTITY)//Regression with RMSE as the loss function\n    .lossFunction(LossFunctions.LossFunction.RMSE)\n```", "```py\n// StockPricePrediction.java\nSystem.out.println(\"Training LSTM network...\");\nfor(int i = 0; i < epochs; i++) {\n            while(iterator.hasNext()) net.fit(iterator.next()); // fit model using mini-batch data\n            iterator.reset(); // reset iterator\n            net.rnnClearPreviousState(); // clear previous state\n        }\n\n>>\n Creating dataSet iterator...\n Loading test dataset...\n Building LSTM networks...\n Training LSTM network...\n```", "```py\n# StockPricePrediction.java\nSystem.*out*.println(\"Saving model...\");\nFile locationToSave = new File(\"data/StockPriceLSTM_\".concat(String.*valueOf*(category)).concat(\".zip\"));\n\n// saveUpdater: i.e., state for Momentum, RMSProp, Adagrad etc. Save this to train your network in future\nModelSerializer.*writeModel*(net, locationToSave, true);\n```", "```py\n//Print the  number of parameters in the network (and for each layer)\nLayer[] layers_before_saving = net.getLayers();\n              int totalNumParams_before_saving = 0;\n\n              for(int i=0; i<layers_before_saving.length; i++ ){\n                  int nParams = layers_before_saving[i].numParams();\n                  System.out.println(\"Number of parameters in layer \" + i + \": \" + nParams);\n                  totalNumParams_before_saving += nParams;\n              }\nSystem.out.println(\"Total number of network parameters: \" + totalNumParams_before_saving);\n>>>\n Saving model...\n Number of parameters in layer 0: 68608\n Number of parameters in layer 1: 131584\n Number of parameters in layer 2: 131584\n Number of parameters in layer 3: 4128\n Number of parameters in layer 4: 1056\n Number of parameters in layer 5: 1056\n Number of parameters in layer 6: 165\n Total number of network parameters: 338181\n```", "```py\n//Initialize the user interface backend\nUIServer uiServer = UIServer.*getInstance*();\n\n//Configure where the network information (gradients, activations, score vs. time etc) is to be stored. //Then add the StatsListener to collect this information from the network, as it trains:\nStatsStorage statsStorage = new InMemoryStatsStorage();\n\n//Alternative: new FileStatsStorage(File) - see UIStorageExample. Attach the StatsStorage instance to the //UI: this allows the contents of the StatsStorage to be visualized:\nuiServer.attach(statsStorage);\n\nint listenerFrequency = 1;\nnet.setListeners(new StatsListener(statsStorage, listenerFrequency));\n```", "```py\nSystem.*out*.println(\"Restoring model...\");\nnet = ModelSerializer.*restoreMultiLayerNetwork*(locationToSave);\n\n//print the score with every 1 iteration\nnet.setListeners(new ScoreIterationListener(1));\n\n//Print the number of parameters in the network (and for each layer)\nLayer[] layers = net.getLayers(); \n\nint totalNumParams = 0;\nfor( int i=0; i<layers.length; i++ ){\n        int nParams = layers[i].numParams(); \n       System.*out*.println(\"Number of parameters in layer \" + i + \": \" + nParams);\n       totalNumParams += nParams;\n}\nSystem.*out*.println(\"Total number of network parameters: \" + totalNumParams);\n>>>\n Restoring model...\n Number of parameters in layer 0: 68608\n Number of parameters in layer 1: 131584\n Number of parameters in layer 2: 131584\n Number of parameters in layer 3: 4128\n Number of parameters in layer 4: 1056\n Number of parameters in layer 5: 1056\n Number of parameters in layer 6: 165\n Total number of network parameters: 338181\n```", "```py\n/** Predict one feature of a stock one-day ahead */\nprivate static void predictPriceOneAhead (MultiLayerNetwork net, List<Pair<INDArray, INDArray>> testData, double max, double min, PriceCategory category) {\n        double[] predicts = new double[testData.size()];\n        double[] actuals = new double[testData.size()];\n\n        for (int i = 0; i < testData.size(); i++) {\n            predicts[i] = net.rnnTimeStep(testData.get(i).getKey()).getDouble(exampleLength - 1) \n                          * (max - min) + min;\n            actuals[i] = testData.get(i).getValue().getDouble(0);\n        }\n\n        RegressionEvaluation eval = net.evaluateRegression(iterator);   \n        System.out.println(eval.stats());\n\n        System.out.println(\"Printing predicted and actual values...\");\n        System.out.println(\"Predict, Actual\");\n\n        for (int i = 0; i < predicts.length; i++) \n            System.out.println(predicts[i] + \",\" + actuals[i]);\n\n        System.out.println(\"Plottig...\");\n        PlotUtil.plot(predicts, actuals, String.valueOf(category));\n    }\n```", "```py\nPriceCategory category = PriceCategory.OPEN; // OPEN: predict open price\nPriceCategory category = PriceCategory.CLOSE; // CLOSE: predict close price\nPriceCategory category = PriceCategory.LOW; // LOW: predict low price\nPriceCategory category = PriceCategory.HIGH; // HIGH: predict high price\n```", "```py\n/** Predict all the features (open, close, low, high prices and volume) of a stock one-day ahead */\nprivate static void predictAllCategories (MultiLayerNetwork net, List<Pair<INDArray, INDArray>> testData, INDArray max, INDArray min) {\n        INDArray[] predicts = new INDArray[testData.size()];\n        INDArray[] actuals = new INDArray[testData.size()];\n        for(int i = 0; i < testData.size(); i++) {\n            predicts[i] = net.rnnTimeStep(testData.get(i).getKey()).getRow(exampleLength - 1)\n                          .mul(max.sub(min)).add(min);\n            actuals[i] = testData.get(i).getValue();\n        }\n\n        System.out.println(\"Printing predicted and actual values...\");\n        System.out.println(\"Predict, Actual\");\n\n        for(int i = 0; i < predicts.length; i++) \n            System.out.println(predicts[i] + \"\\t\" + actuals[i]);\n        System.out.println(\"Plottig...\");\n\n        RegressionEvaluation eval = net.evaluateRegression(iterator);   \n        System.out.println(eval.stats());\n\n        for(int n = 0; n < 5; n++) {\n            double[] pred = new double[predicts.length];\n            double[] actu = new double[actuals.length];\n\n            for(int i = 0; i < predicts.length; i++) {\n                pred[i] = predicts[i].getDouble(n);\n                actu[i] = actuals[i].getDouble(n);\n            }\n            String name;\n            switch(n) {\n                case 0: name = \"Stock OPEN Price\"; break;\n                case 1: name = \"Stock CLOSE Price\"; break;\n                case 2: name = \"Stock LOW Price\"; break;\n                case 3: name = \"Stock HIGH Price\"; break;\n                case 4: name = \"Stock VOLUME Amount\"; break;\n                default: throw new NoSuchElementException();\n            }\n            PlotUtil.plot(pred, actu, name);\n        }\n    }\n```", "```py\npublic static void plot(double[] predicts, double[] actuals, String name) {\n        double[] index = new double[predicts.length];\n        for(int i = 0; i < predicts.length; i++)\n            index[i] = i;\n\n        int min = minValue(predicts, actuals);\n        int max = maxValue(predicts, actuals);\n\n        final XYSeriesCollection dataSet = new XYSeriesCollection();\n        addSeries(dataSet, index, predicts, \"Predicted\");\n        addSeries(dataSet, index, actuals, \"Actual\");\n\n        final JFreeChart chart = ChartFactory.createXYLineChart(\n                \"Predicted vs Actual\", // chart title\n                \"Index\", // x axis label\n                name, // y axis label\n                dataSet, // data\n                PlotOrientation.VERTICAL,\n                true, // include legend\n                true, // tooltips\n                false // urls\n              );\n\n        XYPlot xyPlot = chart.getXYPlot();\n\n        // X-axis\n        final NumberAxis domainAxis = (NumberAxis) xyPlot.getDomainAxis();\n        domainAxis.setRange((int) index[0], (int) (index[index.length - 1] + 2));\n        domainAxis.setTickUnit(new NumberTickUnit(20));\n        domainAxis.setVerticalTickLabels(true);\n\n        // Y-axis\n        final NumberAxis rangeAxis = (NumberAxis) xyPlot.getRangeAxis();\n        rangeAxis.setRange(min, max);\n        rangeAxis.setTickUnit(new NumberTickUnit(50));\n\n        final ChartPanel panel = new ChartPanel(chart);\n        final JFrame f = new JFrame();\n        f.add(panel);\n        f.setDefaultCloseOperation(WindowConstants.EXIT_ON_CLOSE);\n        f.pack();\n        f.setVisible(true);\n    }\n```", "```py\nprivate static void addSeries (final XYSeriesCollection dataSet, double[] x, double[] y, final String label){\n        final XYSeries s = new XYSeries(label);\n        for(int j = 0; j < x.length; j++ ) s.add(x[j], y[j]);\n        dataSet.addSeries(s);\n    }\n```", "```py\nprivate static int minValue (double[] predicts, double[] actuals) {\n        double min = Integer.MAX_VALUE;\n\n        for(int i = 0; i < predicts.length; i++) {\n            if(min > predicts[i]) min = predicts[i];\n            if(min > actuals[i]) min = actuals[i];\n        }\n        return (int) (min * 0.98);\n    }\n```", "```py\nprivate static int maxValue (double[] predicts, double[] actuals) {\n        double max = Integer.MIN_VALUE;\n\n        for(int i = 0; i < predicts.length; i++) {\n            if(max < predicts[i]) max = predicts[i];\n            if(max < actuals[i]) max = actuals[i];\n        }\n        return (int) (max * 1.02);\n    }\n```", "```py\nSystem.out.println(\"Evaluating...\");\nif(category.equals(PriceCategory.OPEN)) {\n            INDArray max = Nd4j.create(iterator.getMaxArray());\n            INDArray min = Nd4j.create(iterator.getMinArray());\n            predictAllCategories(net, test, max, min);\n} else {\n            double max = iterator.getMaxNum(category);\n            double min = iterator.getMinNum(category);\n            predictPriceOneAhead(net, test, max, min, category);\n }\nSystem.out.println(\"Done...\");\n>>>\n Evaluating...\n Printing predicted and actual values...\n Predict, Actual\n ---------------------------------------\n 29.175033326034814,35.61000061035156\n 29.920153324534823,35.70000076293945\n 30.84457991629533,35.9900016784668\n 31.954761620513793,36.150001525878906\n 33.171770076832885,36.79999923706055\n 34.42622247035372,36.150001525878906\n 35.63831635695636,36.41999816894531\n 36.79695794284552,36.04999923706055\n 37.79222186089784,35.9900016784668\n 38.45504267616927,35.470001220703125\n 38.837315702846766,35.66999816894531\n```", "```py\nColumn MSE MAE RMSE RSE PC R^2\n -------------------------------------------------------------------------------------------\n col_0 3.27134e-02 1.14001e-01 1.80868e-01 5.53901e-01 7.17285e-01 4.46100e-01\n```", "```py\nSystem.out.println(\"Evaluating...\");\nif(category.equals(PriceCategory.ALL)) {\n            INDArray max = Nd4j.create(iterator.getMaxArray());\n            INDArray min = Nd4j.create(iterator.getMinArray());\n            predictAllCategories(net, test, max, min);\n} else {\n            double max = iterator.getMaxNum(category);\n            double min = iterator.getMinNum(category);\n            predictPriceOneAhead(net, test, max, min, category);\n   }\nSystem.out.println(\"Done...\");\n>>>\n Evaluating...\n Printing predicted and actual values...\n Predict, Actual\n ------------ ---------------------------------------------------------------\n [[27.8678,27.1462,27.0535,27.9431, 9.7079e5]] [[35.6100,35.8900,35.5500,36.1100, 1.5156e6]]\n [[28.3925,27.2648,27.2769,28.4423, 1.2579e6]] [[35.7000,35.8100,35.6500,36.1000,8.623e5]]\n [[29.0413,27.4402,27.6015,29.1540, 1.6014e6]] [[35.9900,36.1400,35.9000,36.3200, 1.0829e6]]\n [[29.9264,27.6811,28.0419,30.1133, 2.0673e6]] [[36.1500,36.7100,36.0700,36.7600, 1.0635e6]]\n [[30.9201,27.9385,28.5584,31.2908, 2.5381e6]] [[36.8000,36.5700,36.4600,37.1600, 1.0191e6]]\n [[32.0080,28.2469,29.1343,32.6514, 3.0186e6]] [[36.1500,36.2300,35.9300,36.7600, 1.8299e6]]\n [[33.1358,28.5809,29.7641,34.1525, 3.4644e6]] [[36.4200,36.5400,36.1800,36.8900,8.774e5]]\n [[45.2637,31.2634,39.5828,53.1128, 5.0282e6]] [[50.3600,49.2200,49.1700,50.4500,9.415e5]]\n [[45.1651,31.2336,39.5284,52.9815, 4.9879e6]] [[49.1700,49.0100,48.8100,49.4400,9.517e5]]\n```", "```py\nColumn MSE MAE RMSE RSE PC R^2\n -------------------------------------------------------------------------------------------------\n col_0 4.52917e-02 1.35709e-01 2.12819e-01 7.49715e-01 6.60401e-01 2.50287e-01\n col_1 1.52875e-01 3.27669e-01 3.90993e-01 2.54384e+00 6.61151e-01 -1.54384e+00\n col_2 8.46744e-02 2.19064e-01 2.90989e-01 1.41381e+00 6.01910e-01 -4.13806e-01\n col_3 6.05071e-02 1.93558e-01 2.45982e-01 9.98581e-01 5.95618e-01 1.41977e-03\n col_4 2.34488e-02 1.17289e-01 1.53130e-01 9.97561e+00 5.59983e-03 -8.97561e+00\n```"]