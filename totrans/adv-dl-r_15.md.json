["```py\n# IMDB data\nlibrary(keras)\nimdb <- dataset_imdb(num_words = 500) \nc(c(train_x, train_y), c(test_x, test_y)) %<-% imdb\ntrain_x <- pad_sequences(train_x, maxlen = 200) \ntest_x <- pad_sequences(test_x, maxlen = 200)\n```", "```py\n# Model architecture\nmodel <- keras_model_sequential() %>%\n         layer_embedding(input_dim = 500, output_dim = 32) %>%\n         layer_lstm(units = 32) %>%\n         layer_dense(units = 1, activation = \"sigmoid\")\nmodel\n__________________________________________________________________________\nLayer (type)                      Output Shape                  Param # \n==========================================================================\nembedding (Embedding)             (None, None, 32)              16000 \n__________________________________________________________________________\nlstm (LSTM)                       (None, 32)                    8320 \n__________________________________________________________________________\ndense (Dense)                     (None, 1)                     33 \n==========================================================================\nTotal params: 24,353\nTrainable params: 24,353\nNon-trainable params: 0\n__________________________________________________________________________\n```", "```py\n# Compile\nmodel %>% compile(optimizer = \"rmsprop\",  \n         loss = \"binary_crossentropy\",\n         metrics = c(\"acc\"))\n```", "```py\n# Fit model\nmodel_one <- model %>% fit(train_x, train_y,\n         epochs = 10,\n         batch_size = 128,\n         validation_split = 0.2)\nplot(model_one)\n```", "```py\n# Evaluate\nmodel %>% evaluate(train_x, train_y)\n$loss\n [1] 0.3749587\n$acc\n [1] 0.82752\n```", "```py\n# Confusion Matrix\npred <- model %>% predict_classes(train_x)\ntable(Predicted=pred, Actual=imdb$train$y)\n         Actual\n Predicted     0     1\n         0  9258  1070\n         1  3242 11430\n```", "```py\n# Evaluate\nmodel %>% evaluate(test_x, test_y)\n$loss\n [1] 0.3997277\n$acc\n [1] 0.81992\n```", "```py\n# Confusion Matrix\npred1 <- model %>$ predict_classes(text_x)\ntable(Predicted=pred1, Actual=imdb$test$y)\n         Actual\n Predicted     0     1\n         0  9159  1161\n         1  3341 11339\n```", "```py\n# Model architecture\nmodel <- keras_model_sequential() %>%\n         layer_embedding(input_dim = 500, output_dim = 32) %>%\n         layer_lstm(units = 32) %>%\n         layer_dense(units = 1, activation = \"sigmoid\")\n\n# Compile\nmodel %>% compile(optimizer = \"adam\",  \n         loss = \"binary_crossentropy\",\n         metrics = c(\"acc\"))\n\n# Fit model\nmodel_two <- model %>% fit(train_x, train_y,\n         epochs = 10,\n         batch_size = 128,\n         validation_split = 0.2)\nplot(model_two)\n```", "```py\n# Loss and accuracy\nmodel %>% evaluate(train_x, train_y)\n$loss\n[1] 0.3601628\n$acc\n[1] 0.8434\n\npred <- model %>%   predict_classes(train_x)\n\n# Confusion Matrix\ntable(Predicted=pred, Actual=imdb$train$y)\n         Actual\nPredicted     0     1\n        0 11122  2537\n        1  1378  9963\n```", "```py\n# Loss and accuracy\nmodel %>% evaluate(test_x, test_y)\n$loss\n[1] 0.3854687\n$acc\n[1] 0.82868\n\npred1 <- model %>%   predict_classes(test_x)\n\n# Confusion Matrix\ntable(Predicted=pred1, Actual=imdb$test$y)\n         Actual\nPredicted     0     1\n        0 10870  2653\n        1  1630  9847\n```", "```py\n# Number of positive and negative reviews in the train data\ntable(train_y)\ntrain_y\n    0     1 \n12500 12500 \n\n# Number of positive and negative review in the test data\ntable(test_y)\ntest_y\n    0     1 \n12500 12500 \n```", "```py\n# Model architecture\nmodel <- keras_model_sequential() %>%\n         layer_embedding(input_dim = 500, output_dim = 32) %>%\n         layer_lstm(units = 32,\n                    return_sequences = TRUE) %>%\n         layer_lstm(units = 32) %>%\n         layer_dense(units = 1, activation = \"sigmoid\")\n\n# Compiling model\nmodel %>% compile(optimizer = \"adam\",   \n         loss = \"binary_crossentropy\",\n         metrics = c(\"acc\"))\n\n# Fitting model\nmodel_three <- model %>% fit(train_x, train_y,\n         epochs = 10,\n         batch_size = 128,\n         validation_split = 0.2)\n\n# Loss and accuracy plot\nplot(model_three)\n```", "```py\n# Loss and accuracy\nmodel %>% evaluate(train_x, train_y)\n$loss\n[1] 0.3396379\n$acc\n[1] 0.85504\n\npred <- model %>%   predict_classes(train_x)\n\n# Confusion Matrix\ntable(Predicted=pred, Actual=imdb$train$y) \n         Actual\nPredicted     0     1\n        0 11245  2369\n        1  1255 10131\n```", "```py\n# Loss and accuracy\nmodel %>% evaluate(test_x, test_y)\n$loss\n[1] 0.3761043\n$acc\n[1] 0.83664\n\npred1 <- model %>%   predict_classes(test_x)\n\n# Confusion Matrix\ntable(Predicted=pred1, Actual=imdb$test$y)\n         Actual\nPredicted     0     1\n        0 10916  2500\n        1  1584 10000\n```", "```py\n# Model architecture\nmodel <- keras_model_sequential() %>%\n          layer_embedding(input_dim = 500, output_dim = 32) %>%\n          bidirectional(layer_lstm(units = 32)) %>%\n          layer_dense(units = 1, activation = \"sigmoid\")\n# Model summary\nsummary(model)\nModel\n__________________________________________________________\nLayer (type)              Output Shape           Param #  \n==========================================================\nembedding_8 (Embedding)   (None, None, 32)       16000    \n__________________________________________________________\nbidirectional_5 (Bidirect (None, 64)             16640    \n__________________________________________________________\ndense_11 (Dense)          (None, 1)              65       \n==========================================================\nTotal params: 32,705\nTrainable params: 32,705\nNon-trainable params: 0\n__________________________________________________________\n```", "```py\n# Compiling model\nmodel %>% compile(optimizer = \"adam\",   \n          loss = \"binary_crossentropy\",\n          metrics = c(\"acc\"))\n\n# Fitting model\n model_four <- model %>% fit(train_x, train_y,\n          epochs = 10,\n          batch_size = 128,\n          validation_split = 0.2)\n\n# Loss and accuracy plot\nplot(model_four)\n```", "```py\n# Loss and accuracy\nmodel %>% evaluate(train_x, train_y)\n$loss\n[1] 0.3410529\n$acc\n[1] 0.85232\n\npred <- model %>%   predict_classes(train_x)\n\n# Confusion Matrix\ntable(Predicted=pred, Actual=imdb$train$y)\n         Actual\nPredicted     0     1\n        0 10597  1789\n        1  1903 10711\n```", "```py\n# Loss and accuracy\nmodel %>% evaluate(test_x, test_y)\n$loss\n[1] 0.3737377\n$acc\n[1] 0.83448\n\npred1 <- model %>%   predict_classes(test_x)\n\n#Confusion Matrix\ntable(Predicted=pred1, Actual=imdb$test$y)\n         Actual\nPredicted     0     1\n        0 10344  1982\n        1  2156 10518\n```"]