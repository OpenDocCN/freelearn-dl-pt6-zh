<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Developing Movie Recommendation Systems Using Factorization Machines</h1>
                </header>
            
            <article>
                
<p><strong>Factorization machines</strong> (<strong>FM</strong>) are a set of algorithms that enhance the performance of linear models by incorporating second-order feature interactions that are absent in <strong>matrix factorization</strong> (<strong>MF</strong>) algorithms in a supervised way. Therefore, FMs are very robust compared to their classical counterpart—<strong>collaborative filtering </strong>(<strong>CF</strong>)<span>—a</span>nd are gaining popularity in personalization and recommendation systems because they can be used to discover latent features underlying the interactions between two different kinds of entities.</p>
<p>In this chapter, we will develop a sample project for predicting both the rating and ranking to show their effectiveness. Nevertheless, we will see some theoretical background of recommendation systems using MF and CF before diving into the project's implementation using RankSys library-based FMs. In summary, the following topics will be covered in this chapter:</p>
<ul>
<li>Recommendation systems</li>
<li>Matrix factorization and the collaborative filtering approach</li>
<li>Developing FM-based move recommendation systems</li>
<li>Frequently asked questions (FAQs).</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recommendation systems</h1>
                </header>
            
            <article>
                
<p>Recommender techniques are nothing but information agents that try to predict items that users may be interested in and recommend the best ones to the target user. These techniques can be classified based on the information sources they use. For example, user features (age, gender, income, and location), item features (keywords, and genres), user-item ratings (explicit ratings, and transaction data), and other information about the user and item that are useful for the process of recommendation.</p>
<p>Thus, a recommendation system; otherwise known as a <strong>recommendation engine</strong> (<strong>RE</strong>) is a subclass of information filtering systems that help to predict the rating or preference based on the rating provided by users to an item. In recent years, recommendation systems have become increasingly popular.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recommendation approaches</h1>
                </header>
            
            <article>
                
<p>There are a couple of ways to develop REs to produce a list of recommendations, for example, collaborative and content-based filtering, knowledge-based, or the personality-based approach.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Collaborative filtering approaches</h1>
                </header>
            
            <article>
                
<p>By using CF approaches, an RE can be built based on a user's past behavior. Numerical ratings are given on consumed items. Sometimes, it can be based on the decisions made by other users who also have purchased the same items using some widely used data mining algorithms such as Apriori or FP-growth. In the following diagram, you can get some idea of the different recommendation systems:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-667 image-border" src="assets/941dcf58-8778-4aa2-bb6d-caaf171215e3.png" style=""/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">A comparative view of different recommendation systems</div>
<p>Even though these are successful recommendation systems, CF-based approaches often suffer from the following three problems:</p>
<ul>
<li><strong>Cold start: </strong>Sometimes, they can become stuck when a large amount of data about users is required to make a more accurate recommendation system.</li>
<li><strong>Scalability: </strong>A large amount of computation power is often necessary to calculate recommendations using a dataset with millions of users and products.</li>
<li><strong>Sparsity: </strong>This often happens with crowdsourced datasets when a huge number of items are sold on major e-commerce sites. All recommendation datasets are crowd-sourced in some sense. This is a general problem for almost all recommendation systems that have a sufficiently large number of items to offer to a sufficiently large number of users and need not be confined to e-commerce sites only.</li>
</ul>
<p>In this case, active users may rate only a small subset of the whole items sold, so even the most popular items have very few ratings. Accordingly, the user versus items matrix becomes very sparse. In other words, handling a large-scale sparse matrix is computationally very challenging.</p>
<p>To overcome these issues, a particular type of collaborative filtering algorithm uses matrix factorization, which is a low-rank matrix approximation technique. We will see an example of this later in this chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Content-based filtering approaches</h1>
                </header>
            
            <article>
                
<p>With content-based filtering approaches, a series of discrete characteristics of an item are utilized to recommend additional items with similar properties. Sometimes, it is based on a description of the item and a profile of the user's preferences. These approaches try to recommend items that are similar to those that a user liked in the past, or that are currently being used.</p>
<p>A key issue with content-based filtering is whether the system is able to learn user preferences from their actions regarding one content source and use them with other content types. When this type of RE is deployed, it can then be used to predict items or ratings for items that the user may have an interest in.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hybrid recommender systems</h1>
                </header>
            
            <article>
                
<p>As you have seen, there are several pros and cons of using collaborative filtering and content-based filtering approaches. Therefore, to overcome the limitations of these two approaches, recent trends have shown that a hybrid approach can be more effective and accurate. Sometimes, factorization approaches such as FM and <strong>Singular Value Decomposition</strong> (<strong>SVD</strong>) are used to make them robust.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model-based collaborative filtering</h1>
                </header>
            
            <article>
                
<p>Collaborative filtering methods are classified as memory-based, such as the user-based algorithm and model-based collaborative filtering (kernel mapping is recommended). In the model-based collaborative filtering technique, users and products are described by a small set of factors, also called <strong>latent factors</strong> (<strong>LFs</strong>). The LFs are then used to predict the missing entries. The <strong>Alternating Least Squares</strong> (<strong>ALS</strong>) algorithm is used to learn these latent factors.</p>
<p>Compared to a memory-based approach, a model-based approach can handle the sparsity of the original matrix better. This is also scalable, faster, and can avoid overfitting issues. However, it is not flexible and adaptable because it is difficult to add data to the model. Now, let's take a look at an important element in the collaborative filtering approach, called the utility matrix.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The utility matrix</h1>
                </header>
            
            <article>
                
<p>In a collaborative filtering-based recommendation system, there are dimensions of entities: users and items (items refers to products, such as movies, games, and songs). As a user, you might have preferences for certain items. Therefore, these preferences must be motivated out of the data about items, users, or ratings. This data is often represented as a utility matrix, such as a user-item pair. This type of value can represent what is known about the degree of preference that the user has for a particular item.</p>
<p>The following table shows an example utility matrix that represents the rating users have given to movies on a 1-5 scale, with 5 being the highest rating. <strong>HP1</strong>, <strong>HP2</strong>, and <strong>HP3</strong> are acronyms for <em>Harry Potter I</em>, <em>II</em>, and <em>III</em>, <strong>TW</strong> stands for <em>Twilight</em>, and <strong>SW1</strong>, <strong>SW2</strong>, and <strong>SW3</strong> ;stands for <em>Star Wars episodes 1</em>, 2, and 3. The letters <strong>A</strong>, <strong>B</strong>, <strong>C</strong>, and <strong>D</strong> represent the users:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-668 image-border" src="assets/a0963aa4-7115-4b60-834f-de08bdee83dc.png" style=""/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Utility matrix (user versus movies matrix)</div>
<p>There are many blank entries for the user-movie pairs. This means that users have not rated those movies, which increases sparsity. Using this matrix, the goal is to predict the blanks in the utility matrix. Suppose we are curious to know whether user <strong>A</strong> would like <strong>SW2</strong>. This is difficult to predict since there is not much data in the matrix.</p>
<p>Therefore, other properties regarding movies, such as the producer, director, leading actors, or even the similarity of their names, can be used to compute the similarity of the movies <strong>SW1</strong> and <strong>SW2</strong>. This similarity would drive us to conclude that since <strong>A</strong> did not like <strong>SW1</strong>, they are unlikely to enjoy <strong>SW2</strong> either.</p>
<p>However, this might not work for a larger dataset. Therefore, with much more data, we might observe that the people who rated both <strong>SW1</strong> and <strong>SW2</strong> were inclined to give them similar ratings. Finally, we can conclude that A would also give <strong>SW2</strong> a low rating, similar to <strong>A</strong>'s rating of <strong>SW1</strong>. This approach, however, has a serious drawback called the ;<strong>cold-start problem</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The cold-start problem in collaborative-filtering approaches</h1>
                </header>
            
            <article>
                
<p>The term cold-start problem sounds funny, but, as the name implies, it derives from cars. In recommendation engines, however, the term cold-start simply means a circumstance that is not yet optimal for the engine to provide the best possible results.</p>
<p>In collaborative filtering approaches, the recommender system would identify users who share preferences with the active user and propose items that like-minded users have favored. Due to the cold-start problem, this approach would fail to consider items that no-one in the community has rated.</p>
<p>Recommendation engines using CF-based approaches recommend each item based on user actions. The more user actions an item has, the easier it is to tell which user would be interested in it and what other items are similar to it. As time progresses, the system will be able to give more and more accurate recommendations. At a certain stage, when new items or users are added to the user-item matrix, the following problem occurs:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-669 image-border" src="assets/09ebe6c2-f70c-4fbc-b0a0-1392572ad78f.png" style=""/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Users versus items matrices sometimes lead to the cold-start problem</div>
<p>In this case, the RE does not have enough knowledge about this new user or this new item yet. The content-based filtering approach, similar to FM, is a method that can be incorporated to alleviate the cold-start problem.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Factorization machines in recommender systems</h1>
                </header>
            
            <article>
                
<p>In real life, most recommendation problems assume that we have a rating dataset formed by a collection of (user, item, and rating) tuples. However, in many applications, we have plenty of item metadata (tags, categories, and genres) that can be used to make better predictions.</p>
<p>This is one of the benefits of using FMs with feature-rich datasets, because there is a natural way in which extra features can be included in the model, and higher-order interactions can be modeled using the dimensionality parameter.</p>
<p>A few recent types of research show which feature-rich datasets give better predictions:</p>
<ul>
<li>Xiangnan He and Tat-Seng Chua, <em>Neural Factorization Machines for Sparse Predictive Analytics</em>. During proceedings of SIGIR '17, Shinjuku, Tokyo, Japan, August 07-11, 2017</li>
<li>Jun Xiao, Hao Ye, Xiangnan He, Hanwang Zhang, Fei Wu and Tat-Seng Chua (2017). <em>Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks</em> IJCAI, Melbourne, Australia, August 19-25, 2017</li>
</ul>
<p>These papers explain how to make existing data into a feature-rich dataset and how FMs were implemented on the dataset. Therefore, researchers are trying to use FMs to develop more accurate and robust REs. In the next section, we will start developing our project for movie recommendations using FMs. For that, we will be using Apache Spark and RankSys libraries.</p>
<p>Existing recommendation algorithms require a consumption (product) or rating (movie) dataset in <em>(user, item, rating)</em> tuples. These types of dataset are mostly used by variations of CF algorithms. CF algorithms have been widely adopted and have proven to yield good results.</p>
<p>However, in many instances, we have plenty of item metadata (tags, categories, and genres) that can be used to make better predictions as well. Unfortunately, CF algorithms do not use these types of metadata.</p>
<p>FMs can make use of these feature-rich (meta) datasets. An FM can consume these extra features to model higher-order interactions specifying the dimensionality parameter <em>d</em>. Most importantly, FMs are also optimized for handling large-scale sparse datasets. Therefore, a second order FM model would suffice because there is not enough information to estimate interactions that are more complex:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-670 image-border" src="assets/0bbeea54-1a2c-47f3-b5ef-9fb02d82ad45.png" style=""/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">An example training dataset representing a personalization problem with the feature vectors x and the target y. Here, rows refer to movies, while columns include director, actor and genre info, and so on</div>
<p>Let's assume that the dataset of a prediction problem is described by a design matrix <em>X</em> ∈ℝ<em><sup>n</sup></em><sup>x<em>p</em></sup>,. In the preceding diagram, the <em>i<sup>th</sup></em> row, x<em><sub>i</sub></em>∈ℝ<em><sup>p ;</sup></em>of <em>X</em>, describes one case with <em>p</em> real-valued variables and where <em>y<sub>i</sub></em> is the prediction target of the <em>i</em><sup>th</sup> case. Alternatively, we can describe this set as a set <em>S</em> of tuples <em>(x,y)</em>, where (again) <em>x</em> ∈ ℝ<em><sup>p</sup></em> is a feature vector and <em>y</em> is its corresponding target or label.</p>
<p>In other words, in figure 7, every row represents a feature vector <em>x<sub>i</sub></em> with its corresponding target <em>y<sub>i</sub></em>. For easier interpretation, the features are grouped into indicators for the active user (blue), the active item (red), other movies rated by the same user (orange), the time in months (green), and the last movie rated (brown).</p>
<p>Then, the FM algorithm models all the nested interactions (up to order d<em>)</em> between <em>p</em> input variables in <em>x</em> using the following factorized interaction parameters:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/c81dc120-f418-47ad-bc34-ac5df6ece7bc.png" style="width:26.17em;height:4.25em;"/></div>
<p>In this equation, the <em>vs</em> represent <em>k</em>-dimensional latent vectors associated with each variable (the users and the items), and the bracket operator represents the inner product. This kind of representation with data matrices and feature vectors is common in many machine learning approaches, for example, in linear regression or support vector machines (SVM).</p>
<p>However, if you are familiar with the MF models, the preceding equation should look familiar: it contains a global bias as well as user/item-specific biases and includes user-item interactions. Now, if we assume that each <em>x(j)</em> vector is only non-zero at positions <em>u</em> and <em>i</em>, we get the classic MF model:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/1cc28cd9-dfb1-47b0-ae12-0c30b2d6f31d.png" style="width:17.92em;height:1.83em;"/></div>
<p>Nevertheless, FMs can also be used for <span class="StrongEmphasis">classification</span> or <span class="StrongEmphasis">regression</span> and are much more <span class="StrongEmphasis">computationally efficient</span> on <span class="StrongEmphasis">large, sparse datasets</span> than traditional algorithms like linear regression. This property is why FM is widely used for <span class="StrongEmphasis">recommendation</span>: user count and item count are typically very large although the actual number of recommendations is very small (users do not rate all available items!).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Developing a movie recommender system using FMs</h1>
                </header>
            
            <article>
                
<p>In this project, we will show you how to do ranking prediction from the MovieLens 1m dataset. First, we will prepare the dataset. Then, we will train the FM algorithm, which eventually predicts the rankings and ratings for movies. The project code has the following structure:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-671 image-border" src="assets/a6c66d50-7932-41f9-bfbf-5ed054c9579f.png" style=""/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Movie rating and ranking prediction project structure</div>
<p>In summary, the project has the following structure:</p>
<ul>
<li><strong>EDA: </strong>This package is used to do an exploratory analysis of the MovieLens 1M dataset.</li>
<li><strong>Tools, FMCore, and DataUtils: </strong>These are the core FM libraries. For the purpose of this probject, I used (but extended) the <kbd>RankSys</kbd> library (see the <kbd>GitHub</kbd> repository at <a href="https://github.com/RankSys/RankSys">https://github.com/RankSys/RankSys</a>).</li>
<li><strong>Preprocessing: </strong>This package is used to convert the <kbd>MovieLens</kbd> 1M dataset into LibFM format.</li>
<li><strong>Prediction:</strong> This package is used for the movie rating and ranking prediction.</li>
<li><strong>GraphUtil:</strong> This package visualizes some performance metrics over iteration.</li>
</ul>
<p>We will go through all of these packages step by step. Nevertheless, knowing the dataset is a mandate.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dataset description and exploratory analysis</h1>
                </header>
            
            <article>
                
<p>The MovieLens 1M small dataset was downloaded (and used with necessary permission) from the MovieLens website at <a href="https://grouplens.org/datasets/movielens/" target="_blank">https://grouplens.org/datasets/movielens/</a>. I sincerely acknowledge and thank F. Maxwell Harper and Joseph A. Konstan for making the datasets available for use. The dataset was published in <em>MovieLens Dataset: History and Context</em>. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages.</p>
<p>There are three files in the dataset: <kbd>movies.dat</kbd>, <kbd>ratings.dat</kbd>, and <kbd>users.dat</kbd>, which are related to movies, ratings, and users, respectively. These files contain 1,000,209 anonymous ratings of approximately 3,900 movies made by 6,040 MovieLens users who joined MovieLens in 2000. All of the ratings are contained in the <kbd>ratings.dat</kbd> file and are in the following format:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">UserID::MovieID::Rating::Timestamp</pre>
<p>The description is as follows:</p>
<ul>
<li><kbd>UserID</kbd>: This ranges between 1 and 6,040</li>
<li><kbd>MovieID</kbd>: This ranges between 1 and 3,952</li>
<li><kbd>Rating</kbd>: These are made on a 5-star scale</li>
<li><kbd>Timestamp</kbd>: This is represented in seconds</li>
</ul>
<p>Note that each user has rated at least 20 movies. Movie information, on the other hand, is in the <kbd>movies.dat</kbd> file and is in the following format:</p>
<pre>MovieID::Title::Genres</pre>
<p><span>The description is as follows:</span></p>
<ul>
<li><kbd>Title</kbd>: These are identical to titles provided by IMDb (with the release year)</li>
<li><kbd>Genres</kbd>: These are comma-separated (,), and each movie is categorized as action, adventure, animation, children's, comedy, crime, drama, war, documentary, fantasy, film-noir, horror, musical, mystery, romance, sci-fi, thriller, and western</li>
</ul>
<p>Finally, user information is in the <kbd>users.dat</kbd> file and is in the following format:</p>
<pre>UserID::Gender::Age::Occupation::Zip-code </pre>
<p>All demographic information is provided voluntarily by the users and is not checked for accuracy. Only users who have provided some demographic information are included in this dataset. An M for male and F for female denote gender. Age is chosen from the following ranges:</p>
<ul>
<li>1: Under 18</li>
<li>18: 18-24</li>
<li>25: 25-34</li>
<li>35: 35-44</li>
<li>45: 45-49</li>
<li>50: 50-55</li>
<li>56: 56+</li>
</ul>
<p>Occupation is chosen from the following choices:</p>
<ul>
<li>0: Other, or not specified</li>
<li>1: Academic/educator</li>
<li>2: Artist</li>
<li>3: Clerical/admin</li>
<li>4: College/grad student</li>
<li>5: Customer service</li>
<li>6: Doctor/healthcare</li>
<li>7: Executive/managerial</li>
<li>8: Farmer</li>
<li>9: Homemaker</li>
<li>10: K-12 student</li>
<li>11: Lawyer</li>
<li>12: Programmer</li>
<li>13: Retired</li>
<li>14: Sales/marketing</li>
<li>15: Scientist</li>
<li>16: Self-employed</li>
<li>17: Technician/engineer</li>
<li>18: Tradesman/craftsman</li>
<li>19: Unemployed</li>
<li>20: Writer</li>
</ul>
<p>Now that we know the dataset, we can play with the datasets toward exploratory analysis. First, we will create a Spark session as the gateway to the Spark program:</p>
<pre><strong>SparkSession</strong> spark = <strong>new</strong> Builder()<br/>                  .master("local[*]")<br/>                  .config("spark.sql.warehouse.dir", "temp/")// change accordingly<br/>                  .appName("MovieRecommendation")<br/>                  .getOrCreate();</pre>
<p>Then, we will load and parse the <kbd>rating.dat</kbd> file to do some exploratory analysis. The following lines of code should return the DataFrame rating:</p>
<pre>// Read RatingsFile<br/><strong>Dataset&lt;Row&gt;</strong> df1 = spark.read()<br/>                .format("com.databricks.spark.csv")<br/>                .option("inferSchemea", "true")<br/>                .option("header", "true")<br/>                .load(ratingsFile);<br/><br/><strong>Dataset&lt;Row&gt;</strong> ratingsDF = df1.select(df1.col("userId"), df1.col("movieId"),<br/>                df1.col("rating"), df1.col("timestamp"));<br/>ratingsDF.show(10);</pre>
<p><span>The output is as follows:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9aea1ec0-6fe1-45bf-8814-da645acbe6da.png" style=""/></div>
<p>Next, we will load the <kbd>movies.dat</kbd> and prepare the movies DataFrame:</p>
<pre>// Read MoviesFile<br/><strong>Dataset&lt;Row&gt;</strong> df2 = spark.read()<br/>                .format("com.databricks.spark.csv")<br/>                .option("inferSchema", "true")<br/>                .option("header", "true")<br/>                .load(movieFile);<br/>        <br/><strong>Dataset&lt;Row&gt;</strong> moviesDF = df2.select(df2.col("movieId"), df2.col("title"), df2.col("genres"));<br/>moviesDF.show(10);</pre>
<p><span>The output is as follows:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-672 image-border" src="assets/8f533e03-9994-428f-b125-bc49b54234ef.png" style=""/></div>
<p>Then, we will register both DataFrames as temporary tables to make querying easier. To register both Datasets, the following lines of code need to be used:</p>
<pre>ratingsDF.createOrReplaceTempView("ratings");<br/>moviesDF.createOrReplaceTempView("movies");</pre>
<p>Note that this will help to make in-memory querying faster by creating a temporary view as a table in-memory. Then, we will opt to explore some rating and movie-related statistics:</p>
<pre><strong>long</strong> numberOfRatings = ratingsDF.count();<br/><strong>long</strong> numberOfUsers = ratingsDF.select(ratingsDF.col("userId")).distinct().count();<br/><strong>long</strong> numberOfMovies = ratingsDF.select(ratingsDF.col("movieId")).distinct().count();<br/><br/>String print = String.<em>format</em>("Got %d ratings from %d users on %d movies.", numberOfRatings, numberOfUsers, numberOfMovies);<br/>System.<strong><em>out</em></strong>.println(print);</pre>
<p class="mce-root"><span>The output is as follows:</span></p>
<pre>Got 100004 ratings from 671 users on 9066 movies.</pre>
<p>Now, let's get the maximum and minimum ratings along with the count of users who have rated a movie. However, you need to perform a SQL query on the rating table we just created in-memory in the previous step. Making a query here is simple, and it is similar to making a query from a MySQL database or RDBMS.</p>
<p>However, if you are not familiar with SQL-based queries, you are suggested to look at the SQL query specification to find out how to perform a selection using <kbd>SELECT</kbd> from a particular table, how to perform the ordering using <kbd>ORDER</kbd>, and how to perform a joining operation using the <kbd>JOIN</kbd> keyword.</p>
<p>Well, if you know the SQL query, you should get a new dataset by using a complex SQL query as follows:</p>
<pre>// Get the max, min ratings along with the count of users who have rated a movie.<br/><strong>Dataset&lt;Row&gt;</strong> sqlDF = spark.sql(<br/>                "<strong>SELECT</strong> movies.title, movierates.maxr, movierates.minr, movierates.cntu "<br/>                        + "<strong>FROM</strong> (<strong>SELECT</strong> "<br/>                        + "ratings.movieId, <strong>MAX</strong>(ratings.rating) <strong>AS</strong> maxr,"<br/>                        + "<strong>MIN</strong>(ratings.rating) <strong>AS</strong> minr, <strong>COUNT</strong>(distinct userId) <strong>AS</strong> cntu "<br/>                        + "<strong>FROM</strong> ratings "<br/>                        + "<strong>GROUP BY</strong> ratings.movieId) movierates "<br/>                        + "<strong>JOIN</strong> movies <strong>ON</strong> movierates.movieId=movies.movieId "<br/>                        + "<strong>ORDER BY</strong> movierates.cntu <strong>DESC</strong>");<br/>sqlDF.show(10);</pre>
<p class="packt_figure"><span>The output is as follows:</span></p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-673 image-border" src="assets/4bc62580-9bc3-4f30-846b-b540e7625346.png" style=""/></div>
<p>Now, to get an insight, we need to know more about the users and their ratings. Let's find the top 10 most active users and how many times they have rated a movie:</p>
<pre>// Top 10 active users and how many times they rated a movie.<br/><strong>Dataset&lt;Row&gt;</strong> mostActiveUsersSchemaRDD = spark.sql(<br/>                "<strong>SELECT</strong> ratings.userId, count(*) <strong>AS</strong> ct "<br/>                        + "<strong>FROM</strong> ratings "<br/>                        + "<strong>GROUP BY</strong> ratings.userId "<br/>                        + "<strong>ORDER BY</strong> ct <strong>DESC LIMIT</strong> 10");<br/>mostActiveUsersSchemaRDD.show(10);</pre>
<p><span>The output is as follows:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5cbda7d6-4e4c-41d8-9dae-4d925e40931c.png" style=""/></div>
<p>Finally, let's have a look at a particular user and find the movies that, say, user 668, rated higher than 4:</p>
<pre>// Movies that user 668 rated higher than 4<br/><strong>Dataset&lt;Row&gt;</strong> userRating = spark.sql(<br/>                "<strong>SELECT</strong> ratings.userId, ratings.movieId, ratings.rating, movies.title "<br/>                        + "<strong>FROM</strong> ratings JOIN movies "<br/>                        + "<strong>ON</strong> movies.movieId=ratings.movieId "<br/>                        + "<strong>WHERE</strong> ratings.userId=668 <strong>AND</strong> ratings.rating &gt; 4");<br/>userRating.show(10);</pre>
<p><span>The output is as follows:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-675 image-border" src="assets/cbdb75b4-cb1c-493d-ac42-d3425b5250ae.png" style=""/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Movie rating prediction</h1>
                </header>
            
            <article>
                
<p>First, we perform the rating prediction using FM algorithms that learn using <kbd>PointWiseGradientDescent</kbd>. We start with preprocessing and converting data into the LibFM format. To run this rating prediction using the following order of execution:</p>
<ol>
<li>First, execute <kbd>MovieLensFormaterWithMetaData.java</kbd> ;to generate the <kbd>MovieLens</kbd> data in the <kbd>LibFM</kbd> format.</li>
<li>Then, execute <kbd>SplitDataWithMetaData.java</kbd> to prepare the training, test, and validation sets.</li>
<li>Finally, execute ;<kbd>MovieRatingPrediction.java</kbd>, which is the main class.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Converting the dataset into LibFM format</h1>
                </header>
            
            <article>
                
<p>The FM-based model that we are going to reuse can consume the training data only in LibFM format, which is more or less the same as LibSVM. Therefore, first, we must format the MovieLens 1M dataset sp that the training dataset contains both users, movies, and existing rating information.</p>
<div class="packt_tip">The LibFM format is similar to the LibSVM format but has some basic differences. For more information, interested readers can take a look at <a href="http://www.libfm.org/libfm-1.42.manual.pdf">http://www.libfm.org/libfm-1.42.manual.pdf</a>.</div>
<p>At the same time, new features will be generated by the user information and movie information. First, we will define the input (this will be updated according to users, movies, and ratings) and output file path as follows:</p>
<pre><strong>//MovieLensFormaterWithMetaData.java<br/>private</strong> <strong>static</strong> String <em>inputfilepath</em><em>;<br/></em><strong>private</strong> <strong>static</strong> String <em>outputfilepath</em>;</pre>
<p>Then, we define the data path and the output folder, where the generated data in LibFM format will be saved:</p>
<pre><strong>String</strong> foldername = "ml-1m";<br/><strong>String</strong> outFolder = "outFolder";</pre>
<p>Then, we define the target column, which is to be predicted by the FM model. Additionally, we also delete the timestamp column:</p>
<pre><strong>private</strong> <strong>static</strong> <strong>int</strong> <em>targetcolumn</em> = 0;<br/><strong>private</strong> <strong>static</strong> String <em>deletecolumns</em> = "3";</pre>
<p>Then, we set the separator as <kbd>::</kbd> and offset:</p>
<pre><strong>private</strong> <strong>static</strong> String <em>separator</em> = "::";<br/><strong>private</strong> <strong>static</strong> <strong>int</strong> <em>offset</em> = 0;</pre>
<p>Then, we read and parse the user's data (that is, <kbd>users.dat</kbd>) and create three <kbd>Map&lt;Integer, String&gt;</kbd> for the user's genre, the user's age, and the user's occupation:</p>
<pre><strong>Set&lt;Integer&gt;</strong> deletecolumnsset = <strong>new</strong> HashSet&lt;Integer&gt;();<br/><strong>Map&lt;String, Integer&gt;</strong> valueidmap = <strong>new</strong> HashMap&lt;String, Integer&gt;(); <br/><br/><em>targetcolumn</em> = 2; // movielens format<br/><strong>String</strong>[] deletecolumnarr = <em>deletecolumns</em>.split(";"); <br/><br/><strong>for</strong>(<strong>String</strong> deletecolumn : deletecolumnarr) { <br/>          deletecolumnsset.add(Integer.<em>parseInt</em>(deletecolumn));<br/>       }<br/><em>inputfilepath</em> = foldername + File.<strong><em>separator</em></strong> + "users.dat"; <br/><strong>Reader</strong> fr = <strong>new</strong> FileReader(<em>inputfilepath</em>); <br/><strong>BufferedReader</strong> br = <strong>new</strong> BufferedReader(fr); <br/><br/><strong>Map&lt;Integer, String&gt;</strong> usergenemap = <strong>new</strong> HashMap&lt;Integer, String&gt;();<br/><strong>Map&lt;Integer, String&gt;</strong> useragemap = <strong>new</strong> HashMap&lt;Integer, String&gt;();<br/><strong>Map&lt;Integer, String&gt;</strong> useroccupationmap = <strong>new</strong> HashMap&lt;Integer, String&gt;(); <br/><br/><strong>String</strong> line;<br/><strong>while</strong> (br.ready()) {<br/>             line = br.readLine();<br/>             String[] arr = line.split(<em>separator</em>); <br/>             usergenemap.put(Integer.<em>parseInt</em>(arr[0]), arr[1]); <br/>             useragemap.put(Integer.<em>parseInt</em>(arr[0]), arr[2]);<br/>             useroccupationmap.put(Integer.<em>parseInt</em>(arr[0]), arr[3]);<br/>          } <br/>br.close();<br/>fr.close();</pre>
<p>Then, we parse the movie dataset to create a <kbd>Map&lt;Integer, String&gt;</kbd> for movies:</p>
<pre><em>inputfilepath</em> = foldername + File.<strong><em>separator</em></strong> + "movies.dat"; <br/>fr = <strong>new</strong> FileReader(<em>inputfilepath</em>); <br/>br = <strong>new</strong> BufferedReader(fr);<br/><br/><strong>Map&lt;Integer, String&gt;</strong> moviemap = <strong>new</strong> HashMap&lt;Integer, String&gt;();<br/><br/><strong>while</strong> (br.ready()) {<br/>              line = br.readLine(); <br/>              String[] arr = line.split(<em>separator</em>); <br/>               moviemap.put(Integer.<em>parseInt</em>(arr[0]), arr[2]); <br/>}<br/>br.close();<br/>fr.close();</pre>
<p>Then, we parse the rating dataset to create a <kbd>Map&lt;Integer, String&gt;</kbd> for existing ratings. Additionally, we define the output filename where the rating data in the LibFM format will be saved:</p>
<pre>inputfilepath = foldername + File.separator + "ratings.dat";<br/>outputfilepath = outFolder + File.separator + "ratings.libfm";<br/><strong>BufferedWriter</strong> writer = <strong>new</strong> BufferedWriter(<strong>new</strong> OutputStreamWriter(<strong>new</strong> FileOutputStream(outputfilepath)));<br/><br/>        fr = new FileReader(inputfilepath);<br/>        br = new BufferedReader(fr);<br/><br/>        <strong>while</strong>(br.ready()) {<br/>            line = br.readLine();<br/>            <strong>String</strong>[] arr = line.split(separator);<br/>            <strong>StringBuilder</strong> sb = new StringBuilder();<br/>            sb.append(arr[targetcolumn]);<br/>            <br/>            <strong>int</strong> columnidx = 0;<br/>            <strong>int</strong> userid = Integer.parseInt(arr[0]);<br/>            <strong>int</strong> movieid = Integer.parseInt(arr[1]);<br/>            <br/>            <strong>for</strong>(<strong>int</strong> i = 0; i &lt; arr.length; i++) {<br/>                <strong>if</strong>(i != targetcolumn &amp;&amp; !deletecolumnsset.contains(i)) {<br/>                    <strong>String</strong> useroritemid = <strong>Integer</strong>.toString(columnidx) + " " + arr[i];<br/>                    <br/>                    <strong>if</strong>(!valueidmap.containsKey(useroritemid)) {<br/>                        valueidmap.put(useroritemid, offset++);<br/>                    }<br/>                    <br/>                    sb.append(" ");<br/>                    sb.append(valueidmap.get(useroritemid));<br/>                    sb.append(":1");<br/><br/>                    columnidx++;<br/>                }</pre>
<p>Then, we start adding attributes such as gender information, age, occupation, and movie class information:</p>
<pre>// Add attributes<br/><strong>String</strong> gender = usergenemap.get(userid);<br/><strong>String</strong> attributeid = "The gender information " + gender;<br/>            <br/> <strong>if</strong>(!valueidmap.containsKey(attributeid)) {<br/>                valueidmap.put(attributeid, offset++);<br/>            }<br/><br/>            sb.append(" ");<br/>            sb.append(valueidmap.get(attributeid));<br/>            sb.append(":1");<br/><br/>            <strong>String</strong> age = useragemap.get(userid);<br/>            attributeid = "The age information " + age;<br/>            <br/>            <strong>if</strong>(!valueidmap.containsKey(attributeid)) {<br/>                valueidmap.put(attributeid, offset++);<br/>            }<br/><br/>            sb.append(" ");<br/>            sb.append(valueidmap.get(attributeid));<br/>            sb.append(":1");<br/><br/>            <strong>String</strong> occupation = useroccupationmap.get(userid);<br/>            attributeid = "The occupation information " + occupation;<br/>            <br/>            <strong>if</strong>(!valueidmap.containsKey(attributeid)) {<br/>                valueidmap.put(attributeid, offset++);<br/>            }<br/><br/>            sb.append(" ");<br/>            sb.append(valueidmap.get(attributeid));<br/>            sb.append(":1");<br/><br/>            <strong>String</strong> movieclassdesc = moviemap.get(movieid);<br/>            <strong>String</strong>[] movieclassarr = movieclassdesc.split("\\|");<br/>            <br/>            <strong>for</strong>(<strong>String</strong> movieclass : movieclassarr) {<br/>                attributeid = "The movie class information " + movieclass;<br/>                <strong>if</strong>(!valueidmap.containsKey(attributeid)) {<br/>                    valueidmap.put(attributeid, offset++);<br/>                }<br/><br/>                sb.append(" ");<br/>                sb.append(valueidmap.get(attributeid));<br/>                sb.append(":1");<br/>}</pre>
<p>In the previous code block, <kbd>:1</kbd> ;stands for which movie the user has provided a rating for. Finally, we add the metadata information, <kbd>userid</kbd> and <kbd>movieid</kbd>:</p>
<pre>//add metadata information, userid and movieid<br/>sb.append("#");<br/>sb.append(userid);<br/>sb.append(" "+movieid);<br/>writer.write(sb.toString());<br/>writer.newLine();</pre>
<p>Now, the resulting rating dataset (once <kbd>MovieLensFormaterWithMetaData.java</kbd> is executed) in LibFM format will be saved in the <kbd>formatted_data</kbd> directory as <kbd>ratings.libfm</kbd> ;having the following structure:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-676 image-border" src="assets/260b022e-5277-4ad9-ba90-c0104a8266db.png" style=""/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training and test set preparation</h1>
                </header>
            
            <article>
                
<p>Now that we have seen how to convert rating, movie, and metadata, we can now start creating training, test, and validation sets from the data in LibFM format. First, we set the path of the LibFM files to be used as follows:</p>
<pre><strong>//</strong>SplitDataWithMetaData.java<br/><strong>private </strong><strong>static</strong> String <em>ratinglibFM</em> = <em>formattedDataPath</em> + "/" + "ratings.libfm"; // input<br/><strong>private </strong><strong>static</strong> String <em>ratinglibFM_train</em> = <em>formattedDataPath</em> + "/" + "ratings_train.libfm"; // for traning<br/><strong>private </strong><strong>static</strong> String <em>ratinglibFM_test</em> = <em>formattedDataPath</em> + "/" + "ratings_test.libfm"; // for testing<br/><strong>private </strong><strong>static</strong> String <em>ratinglibFM_test_meta</em> = <em>formattedDataPath</em> +"/"+"ratings_test.libfm.meta";// metadata<br/><strong>private </strong><strong>static</strong> String <em>ratinglibFM_valid</em> = <em>formattedDataPath</em> + "/" + "ratings_valid.libfm"; // validation</pre>
<p>Then, we show the output directory to write the split training, validation, and test sets:</p>
<pre><strong>private </strong><strong>static</strong> String <em>formattedDataPath</em> = "outFolder";</pre>
<p>Then, we instantiate the <kbd>BufferedWriter</kbd> that is going to be used for writing the split files:</p>
<pre><strong>Reader</strong> fr = new FileReader(ratinglibFM);<br/><strong>Random</strong> ra = new Random();<br/><br/><strong>BufferedWriter</strong> trainwrite = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(ratinglibFM_train)));<br/><br/><strong>BufferedWriter</strong> testwrite = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(ratinglibFM_test)));<br/><br/><strong>BufferedWriter</strong> testmetawrite = new BufferedWriter(new OutputStreamWriter(new                       FileOutputStream(ratinglibFM_test_meta)));   <br/>     <br/><strong>BufferedWriter</strong> validwrite = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(ratinglibFM_valid)));<br/><br/><strong>BufferedReader</strong> br = new BufferedReader(fr);<br/><strong>String</strong> line = null;<br/><strong>int</strong> testline = 0;<br/>        <br/><strong>while</strong>(br.ready()) {<br/>       line = br.readLine();<br/>       <strong>String</strong>[] arr = line.split("#");<br/>       <strong>String</strong> info = arr[0];<br/>            <br/>       <strong>double</strong> dvalue = ra.nextDouble();<br/>       <strong>if</strong>(dvalue&gt;0.9)<br/>            {<br/>             validwrite.write(info);<br/>             validwrite.newLine();<br/>            }<br/>            <br/>       <strong>else if</strong>(dvalue &lt;= 0.9 &amp;&amp; dvalue&gt;0.1) {<br/>                trainwrite.write(info);<br/>                trainwrite.newLine();<br/>         } <strong>else</strong> {<br/>                testwrite.write(info);<br/>                testwrite.newLine();<br/>           <strong>if</strong>(arr.length==2)<br/>                {<br/>                testmetawrite.write(arr[1] + " " + testline);<br/>                testmetawrite.newLine();<br/>                testline++;<br/>            }<br/>         }<br/>  }</pre>
<p>Finally, we close the file pointers to release the resources:</p>
<pre>br.close();<br/>fr.close();<br/><br/>trainwrite.flush();<br/>trainwrite.close();<br/>        <br/>testwrite.flush();<br/>testwrite.close();<br/><br/>validwrite.flush();<br/>validwrite.close();<br/>        <br/>testmetawrite.flush();<br/>testmetawrite.close();</pre>
<p>Now, the resulting rating datasets (once <kbd>SplitDataWithMetaData.java</kbd> is executed) in LibFM format will be saved in the <kbd>formatted_data</kbd> directory having the following LibFM (similar to LibSVM) format:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-677 image-border" src="assets/36100945-4ad5-4e4b-b091-e80013f3884c.png" style=""/></div>
<p>Finally, the directory (that is, <kbd>formatted_data</kbd>) will have the following files in it:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-678 image-border" src="assets/11798569-110f-47d7-80ab-8e97f2a8aa58.png" style=""/></div>
<p>Fantastic! Now that our dataset is ready, we can now start making the movie rating prediction using the FM algorithm.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Movie rating prediction</h1>
                </header>
            
            <article>
                
<p>Now that all of the datasets required for training, validating, and evaluating are ready, we can start training the FM model. We first start by showing the filename for the training data:</p>
<pre><strong>final</strong> String trainFile = <em>formattedDataPath</em>+ "/" + "ratings_train.libfm";</pre>
<p>Then, we set the testing data file path:</p>
<pre><strong>final</strong> String testFile = <em>formattedDataPath</em>+ "/" + "ratings_test.libfm";</pre>
<p>Then, we set the testing metadata file path:</p>
<pre><strong>final</strong> String testMetaFile = <em>formattedDataPath</em>+ "/" + "ratings_test.libfm.meta";</pre>
<p>Then, the filename for the final prediction output file:</p>
<pre><strong>final</strong> String outputFile = <em>formattedDataPath</em>+ "/" + "predict_output.txt";</pre>
<p>Then, we set up the path for writing the logs, metrics, time, and so on for each iteration to a file (but don't worry, we will see them in graph form, too):</p>
<pre><strong>final</strong> String rLog = <em>outPut</em> + "/" + "metrics_logs.txt";</pre>
<p>Then, we set up the dimension of k0, k1, and k2 so that k0 is use bias, k1 is the use of one-way interactions, and k2 is the dim of two-way interactions:</p>
<pre><strong>final</strong> String dimension = "1,1,8"; // tunable parameters</pre>
<p>We will iterate the training for 100 times the number of iterations:</p>
<pre><strong>final</strong> String iterations = "100"; // tunable parameter</pre>
<p>We then set the learning rate for SGD—the rate at which the optimizer tries to minimize the error:</p>
<pre><strong>final</strong> String learnRate = "0.01"; // tunable and learnable parameter</pre>
<p>Now that the optimizer knows the learning rate, the next important parameter is setting up the regularization parameters to regularize the training against overfitting.</p>
<p>The Java-based FM library needs three-way regularization: bias, one-way, and two-way regularization. Therefore, the format accepted by the FM library is r0, r1, r2. Here, r0 is bias regularization, r1 is one-way regularization, and r2 is two-way regularization:</p>
<pre><strong>final</strong> String regularization = "0,0,0.1";</pre>
<p>Then, we initialize the standard deviations for the initialization of two-way factors:</p>
<pre><strong>final</strong> String stdDeviation = "0.1";</pre>
<p>Then, we use the ;<kbd>LibSVMDataProvider()</kbd> class for loading both training and test sets:</p>
<pre>System.<strong><em>out</em></strong>.println("Loading train...t");<br/><strong>DataProvider</strong> train = <strong>new</strong> LibSVMDataProvider();<br/><strong>Properties</strong> trainproperties = <strong>new</strong> Properties();<br/><br/>trainproperties.put(Constants.<strong><em>FILENAME</em></strong>, trainFile);<br/>train.load(trainproperties,<strong>false</strong>);<br/><br/>System.<strong><em>out</em></strong>.println("Loading test... t");<br/><strong>DataProvider</strong> test = <strong>new</strong> LibSVMDataProvider();<br/><strong>Properties</strong> testproperties = <strong>new</strong> Properties();<br/><br/>testproperties.put(Constants.<strong><em>FILENAME</em></strong>, testFile);<br/>test.load(testproperties,<strong>false</strong>);</pre>
<p>One the training and test sets are loaded, we start creating the user-item table (that is, the main table):</p>
<pre><strong>int</strong> num_all_attribute = Math.<em>max</em>(train.getFeaturenumber(), test.getFeaturenumber());<br/><strong>DataMetaInfo</strong> meta = <strong>new</strong> DataMetaInfo(num_all_attribute);<br/>meta.debug();<br/>Debug.<em>openConsole</em>();</pre>
<p>Then, we instantiate the factorization machine before we start the training:</p>
<pre><strong>FmModel</strong> fm = <strong>new</strong> FmModel();</pre>
<p>Then, the <kbd>init()</kbd> method is used for initializing the parameters needed for instantiating and training the following FM model's parameters:</p>
<pre><strong>public</strong> FmModel()<br/>    {<br/>        num_factor = 0;<br/>        initmean = 0;<br/>        initstdev = 0.01;<br/>        reg0 = 0.0;<br/>        regw = 0.0;<br/>        regv = 0.0; <br/>        k0 = true;<br/>        k1 = true;<br/>    }</pre>
<p>The signature of the <kbd>init()</kbd> method goes as follows:</p>
<pre><strong>public</strong> <strong>void</strong> init()<br/>    {<br/>        w0 = 0;<br/>        w = new double[num_attribute];<br/>        v = new DataPointMatrix(num_factor, num_attribute);<br/>        Arrays.fill(w, 0);<br/>        v.init(initmean, initstdev);<br/>        m_sum = new double[num_factor];<br/>        m_sum_sqr = new double[num_factor];<br/>    }</pre>
<p>Then, we set the number of attributes and standard deviations from the main class:</p>
<pre>fm.num_attribute = num_all_attribute;<br/>fm.initstdev = Double.<em>parseDouble</em>(stdDeviation);</pre>
<p>Then, we set the number of dimensions in the factorization. In our case, we have 3-way interaction—user, movie, and rating:</p>
<pre><strong>Integer</strong>[] dim = <em>getIntegerValues</em>(dimension);<br/><strong>assert</strong> (dim.length == 3);<br/>fm.k0 = dim[0] != 0;<br/>fm.k1 = dim[1] != 0;<br/>fm.num_factor = dim[2];</pre>
<p>The preceding values are actually parsed using the <kbd>getIntegerValues()</kbd> method, which accepts the dimension as a string and split using <kbd>,</kbd>.</p>
<p>Finally, it returns only integer values for the dimension to be used by the model for making interactions. The following signature is used for this:</p>
<pre><strong>static public</strong> Integer[] getIntegerValues(<strong>String</strong> parameter) {<br/>        <strong>Integer</strong>[] result = null;<br/>        <strong>String</strong>[] strresult = Util.tokenize(parameter, ",");<br/>        <strong>if</strong>(strresult!=null &amp;&amp; strresult.length&gt;0) {<br/>            result = new Integer[strresult.length];<br/>            <strong>for</strong>(<strong>int</strong> i=0;i&lt;strresult.length;i++) {<br/>                result[i] = Integer.parseInt(strresult[i]);<br/>            }<br/>        }<br/>        <strong>return</strong> result;<br/>    }</pre>
<p>Then, we set up the learning method as <strong>Stochastic Gradient Descent</strong> (<strong>SGD</strong>):</p>
<pre><strong>FmLearn</strong> fml = <strong>new</strong> FmLearnSgdElement();<br/>((FmLearnSgd) fml).num_iter = Integer.<em>parseInt</em>(iterations);<br/><br/>fml.fm = fm;<br/>fml.max_target = train.getMaxtarget();<br/>fml.min_target = train.getMintarget();<br/>fml.meta = meta;</pre>
<p>Then, we define the task to be performed. In our case, it is regression. However, we are going to use ;<kbd>TASK_CLASSIFICATION</kbd> for classification:</p>
<pre>fml.task = TaskType.<strong><em>TASK_REGRESSION</em></strong></pre>
<p>Then, we set the regularization:</p>
<pre><strong>Double</strong>[] reg = <em>getDoubleValues</em>(regularization);<br/><strong>assert</strong> ((reg.length == 3)); // should meet 3 way regularization<br/><br/>fm.reg0 = reg[0];<br/>fm.regw = reg[1];<br/>fm.regv = reg[2];</pre>
<p>Then, when it comes to the learning rate, we have to set the learning rates (individual, per layer) unlike the DL4J library:</p>
<pre>FmLearnSgd fmlsgd = (FmLearnSgd) (fml);<br/><br/><strong>if</strong> (fmlsgd != <strong>null</strong>) {<br/>        <strong>Double</strong>[] lr = <em>getDoubleValues</em>(learnRate);<br/>        <strong>assert</strong> (lr.length == 1);<br/>        fmlsgd.learn_rate = lr[0];<br/>        <strong>Arrays</strong>.<em>fill</em>(fmlsgd.learn_rates, lr[0]);<br/>}</pre>
<p>The preceding values are actually parsed using the <kbd>getDoubleValues()</kbd> method, which accepts the learning rate as a string and split using <kbd>,</kbd>. Finally, it returns only a single value for the learning rate to be used by the model. The following signature is used for this:</p>
<pre><strong>static public</strong> <strong>Double</strong>[] getDoubleValues(String parameter) {<br/>        <strong>Double</strong>[] result;<br/>        <strong>String</strong>[] strresult = Util.tokenize(parameter, ",");<br/>        <strong>if</strong>(strresult!=null &amp;&amp; strresult.length&gt;0) {<br/>            result = <strong>new</strong> Double[strresult.length];<br/>            <strong>for</strong>(<strong>int</strong> i=0; i&lt;strresult.length; i++) {<br/>                result[i] = <strong>Double</strong>.parseDouble(strresult[i]);<br/>            }<br/>        }<br/>        <strong>else</strong> {<br/>            result = new Double[0];<br/>        }<br/>        <strong>return</strong> result;<br/>    }</pre>
<p>Now that all the hyperparameters are set, we are ready to start the training. For this, unlike DL4J FM, it comes with a ;<kbd>learn()</kbd> method for learning the model:</p>
<pre>fml.learn(train, test);</pre>
<p>The <kbd>learn()</kbd> method is an abstract method that takes both train and test sets:</p>
<pre>//FmLearn.java<br/><strong>public </strong><strong>abstract </strong><strong>void</strong> learn(DataProvider train, DataProvider test) <strong>throws</strong> Exception;</pre>
<p>The concrete implementation of the ;<kbd>learn()</kbd> method takes both the training and test sets. Then, it shuffles the training set to avoid the bias in training. Then, it performs the prediction operation using the ;<kbd>predict()</kbd> method for the task type we defined at the beginning (that is, regression in our case).</p>
<p>Finally, it evaluates the model on the test set and computes the MSE for both the training and test set. The actual implementation of this method goes as follows:</p>
<pre>//FmLearnSgdElement.java<br/><strong>public void</strong> learn(<strong>DataProvider</strong> train, <strong>DataProvider</strong> test)  <strong>throws</strong> Exception{<br/>        <strong>super</strong>.learn(train, test);<br/>        <strong>List&lt;Double&gt;</strong> iterationList=new ArrayList&lt;Double&gt;();<br/>        <strong>List&lt;Double&gt;</strong> trainList=new ArrayList&lt;Double&gt;();<br/>        <strong>List&lt;Double&gt;</strong> testList=new ArrayList&lt;Double&gt;();<br/><br/>        // SGD<br/>        for(<strong>int</strong> i = 0; i &lt; num_iter; i++) {<br/>            <strong>try</strong><br/>            {<br/>                <strong>double</strong> iteration_time = <strong>Util</strong>.getusertime();<br/>                train.shuffle();<br/>                <strong>for</strong>(train.getData().begin(); !train.getData().end(); train.getData().next()) {<br/>                    <strong>double</strong> p = fm.predict(train.getData().getRow(), sum, sum_sqr);<br/>                    <strong>double</strong> mult = 0;<br/><br/>                    <strong>if</strong>(task == TaskType.<strong>TASK_REGRESSION</strong>) {<br/>                        p = Math.min(max_target, p);<br/>                        p = Math.max(min_target, p);<br/>                        mult = -(train.getTarget()[train.getData().getRowIndex()]-p);<br/>                    } <strong>else if</strong>(task == TaskType.<strong>TASK_CLASSIFICATION</strong>) {<br/>                        mult = -train.getTarget()[train.getData().getRowIndex()]*<br/>                                (1.0-1.0/(1.0+Math.exp(-train.getTarget()[train.getData()<br/>                                .getRowIndex()]*p)));<br/>                    }                <br/>                    SGD(train.getData().getRow(), mult, sum);                    <br/>                }                <br/>                iteration_time = (Util.getusertime() - iteration_time);<br/>                <strong>double</strong> rmse_train = evaluate(train);<br/>                <strong>double</strong> rmse_test = evaluate(test);<br/>                iterationList.add((double)i);<br/>                testList.add(rmse_test);<br/>                trainList.add(rmse_train);<br/>                <br/>                <strong>String</strong> print = String.format("#Iterations=%2d::  <br/>                               Train_RMSE=%-10.5f  Test_RMSE=%-10.5f", i, rmse_train, rmse_test);<br/>                Debug.println(print);<br/>                <strong>if</strong>(log != null) {<br/>                    log.log("rmse_train", rmse_train);<br/>                    log.log("time_learn", iteration_time);<br/>                    log.newLine();<br/>                }<br/>            }<br/>            <strong>catch</strong>(Exception e)<br/>            {<br/>                <strong>throw</strong> <strong>new</strong> JlibfmRuntimeException(e);// Exception library for Java FM<br/>            }<br/>        }    <br/>        <strong>PlotUtil_Rating</strong>.plot(convertobjectArraytoDouble(iterationList.toArray()),<br/>                convertobjectArraytoDouble(testList.toArray()),<br/>                convertobjectArraytoDouble(trainList.toArray()));<br/><br/>    }</pre>
<p>In the preceding code block, the FM model performs the prediction operation, similar to any other regression algorithm, by considering three-way interaction and so on and computing the prediction as a probability:</p>
<pre>// FmModel.java, we create a sparse matrix <br/><strong>public double</strong> predict(<strong>SparseRow</strong> x, <strong>double</strong>[] sum, <strong>double</strong>[] sum_sqr)<br/>    {<br/>        <strong>double</strong> result = 0;<br/>        <strong>if</strong>(k0) {    <br/>            result += w0;<br/>        }<br/>        <strong>if</strong>(k1) {<br/>            <strong>for</strong>(int i = 0; i &lt; x.getSize(); i++) {<br/>                result += w[x.getData()[i].getId()] * x.getData()[i].getValue();<br/>            }<br/>        }<br/>        <strong>for</strong>(<strong>int</strong> f = 0; f &lt; num_factor; f++) {<br/>            sum[f] = 0;<br/>            sum_sqr[f] = 0;<br/>            <strong>for</strong>(<strong>int</strong> i = 0; i &lt; x.getSize(); i++) {<br/>                <strong>double</strong> d = v.get(f,x.getData()[i].getId()) * x.getData()[i].getValue();<br/>                sum[f] = sum[f]+d;<br/>                sum_sqr[f] = sum_sqr[f]+d*d;<br/>            }<br/>            result += 0.5 * (sum[f]*sum[f] - sum_sqr[f]);<br/>        }<br/><br/>        <strong>return</strong> result;<br/> }</pre>
<p>Nevertheless, at the end, the training and test MSE per iteration is visualized using the <kbd>plot()</kbd> method from the <kbd>PlotUtil_Rating</kbd> class. We'll discuss this class later on.</p>
<p>Additionally, we also initialize the logging so that the result and progress of the computations are printed on the console:</p>
<pre>System.<strong><em>out</em></strong>.println("logging to " + rLog);<br/>RLog rlog = <strong>new</strong> RLog(rLog);<br/>fml.log = rlog;<br/>fml.init();<br/>rlog.init();<br/>fm.debug();<br/>fml.debug();</pre>
<p>Finally, we evaluate the model on the test set. Since our task is a regression task, we compute the regression metric, such as RMSE, for each iteration:</p>
<pre><strong>String</strong> print = String.<em>format</em>("#Iterations=%s:: Train_RMSE=%-10.5f Test_RMSE=%-10.5f", iterations, fml.evaluate(train), fml.evaluate(test));<br/>System.<strong><em>out</em></strong>.println(print);</pre>
<pre class="mce-root"><q>&gt;&gt;&gt;<br/></q><span class="packt_screen">Loading train...<br/> Loading test...<br/> #attr=9794 #groups=1<br/> #attr_in_group[0]=9794<br/> logging to outFolder/output.txt<br/> num_attributes=9794<br/> use w0=true<br/> use w1=true<br/> dim v =8<br/> reg_w0=0.0<br/> reg_w=0.0<br/> reg_v=0.0<br/> init ~ N(0.0,0.1)<br/> num_iter=100<br/> task=TASK_REGRESSION<br/> min_target=1.0<br/> max_target=5.0<br/> learnrate=0.01<br/> learnrates=0.01,0.01,0.01<br/> #iterations=100<br/> #Iterations= 0:: Train_RMSE=0.92469 Test_RMSE=0.93231<br/> #Iterations= 1:: Train_RMSE=0.91460 Test_RMSE=0.92358<br/> #Iterations= 2:: Train_RMSE=0.91595 Test_RMSE=0.92535<br/> #Iterations= 3:: Train_RMSE=0.91238 Test_RMSE=0.92313<br/> ...<br/> #Iterations=98:: Train_RMSE=0.84275 Test_RMSE=0.88206<br/> #Iterations=99:: Train_RMSE=0.84068 Test_RMSE=0.87832</span></pre>
<p>Finally, we save the prediction and all associated metrics in a file:</p>
<pre>// prediction at the end<br/><strong>String</strong> print = String.format("#Iterations=%s::  Train_RMSE=%-10.5f  Test_RMSE=%-10.5f", iterations, fml.evaluate(train), fml.evaluate(test));<br/>System.out.println(print);<br/><br/>// save prediction<br/><strong>Map&lt;Integer, String&gt;</strong> ratingsMetaData = new HashMap&lt;&gt;();<br/><strong>if</strong>(Files.exists(Paths.get(testMetaFile))) {<br/>            <strong>BufferedReader</strong> bufferedReader = new BufferedReader(new FileReader(testMetaFile));<br/>            <strong>String</strong> line;<br/>            <br/>            <strong>while</strong>((line = bufferedReader.readLine()) != null) {<br/>                <strong>String</strong>[] splitLine = line.split("\\s+");<br/>                <strong>if</strong>(splitLine.length &gt; 0) {<br/>                    <strong>Integer</strong> indexKey = Integer.parseInt(splitLine[2]);<br/>                    String userIdmovieIdValue = splitLine[0] + " " +  splitLine[1];<br/>                    ratingsMetaData.put(indexKey, userIdmovieIdValue);<br/>                }<br/>            }<br/>        }<br/><br/><strong>double</strong>[] pred = new double[test.getRownumber()];<br/>fml.predict(test, pred);<br/>Util.save(ratingsMetaData, pred, outputFile);<br/>        <br/><strong>String</strong> FILENAME = Constants.FILENAME;<br/>// Save the trained FM model <br/>fmlsgd.saveModel(FILENAME);</pre>
<p>The preceding code block will generate two files called ;<kbd>predict_output.txt</kbd> and <kbd>metrics_logs.txt</kbd> for writing predicted results and logs, respectively. For example, a sample from the <kbd>predicted_output.txt</kbd> file shows that the second column is the movie ID and the third column is the predicted rating out of 5.0, as follows:</p>
<pre><span class="packt_screen">1 3408 4.40<br/> 1 2797 4.19<br/> 1 720 4.36<br/> 1 1207 4.66<br/> 2 1537 3.92<br/> 2 1792 3.39<br/> 2 1687 3.32<br/> 2 3107 3.55<br/> 2 3108 3.46<br/> 2 3255 3.65</span></pre>
<p>On the other hand, <kbd>metrics_logs.txt</kbd> shows metrics such as RMSE, MAE, logs, as shown in the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-679 image-border" src="assets/1133cb50-c9fd-41d2-9223-a7f4e5cd5a08.png" style=""/></div>
<p>Nevertheless, since making some sense of the training status and prediction, it is difficult just seeing these values, therefore, I decided to plot them. The following graph shows the MSE for both the training and testing phase for each iteration:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7f56c119-7126-4ba2-8020-792ced3044aa.png" style=""/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Training and test MSE per iteration (for 100 iterations)</div>
<p>The preceding graph shows that both training and test errors are consistent, which means the FM model was not overfitted. This graph also shows that the error count is still very high. Then, I iterated the training 1,000 times and found that errors had been reduced slightly, which is reported in the following graph:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-681 image-border" src="assets/c151fd9e-375d-4f6d-8405-c803b312bbb5.png" style=""/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Training and test MSE per iteration for up to 1,000 iterations</div>
<p>Now, to plot the preceding graph, I wrote a ;<kbd>plot()</kbd> method in the <kbd>PlotUtil_Rating.java</kbd> class that uses the ;<kbd>JFreeChart</kbd> library for plotting the training and test error/iteration:</p>
<pre><strong>public static void</strong> plot(<strong>double</strong>[] iterationArray, <strong>double</strong>[] testArray, <strong>double</strong>[] trainArray) {<br/>    <strong>final XYSeriesCollection</strong> dataSet = <strong>new</strong> XYSeriesCollection();<br/>    addSeries(dataSet, iterationArray, testArray, "Test MSE per iteration");<br/>    addSeries(dataSet, iterationArray, trainArray, "Training MSE per iteration");<br/>    <br/>    <strong>final JFreeChart</strong> chart = ChartFactory.createXYLineChart(<br/>            "Training and Test error/iteration (1000 iterations)", // chart title<br/>            "Iteration", // x axis label<br/>            "MSE", // y axis label<br/>            dataSet, // data<br/>            PlotOrientation.VERTICAL,<br/>            true, // include legend<br/>            true, // tooltips<br/>            false // urls<br/>    );<br/>    <br/>    <strong>final ChartPanel</strong> panel = new ChartPanel(chart);<br/>    <strong>final JFrame</strong> f = new JFrame();<br/>    f.add(panel);<br/>    f.setDefaultCloseOperation(WindowConstants.EXIT_ON_CLOSE);<br/>    f.pack();<br/>    f.setVisible(true);<br/>}</pre>
<p>Whereas the <kbd>addSeries()</kbd> method from the <kbd>XYSeries</kbd> class adds the series for the plot:</p>
<pre><strong>private static void</strong> addSeries (<strong>final</strong> XYSeriesCollection dataSet, <strong>double</strong>[] x, <strong>double</strong>[] y, <strong>final</strong> String label){<br/>    <strong>final</strong> XYSeries s = new XYSeries(label);<br/>    <strong>for</strong>(<strong>int</strong> j = 0; j &lt; x.length; j++ ) s.add(x[j], y[j]);<br/>    dataSet.addSeries(s);<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Which one makes more sense ;– ranking or rating?</h1>
                </header>
            
            <article>
                
<p><span class="ember-view">Is a rating or ranking prediction more logical while developing a movie recommendation system? If the amount of ratings per user is high enough, factorizing the user-product matrix is the best thing, in my opinion. However, if the dataset is too sparse, the prediction can be extremely inaccurate.</span></p>
<p><span class="ember-view">Knowing this fact, I was exploring the RankSys library and found that one of the contributors is arguing that ranking is more logical. He did not provide any explanation, though.</span> <span class="ember-view">Later on, I talked to some recommender system developers and researchers and got to know that he probably meant ranking is less sensitive to the prediction error due to the gap between a number of ratings and items. The reason is that ranking preserves the hierarchy, independent of the absolute rating.</span></p>
<p><span class="ember-view">Based on this understanding, later on, I decided to go one step further toward ranking prediction. For this, I wrote a spate class called</span> <kbd>RankingPrediction.java</kbd> for <span class="ember-view">predicting movie ranking by each user in the test set, which has the following structure:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-682 image-border" src="assets/31a53fdf-8eae-44d1-845a-c9ffd79f05f8.png" style=""/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Movie ranking prediction subproject structure</div>
<p>This has three methods, which are as follows:</p>
<ul>
<li><kbd>createIndexFromFile()</kbd>: This method is used for the creation of indexes from files that are passing as an argument in the method parameters itself.</li>
<li><kbd>generateTrainAndTestDataSet()</kbd>: This is used for separating data into training and testing sets, which is an important part of evaluating data mining models.</li>
<li><kbd>main()</kbd>: This is used for the creation of indexes, both for items and users, and is used for the following operations:
<ul>
<li>Index for a set of users</li>
<li>Index for a set of items</li>
<li>Stores the preferences/rating for users and items provided by <kbd>FastUserIndex</kbd> and <kbd>FastItemIndex</kbd></li>
<li>Creates a recommender interface that will be used by <kbd>FMRecommender</kbd></li>
<li>Uses a factorization machine that uses <kbd>RMSE-like loss</kbd> with a balanced sampling of negative instances</li>
</ul>
</li>
</ul>
<p>First, we set the path of the input data files:</p>
<pre><strong>final String</strong> folderPath = "ml-1m";<br/><strong>final String</strong> indexPath = "index";<br/><strong>final String</strong> userFileName = "users.dat";<br/><strong>final String</strong> moviesFileName = "movies.dat";<br/><strong>final String</strong> ratingsFileName = "ratings.dat";<br/><strong>final String</strong> encodingUTF8 = "UTF-8";<br/><br/><strong>final String</strong> userDatPath = folderPath + "/" + userFileName;<br/><strong>final String</strong> movieDatPath = folderPath + "/" + moviesFileName;</pre>
<p>Then, we set the path for the user and movie indexes stated previously:</p>
<pre><strong>final</strong> <strong>String</strong> indexPath = "index";<br/><strong>final String</strong> userIndexPath = indexPath + "/" + "userIndex";<br/><strong>final String</strong> movieIndexPath = indexPath + "/" + "movieIndex";</pre>
<p>Then, we set the path for the resultant file, where the training and test set will be generated:</p>
<pre><strong>String</strong> trainDataPath = indexPath + "/ratings_train";<br/><strong>String</strong> testDataPath = indexPath + "/ratings_test";<br/><strong>final</strong> <strong>String</strong> ratingsDatPath = folderPath + "/" + ratingsFileName;</pre>
<p>Then, we create the user index for all the users in the <kbd>users.dat</kbd> file. Here, the users are internally represented with numerical indices from 0 (inclusive) to the number of indexed users (exclusive):</p>
<pre><strong>FastUserIndex&lt;Long&gt;</strong> userIndex = <strong>SimpleFastUserIndex</strong>.<em>load</em>(UsersReader.<em>read</em>(userIndexPath, <em>lp</em>));</pre>
<p>In the preceding line of code, we used the <kbd>SimpleFastUserIndex</kbd> class from the RankSys library that helped in creating a simple implementation of <kbd>FastUserIndex</kbd> backed by a bi-map called ;<kbd>IdxIndex</kbd>.</p>
<p>Then, we create the item index for all of the items in the <kbd>movies.dat</kbd> file. This creates the index for a set of items. Here, the items are internally represented with numerical indices from 0 (inclusive) to the number of indexed items (exclusive):</p>
<pre><strong>FastItemIndex&lt;Long&gt;</strong> itemIndex = SimpleFastItemIndex.<em>load</em>(ItemsReader.<em>read</em>(movieIndexPath, <em>lp</em>));</pre>
<p>In the preceding line of code, we used the <kbd>SimpleFastItemIndex</kbd> class from the RankSys library, which helps us create a simple implementation of <kbd>FastItemIndex</kbd> backed by a bi-map called ;<kbd>IdxIndex</kbd>. Then, we store the preferences/rating for users and items provided by <kbd>FastUserIndex</kbd> and <kbd>FastItemIndex</kbd>:</p>
<pre>FastPreferenceData&lt;Long, Long&gt; trainData = SimpleFastPreferenceData.<em>load</em>(SimpleRatingPreferencesReader.<em>get</em>().read(trainDataPath, <em>lp</em>, <em>lp</em>), userIndex, itemIndex);<br/><br/>FastPreferenceData&lt;Long, Long&gt; testData = SimpleFastPreferenceData.<em>load</em>(SimpleRatingPreferencesReader.<em>get</em>().read(testDataPath, <em>lp</em>, <em>lp</em>), userIndex, itemIndex);</pre>
<p>Then, we invoke these two methods for creating user and item indexes:</p>
<pre><strong>if</strong> (!Files.<em>exists</em>(Paths.<em>get</em>(userIndexPath))) {<br/>     <em>createIndexFromFile</em>(userDatPath, encodingUTF8, userIndexPath);<br/>}<br/><br/><strong>if</strong> (!Files.<em>exists</em>(Paths.<em>get</em>(movieIndexPath))) {<br/><em>     createIndexFromFile</em>(movieDatPath, encodingUTF8, movieIndexPath);<br/>}</pre>
<p>In the preceding if statements, we generated indexes from file using the <kbd>createIndexFromFile()</kbd> method that goes as follows:</p>
<pre><strong>static void</strong> createIndexFromFile(<strong>String</strong> fileReadPath, <strong>String</strong> encodings, <strong>String</strong> fileWritePath) <strong>throws</strong> IOException {<br/>        <strong>BufferedReader</strong> bufferedReader = <strong>new</strong> BufferedReader(<strong>new</strong> InputStreamReader(<strong>new</strong> FileInputStream(<br/>                        fileReadPath), Charset.forName(encodings)));<br/>        <strong>BufferedWriter</strong> writer = <strong>new</strong> BufferedWriter(<strong>new</strong> OutputStreamWriter(<br/>                        <strong>new</strong> FileOutputStream(fileWritePath)));<br/><br/>        <strong>String</strong> line;<br/>        <strong>while</strong>((line = bufferedReader.readLine()) != null) {<br/>            <strong>StringBuilder</strong> builder = new StringBuilder();<br/>            <strong>String</strong>[] lineArray = line.split("::");<br/>            builder.append(lineArray[0]);<br/>            writer.write(builder.toString());<br/>            writer.newLine();<br/>        }<br/>        <br/>        writer.flush();<br/><br/>        bufferedReader.close();<br/>        writer.close();<br/>    }</pre>
<p>Once the index files are generated, we then start generating the training and test sets as follows:</p>
<pre><strong>if</strong> ( !Files.<em>exists</em>(Paths.<em>get</em>(trainDataPath))) {<br/><em>    generateTrainAndTestDataSet</em>(ratingsDatPath, trainDataPath, testDataPath);<br/>}</pre>
<p>In this code block, we used the ;<kbd>generateTrainAndTestDataSet()</kbd> method for generating both training and test sets:</p>
<pre><strong>static void</strong> generateTrainAndTestDataSet(<strong>String</strong> ratingsDatPath, <strong>String</strong> trainDataPath, <strong>String</strong> testDataPath) <strong>throws</strong> IOException {<br/>        <strong>BufferedWriter</strong> writerTrain = <strong>new</strong> BufferedWriter(new OutputStreamWriter(<br/>                        <strong>new</strong> FileOutputStream(trainDataPath)));<br/><br/>        <strong>BufferedWriter</strong> writerTest = <strong>new</strong> BufferedWriter(<strong>new</strong> OutputStreamWriter(<br/>                        <strong>new</strong> FileOutputStream(testDataPath)));<br/><br/>        <strong>BufferedReader</strong> bufferedReader = <strong>new</strong> BufferedReader(<strong>new</strong> FileReader(ratingsDatPath));<br/>        <strong>List&lt;String&gt;</strong> dummyData = new ArrayList&lt;&gt;();<br/>        <strong>String</strong> line;<br/><br/>        <strong>while</strong>((line = bufferedReader.readLine()) != null) {<br/>            String removeDots = line.replaceAll("::", "\t");<br/>            dummyData.add(removeDots);<br/>        }<br/>        <br/>        bufferedReader.close();<br/><br/>        <strong>Random</strong> generator = new Random();<br/>        <strong>int</strong> dataSize = dummyData.size();<br/>        <strong>int</strong> trainDataSize = (int)(dataSize * (2.0 / 3.0));<br/>        <strong>int</strong> i = 0;<br/>        <br/>        <strong>while</strong>(i &lt; trainDataSize){<br/>            <strong>int</strong> random = generator.nextInt(dummyData.size()-0) + 0;<br/>            line = dummyData.get(random);<br/>            dummyData.remove(random);<br/>            writerTrain.write(line);<br/>            writerTrain.newLine();<br/>            i++;<br/>        }<br/><br/>        <strong>int</strong> j = 0;<br/>        <strong>while</strong>(j &lt; (dataSize - trainDataSize)){<br/>            writerTest.write(dummyData.get(j));<br/>            writerTest.newLine();<br/>            j++;<br/>        }<br/><br/>        writerTrain.flush();<br/>        writerTrain.close();<br/><br/>        writerTest.flush();<br/>        writerTest.close();<br/>    }</pre>
<p>The preceding method divides up 2/3 as the training set and 1/3 as the test set. Finally, the file pointers are closed to release the resources. If the preceding three if statements executed successfully, you should see that two index files and two other files for the training and test sets have been generated:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-683 image-border" src="assets/f570978c-1cf1-4616-a08b-e0e0228224a3.png" style=""/></div>
<p>Then, we create a recommender interface, which will be used by the <kbd>FMRecommender</kbd> class, which generates recommendations without any restriction on the items being recommended:</p>
<pre>Map&lt;String, Supplier&lt;Recommender&lt;Long, Long&gt;&gt;&gt; recMap = <strong>new</strong> HashMap&lt;&gt;();</pre>
<p>Finally, wrap up the preference factorization machine to work with RankSys user-preference pairs. Then, we train the model by setting the learning rate, regularization, and standard deviation, and iterate the training up to 100 times using <kbd>PointWiseGradientDescent</kbd>. FM then uses RMSE-like loss with a balanced sampling of negative instances:</p>
<pre>// Use Factorisation machine that uses RMSE-like loss with balanced sampling of negative instances:<br/><strong>String</strong> outFileName = "outFolder/Ranking_RMSE.txt";<br/>recMap.put(outFileName, Unchecked.supplier(() -&gt; {<br/>            <strong>double</strong> negativeProp = 2.0D;<br/>            <br/>            <strong>FMData</strong> fmTrain = <strong>new</strong> OneClassPreferenceFMData(trainData, negativeProp);<br/>            <strong>FMData</strong> fmTest = <strong>new</strong> OneClassPreferenceFMData(testData, negativeProp);<br/>            <br/>            <strong>double</strong> learnRate = 0.01D; // Learning Rate<br/>            <strong>int</strong> numIter = 10; // Number of Iterations<br/>            <strong>double</strong> sdev = 0.1D;<br/>            <strong>double</strong> regB = 0.01D;<br/>            <br/>            <strong>double</strong>[] regW = new double[fmTrain.numFeatures()];<br/>            Arrays.fill(regW, 0.01D);<br/>            <strong>double</strong>[] regM = new double[fmTrain.numFeatures()];<br/>            <br/>            Arrays.fill(regM, 0.01D);<br/>            <strong>int</strong> K = 100;<br/>            <br/>            // returns enclosed FM<br/><strong>            FM</strong> fm = <strong>new</strong> FM(fmTrain.numFeatures(), K, <strong>new</strong> Random(), sdev);<br/>            (<strong>new</strong> PointWiseGradientDescent(learnRate, numIter, PointWiseError.rmse(), <br/>                                          regB, regW, regM)).learn(fm, fmTrain, fmTest);<br/>             // From general purpose factorization machines to preference FM for user-preference  <br/>            PreferenceFM&lt;Long, Long&gt; prefFm = <strong>new</strong> PreferenceFM&lt;Long, Long&gt;(userIndex, itemIndex, fm);<br/>            <br/>            <strong>return new</strong> FMRecommender&lt;Long, Long&gt;(prefFm);<br/>        }));</pre>
<p>In the preceding code block, the FM model is trained using the <kbd>learn()</kbd> method, which is pretty similar to the <kbd>learn()</kbd> method used for predicting rating in the previous section. Then, to evaluate the model, first, we set the target user and <kbd>SimpleRecommendationFormat</kbd>, which is in tab-separated, user-item score triplets (that is, present in the original dataset):</p>
<pre><strong>Set&lt;Long&gt;</strong> targetUsers = testData.getUsersWithPreferences().collect(Collectors.<em>toSet</em>());<br/>//Format of the recommendation generated by the FM recommender model as &lt;user, prediction)<br/><strong>RecommendationFormat&lt;Long, Long&gt;</strong> format = <strong>new</strong> SimpleRecommendationFormat&lt;&gt;(<em>lp</em>, <em>lp</em>);<br/><strong>Function&lt;Long, IntPredicate&gt;</strong> filter = FastFilters.<em>notInTrain</em>(trainData);<br/><strong>int</strong> maxLength = 100;</pre>
<p>Then, we invoke the <kbd>RecommenderRunner</kbd> interface to generate recommendations and print it based on the format:</p>
<pre>// Generate recommendations and print it based on the format.<br/><strong>RecommenderRunner&lt;Long, Long&gt;</strong> runner = <strong>new</strong> FastFilterRecommenderRunner&lt;&gt;(userIndex, itemIndex, targetUsers.stream(), filter, maxLength);<br/>        <br/> recMap.forEach(Unchecked.biConsumer((name, recommender) -&gt; {<br/>            System.out.println("Ranking prediction is ongoing...");<br/>            System.out.println("Result will be saved at " + name);<br/>            <strong>try</strong>(RecommendationFormat.Writer&lt;Long, Long&gt; writer = format.getWriter(name)) {<br/>                runner.run(recommender.get(), writer);<br/>            }<br/>        }));</pre>
<p>The preceding code block will perform the evaluation on the test set and write the recommendation in the text file we specified previously:</p>
<pre><span class="packt_screen"><q>&gt;&gt;</q><br/> Ranking prediction is ongoing...<br/> Result will be saved at outFolder/Ranking_RMSE.txt<br/> INFO: iteration n = 1 t = 3.92s<br/> INFO: iteration n = 2 t = 3.08s<br/> INFO: iteration n = 3 t = 2.88s<br/> INFO: iteration n = 4 t = 2.84s<br/> INFO: iteration n = 5 t = 2.84s<br/> INFO: iteration n = 6 t = 2.88s<br/> INFO: iteration n = 7 t = 2.87s<br/> INFO: iteration n = 8 t = 2.86s<br/> INFO: iteration n = 9 t = 2.94s<br/> ...<br/> INFO: iteration n = 100 t = 2.87s<br/> Graph plotting...</span></pre>
<p class="mce-root">The prediction has been saved at outFolder/Ranking_RMSE.txt</p>
<p>Now, let's take a look at the output file:</p>
<pre><span class="packt_screen">944 2396 0.9340957389234708<br/> 944 593 0.9299994477666256<br/> 944 1617 0.9207678675263278<br/> 944 50 0.9062805385053954<br/> 944 1265 0.8740234972054955<br/> 944 589 0.872143533435846<br/> 944 480 0.8659624750023733<br/> 944 2028 0.8649344355656503<br/> 944 1580 0.8620307480644472<br/> 944 2336 0.8576568651679782<br/> 944 1196 0.8570902991702303</span></pre>
<p>This snapshot from the output file shows the predicted ranking by user 944 for different movies. Now that we can see that our FM model has predicted the user's ranking for movies, inspecting model performance in terms of accuracy and execution time would make sense.</p>
<p>For this, I wrote a class called <kbd>PlotUtil_Rank.java</kbd>. This class takes the metrics type and a number of iterations and generates the plot using the <kbd>plot()</kbd> method:</p>
<pre><strong>public static void</strong> plot(<strong>double</strong>[] iterationArray, <strong>double</strong>[] timeArray, <strong>String</strong> chart_type, <strong>int</strong> iter) {<br/>        <strong>String</strong> series = null;<br/>        <strong>String</strong> title = null;<br/>        <strong>String</strong> x_axis = null;<br/>        <strong>String</strong> y_axis = null;<br/>        <br/>        <strong>if</strong>(chart_type =="MSE"){        <br/>            series = "MSE per Iteration (" + iter + " iterations)";<br/>            title = "MSE per Iteration (" + iter + " iterations)";<br/>            x_axis = "Iteration";<br/>            y_axis = "MSE";<br/>        }<strong>else</strong> {<br/>            series = "Time per Iteration (" + iter + " iterations)";<br/>            title = "Time per Iteration (" + iter + " iterations)";<br/>            x_axis = "Iteration";<br/>            y_axis = "Time";            <br/>        }<br/>            final XYSeriesCollection dataSet = new XYSeriesCollection();<br/>            addSeries(dataSet, iterationArray, timeArray, series);<br/>        <br/>            <strong>final JFreeChart</strong> chart = ChartFactory.createXYLineChart(<br/>                    title, // chart title<br/>                    x_axis, // x axis label<br/>                    y_axis, // y axis label<br/>                    dataSet, // data<br/>                    PlotOrientation.VERTICAL,<br/>                    true, // include legend<br/>                    true, // tooltips<br/>                    false // urls<br/>                    );<br/>        <br/>        <strong>final ChartPanel</strong> panel = <strong>new</strong> ChartPanel(chart);<br/>        <strong>final JFrame</strong> f = <strong>new</strong> JFrame();<br/>        f.add(panel);<br/>        f.setDefaultCloseOperation(WindowConstants.EXIT_ON_CLOSE);<br/>        f.pack();<br/>        f.setVisible(true);<br/>    }</pre>
<p>This method is further called from the <kbd>PointWiseGradientDescent.java</kbd> class. First, we create two <kbd>ArrayList</kbd> of <kbd>Double</kbd> to hold the execution time and MSE:</p>
<pre>//PointWiseGradientDescent.java<br/><strong>List&lt;Double&gt;</strong> timeList = <strong>new</strong> ArrayList&lt;Double&gt;();<br/><strong>List&lt;Double&gt;</strong> errList = <strong>new</strong> ArrayList&lt;Double&gt;();</pre>
<p>Then, for each iteration, the ;<kbd>learn()</kbd> method generates both the MSE error and time for each iteration and puts them in the list:</p>
<pre>iter = t;<br/><strong>long</strong> time1 = System.<em>nanoTime</em>() - time0;<br/>iterationList.add((<strong>double</strong>)iter);<br/>timeList.add((<strong>double</strong>)time1 / 1_000_000_000.0);<br/>errList.add(error(fm, test));</pre>
<p>Finally, the <kbd>plot()</kbd> method is called as follows to plot the graph:</p>
<pre><strong>PlotUtil_Rank</strong>.<em>plot</em>(convertobjectArraytoDouble(iterationList.toArray()),     convertobjectArraytoDouble(errList.toArray()), "MSE", iter); <br/><br/><strong>PlotUtil_Rank</strong>.<em>plot</em>(convertobjectArraytoDouble(iterationList.toArray()), convertobjectArraytoDouble(timeList.toArray()), "TIME", iter);</pre>
<p>By the way, <kbd>convertobjectArraytoDouble()</kbd>, which is shown in the following code, is used to convert the object array into doubles to act as data points for the plots:</p>
<pre><strong>public </strong><strong>double</strong> [] convertobjectArraytoDouble(Object[] objectArray){<br/><strong>               double</strong>[] doubleArray = <strong>new</strong><strong>double</strong>[objectArray.length];<br/>               //Double[ ]doubleArray=new Double();<br/><strong>               for</strong>(<strong>int</strong> i = 0; i &lt; objectArray.length; i++){<br/>                   Object object = objectArray[i]; <br/>                   String string = object.toString(); <strong>double</strong> dub = Double.<em>valueOf</em>(string).doubleValue();<br/>                   doubleArray[i] = dub;<br/>                       }<br/><strong>               return</strong> doubleArray;<br/>     }</pre>
<p>The preceding invocation should generate two graphs. First, we see the MSE per iteration, and the following graph reports the same for 100 iterations:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-684 image-border" src="assets/07ab7d7b-9aca-4220-9d58-84f427c6cee1.png" style=""/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">MSE per iteration (up to 100<sup>th</sup>)</div>
<p>Then, we see the time per iteration, and the following graph reports the same for the 100th iteration:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-685 image-border" src="assets/dfe6c1de-3150-473f-9461-dce817101237.png" style=""/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Time per iteration (up to 100<sup>th</sup>)</div>
<p>Finally, from the second graph, we cannot make important insights except that the execution time per iteration fluctuated a lot. However, on the 90<sup>th</sup> iteration, the time needed for each iteration was saturated.</p>
<p>On the other hand, the MSE drastically decreased after the 20th iteration from 0.16 to 0.13, but was saturated after the 25<sup>th</sup> iteration. This means increasing only a number of iterations, will not help us further reduce the MSE. Therefore, I would suggest that you try this after changing not only the number of iterations but also other hyperparameters.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Frequently asked questions (FAQs)</h1>
                </header>
            
            <article>
                
<p>Now that we have seen how to develop a movie recommendation that predicts both the rating and ranking of movies by users, there are some issues that require our attention, too. Also, we couldn't cover/discuss the library in this chapter, so I suggest that you read the documentation more carefully.</p>
<p>However, we will still see some frequently asked questions that might already be on your mind in this section. Answers to these questions can be found in the Appendix.</p>
<ol>
<li>How can I save a trained FM model?</li>
<li>How can I restore a saved FM model from disk?</li>
<li>Can I use the FM algorithm for solving a classification task?</li>
<li>Give me a few example use cases where FM algorithms have been used.</li>
<li>C<span class="rendered_qtext">an I use the FM algorithm for making top-N recommendations?</span></li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we saw how to develop a movie recommendation system using FMs, which are a set of algorithms that enhance the performance of linear models by incorporating second-order feature interactions that are absent in matrix factorization algorithms in a supervised way.</p>
<p>Nevertheless, we have seen some theoretical background of recommendation systems using matrix factorization and collaborative filtering before diving into the project's implementation using RankSys library-based FMs. Due to page limitation, I didn't discuss the library more extensively. However, readers are suggested to take a look athe API documentation on GitHub at <a href="https://github.com/RankSys/RankSys">https://github.com/RankSys/RankSys</a>.</p>
<p>This project not only covers movie rating prediction by individual users but also discusses ranking prediction, too. Consequently, we also used FMs for predicting the ranking of movies.</p>
<p>This is more or less the end of our journey toward developing an end-to-end project with Java. However, we are not done yet! In the next chapter, we will discuss some recent trends of deep learning. Then, we will see some emerging use cases that can be implemented using DL4J library or least we'll see some pointers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Answers to questions</h1>
                </header>
            
            <article>
                
<p><strong>Answer</strong> <strong>to question 1</strong>: For this, you can invoke the <kbd>saveModel()</kbd> method by providing the input model filename:</p>
<pre><strong>String</strong> FILENAME = Constants.FILENAME;<br/>// Save the trained FM model <br/>fmlsgd.saveModel(FILENAME);</pre>
<p>The <kbd>saveModel()</kbd> method goes as follows:</p>
<pre><strong>public void</strong> saveModel(<strong>String</strong> FILENAME) <strong>throws</strong> Exception<br/>    {<br/>        <strong>FILENAME</strong> = Constants.FILENAME;<br/>        <strong>FileOutputStream</strong> fos = null;<br/>        <strong>DataOutputStream</strong> dos = null;        <br/>        <strong>try</strong> {      <br/>            fos = new FileOutputStream(FILENAME);<br/>            dos = new DataOutputStream(fos);<br/>            dos.writeBoolean(fm.k0);<br/>            dos.writeBoolean(fm.k1);<br/>            dos.writeDouble(fm.w0);<br/>            dos.writeInt(fm.num_factor);<br/>            dos.writeInt(fm.num_attribute);<br/>            dos.writeInt(task.ordinal());<br/>            dos.writeDouble(max_target);<br/>            dos.writeDouble(min_target);<br/>            <br/>            <strong>for</strong>(<strong>int</strong> i=0;i&lt;fm.num_attribute;i++)<br/>            {<br/>                dos.writeDouble(fm.w[i]);<br/>            }<br/>            <br/>            <strong>for</strong>(<strong>int</strong> i=0;i&lt;fm.num_factor;i++)<br/>            {<br/>                dos.writeDouble(fm.m_sum[i]);<br/>            }<br/>            <br/>            <strong>for</strong>(<strong>int</strong> i=0;i&lt;fm.num_factor;i++)<br/>            {<br/>                dos.writeDouble(fm.m_sum_sqr[i]);<br/>            }<br/>            <br/>            <strong>for</strong>(<strong>int</strong> i_1 = 0; i_1 &lt; fm.num_factor; i_1++) {<br/>                <strong>for</strong>(<strong>int</strong> i_2 = 0; i_2 &lt; fm.num_attribute; i_2++) {                    <br/>                    dos.writeDouble(fm.v.get(i_1,i_2));<br/>                }<br/>            }<br/>            <br/>            dos.flush();<br/>        }<br/>        <strong>catch</strong>(<strong>Exception</strong> e) {<br/>            <strong>throw</strong> <strong>new</strong> JlibfmRuntimeException(e);<br/>        } <strong>finally</strong> {          <br/>             <strong>if</strong>(dos!=null)<br/>                dos.close();<br/>             <strong>if</strong>(fos!=null)<br/>                fos.close();<br/>        }<br/>    }</pre>
<p>Then, the method will save all the metadata (including dimension, rank, weight, and attribute information) of the trained model onto disk.</p>
<p><strong>Answer</strong> <strong>to question 2</strong>: For this, you can invoke the ;<kbd>therestoreModel()</kbd> method by providing the input model filename:</p>
<pre><strong>public void</strong> restoreModel(<strong>String</strong> FILENAME) <strong>throws</strong> Exception<br/>    {<br/>        <strong>FILENAME</strong> = Constants.FILENAME;<br/>        <strong>InputStream</strong> is = null;<br/>        <strong>DataInputStream</strong> dis = null;        <br/>        <strong>try</strong> {      <br/>            is = <strong>new</strong> FileInputStream(FILENAME);          <br/>            dis = <strong>new</strong> DataInputStream(is);<br/>            <br/>            fm.k0 = dis.readBoolean();<br/>            fm.k1 = dis.readBoolean();<br/>            fm.w0 = dis.readDouble();<br/>            fm.num_factor = dis.readInt();<br/>            fm.num_attribute = dis.readInt();<br/>            <br/>            <strong>if</strong>(dis.readInt() == 0)<br/>            {<br/>               task = TaskType.TASK_REGRESSION;<br/>            }<br/>            <strong>else</strong><br/>            {<br/>               task = TaskType.TASK_CLASSIFICATION;<br/>            }<br/>           <br/>            max_target = dis.readDouble();<br/>            min_target = dis.readDouble();<br/>            <br/>            fm.w = new double[fm.num_attribute];<br/>            <br/>            <strong>for</strong>(<strong>int</strong> i=0;i&lt;fm.num_attribute;i++)<br/>            {<br/>                fm.w[i] = dis.readDouble();<br/>            }<br/>            <br/>            fm.m_sum = new double[fm.num_factor];<br/>            fm.m_sum_sqr = new double[fm.num_factor];<br/>            <br/>            <strong>for</strong>(<strong>int</strong> i=0;i&lt;fm.num_factor;i++)<br/>            {<br/>               fm.m_sum[i] = dis.readDouble();<br/>            }<br/>            <br/>            <strong>for</strong>(<strong>int</strong> i=0;i&lt;fm.num_factor;i++)<br/>            {<br/>                fm.m_sum_sqr[i] = dis.readDouble();<br/>            }<br/>            <br/>            fm.v = new DataPointMatrix(fm.num_factor, fm.num_attribute);<br/>            <br/>            <strong>for</strong>(<strong>int</strong> i_1 = 0; i_1 &lt; fm.num_factor; i_1++) {<br/>                <strong>for</strong>(<strong>int</strong> i_2 = 0; i_2 &lt; fm.num_attribute; i_2++) {        <br/>                    fm.v.set(i_1,i_2, dis.readDouble());<br/>                }<br/>            }<br/>            <br/>        }<br/>        <strong>catch</strong>(<strong>Exception</strong> e) {<br/>            <strong>throw new</strong> JlibfmRuntimeException(e);<br/>        } <strong>finally</strong> {          <br/>             <strong>if</strong>(dis!=null)<br/>                dis.close();<br/>             <strong>if</strong>(is!=null)<br/>                is.close();<br/>        }<br/>    }</pre>
<p>The invocation of this method will restore the saved model, including all the metadata (for example, dimension, rank, weight, and attribute information) of the trained model from the disk.</p>
<p><strong>Answer</strong> <strong>to question 3</strong>: Yes, of course. This algorithm is very effective for very sparse datasets, too. All you need is to have the predicted labels in the integer and the task type classification, that is, <kbd>task == TaskType.TASK_CLASSIFICATION</kbd>.</p>
<p><strong>Answer to question 4</strong>: There are several use cases where FM-based approaches have been applied. For example:</p>
<ul>
<li>
<p>Predicting whether the user is going to buy an item in a session from a given sequence of click events performed by users. Also, if he/she is buying, what would be the items he/she is going to buy? This problem is called the RecSys Challenge 2015 (see more at <a href="http://2015.recsyschallenge.com/challenge.html">http://2015.recsyschallenge.com/challenge.html</a>).</p>
<p>To see a sample solution, interested readers can take a look at the following book titled <em>Deep Learning with TensorFlow - Second Edition</em> by Karim et al Packt Publishing, March 2018 (see more at <a href="https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-tensorflow-second-edition">https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-tensorflow-second-edition</a>).</p>
</li>
<li>
<p><em>Using Factorization Machines for Hybrid Recommendation Systems Based on Behavioral, Product, and Customer Data</em> (see more at <a href="https://dl.acm.org/citation.cfm?id=2796542">https://dl.acm.org/citation.cfm?id=2796542</a>).</p>
</li>
</ul>
<p><strong>Answer to question 5</strong>: Yes, you can extract it <span class="inline_editor_value"><span class="ui_qtext_rendered_qtext">from implicit feedback (from reviews, events, transactions, and so on), since converting the rating prediction results to top-N lists is a trivial job. However, I don't think there's any open source implementations available, but you can of course try by modifying LibFM significantly to use pairwise ranking.</span></span></p>
<div class="book-top-block-info-anl cf">
<div class="book-top-block-info-authors left"><br/>
<div class="book-top-block-star-rating"/>
</div>
</div>


            </article>

            
        </section>
    </body></html>