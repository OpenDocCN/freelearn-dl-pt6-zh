<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Recurrent Neural Networks</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, we marveled over the visual cortex and leveraged some insights from the way it processes visual signals to inform the architecture of <strong>Convolutional Neural Networks</strong> (<strong>CNNs</strong>), which form the base of many state-of-the-art computer vision systems. However, we do not understand the world around us with vision alone. Sound, for one, also plays a very important role. More specifically, we humans love to communicate and express intricate thoughts and ideas through sequences of symbolic reductions and abstract representations. Our built-in hardware allows us to interpret vocalizations or demarcations thereof, composing the base of human thought and collective understandings, upon which more complex representations (such as human languages, for instance) may be composed. In essence, these sequences of symbols are reduced representations of the world around us, through our own lenses, which we use to navigate our surroundings and effectively express ourselves. It stands to reason that we would want machines to understand this manner of processing sequential information, as it could help us to resolve many problems we face with such sequential tasks in the real world. But what kind of problems?</p>
<p>Following are the topics that will be covered in this chapter:</p>
<ul>
<li>Modeling sequences</li>
<li>Summarizing different types of sequence processing tasks</li>
<li>Predicting an output per time step</li>
<li>Backpropagation through time</li>
<li>Exploding and vanishing gradients</li>
<li>GRUs</li>
<li>Building character-level language models in keras</li>
<li>Statistics of character modeling</li>
<li>The purpose of controlling stochastically</li>
<li>Testing different RNN models</li>
<li>Building a SimpleRNN</li>
<li>Building GRUs</li>
<li>On processing reality sequentially</li>
<li>Bi-directional layer in Keras</li>
<li>Visualizing output values </li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Modeling sequences</h1>
                </header>
            
            <article>
                
<p>Perhaps you want to get the right translation for your order in a restaurant while visiting a foreign country. Maybe you want your car to perform a sequence of movements automatically so that it is able to park by itself. Or maybe you want to understand how different sequences of adenine, guanine, thymine, and cytosine molecules in the human genome lead to differences in biological processes occurring in the human body. What's the commonality between these examples? Well, these are all sequence modeling tasks. In such tasks, the training examples (being vectors of words, a set of car movements generated by on-board controls, or configuration of <em>A</em>, <em>G</em>, <em>T</em>, and <em>C</em> molecules) are essentially multiple time-dependent data points of a possibly varied length.</p>
<p>Sentences, for example, are composed of words, and the spatial configuration of these words allude not only to what has been said, but also to what is yet to come. Try and fill in the following blank:</p>
<p><em>Don't judge a book by its ___.</em></p>
<p>How did you know that the next word would be <em>cover</em>? You simply look at the words and their relative positions and performed some sort of Bayesian inference, leveraging the sentences you have previously seen and their apparent similarity to the example at hand. In essence, you used your internal model of the English language to predict the most probable word to follow. Here, <em>language model</em> simply refers to the probability of a particular configuration of words occurring together in a given sequence. Such models are the fundamental components of modern speech recognition and machine translation systems, and simply rely on modeling the likelihood of sequences of words.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using RNNs for sequential modeling</h1>
                </header>
            
            <article>
                
<p>The field of natural language understanding is a common area where <strong>recurrent neural networks</strong> (<strong>RNNs</strong>) tend to excel. You may imagine tasks such as recognizing named entities and classifying the predominant sentiment in a given piece of text. However, as we mentioned, RNNs are applicable to a broad spectrum of tasks that involve modeling time-dependent sequences of data. Generating music is also a sequence modeling task as we tend to distinguish music from a cacophony by modeling the sequence of notes that are played in a given tempo.</p>
<p>RNN architectures are even applicable for some visual intelligence tasks, such as video activity recognition. Recognizing whether a person is cooking, running, or robbing a bank in a given video is essentially modeling sequences of human movements and matching them to specific classes. In fact, RNNs have been deployed for some very interesting use cases, including generating text in Shakespearean style, creating realistic (but incorrect) algebraic papers, and even producing source code for the Linux operating system with proper formatting.</p>
<p>So, what makes these networks so versatile at performing these seemingly diverse tasks? Well, before we answer this, let's refresh our memory on some of the difficulties we faced using neural nets so far:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1224 image-border" src="Images/a3ef793d-f2f1-4923-a5b9-0e1680930241.png" style="width:34.50em;height:25.17em;" width="414" height="302"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Fake algebraic geometry, generated by RNN, courtesy of Andrej Karpathy</div>
<p>Which means:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1225 image-border" src="Images/ee7a9951-c981-4b4f-b1d8-9b3e02bf45eb.png" style="width:34.92em;height:5.83em;" width="481" height="81"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">What's the catch?</h1>
                </header>
            
            <article>
                
<p><span>A problem with all of the networks we have built so far is that they only accepted inputs and outputs of fixed sizes for given training examples. We have always had to specify our input shape, defining the dimensions of the tensor entering our network, which in turn returns a fixed size output in terms of a class probability score, for example. Moreover, the hidden layers in our networks each had their own weights and activations, which behaved somewhat independently of each other, without identifying relationships between successive input values. This holds true for both the feedforward and the CNNs that we have familiarized ourselves with in previous chapters. For each network we built, we used non-sequential training vectors, which would propagate through a constant number of layers and produce a single output.</span></p>
<p><span>While we did see some multi-output models to visualize the intermediate layers of CNNs, we never really modified our architecture to operate over a sequence of vectors. This basically prohibited us from sharing any time-dependent information that may affect the likelihood of our predictions. Discarding time-dependent information has got us by so far for the tasks we dealt with. In the case of image classification, the fact that your neural network saw the image of a cat at the last iteration does not really help it classify the current image it is viewing because the class probabilities of these two instances are not temporally related. However, this approach already caused us some trouble for the use case of sentiment analysis. Recall in <a href="46e25614-bb5a-4cca-ac3e-b6dfbe29eea5.xhtml" target="_blank">Chapter 3</a>, <em>Signal Processing - Data Analysis with Neural Networks</em>, that we classified movie reviews by treating each review as a bag of undirected words (that is, not in their sequential order). This approach entailed transforming each review into a fixed-length vector that's defined by the size of our vocabulary (that is, the number of unique words in the corpus, which we had chosen to be 12,000 words). While useful, this is certainly not the most efficient or scalable form of representing information, as a sentence of any given length must be represented by a 12,000-dimensional vector. The simple feedforward network we trained (attaining an accuracy just above 88 %) incorrectly classified the sentiment of one of the reviews, which has been reproduced here:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/0d2f4a36-47d1-46d5-a154-564f4aff2342.png" width="988" height="181"/></div>
<p>Our network seemed to have gotten confused due to the (unnecessarily) complex sentence with several long-term dependencies and contextual valence shifters. In retrospect, we noted unclear double negatives referring to various entities such as the director, actor, and the movie itself; yet we were able to make out that the overall sentiment of the review was clearly positive. Why? Simply because we are able to track concepts that are relevant to the general sentiment of the review, as we read it word for word. In our minds, we are able to assess how each new word of the review we see affects the general meaning of the statement we have read so far. In this manner, we adjust our sentiment score for a review as we read along and come across new information (such as adjectives or negations) that may affect this score at a given time step.</p>
<p>Just like in CNNs, we want our network to be able to use representations that have been learned on a certain segment of the input, which are then usable later on in other segments and examples. In other words, we need to be able to share the weights of our network from previous time steps to connect bits of information as we sequentially go over our input review. This is pretty much what RNNs allow us to do. These layers leverage the additional information that's encoded in successive events, which it does by looping over a sequence of input values. Depending on the architectural implementation, RNNs can save relevant information in its memory (also referred to as its state) and use this information to perform predictions at subsequent time steps.</p>
<p>This mechanism is notably different from the networks we saw earlier, which processed each training iteration independently and did not maintain any state between predictions. There are several different implementations of recurrent neural networks, ranging from <strong>Gated Recurrent Units</strong> (<strong>GRUs</strong>), stateful and stateless <strong>Long Short-Term Memory</strong> (<strong>LSTM</strong>) networks, bi-directional units, and many more. As we will soon discover, each of these architectures help to address a certain type of problem, building on the shortcomings of each other:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/7d9ac677-7a6d-493d-8769-4c6a1737b07c.png" width="1089" height="188"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Basic RNN architecture</h1>
                </header>
            
            <article>
                
<p>Now, let's have a look at how the RNN architecture differentiates itself from the other networks that we have seen so far by unrolling it through time. Let's consider a new time series problem: speech recognition. This task can be performed by computers to identify the flow of words during a segment of human speech. This can be used to transcribe the speech itself, translate it, or use it as input for instructions, similar to the manner in which we instruct each other. Such applications form the base of systems such as Siri or Alexa and perhaps more complex and cognitive virtual assistants of the future. So, how can an RNN decode the sequence of decomposed vibrations that are recorded by the microphone on your computer into a string variable corresponding to the input speech?</p>
<p class="mce-root">Let's consider a simplified theoretical example. Imagine that our training data maps a sequence of human vocalizations to a set of human-readable words. In other words, you show your network an audio clip and it spits out a transcript of whatever was said within. We task an RNN to go over a segment of speech by treating it as sequences of vectors (representing sound bytes). The network can then try to predict what words of the English language these sound bytes may represent at each time step:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1140 image-border" src="Images/d74466a5-cfac-4d7a-b9d7-a03245b7de68.png" style="width:54.50em;height:27.75em;" width="654" height="333"/></p>
<p>Consider the set of vectors that represent the sound byte for the words <em>today is a nice day</em>. A recurrent layer will unfold this sequence in several time steps. In the first time step, it will take the vector representing vocalization for the first word in the sequence as input (that is, <em>today</em>), compute a dot product with the layer weights, and pass the product through a non-linear activation function (commonly tanh for RNNs) to output a prediction. This prediction corresponds to a word that the network thinks it has heard. At the second time step, the recurrent layer receives the next sound byte (that is, for the word <em>is</em>) in the sequence, along with the activation values from the first time step. Both of these values are then squashed through the activation function to produce a prediction for the current time step. This basically allows the layer to leverage information from the previous time steps to inform the prediction at the current time step. This process is repeated as the recurrent layer receives each vocalization in a given sequence, along with the activation values from previous vocalizations. The layer may compute a Softmax probability score for each word in our dictionary, picking the one with the highest value as output for the given layer. This word corresponds to what our network thinks it has heard at this time.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Temporarily shared weights</h1>
                </header>
            
            <article>
                
<p>Why is it useful to temporally connect activations? Well, as we pointed out earlier, each word affects the probability distribution of the next word to come. If our sentence began with the word <em>Yesterday</em>, it is much more likely to be followed by the word <em>was</em>, than the word <em>is</em>, reflecting the use of the past tense. Such syntactic information can be passed along through recurrent layers to inform the predictions of the network at each step by using what the network has output in previous time steps. As our network trains on given segments of speech, it will adjust its layer weights to minimize the difference between what it predicts and the true value of each output by (hopefully) learning such grammatical and syntactic rules, among other things. Importantly, the recurrent layer's weights are temporally shared, allowing activations from previous time steps to have influence over predictions of subsequent time steps. Doing so, we no longer treat each prediction in isolation, but as a function of the network's activations at previous time steps, along with some input at the current time step.</p>
<p>The actual workflow of speech recognition models may be a bit more complex than what we described previously, which involves data normalization techniques such as the Fourier transformation, which lets us decompose audio signals into their constituent frequencies. In essence, we always try to normalize our input data with the goal to better represent data to our neural networks, as this helps it to converge faster to encode useful predictive rules. The key take-away from this example is that recurrent layers can leverage earlier temporal information to inform its predictions at the current time step. As we progress through this chapter, we will see how these architectures can be adopted for modeling different lengths of sequence input and output data.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Sequence modeling variations in RNNs</h1>
                </header>
            
            <article>
                
<p><span>The speech recognition example consists of modeling a synchronized many-to-many sequence, where we predicted many sets of vocalizations to many words that correspond to these vocalizations. We can use a similar architecture for the task of video captioning, where we would want to sequentially label each frame of the video with the dominant object within. This is yet another synchronized many-to-many sequence, as we output a prediction at each time step that corresponds to the input frame of the video.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Encoding many-to-many representations</h1>
                </header>
            
            <article>
                
<p><span>We can also have a semi-synchronized many-to-many sequence in the case of machine translation. This use case is semi-synchronized, as we do not immediately output a prediction at each time step. Instead, we use the encoder section of our RNN to capture the entire phrase so that it can be translated before we proceed and actually translate it. This lets us find better representations of the input data in the output language, instead of just translating each word at a time. The latter approach is not very robust and often leads to inaccurate translations. In the following example, an RNN translates the French phrase <em>C'est pas mal!</em> into the equivalent term in English, <em>It's nice!</em></span>, <span>which is a much more accurate translation than the literal, <em>It's not bad!</em>. Hence, RNNs can help us to decipher the peculiar rules that are applied to complementing a person in the French language. This may help avoid quite a few misunderstandings:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/0dc153e8-dbf9-4326-8147-380991d5df01.png" style="width:28.17em;height:17.67em;" width="482" height="302"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Many-to-one</h1>
                </header>
            
            <article>
                
<p><span>Similarly, you can also have a many-to-one architecture to address tasks such as attributing many sequences of words forming a sentence to one corresponding sentiment score. This is just like what we had to do in our previous exercise with the IMDb dataset. Last time, our approach involved representing each review as an undirected bag-of-words. With RNNs, we can approach this problem by modeling a review as a directed sequence of individual words, in their correct order, hence leveraging the spatial information from the arrangement of words to inform our sentiment score. Here is a simplified example of a many-to-one RNN architecture for sentiment classification:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/e5504705-2713-4b8a-bc3c-3854837869a7.png" style="width:30.17em;height:19.25em;" width="437" height="279"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">One-to-many</h1>
                </header>
            
            <article>
                
<p><span>Finally, different variations of sequential tasks may demand different architectures. Another commonly used architecture is the one-to-many RNN model, which we would use for the use case of music generation or image captioning. For music generation, we essentially feed our network one input note, make it predict the next note in the sequence, and then leverage its very own prediction as input for the next time step:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/f8f6a4c0-d250-4103-9ede-c2ba360e3e4b.png" style="width:35.25em;height:16.92em;" width="447" height="215"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">One-to-many for image captioning</h1>
                </header>
            
            <article>
                
<p><span>Another novel example of a one-to-many architecture is what is commonly used for the task of image captioning. This is when we show our network an image and ask it to describe what is going on with a small caption. To do this, we essentially feed our network one image at a time to output many words corresponding to what is going on in the image. Commonly, you may stack a recurrent layer on top of a CNN that has already been trained on some entities (objects, animals, people, and so on). Doing so, you could use the recurrent layer to intake the output values of the convolutional network all together, and sequentially go over the image to output meaningful words corresponding to a description of the input image. This is a more complex setup that we will elaborate on in later chapters. For now, it is useful to know that LSTM networks (shown as follows) are a type of RNN that's inspired by semantic and episodic divisions of the human memory structure and will be the prime topic of discussion in <a href="62bc2e63-11f3-43ab-a3ae-967c6603c306.xhtml" target="_blank">Chapter 6</a>, <em>Long-Short Term Memory Networks</em>. In the following diagram, we can see how the network is able to pick up on the fact that there are several giraffes standing about, leveraging the output it receives from the CNN.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summarizing different types of sequence processing tasks</h1>
                </header>
            
            <article>
                
<p>Now, we have familiarized ourselves with the basic idea of what a recurrent layer does and have gone over some specific examples of use cases (from speech recognition, machine translation, and image captioning) where variations of such time-dependent models may be used. The following diagram provides a visual summary of some of the sequential tasks we discussed, along with the type of RNN that's suited for the job:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/0bd4c08a-3dbf-4d48-9fb8-d7800c486b63.png" width="992" height="467"/></div>
<p>Next, we will dive deeper into the governing equations, as well as the learning mechanism behind RNNs.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How do RNNs learn?</h1>
                </header>
            
            <article>
                
<p>As we saw previously, for virtually all neural nets, you can break down the learning mechanism into two separate parts. The forward propagation equations govern the rules that allow data to propagate forward in our neural network, all of the way to the network predictions. The backpropagation of errors are defined by equations (such as the loss function and the optimizer), which allow our model's prediction errors to move backward through our model's layers, adjusting the weights on each layer toward the correct prediction values.</p>
<p>This is essentially the same for RNNs, yet with a few architectural variations to account for time-dependent information flows. To do this, RNNs can leverage an internal state, or <em>memory</em>, to encode useful time-dependent representations. First, let's have a look at the forward pass of data in a recurrent layer. A recurrent layer basically combines the input vector that's entering the layer with a state vector to produce a new output vector at each time step. Soon, we will see how iteratively updating these state vectors can be leveraged to preserve temporally relevant information in a given sequence.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">A generic RNN layer</h1>
                </header>
            
            <article>
                
<p>The following diagram hopefully familiarizes this process. On the left, the gray arrow in the diagram illustrates how activations from current time steps are sent forward to future time steps. This holds true for all RNNs, forming a distinct signature of their architecture. On the right-hand side, you will notice a reduced representation of the RNN unit. This is one of the most common demarcations of RNNs that you will find in countless computer science research papers:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/30b9a91b-026c-4fe1-a6c4-93fa6eb8a63f.png" style="width:41.50em;height:17.50em;" width="605" height="255"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">To sequence, or not to sequence?</div>
<p>The RNN layer essentially processes its input values in a time-dependent and sequential manner. It employs a state (or memory), which allows us to address sequence modeling tasks in a novel way. However, there are quite a few examples where approaching non-sequential data in a sequential manner has allowed us to address standard use cases in more efficient ways. Take the example of the research conducted by DeepMind on steering the attention of a network on images.</p>
<p class="mce-root"/>
<p>Instead of simply applying a computation-heavy CNN for image classification, DeepMind researchers showed how RNNs that have been trained through reinforcement learning can be used to perform the same function and achieve even better accuracy at more complex tasks such as classifying cluttered images, along with other dynamic visual control problems. One of the main architectural take backs from their work was that their RNN effectively extracted information from images or videos by adaptively selecting sequence or regions to process at a high resolution, thereby reducing the redundant computational complexity of processing an entire image at a high resolution. This is pretty neat, as we don't necessarily need to process all of the parts of an image to perform classification. Most of what we need is usually centered around a local area of the image in question:<span> <span class="MsoHyperlink"><a href="https://deepmind.com/research/publications/recurrent-models-visual-attention/" target="_blank">https://deepmind.com/research/publications/recurrent-models-visual-attention/</a>.</span></span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Forward propagation</h1>
                </header>
            
            <article>
                
<p>So, how does information actually flow through this-here RNN architecture? Let's use a demonstrative example to introduce the forward pass operations in RNNs. Imagine the simple task of predicting the next word in a phrase. Suppose our phrase is: <em>to be or not to be</em>. As the words enter the network, we can break down the computations that are performed at each time step into two conceptual categories. In the following diagram, you can visualize each arrow as performing a computation (or dot product operation) on a given set of values:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/ecf33ff7-1e17-4e70-b5cd-a5c3983031d3.png" style="width:50.42em;height:16.33em;" width="1126" height="365"/></div>
<p>We can see that, in a recurrent cell, computations occur both vertically and horizontally as data propagates through it. It is important to remember that all parameters (or weight matrices) of the layer are temporally shared, meaning that the same parameters are used for computations at every time step. At the first time step, our layer will use these sets of parameters to compute two output values. One of these is the layer's activation value at the current time step, whereas the other represents the predicted value at the current time step. Let's start with the first one.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Computing activations per time step</h1>
                </header>
            
            <article>
                
<p><span>The following equation denotes the activation of a recurrent layer at time, <em>t</em>. The term <em>g</em> denotes the non-linear activation function that's chosen for the recurrent layer, which is conventionally a tanh function. Inside the brackets, we find two matrix-level multiplications being performed and then being added up along with a bias term</span> (<span><em>ba</em></span>):</p>
<p class="CDPAlignCenter CDPAlign"><em>at = g [ (W<sup>ax</sup> x x<sup>t</sup> ) + (Waa x a(t-1)) + ba ]</em></p>
<p>The term (<em>W<sup>ax</sup></em>) governs the transformation of our input vector, <span><img src="Images/ebdcf4e7-33d9-4f4e-b3f1-6e2a1b117f3d.png" style="width:0.50em;height:1.17em;" width="11" height="26"/>,</span> at time, <em>t</em>, as it enters the recurrent layer. This matrix of weights is temporally shared, meaning that we use the same weight matrix at each time step. Then, we get to the term (<em>Waa</em>), which refers to the temporally shared weight matrix governing the activations from the previous time step. At the first time step, (<em>Waa</em>) is randomly initialized with very small values (or zeros), since we don't actually have any activation weights to compute with just yet. The same holds for the value (<em>a<span class="MsoFootnoteReference">&lt;0&gt;</span></em>), which is also initialized as a zeroed vector. Hence, at time step one, we our equation will look something like this:</p>
<p class="CDPAlignCenter CDPAlign"><em><span class="ItalicsPACKT">a1 = tanH [ (W<sup>ax</sup></span> <span><span class="ItalicsPACKT">x</span></span> x<span><span class="ItalicsPACKT">1 ) + (Waa x a(0)) + ba ]</span></span></em></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Simplifying the activation equation</h1>
                </header>
            
            <article>
                
<p>We can further simplify this equation by stacking the two weight matrices (<span class="ItalicsPACKT">W</span>ax <span class="ItalicsPACKT">and W</span>aa<span class="ItalicsPACKT">)</span> horizontally into a single matrix (W<sub>a</sub>) that defines all of the weights (or the state) of a recurrent layer. We will also vertically stack the two vectors representing the activations from the previous time step (<em>a<span class="MsoFootnoteReference">(t-1)</span></em>) and the input at the current time ( <span><img src="Images/d3b3e016-18de-4d98-be08-c5d9a8826797.png" style="width:0.50em;height:1.25em;" width="11" height="26"/> </span><span class="MsoFootnoteReference">t</span> ) to form a new matrix that we denote as <em>[a<span class="MsoFootnoteReference">(t-1)</span>, <span><img src="Images/45557d34-7a42-4cc5-b4ea-eb504c46f4eb.png" style="width:0.50em;height:1.25em;" width="11" height="26"/></span> <span class="MsoFootnoteReference">t</span> ]</em> . This lets us simplify our previous activation, as follows:</p>
<p style="padding-left: 60px"><em><span class="ItalicsPACKT">at = tanH [ (W</span><span><img src="Images/e76fecd2-fe5a-4716-a1da-048104147a2e.png" width="14" height="20"/></span> <span><span class="ItalicsPACKT">x</span></span> <span><img src="Images/b7d3a7c5-8985-4076-9db2-0ab3f5c850ca.png" width="8" height="20"/></span> <span><span class="ItalicsPACKT">t ) + (Waa x a(t-1)) + ba ] </span></span><span>or <span class="ItalicsPACKT">at = tanH (W</span></span><span><img src="Images/5f597f64-f660-4896-be74-16289a777546.png" width="17" height="20"/></span><span><span class="ItalicsPACKT">a(t-1)</span></span><span class="ItalicsPACKT">,</span> <span><img src="Images/71373feb-6c48-4dcb-9caa-3bd3750e0dd8.png" width="8" height="20"/></span> <span><span class="ItalicsPACKT">t ] + ba )</span></span></em></p>
<p><span>Conceptually, since the height of the two matrices (W</span><span><img src="Images/7ee6ef33-8386-4d3a-a8eb-31f499fa003f.png" style="width:3.67em;height:1.42em;" width="60" height="23"/></span>) remains constant, we are able to stack them horizontally in the manner we did. The same goes for the length of the input (<span><img src="Images/22c27f03-9e5f-401d-80ba-870c948b2871.png" style="width:0.58em;height:1.42em;" width="12" height="29"/> </span><span class="MsoFootnoteReference">t</span>) and activation vector (<em>a<span class="MsoFootnoteReference">(t-1)</span></em>), which also remains constant as data propagates through an RNN. Now, the computation step can be denoted as the weight matrix <span>(W<sub>a</sub></span>) is multiplied both with the activation from the previous time step, as well as with the input from the current time step, after which a bias term is added and the whole term is passed through a non-linear activation function. We can visualize this process unfolding through time with the new weight matrix, as shown in the following diagram:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/3e5e7f94-b73d-42bb-9ed6-7a9c089fb868.png" width="602" height="227"/></div>
<p>In essence, the use of the temporally shared weight parameters (such as <em>Wa</em> <span>and <em>Wya</em>) allows us to leverage information from earlier on in the sequence to inform predictions at later time- teps. Now, you know how activations are iteratively computed for each time step as data flows through a recurrent layer.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Predicting an output per time step</h1>
                </header>
            
            <article>
                
<p>Next, we will look at the equation that leverages the activation value that we just calculated to produce a prediction (<span><img src="Images/94bdb4d8-346d-4392-8547-4550156203ea.png" width="16" height="23"/></span> at the given time step (<em>t</em>). This is represented like so:</p>
<p style="padding-left: 210px"><em><span><img src="Images/c2da3b60-fd3d-41a0-b36f-2deb2800f3f5.png" width="12" height="21"/></span> <span class="ItalicsPACKT">= g</span> <span class="ItalicsPACKT">[ (Way</span> <span class="ItalicsPACKT">x</span> <span class="ItalicsPACKT">at</span><span class="ItalicsPACKT">) +</span> <span class="ItalicsPACKT">by</span> <span class="ItalicsPACKT">]</span></em></p>
<p><span>This tells us is that our layer's prediction at a time step is determined by computing a dot product of yet another temporally shared output matrix of weights, along with the activation output</span> (<em>a<span class="MsoFootnoteReference">t</span></em>) we just computed using the earlier equation.</p>
<p class="mce-root"/>
<p>Due to the sharing of the weight parameters, information from previous time steps is preserved and passed through the recurrent layer to inform the current prediction. For example, the prediction at time step three leverages information from the previous time steps, as shown by the green arrow here:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/020d9e3e-b7ad-4fed-b41b-db712bab664b.png" style="width:34.50em;height:15.42em;" width="459" height="206"/></div>
<p><span>To formalize these computations, we mathematically show the relation between the predicted output at the third time step with respect to the activations at previous time steps, as follows:</span></p>
<ul>
<li><em><span><img src="Images/c003db51-5aab-473c-9e57-5bea6611fa35.png" width="13" height="21"/></span> <span class="ItalicsPACKT">= sigmoid [ (Way</span> <span class="ItalicsPACKT">x</span> <span class="ItalicsPACKT">a3</span><span class="ItalicsPACKT"><em>)</em> +</span> <span class="ItalicsPACKT">by</span></em> <span class="ItalicsPACKT">]</span></li>
</ul>
<p><span>Where <em><span>a<span class="MsoFootnoteReference">(3)</span></span></em> is define by the following:</span></p>
<ul>
<li><em>a3 = <span class="ItalicsPACKT">sigmoid (W</span><span><img src="Images/49ef1f9f-c46d-4975-92fa-0cf0963c59d0.png" width="17" height="20"/></span><span><span class="ItalicsPACKT">a(2)</span></span><span class="ItalicsPACKT">,</span> <span><img src="Images/da73e7b9-513b-4b84-a764-8c01ef19d543.png" width="8" height="20"/></span></em><span><span class="ItalicsPACKT"><em>3 ] + ba )</em></span></span></li>
</ul>
<p><span>Where <em>a</em></span><span><em><span class="MsoFootnoteReference">(2)</span></em></span> <span>is defined by the following:</span></p>
<ul>
<li><em>a2 =</em> <span class="ItalicsPACKT"><em>sigmoid</em></span> <span class="ItalicsPACKT"><em>(W</em></span><em><span><img src="Images/89282f8e-619a-418d-9988-d949c010a5aa.png" width="17" height="20"/></span><span><span class="ItalicsPACKT">a(1)</span></span><span class="ItalicsPACKT">,</span> <span><img src="Images/01d42088-c76b-475a-83bd-c1d6d5c4cfcf.png" width="8" height="20"/></span></em><span><span class="ItalicsPACKT"><em>2 ] + ba )</em></span></span></li>
</ul>
<p><span>Where</span> <em><span>a</span><span class="MsoFootnoteReference">(1)</span></em> <span>is defined by the following:</span></p>
<ul>
<li><em>a1 = <span class="ItalicsPACKT">sigmoid (W</span><span><img src="Images/3eca3c48-eacc-4485-8d76-da83a1a9fc8c.png" width="17" height="20"/></span><span><span class="ItalicsPACKT">a(0)</span></span><span class="ItalicsPACKT">,</span> <span><img src="Images/23fc8ac4-b910-41d8-a11e-7dffeba43a8c.png" width="8" height="20"/></span></em><span><span class="ItalicsPACKT"><em>1 ] + ba )</em></span></span></li>
</ul>
<p>Finally, <em>a<span class="MsoFootnoteReference">(0)</span></em> is commonly initialized as a vector of zeros. The main concept to understand here is that the RNN layer recursively processes a sequence through many time steps before passing the activations forward. Now, you are completely familiar with all the equations that govern the forward propagation of information in RNNs at a high level. This method, while powerful at modeling many temporal sequences, does have its limitations.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The problem of unidirectional information flow</h1>
                </header>
            
            <article>
                
<p>A primary limitation is that we are only able to inform our prediction at current time steps with activation values from previous time steps, but not from future time steps. Why would we want to do this? Well, consider the problem of named entity recognition, where we may employ a synchronized many-to-many RNN to predict whether each word in our sentence is a named entity (such as the name of a person, a place, a product, and so on). We may run into some problems, such as the following:</p>
<ul>
<li><span><span>The Spartan</span> marched forward, despite the obstacles thrown at him.</span></li>
<li>The Spartan <span>lifestyle that these people face is unimaginable to many.</span></li>
</ul>
<p>As we can see, by looking as the first two words only, we ourselves would not be able to tell whether the word Spartan refers to a noun (and hence is a named entity) or refers to an adjective. It is only later on, when we read the rest of the sentence, that we are able to attribute the correct label on the word. Similarly, our network will not be able to accurately predict that the word Spartan in the first sentence is a named entity unless we let it leverage activation values from future time steps. Since RNNs can learn sequential grammar rules from an annotated dataset, it will be able to learn the fact that named entities are often followed by verbs (such as marched) rather than nouns (such as lifestyle), and hence will be able to accurately predict that the word <em>Spartan</em> refers to a named entity on the first sentence only. This becomes possible with a specific type of RNN known as a bi-directional RNN, which we will look at later on in this chapter. It is also noteworthy that an annotated dataset with part of speech tags (tags referring to whether a word is a noun, adjective, and so on) will greatly increase your network's ability to learn useful sequential representations, like we want it to do here. We can visualize the first part of both our sentences, annotated with part of speech tags, as follows:</p>
<ul>
<li class="packt_figure"><span><span>The Spartan</span> marched...</span>à:</li>
</ul>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/081b15e7-8f55-49de-a32e-235c6cfc7ff0.png" style="width:30.58em;height:11.08em;" width="383" height="139"/></div>
<ul>
<li class="packt_figure"><span><span>The Spartan</span> lifestyle...</span> à:</li>
</ul>
<div class="packt_figure CDPAlignCenter CDPAlign"> <img src="Images/3b55564c-c0b7-40bf-af27-76eb9b8b0bf4.png" width="419" height="204"/></div>
<p>The sequences of words that precede this provide us with more information on the current word than the words that come before it. We will soon see how bi-directional RNNs may leverage information from future time steps as well as past time steps to compute predictions at the present time.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The problems of long-term dependencies</h1>
                </header>
            
            <article>
                
<p>Another common problem we face with simple recurrent layers is their weakness in modeling long-term sequence dependencies. To clarify what we mean by this, consider the following examples, which we feed to an RNN word by word to predict the next words to come:</p>
<ul>
<li><span>The monkey had enjoyed eating bananas for a while and was eager to have more,</span></li>
<li>The <span>monkey</span><span>s had enjoyed eating bananas for a while and were eager to have more.</span></li>
</ul>
<p><span>To predict the word at the 11<sup>th</sup> time step each sequence, the network must remember whether the subject of the sentence (monkey), seen at time-step 2, is a singular or plural entity. However, as the model trains and the errors are backpropagated through time, the weights for the time steps that are closer to the current time step are affected to a larger extent than the weights of earlier time steps. Mathematically speaking, this is the problem of vanishing gradients, which is associated with extremely small values of the chain rule-based partial derivatives of our loss function. The weights in our recurrent layer, which are normally updated in proportion to these partial derivatives at each time step, are not <em>nudged</em> enough in the right direction, prohibiting our network to learn any further. In this manner, the model is unable to update the layer weights to reflect long-term grammatical dependencies from earlier time steps, like the one reflected in our example. This is an especially cumbersome problem, since it significantly affects the backpropagation of errors in recurrent layers. Soon, we will see how to partially address this problem with more complex architectures such as the GRU and the LSTM networks. First, let's understand the process of backpropagation in RNNs, which gives birth to this problem.</span></p>
<p><span>You may well have wondered how exactly an RNN backpropagates its errors to adjust the temporarily shared weights of the layer as it goes over a sequence of inputs. This process is even described by an interesting name. Unlike other neural networks we have come across, RNNS are known to perform backpropagation through time.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Backpropagation through time</h1>
                </header>
            
            <article>
                
<p>Essentially, we are backpropagating our errors through several time steps, reflecting the length of a sequence. As we know, the first thing we need to have to be able to backpropagate our errors is a loss function. We can use any variation of the cross-entropy loss, depending on whether we are performing a binary task per sequence (that is, entity or not, per word à binary cross-entropy) or a categorical one (<span>that is,</span> the next word out of the category of words in our vocabulary à categorical cross entropy). The loss function here computes the cross-entropy loss between a predicted output <span><img src="Images/6ebd4a7c-8d96-4cd2-9c2d-2fb746fb420d.png" style="width:1.50em;height:1.42em;" width="25" height="24"/></span> and actual value <em>(y)</em>, at time step, <em>t</em>:</p>
<p style="padding-left: 120px"><em><span><img src="Images/46ec09e1-ff3f-49fc-a4e7-4d2cab07b46a.png" width="35" height="20"/></span><span><span class="ItalicsPACKT">(</span></span> <span><img src="Images/aa137547-d065-4e5f-946c-fcb135fc277b.png" width="94" height="20"/></span> <span><img src="Images/59cd5142-6f5b-4cb8-b930-f2cb8c7b63ae.png" width="10" height="20"/></span> <span class="ItalicsPACKT">log</span> <span><img src="Images/0f3b1dbe-0f85-4cfb-abdf-c011330710ed.png" width="40" height="20"/></span> <span class="ItalicsPACKT">- [ (1-</span><span><img src="Images/15d6e47b-8878-42b1-b060-0af7fabf429c.png" width="122" height="20"/></span></em></p>
<p>This function essentially lets us perform an element-wise loss computation of each predicted and actual output, at each time step for our recurrent layer. Hence, we generate a loss value at each prediction the network makes, for each word (or sequence) it sees. We can then sum up each individual loss value to define the overall loss of our recurrent layer, operating over <em>ty</em> number of time steps. Hence, the overall loss of our network can be denoted as follows:</p>
<p style="padding-left: 180px"><span><img src="Images/eae7767c-e6d4-4719-94ee-5b37bb3d6eee.png" width="181" height="50"/></span></p>
<p>Using this denotation of the overall loss of our network, we can differentiate it with respect to the layer weights at each time step to compute the model's errors. We can visualize this process by referring back to our recurrent layer diagram. The arrows demarcate the backpropagation of errors through time.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Visualizing backpropagation through time</h1>
                </header>
            
            <article>
                
<p><span>Here, we backpropagate the errors in our model with respect to the layer weights at each time step and adjust the weight matrices, <em>Way</em> and <em>Wa</em></span>, <span>as the model trains. We are still essentially computing the gradient of the loss function with respect to all of the network parameters, and proportionally nudging both the weight matrices in the opposite direction for each time step in our sequence:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/ca8eeab8-a691-4bd8-baa3-eb46419af982.png" width="928" height="291"/></div>
<p>Now, we know how RNNs overate over a sequence of vectors and leverage time-dependent contingencies to inform predictions at each step.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Exploding and vanishing gradients</h1>
                </header>
            
            <article>
                
<p>Backpropagating the model's errors in a deep neural network, however, comes with its own complexities. This holds equally true for RNNs, facing their own versions of the vanishing and exploding gradient problem. As we discussed earlier, the activation of neurons in a given time step is dependent on the following equation:</p>
<p style="padding-left: 150px"><em><span class="ItalicsPACKT">at = tanH [ (W</span><span><img src="Images/49479bca-1721-40de-9026-bc9268c48c87.png" width="14" height="20"/></span> <span><span class="ItalicsPACKT">x</span></span> <span><img src="Images/3175fbaa-c555-4dde-8aa9-6641b48527ea.png" width="8" height="20"/></span> <span><span class="ItalicsPACKT">t ) + (Waa x a(t-1)) + ba ]</span></span></em></p>
<p>We saw how <em><span>Wax</span></em> and <em>Waa</em> are two separate weight matrices that the RNN layers share through time. These matrices are multiplied to the input matrix at current time, and the activation from the previous time step, respectively. The dot products are then summed up, along with a bias term, and passed through a tanh activation function to compute the activation of neurons at current time (<em>t</em>). We then used this activation matrix to compute the predicted output at current time (<span><img src="Images/0d6d9ba5-a6ca-4868-b7fc-5db15a607871.png" style="width:0.83em;height:1.42em;" width="15" height="25"/></span>), before passing the activation forward to the next time step:</p>
<p style="padding-left: 150px"><em><span><img src="Images/fcfd4173-60dc-4147-ad63-3e8ba6eaf87c.png" width="12" height="21"/></span> <span class="ItalicsPACKT">= softmax [ (Way</span> <span class="ItalicsPACKT">x</span> <span class="ItalicsPACKT">at</span><span class="ItalicsPACKT">) +</span> <span class="ItalicsPACKT">by</span> <span class="ItalicsPACKT">]</span></em></p>
<p>Hence, the weight matrices (<em>Wax</em>, <em>Waa</em>, and <em>Way</em>) represent the trainable parameters of a given layer. During backpropagation through time, we first compute the product of gradients, which represent the changes in the layer weights of each time step with respect to the changes in the predicted and actual output. Then, we use these products to update the respective layer weights in the opposite direction of the change. However, when backpropagating across multiple time steps, these products may become infinitesimally small (hence not shifting the layer weights significantly), or gargantuanly big (hence overshooting from ideal weights). This is mainly true for the activation matrix (<em>Waa</em>). It represents the memory of our RNN layer since it encodes time-dependent information from previous time steps. Let's clarify this notion with a conceptual example to see how updating the activation matrix at earlier time steps becomes increasingly hard when dealing with long sequences. Suppose you wanted to calculate the gradient of your loss at time step three with respect to your layer weights, for example.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Thinking on the gradient level</h1>
                </header>
            
            <article>
                
<p>The activation matrix at a given time step is a function of the activation matrix from the previous time step. Hence, we are forced to recursively define the loss at time step three as a product of the sub-gradients of layer weights from previous time steps:</p>
<p class="CDPAlignCenter CDPAlign"><span class="ItalicsPACKT"><img src="Images/3fa444c5-b97f-42f8-ae0d-3746cb3a7c0e.png" style="width:29.75em;height:14.92em;" width="488" height="245"/></span></p>
<p><span>Here, (<em>L</em>) represents the loss, (<em>W</em>) represents the weight matrices of a time step, and the <em>x</em> values are the inputs at a given time steps. Mathematically, this is equivalent to the following:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/90b4c49d-fe88-4e31-841d-4879da3ea31b.png" style="width:21.08em;height:11.00em;" width="542" height="282"/></div>
<p>The derivatives of these functions are stored in a Jacobean matrix, representing point-wise derivations of the weight and loss vectors. Mathematically, the derivatives of these functions are bound by an absolute value of 1. However, small derivative values (close to 0), over several time-steps of matrix-wise multiplications, degrade exponentially, almost vanishing, which in turn prohibits the model from converging. The same holds true for large values (larger than 1) in the activation matrix, where the gradients will become increasingly large until they are attributed a NaN value (not a number), abruptly terminating the training process. How can we address these problems?</p>
<div class="packt_infobox">You can find more information on vanishing gradients at: <span class="MsoHyperlink"><span><a href="http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/" target="_blank">http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/</a>.</span></span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Preventing exploding gradients through clipping</h1>
                </header>
            
            <article>
                
<p><span>In the case of exploding gradients, the problem is much more evident. Your model simply stops training, returning a value error of NaN, corresponding to the exploded gradient values. A simple solution to this is to clip your gradients by defining an arbitrary upper bound or threshold value to prevent the gradients from getting too big. Keras lets us implement this with ease as you can define this threshold by manually initiating an optimizer and passing it a <kbd>clipvalue</kbd> or <kbd>clipnorm</kbd> argument, as shown here:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/43b2da26-4987-453f-a13e-2fe6ee04da70.png" width="708" height="301"/></div>
<p>You can then pass the <kbd>optimizers</kbd> variable to your model when compiling it. This idea of clipping gradients is extensively discussed, along with other problems that are associated with training RNNs, in the paper titled: <em>On the difficulty of training recurrent neural networks</em><span>, which is available at </span><span class="MsoHyperlink"><a href="http://proceedings.mlr.press/v28/pascanu13.pdf" target="_blank">http://proceedings.mlr.press/v28/pascanu13.pdf</a>.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Preventing vanishing gradients with memory</h1>
                </header>
            
            <article>
                
<p>In the case of vanishing gradients, our network stops learning anything new as the weights are insignificantly nudged at each update. The problem is particularly cumbersome for the case of RNNs, as they attempt to model long sequences over potentially many time steps, and so the model has a very hard time backpropagating the errors to nudge the layer weights of earlier time steps. We saw how this can affect language modeling tasks such as learning grammar rules and entity-based dependencies (with the monkey example). Thankfully, several solutions have been devised to address this problem. Some have ventured along the lines of careful initialization of the activation matrix, <em>Waa</em>, using a ReLU activation function to pre-train the layer weights in an unsupervised manner. More commonly, however, others have addressed this problem by designing more sophisticated architectures that are capable of storing long-term information based on its statistical relevance to current events in the sequence. This is essentially the base intuition behind more complex RNN variations such as the <strong>Gated Recurrent Units</strong> (<strong>GRUs</strong>) and <strong>Long Short-Term Memory</strong> (<strong>LSTM</strong>) networks. Let's see how GRUs address the problem of long-term dependencies.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">GRUs</h1>
                </header>
            
            <article>
                
<p>The GRU can be considered the younger sibling of the LSTM, which we will look at <a href="62bc2e63-11f3-43ab-a3ae-967c6603c306.xhtml" target="_blank">Chapter 6</a>, <em>Long-Short Term Memory Networks</em>. In essence, both leverage similar concepts to modeling long-term dependencies, such as remembering whether the subject of the sentence is plural, when generating following sequences. Soon, we will see how memory cells and flow gates can be used to address the vanishing gradient problem, while better modeling long term dependencies in sequence data. The underlying difference between GRUs and LSTMs is in the computational complexity they represent. Simply put, LSTMs are more complex architectures that, while computationally expensive and time-consuming to train, perform very well at breaking down the training data into meaningful and generalizable representations. GRUs, on the other hand, while computationally less intensive, are limited in their representational abilities compared to LSTM. However, not all tasks require heavyset 10-layer LSTMs (like the ones used by Siri, Cortana, Alexia, and so on). As we will soon see, character-level language modeling can be achieved with quite simple architectures to begin with, producing increasingly interesting results with relatively lightweight models such as GRUs. The following diagram shows the basic architectural difference between the SimpleRNN we have been discussing so far and the GRU.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The memory cell</h1>
                </header>
            
            <article>
                
<p>Again, we have two input values entering the unit, namely the sequence input at the current time and the layer activations from the preceding time step. One of the main differences in the GRU is the addition of a memory cell (<em>c</em>), which lets us store some relevant information at a given time step to inform later predictions. In practice, this changes how we calculate the activations at a given time step (<em>c<sup><span class="MsoFootnoteReference">t</span></sup></em>, which here is the same as <em>a<sup><span class="MsoFootnoteReference">t</span></sup></em>) in GRUs:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/5d45b808-83ca-40ac-ba99-bb81fc3b79b4.png" style="width:45.17em;height:16.75em;" width="1363" height="503"/></div>
<p><span>Going back to the monkey example, a word-level GRU model has the potential to better represent the fact that there are several entities in the second sentence that's given here, and hence will remember to use the word</span> <strong>were</strong> <span>instead of <strong>was</strong> to complete the sequence:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><span class="ItalicsPACKT"><img src="Images/3adae2d4-7633-4586-9ad5-15cc5dd89532.png" style="width:38.50em;height:10.42em;" width="863" height="232"/></span></div>
<p>How does this memory cell actually work? Well, the value of (<em>c<sup><span class="MsoFootnoteReference">t</span></sup></em>) stores the activation values (<em>a<sup><span class="MsoFootnoteReference">t</span></sup></em>) at a given time step (time step 2) and is passed forward to subsequent time steps if deemed relevant to the sequence at hand. Once the relevance of this activation is lost (that is, a new dependency has been detected in the sequence), the memory cell can be updated with a new value of (<em>c<sup><span class="MsoFootnoteReference">t</span></sup></em>), reflecting time-dependent information that may be more relevant:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/a4f4ffc2-9b3f-44df-ab6c-1fe7306206bf.png" style="width:26.42em;height:18.50em;" width="932" height="651"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">A closer look at the GRU cell</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Representing the memory cell</h1>
                </header>
            
            <article>
                
<p>When processing our example sentences, a word-level RNN model may store the activations at time step 2 (for the words <em>monkey</em> and <em>monkeys</em>), and save it until time step 11, where it is used to predict the output words <em>was</em> and <em>were</em>, respectively. At each time step, a contender value (<em>c <sup>̴<span class="MsoFootnoteReference">t</span></sup></em>) is generated, which attempts to replace the value of the memory cell, (<em>c<sup><span class="MsoFootnoteReference">t</span></sup></em>). However, as long as (<em>c<sup><span class="MsoFootnoteReference">t</span></sup></em>) remains statistically relevant to the sequence, it is conserved, only to be discarded later on for more relevant representation. Let's see how this is mathematically implemented, starting with the contender value, (<em>c <sup>̴<span class="MsoFootnoteReference">t</span></sup></em>). To implement this parameter, we will initialize a new weight matrix, (<em>Wc</em>). Then, we will compute the dot product of (<em>Wc</em>) with the previous activation (<em>c<sup><span class="MsoFootnoteReference">t-1</span></sup></em>) and the input at the current time (<span><img src="Images/005b1e37-203a-4ae1-b717-95d0ed56f958.png" style="width:0.67em;height:1.58em;" width="8" height="20"/></span> <span class="MsoFootnoteReference">t</span>) and pass the resulting vector through a non-linear activation function such as tanh. This operation is strikingly similar to the standard forward propagation operation we saw previously.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Updating the memory value</h1>
                </header>
            
            <article>
                
<p>Mathematically, we can represent this computation as follows:</p>
<p style="padding-left: 180px"><em>c <sup>̴<span class="MsoFootnoteReference">t</span></sup> = tanh ( Wc [ c<sup><span class="MsoFootnoteReference">t-1</span></sup>, <span><img src="Images/d30f337b-9a65-4151-82d8-203b210d2aee.png" width="9" height="23"/></span> <span class="MsoFootnoteReference">t</span> ] + bc)</em></p>
<p>More importantly, the GRU also implements a gate denoted by the Greek alphabet gamma (Γu ), which basically computes a dot product of inputs and previous activations through yet another non-linear function:</p>
<p style="padding-left: 180px"><em>Γu = sigmoid ( Wu [ c<sup><span class="MsoFootnoteReference">t-1</span></sup>, <span><img src="Images/8d63a839-9c80-49b7-80cf-5789501a6bb9.png" width="9" height="23"/></span> <span class="MsoFootnoteReference">t</span> ] + bu)</em></p>
<p>The purpose of this gate is to determine whether we should update our current value (<em>c<sup><span class="MsoFootnoteReference">t</span></sup></em>) with a candidate value (<em>c <sup>̴<span class="MsoFootnoteReference">t</span></sup></em>). The value of the gate (Γu) can be thought of as a binary value. In practice, we know that the sigmoid activation function is known for squishing values between zero and one. In fact, the vast majority of input values entering a sigmoid activation function will come out as either zero or one, hence it is practical to think of the gamma variable as a binary value that decides whether to replace (<em>c<sup><span class="MsoFootnoteReference">t</span></sup></em>) with (<em>c <sup>̴<span class="MsoFootnoteReference">t</span></sup></em>) or not at every time step:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/68fa8246-5c30-4b86-ab85-939a6ff30292.png" style="width:34.33em;height:18.67em;" width="604" height="328"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Mathematics of the update equation</h1>
                </header>
            
            <article>
                
<p>Let's see how this would work out in practice. We will use our earlier example once more, which has been extended here to theoretically demonstrate when a world-level GRU model may work:</p>
<p><em>The monkey had enjoyed eating bananas for a while and was <span>eager to have more. The bananas themselves were the best one could find on this side of the island...</span></em></p>
<p>As a GRU layer goes over this sequence, it may store the activation values at the second time step as (c<sup><span class="MsoFootnoteReference">t</span></sup>), detecting the presence of a singular entity (that is, <em>monkey</em>). It will carry forward this representation until it reaches a new concept in the sequence (<em>The bananas</em>), at which point the update gate (Γu) will allow the new candidate activation value (c ̴<span class="MsoFootnoteReference">t</span>) to replace the old value in the memory cell (c), reflecting the new plural entity, <em>bananas</em>. Mathematically, we can tie all of this up by defining how the activation value (c<span class="MsoFootnoteReference">t</span>) is calculated in a GRU:</p>
<p style="padding-left: 180px"><em>c<span class="MsoFootnoteReference">t</span> = ( Γu x c ̴<span class="MsoFootnoteReference">t</span> <span>) + [</span> ( 1- Γu ) x c<span class="MsoFootnoteReference">t-1</span> ]</em></p>
<p>As we can see here, the activation values at a given time step are defined by a sum of two terms. The first term reflects the product of the gate value and the candidate value. The second term denotes the inverse of the gate value, multiplied by the activation from the previous time step. Intuitively, the first term simply controls whether to let the update term be included in the equation by being either one or zero. The second term controls the potential neutralization of the activation of the previous time step (c<span class="MsoFootnoteReference">t-1</span>). Let's have a look at how these two terms work together to decide whether or not an update is performed at a given time step.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Implementing the no-update scenario</h1>
                </header>
            
            <article>
                
<p>In the case where the value (Γu) is zero, the first term reduces to zero altogether, removing the effect of (c ̴<span class="MsoFootnoteReference">t</span>), while the second term simply takes the activation value from the previous time step:</p>
<pre>If Γu = 0:<br/>c<span class="MsoFootnoteReference">t</span> = ( 0 x c ̴<span class="MsoFootnoteReference">t</span> ) + ((1 - 0) x c<span class="MsoFootnoteReference">t-1</span> )<br/>   = 0 + c<span class="MsoFootnoteReference">t-1<br/></span>Therefore, c<span class="MsoFootnoteReference">t</span> = c<span class="MsoFootnoteReference">t-1</span></pre>
<p>In this scenario, no update is performed, and the previous activations (<kbd>c<span class="MsoFootnoteReference">t</span></kbd>) are preserved and passed forward to the next time step.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Implementing the update scenario</h1>
                </header>
            
            <article>
                
<p>On the other hand, if the gate holds a <kbd>1</kbd>, the equation allows c ̴<span class="MsoFootnoteReference">t</span> to become the new value of <kbd>c<span class="MsoFootnoteReference">t</span></kbd>, since the second term reduces to zero <kbd>(( 1-1) x c<span class="MsoFootnoteReference">t-1</span>)</kbd>. This is what allows us to effectively perform an update to our memory cell, hence conserving useful time-dependent representations. The update scenario can be denoted mathematically like so:</p>
<pre>If Γu = 1:<br/>c<span class="MsoFootnoteReference">t</span> = ( 1 x c ̴<span class="MsoFootnoteReference">t</span> ) + ((1 - 1) x c<span class="MsoFootnoteReference">t-1</span> )<br/>   = c ̴<span class="MsoFootnoteReference">t</span>+ (0 x c<span class="MsoFootnoteReference">t-1</span>)<br/>Therefore, c<span class="MsoFootnoteReference">t</span> = c ̴<span class="MsoFootnoteReference">t</span></pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Preserving relevance between time steps</h1>
                </header>
            
            <article>
                
<p>The nature of the two terms that are used to perform our memory update helps us to preserve relevant information across multiple time steps. Hence, this implementation potentially provides a solution to the vanishing gradient issue by modeling long-term dependencies with the use of a memory cell. You may wonder, however, how exactly does the GRU assess the relevance of an activation? The update gate simply allows the replacement of the activation vector (<em>c<sup><span class="MsoFootnoteReference">t</span></sup></em>) with the new candidate (<em>c <sup>̴<span class="MsoFootnoteReference">t</span></sup></em>), but how do we know how relevant the previous activation (<em>c<sup><span class="MsoFootnoteReference">t-1</span></sup></em>) is to the current time step? Well, earlier, we presented a simplified equation for governing the GRU unit. A last addition to its implementation is the relevance gate (Γr), which helps us to do exactly what it suggests. Hence, we calculate the candidate value (<em>c <sup>̴<span class="MsoFootnoteReference">t</span></sup></em>) using this relevance gate (Γr) to incorporate the relevance of activation values from the previous time step (<em>c</em><sup><em><span class="MsoFootnoteReference"><em>t</em>-1</span></em></sup>) to the current one (<em>c<sup><span class="MsoFootnoteReference">t</span></sup></em>). This helps us to assess how relevant the activations from the previous time steps are to the current input sequence at hand and is implemented in a very familiar way, as shown in the following diagram:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/88c3f787-2091-4af8-8fb0-f1baebc84124.png" style="width:28.83em;height:14.67em;" width="598" height="305"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Formalizing the relevance gate</h1>
                </header>
            
            <article>
                
<p>The following equations show the full spectrum of the GRU equations, including the relevance gate term, which is now included in the computation we performed earlier to get the contender memory value, (c ̴<span class="MsoFootnoteReference">t</span> ):</p>
<ul>
<li><strong>Earlier</strong>: <em>c ̴t = tanh ( Wc [ ct-1, <span><img src="Images/1666159b-52ff-45a0-a1d6-2ed0792818e5.png" width="8" height="20"/></span> t ] + bc)</em></li>
<li><strong>Now</strong>: <em>c ̴t = tanh ( Wc [ Γr , ct-1, <span><img src="Images/8a195fb9-f845-4c0c-b258-dbe27c76fcac.png" width="8" height="20"/></span> t ] + bc)</em></li>
<li><strong>Where</strong>: <em>Γr = sigmoid ( Wr [ ct-1, <span><img src="Images/8b555231-db98-4e95-926a-b4ed29399edf.png" width="8" height="20"/></span> t ] + br)</em></li>
</ul>
<p>Not surprisingly, (Γr) is computed by initializing yet another weight matrix (<em>Wr</em>) and computing its dot product with past activations (<em>c<sup><span class="MsoFootnoteReference">t-1</span></sup></em>) and current inputs (<span><img src="Images/288f2225-c922-4231-9fb6-8a3474d237fa.png" style="width:0.67em;height:1.58em;" width="11" height="26"/></span> <span class="MsoFootnoteReference">t</span>) before summing them through a sigmoid activation function. The equation that's computing the current activation (<em>c<sup><span class="MsoFootnoteReference">t</span></sup></em>) remains the same, except for the (<em>c <sup>̴<span class="MsoFootnoteReference">t</span></sup></em>) term within it, which is now incorporating the relevance gate (Γr) in its calculation:</p>
<p style="padding-left: 180px"><em>ct = ( Γu x c ̴t ) + [ ( 1- Γu ) x ct-1 ]</em></p>
<p>The predicted output at a given time step is calculated in the same manner as it was for the SimpleRNN layer. The only difference is that the term (<em>a<sup><span class="MsoFootnoteReference">t</span></sup></em>) is replaced by the term (<em>c<sup><span class="MsoFootnoteReference">t</span></sup></em>), which denotes the activations of neurons in a GRU layer at time step (<em>t</em>):</p>
<p style="padding-left: 180px"><em><span><img src="Images/f0e96174-8b99-4ab8-8570-59e838271286.png" width="12" height="21"/></span> = softmax [ (Wcy x ct) + by ]</em></p>
<p>Practically speaking, both terms (<em>a<sup><span class="MsoFootnoteReference">t</span></sup></em> and <em>c<sup><span class="MsoFootnoteReference">t</span></sup></em>) can be thought of as synonymous in the case of GRUs, but we will later see architectures where this no longer applies, such as in LSTMs. For the time being, we have covered the basic equations that govern the forward propagation of data in a GRU unit. You've seen how we can compute the activations and the output values at each time step and use different gates (such as the update and relevance gates) to control the flow of information, allowing us to assess and store long-term dependencies. What we saw here is a very common implementation that addresses the vanishing gradients problem. However, it is but one of potentially many more. Researchers have found this particular formulaic implementation to be a successful way to gauge relevance and model sequential dependencies for an array of different problems since their introduction in 2014 by Kyunghyun Cho et al.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Building character-level language models in Keras</h1>
                </header>
            
            <article>
                
<p>Now, we have a good command over the basic learning mechanism of different types of RNNs, both simple and complex. We also know a bit about different sequence processing use cases, as well as different RNN architectures that permit us to model these sequences. Let's combine all of this knowledge and put it to use. Next up, we will test these different models on a hands-on task and see how each of them do.</p>
<p>We will explore the simple use case of building a character level language model, much like the autocorrect model almost everybody is familiar with, which is implemented on word processor applications for almost all devices. A key difference will be that we will train our RNN to derive a language model from Shakespeare's Hamlet. Hence, our network will take a sequence of characters from Shakespeare's <em>Hamlet</em> as input and iteratively compute the probability distribution of the next character to come in the sequence. Let's make some imports and load in the necessary packages:</p>
<pre><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="k">import</span> <span class="n">gutenberg</span>

<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Bidirectional</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">SimpleRNN</span><span class="p">,</span> <span class="n">GRU</span><span class="p">,</span> <span class="n">BatchNormalization</span>

<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span> <span class="n">LambdaCallback</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span> <span class="n">ModelCheckpoint<br/></span>from keras.utils.data_utils import get_file<br/>from keras.utils.data_utils import get_file</pre>
<p class="CDPAlignCenter CDPAlign"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Loading in Shakespeare's Hamlet</h1>
                </header>
            
            <article>
                
<p>We will use the <strong>Natural Language Toolkit </strong>(<strong>NLTK</strong>) package in Python to import and preprocess the play, which can be found in the <kbd>gutenberg</kbd> corpus:</p>
<pre><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="k">import</span> <span class="n">gutenberg<br/></span><span class="n">hamlet</span> <span class="o">=</span> <span class="n">gutenberg</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">'shakespeare-hamlet.txt'</span><span class="p">)<br/></span><span class="n">text</span> <span class="o">=</span><span class="s1">''<br/></span><span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">hamlet</span><span class="p">:</span>            <span class="c1"># For each word<br/></span><span class="n">text</span><span class="o">+=</span><span class="nb">str</span><span class="p">(</span><span class="n">word</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>        <span class="c1"># Convert to lower case and add to string variable<br/></span><span class="n">text</span><span class="o">+=</span> <span class="s1">' '</span>                     <span class="c1"># Add space</span>   
<span class="nb">print</span><span class="p">(</span><span class="s1">'Corpus length, Hamlet only:'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">))<br/><br/>-----------------------------------------------------------------------<br/><strong>Output:</strong><br/><strong><span>Corpus length, Hamlet only: 166765</span></strong><br/></span></pre>
<p>The string variable (<kbd>text</kbd>) contains the entire sequence of characters that make up the play Hamlet. We will now break it up into shorter sequences that we can feed to our recurrent network at successive time steps. To forge the input sequences, we will define an arbitrary length of characters that the network sees at each time step. We will sample these characters from the text string by iteratively sliding over them and collecting sequences of characters (denoting our training features), along with the next character of the given sequence (as our training labels). Naturally, taking samples over longer sequences allows the network to compute more accurate probability distributions, hence reflecting contextual information on the character to follow. As a result, however, this is also computationally more intensive, both for training the model and to generate predictions during testing.</p>
<p><span>Each of our input sequences (<kbd>x</kbd>) will correspond to 40 characters, and one output character (<kbd>y1</kbd>) that corresponds to the next character in the sequence. We can create this data structure of 11 characters per row by using the range function to span by segments characters of our entire string (text) at a time, and saving them in a list, as shown here. We can see that we have broken up the entire play into about 55, 575 sequences of characters.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Building a dictionary of characters</h1>
                </header>
            
            <article>
                
<p>Now, we will proceed and create a vocabulary, or dictionary of characters, for mapping each character to a specific integer. This is a necessary step for us to be able to represent these integers as vectors, which we can sequentially feed into our network at each time step. We will create two versions of our dictionary: one with characters mapped to indices, and the other with indices mapped to characters.</p>
<p>This is just for the sake of practicality, as we will need both lists for reference:</p>
<p class="mce-root"/>
<div>
<pre><span class="n">characters</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">text</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Total characters:'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">))<br/></span><span class="n">char_indices</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">l</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">characters</span><span class="p">))</span>
<span class="n">indices_char</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">characters</span><span class="p">))</span>
-----------------------------------------------------------------------<br/><strong>Output:</strong><br/><strong>Total characters= 65</strong></pre></div>
<p>You can always check how large your vocabulary is by checking the length of the mapping dictionary. In our case, it appears that we have <kbd>66</kbd> unique characters that make up the sequences forming the play Hamlet.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Preparing training sequences of characters</h1>
                </header>
            
            <article>
                
<p>After constructing our dictionary of characters, we will break up the text making up Hamlet into a set of sequences that can be fed to our network, with a corresponding output character for each sequence:</p>
<pre><span class="sd">'''</span>
<span class="sd">Break text into :</span>
<span class="sd">Features  -    Character-level sequences of fixed length        </span>
<span class="sd">Labels    -    The next character in sequence     </span>
<span class="sd">'''</span>
<span class="n">training_sequences</span> <span class="o">=</span> <span class="p">[]</span>          <span class="c1"># Empty list to collect each sequence<br/> </span>
<span class="n">next_chars</span> <span class="o">=</span> <span class="p">[]</span>                  <span class="c1"># Empty list to collect next character in sequence<br/></span>
<span class="n">seq_len</span><span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">1   </span> <span class="c1"># Define lenth of each input sequence &amp; stride to move before sampling next sequence<br/></span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>     <span class="c1"># Loop over text with window of 35 characters, moving 1 stride at a time<br/></span><span class="n"><br/>training_sequences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">seq_len</span><span class="p">])</span> <span class="c1"># Append sequences to traning_sequences<br/><br/></span><span class="n">next_chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">seq_len</span><span class="p">])</span>            <span class="c1"># Append following character in sequence to next_chars</span></pre>
<p>We created two lists and looped over our text string to append a sequence of 40 characters at a time. One list holds the training sequences, while the other holds the next character to come, following the 40 characters of the sequence. We have implemented an arbitrary sequence length of 40, but you are free to experiment with it. Keep in mind that setting too small a sequence will not allow you network to look far back enough to inform predictions, whereas setting to big a sequence may give your network a hard time converging, as it won't be able to find the most efficient representations. Just like the story of Goldilocks and the three bears, you will aim for a sequence length that is <em>just right</em>, as informed by experiments and/or domain knowledge.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Printing out example sequences</h1>
                </header>
            
            <article>
                
<p>Similarly, we also arbitrarily choose to stride through our text file with a window of one character at a time. This simply means that we can potentially sample each character multiple times, just like how our convolutional filter progressively sampled an entire image by striding through it in fixed steps:</p>
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3">
<pre><span class="c1"># Print out sequences and labels to verify</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Number of sequences:'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_sequences</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'First sequences:'</span><span class="p">,</span> <span class="n">training_sequences</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Next characters in sequence:'</span><span class="p">,</span> <span class="n">next_chars</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Second sequences:'</span><span class="p">,</span> <span class="n">training_sequences</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Next characters in sequence:'</span><span class="p">,</span> <span class="n">next_chars</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">])<br/>-----------------------------------------------------------------------<br/><strong>Output<br/></strong><br/></span><strong>Number of sequences: 166730</strong><br/><strong>First sequences: ['[ the tragedie of hamlet by william']</strong><br/><strong>Next characters in sequence: [' ']</strong><br/><strong>Second sequences: [' the tragedie of hamlet by william ']</strong><br/><strong>Next characters in sequence: ['s']</strong></pre></div>
</div>
</div>
</div>
<p>The difference here is that we embed this sequentially in the training data itself, instead of letting a layer perform the striding operation while training. This is an easier (and more logical) approach with text data, which can be easily manipulated to produce the sequences of characters, at desired strides, from our entire text of Hamlet. As we can see, each of our lists now stores sequences of strings that are sampled at a stride of three steps, from the original text string. We printed out the first and second sequences and labels of our training data, which demonstrates the sequential nature of its arrangement.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Vectorizing the training data</h1>
                </header>
            
            <article>
                
<p>The next step is one that your already quite familiar with. We will simply vectorize our data by transforming our list of training sequences into a three-dimensional tensor representing one-hot encoded training features, with their corresponding labels (that is, the next word to come in the sequence). The dimensions of the feature matrix can be represented as (<em>time steps x sequence length x number of characters</em>). In our case, this amounts to 55,575 sequences, each of a length of 40. Hence, our tensor will be composed of 55,575 matrices, each with <kbd>40</kbd> vectors of <kbd>66</kbd> dimensions, stacked on top of each other. Here, each vector represents a single character, in a sequence of 40 characters. It has 66 dimensions, as we have one-hot-encoded each character as a vector of zeros, with <kbd>1</kbd> in the index position of that character from our dictionary:</p>
<pre><span class="c1">#Create a Matrix of zeros</span>
<span class="c1"># With dimensions : (training sequences, length of each sequence, total unique characters)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">training_sequences</span><span class="p">),</span> <span class="n">seq_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">training_sequences</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">training_sequences</span><span class="p">):</span>     <span class="c1">#Iterate over training sequences</span>
<span class="k">for</span> <span class="n">sub_index</span><span class="p">,</span> <span class="n">chars</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sequence</span><span class="p">):</span>          <span class="c1">#Iterate over characters per sequence</span>
<span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="n">sub_index</span><span class="p">,</span> <span class="n">char_indices</span><span class="p">[</span><span class="n">chars</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>      <span class="c1">#Update character position in feature matrix to 1</span>
<span class="n">y</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="n">char_indices</span><span class="p">[</span><span class="n">next_chars</span><span class="p">[</span><span class="n">index</span><span class="p">]]]</span> <span class="o">=</span> <span class="mi">1</span>         <span class="c1">#Update character position in label matrix to 1<br/></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Data vectorization completed.'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Feature vectors shape'</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Label vectors shape'</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)<br/><br/>-----------------------------------------------------------------------<br/><strong><span>Data vectorization completed. <br/>Feature vectors shape (166730, 35, 43) <br/>Label vectors shape (166730, 43)</span></strong><br/></span></pre>
<div class="packt_figure CDPAlignCenter CDPAlign"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Statistics of character modeling</h1>
                </header>
            
            <article>
                
<p>We often distinguish words and numbers as being in different realms. As it happens, they are not so far apart. Everything can be deconstructed using the universal language of mathematics. This is quite a fortunate property of our reality, not just for the pleasure of modeling statistical distributions over sequences of characters. However, since we are on the topic, we will go ahead and define the concept of language models. In essence, language models follow Bayesian logic that relates the probability of posterior events (or tokens to come) as a function of prior occurrences (tokens that came). With such an assumption, we are able to construct a feature space corresponding to the statistical distribution of words over a period of time. The RNNs we will build shortly will each construct a unique feature space of probability distributions. Then, we are able to feed it a sequence of characters and recursively generate the next character to come using the distribution schemes.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Modeling character-level probabilities</h1>
                </header>
            
            <article>
                
<p>In <strong>natural language processing</strong> (<strong>NLP</strong>), the unit of a string is denoted as a token. Depending on how you wish to preprocess your string data, you can have word tokens or character tokens. We will be working with character tokens for the purpose of this example, as our training data is set up to make our network predict a single character at a time. Hence, given a sequence of characters, our network will output a Softmax probability score for each of the characters in our vocabulary of characters. In our case, we initially had 66 total characters in Shakespeare's Hamlet. These included uppercase and lowercase letters, which are quite redundant for the task at hand. Hence, to increase our efficiency and keep track of less Softmax scores, we will reduce our training vocabulary by converting the Hamlet text into lowercase, leaving us with 44 characters. This means that, at each network prediction, it will generate a 44-way Softmax output. We can take the character with the maximum score (that is, do some greedy sampling) and add it to the input sequence, then ask our network what it thinks should come next. RNNs are able to learn the general structure of words in the English language, as well as punctuation and grammar rules, and even have a flair for inventing novel sequences, ranging from cool sounding names to possibly life-saving molecular compounds, depending on what sequence you decide to feed it. In fact, RNNs have been shown to capture the syntax of molecular representations and can be fine-tuned to generate specific molecular targets. This helps researchers considerably in tasks such as drug discovery and is a vivid area of scientific research. <span>For further reading, check out the following link:</span></p>
<p><span><span class="MsoHyperlink"><a href="https://www.ncbi.nlm.nih.gov/pubmed/29095571" target="_blank">https://www.ncbi.nlm.nih.gov/pubmed/29095571</a></span></span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Sampling thresholds</h1>
                </header>
            
            <article>
                
<p>To be able to generate sequences of Shakespeare-like sentences, we need to devise a mannerism to sample our probability distributions. These probability distributions are represented by our model's weights and continuously change at successive time steps during the training process. Sampling these distributions is akin to peeking into the network's idea of Shakespearean text at the end of each training epoch. We are essentially using the probability distributions that have been learned by our model to generate a sequence of characters. Moreover, depending on the sampling strategy we choose, we could potentially introduce some controlled randomness in our generated text to force our model to come up with some novel sequences. This can result in interesting formulations and is quite entertaining in practice.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The purpose of controlling stochasticity</h1>
                </header>
            
            <article>
                
<p>The main concept behind sampling is how you choose control stochasticity (or randomness) in selecting the next character from the probability distributions for possible characters to come. Various applications may ask for different approaches.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Greedy sampling</h1>
                </header>
            
            <article>
                
<p>If you are trying to train an RNN for automatic text completion and correction, you will probably be better off going with a greedy sampling strategy. This simply means that, at each sampling step, you will choose the next character in the sequence based on the character that was attributed the highest probability distribution by our Softmax output. This ensures that your network will output predictions that likely correspond to words you most commonly use. On the other hand, you may want to try a more stratified approach when training an RNN to generate cool names, handwriting in a particular person's style, or even producing undiscovered molecular compounds. In this case, you wouldn't want to choose the most likely characters to come, as this is simply boring. We can instead introduce some controlled randomness (or stochasticity) by picking out the next character in a probabilistic manner, rather than a fixed one.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Stochastic sampling</h1>
                </header>
            
            <article>
                
<p><span>One approach could be, instead of simply choosing the next character based on the Softmax output values, to reweight the probability distribution of these output values at a given time step. This lets us do things such as assign a proportional probability score for any of the characters of our vocabulary to be chosen next. As an example, suppose a given character has an assigned probability of 0.25 to be the next character in the sequence. We will then choose it one out of four times as the next character. In this manner, we are able to systematically introduce a little randomness, which gives rise to creative and realistic, albeit artificial words and sequences. Playing around by introducing randomness can often be usefully informative in the realm of generative modeling, as we will see in later chapters. For now, we will implement the controlled introduction of randomness in our sampling strategy by introducing a sampling threshold, which lets us redistribute the Softmax prediction probabilities of our model,</span> <span class="MsoHyperlink"><span><a href="https://arxiv.org/pdf/1308.0850.pdf" target="_blank">https://arxiv.org/pdf/1308.0850.pdf</a>:</span></span></p>
<pre><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">softmax_predictions</span><span class="p">,</span> <span class="n">sample_threshold</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>   
<span class="n">softmax_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">softmax_predictions</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float64'</span><span class="p">)</span>    <br/><span class="c1"># Make array of predictions, convert to float</span>
    
<span class="n">log_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">softmax_preds</span><span class="p">)</span> <span class="o">/</span> <span class="n">sample_threshold</span>                 <br/><span class="c1"># Log normalize and divide by threshold</span>
    
<span class="n">exp_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_preds</span><span class="p">)</span>                                        <br/><span class="c1"># Compute exponents of log normalized terms</span>
     
<span class="n">norm_preds</span> <span class="o">=</span> <span class="n">exp_preds</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">exp_preds</span><span class="p">)</span>                           <br/><span class="c1"># Normalize predictions</span>
    
<span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm_preds</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>                       <br/><span class="c1"># Draw sample from multinomial distribution</span>

<span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>                                               <span class="c1">#Return max value</span></pre>
<p>This threshold denotes the entropy of the probability distribution we will be using, to sample a given generation from our model. A higher threshold will correspond to higher entropy distributions, leading to seemingly unreal and less structured sequences. Lower thresholds, on the other hand, will plainly encode English language representations and morphology, generating familiar words and terms.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Testing different RNN models</h1>
                </header>
            
            <article>
                
<p>Now that we have our training data preprocessed and ready in tensor format, we can try a slightly different approach than previous chapters. Normally, we would go ahead and build a single model and then proceed to train it. Instead, we will construct several models, each reflecting a different RNN architecture, and train them successively to see how each of them do at the task of generating character-level sequences. In essence, each of these models will leverage a different learning mechanism and induct its proper language model, based on sequences of characters it sees. Then, we can sample the language models that are learned by each network. In fact, we can even sample our networks in-between training epochs to see how our network is doing at generating Shakespearean phrases at the level of each epoch. Before we continue to build our networks, we must go over some basic strategies to inform our task of language modeling and sampling. Then, we will build some Keras callbacks that let us interact with and sample our model while it trains.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using custom callbacks to generate text</h1>
                </header>
            
            <article>
                
<p>Next, we will construct a custom Keras callback that will allow us to use the sample function we just constructed to iteratively probe our model at the end of each training epoch. As you will recall, callbacks are a class of functions that allow operations to be performed on our model (such as saving and testing) during the training process. These are very useful functions to visualize how a model performs throughout the training process. Essentially, this function will take a random sequence of characters from the Hamlet text and then generate 400 characters to follow on, starting from the given input. It does this for each of the five sampling thresholds chosen and prints out the generated results at the end of each epoch:</p>
<pre><span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
<span class="k">global</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name<br/></span><span class="nb">print</span><span class="p">(</span><span class="s1">'----- Generating text after Epoch: </span><span class="si">%d</span><span class="s1">'</span> <span class="o">%</span> <span class="n">epoch</span><span class="p">)</span>
<span class="n">start_index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="n">seq_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>    <br/><span class="c1"># Random index position to start sample input sequence</span>
<span class="n">end_index</span> <span class="o">=</span> <span class="n">start_index</span> <span class="o">+</span> <span class="n">seq_len</span>                           <br/><span class="c1"># End of sequence, corresponding to training sequence length</span>
<span class="n">sampling_range</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">]</span>                  <br/><span class="c1"># Sampling entropy threshold</span>
<span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">sampling_range</span><span class="p">:</span><span class="nb">print</span><span class="p">(</span><span class="s1">'----- *Sampling Threshold* :'</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)<br/></span><span class="n">generated</span> <span class="o">=</span> <span class="s1">''</span>                                          <br/><span class="c1"># Empty string to collect sequence</span>
<span class="n">sentence</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span> <span class="n">end_index</span><span class="p">]</span>                 <br/><span class="c1"># Random input sequence taken from Hamlet</span>
<span class="n">generated</span> <span class="o">+=</span> <span class="n">sentence</span>                                  <br/> <span class="c1"># Add input sentence to generated</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Input sequence to generate from : "'</span> <span class="o">+</span> <span class="n">sentence</span> <span class="o">+</span> <span class="s1">'"'</span><span class="p">)</span>     
<span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">generated</span><span class="p">)</span>                            <br/><span class="c1"># Print out buffer instead of waiting till the end</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">400</span><span class="p">):</span>                                   <br/><span class="c1"># Generate 400 next characters in the sequence</span>
<span class="n">x_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">)))</span>   <br/><span class="c1"># Matrix of zeros for input sentence</span>
<span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>                <br/><span class="c1"># For character in sentence</span>
<span class="n">x_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">char_indices</span><span class="p">[</span><span class="n">char</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>          <br/><span class="c1"># Change index position for character to 1.</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>        <br/><span class="c1"># Make prediction on input vector</span>
<span class="n">next_index</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>              <br/><span class="c1"># Get index position of next character using sample function</span>
<span class="n">next_char</span> <span class="o">=</span> <span class="n">indices_char</span><span class="p">[</span><span class="n">next_index</span><span class="p">]</span>               <br/><span class="c1"># Get next character using index<br/></span><span class="n">generated</span> <span class="o">+=</span> <span class="n">next_char</span>                             <br/><span class="c1"># Add generated character to sequence</span>
<span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">next_char<br/></span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">next_char</span><span class="p">)<br/></span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()<br/>-----------------------------------------------------------------------<br/><strong>Output:<br/></strong><br/></span><strong><span class="n">print_callback</span> <span class="o">=</span> <span class="n">LambdaCallback</span><span class="p">(</span><span class="n">on_epoch_end</span><span class="o">=</span><span class="n">on_epoch_end</span><span class="p">)</span></strong></pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Testing multiple models</h1>
                </header>
            
            <article>
                
<p>The last task on our list is to build a helper function that will train, sample, and save a list of RNN models. This function also saves the history objects of the model that we used earlier to plot out the loss and accuracy values per epoch, which can be useful in case you want to explore different models and their relative performances at a later time:</p>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3">
<pre><span class="k">def</span> <span class="nf">test_models</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span>
    
    <span class="k">for</span> <span class="n">network</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">:</span>   
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Initiating compilation...'</span><span class="p">)</span>
        
        <span class="c1"># Initialize model</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">network</span><span class="p">()</span>
        <span class="c1"># Get model name</span>
        <span class="n">model_name</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">network</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>  
        
        <span class="c1">#Filepath to save model with name, epoch and loss </span>
        <span class="n">filepath</span> <span class="o">=</span> <span class="s2">"C:/Users/npurk/Desktop/Ch5RNN/all_models/versions/</span><span class="si">%s</span><span class="s2">_epoch-</span><span class="si">{epoch:02d}</span><span class="s2">-loss-</span><span class="si">{loss:.4f}</span><span class="s2">.h5"</span><span class="o">%</span><span class="n">model_name</span>
        
        <span class="c1">#Checkpoint callback object </span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">'loss'</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'min'</span><span class="p">)</span>
        
        <span class="c1"># Compile model</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Compiled:'</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">model_name</span><span class="p">))</span>
        
        <span class="c1"># Initiate training</span>
        <span class="n">network</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
              <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
              <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
              <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">print_callback</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">])</span>
        
        <span class="c1"># Print model configuration</span>
        <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
           
        <span class="c1">#Save model history object for later analysis</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'C:/Users/npurk/Desktop/Ch5RNN/all_models/history/</span><span class="si">%s</span><span class="s1">.pkl'</span><span class="o">%</span><span class="n">model_name</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">file_pi</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">history</span><span class="p">,</span> <span class="n">file_pi</span><span class="p">)<br/><br/></span><strong>test_models<span class="p">(</span><span class="n">all_models</span><span class="p">,</span><span> </span><span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span></strong></pre></div>
</div>
</div>
</div>
</div>
<p>Now, we can finally proceed to the task of constructing several types of RNNs and training them with the helper function to see how different types of RNNs perform at generating Shakespeare-like texts.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Building a SimpleRNN</h1>
                </header>
            
            <article>
                
<p><span>The SimpleRNN model in Keras is a basic RNN layer, like the ones we discussed earlier. While it has many parameters, most of them are set with excellent defaults that will get you by for many different use cases. Since we have initialized the RNN layer as the first layer of our model, we must pass it an input shape, corresponding to the length of each sequence (which we chose to be 40 characters earlier) and the number of unique characters in our dataset (which was 44). While this model is computationally compact to run, it gravely suffers from the vanishing gradients problem we spoke of. As a result, it has some trouble modeling long-term dependencies:</span></p>
<pre><span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Bidirectional</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">SimpleRNN</span><span class="p">,</span> <span class="n">GRU</span><span class="p">,</span> <span class="n">BatchNormalization<br/>from keras.optimizers import RMSprop<br/></span><span class="sd">'''Fun part: Construct a bunch of functions returning different kinds of RNNs, from simple to more complex'''<br/></span><span class="k">def</span> <span class="nf">SimpleRNN_stacked_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SimpleRNN</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">)),</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SimpleRNN</span><span class="p">(</span><span class="mi">128</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span></pre>
<p><span>Note that this two-layered model has a final dense layer with a number of neurons corresponding to each of the 44 unique characters in our dataset. We equip it with a Softmax activation function, which will output a 44-way probability score at each time step, corresponding to the likelihood of each character to follow. All of the models we build for this experiment will have this final dense layer in common. Finally, all RNNs have the ability to remain stateful. This simply refers to passing on the layer weights for computations on the subsequent sequences of our training data. This feature can be explicitly set in all RNNs, with the <kbd>stateful</kbd> argument, which takes a Boolean value and can be provided when initializing a layer.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Stacking RNN layers</h1>
                </header>
            
            <article>
                
<p>Why have one, when you can have two? All of the recurrent layers in Keras can return two different types of tensors, depending on what you wish to accomplish. You could either receive a 3D tensor of dimensions as output (<kbd>batch_size</kbd>, <kbd>time_steps</kbd>, <kbd>output_features</kbd>) or simply a 2D one, with dimensions of (<kbd>time_steps</kbd>, <kbd>output_features</kbd>). We query the 3D tensor if we want our model to return entire sequences of successive output values on each time step. This is useful if we want to stack an RNN layer on top of another, and then ask the first layer to return all of the activations to the second layer that's stacked. Returning all activations essentially means returning the activation for each specific time step. These values can be subsequently fed into yet another recurrent layer, which aims to encode higher level abstract representations from the same input sequence. The following diagram shows the mathematical consequences of setting the Boolean argument to <strong>True</strong> or <strong>False</strong>:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/03ea7c75-466e-4209-b81f-49a95778f42d.png" style="width:45.50em;height:17.42em;" width="722" height="276"/></div>
<p>Setting it to true will simply return a tensor with predictions for each time step, instead of the prediction from the last time step only. The stacking of recurrent layers is quite useful. By stacking RNN layers on top on one another, we potentially increase the time-dependent representational value of our network, allowing it to memorize more abstract patterns that are potentially present in our data.</p>
<p><span>On the other hand, if we want it to only return the output at the last time step for each input sequence, we can ask it to return a 2D tensor. This is necessary when we want to go ahead and actually predict which of the characters from our vocabulary is most likely to be next. We can control this implementation with the <kbd>return_sequences</kbd> argument, which is passed when we add a recurrent layer. Alternatively, we can set it to false, making our model return the activation values from the last time step only, which can be propagated forward for classification:</span></p>
<pre><span class="k">def</span> <span class="nf">SimpleRNN_stacked_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SimpleRNN</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">)),</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SimpleRNN</span><span class="p">(</span><span class="mi">128</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span></pre>
<div class="packt_infobox">Note that the <kbd>return_sequences</kbd> argument can only be invoked for the penultimate hidden layers, and not for the hidden layer preceding the densely connected output layer, since the output layer is only tasked with classifying the next sequence to come.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Building GRUs</h1>
                </header>
            
            <article>
                
<p>Excellent at mitigating the vanishing gradients problem, the GRU is a good choice for modeling long-term dependencies such as grammar, punctuation, and word morphology:</p>
<pre><span class="k">def</span> <span class="nf">GRU_stacked_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">)),</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span></pre>
<p>Just like the SimpleRNN, we define the dimensions of the input at the first layer and return a 3D tensor output to the second GRU layer, which will help retain more complex time-dependent representations that are present in our training data. We also stack two GRU layers on top of each other to see what the increased representational power of our model produces:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/bc2f701b-6f1c-424b-a062-39703e28e64e.png" style="width:54.50em;height:22.33em;" width="1025" height="421"/></div>
<p>Hopefully, this architecture results in realistic albeit novel sequences of text that even a Shakespeare expert couldn't tell apart from the real deal. Let's visualize the model we built here through the following diagram:</p>
<div class="packt_tip packt_infobox">Note that we have also included the line <kbd>model.summary()</kbd> in our trainer function we built earlier to visually depict the structure of the model after it is fit.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Building bi-directional GRUs</h1>
                </header>
            
            <article>
                
<p>Next in our models to test is yet another GRU unit, but this time with a twist. We nest it within a bi-directional layer, which allows us to feed our model each sequence in both the normal and the reverse order. In this manner, our model is able to <em>see</em> what is yet to come, leveraging future sequence data to inform predictions at the current time step. The nature of processing a sequence in a bi-directional manner greatly enhances the extracted representations from our data. In fact, the order of processing a sequence can have a significant effect on the type of representations that are learned after.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">On processing reality sequentially</h1>
                </header>
            
            <article>
                
<p>The notion of changing the order of processing a sequence is quite an intriguing one. We humans certainly seem to prefer a certain order of learning things over another. The second sentence that's been reproduced in the following image simply makes no sense to us, even though we know exactly what each individual word within the sentence means. Similarly, many of us have a hard time reciting the letters of the alphabet backward, even though we are extremely familiar with each letter, and compose much more complex concepts with them, such as words, ideas, and even Keras code:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/1a56a47a-a34a-4dc3-9911-acdd412050a6.png" style="width:36.58em;height:9.33em;" width="376" height="96"/></div>
<p>It is very likely that our sequential preferences have to do with the nature of our reality, which is sequential and forward-moving by definition. <span>At the end of the day, the configuration of the 10<sup>11</sup> neurons in our brain has been engineered by time and natural forces to best encode and represent the deluge of time-dependent sensory signals we come across, every living second of our lives. It stands to reason that our own neural architecture efficiently implements a mechanism that tends to prefer processing signals in a specific order. However, that is not to say that we cannot part ways with a learned order, as many pre-school kids take up the challenge of reciting the alphabet backward and do so quite successfully. Other sequential tasks such as listening to natural language or rhythmic music, however, may be harder to process in reverse order. But don't take my word for it. Try listening to your favorite song in reverse and see whether you still like it as much.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Benefits of re-ordering sequential data</h1>
                </header>
            
            <article>
                
<p>In some manner, it seems that bi-directional networks are able to potentially overcome our own biases in processing information. As you will see, they can learn equally useful representations that we would have otherwise not thought to include to inform and enhance our predictions. It all depends on how important it is to process a given signal, in its sequential order, for the task at hand. In the case of our earlier natural language example, this was quite crucial to determine the <strong>part-of-speech</strong> (<strong>POS</strong>) tag for the word <em>Spartan</em>:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/259ac156-568d-4eb2-938c-498308c58d7f.png" style="width:29.08em;height:14.17em;" width="419" height="204"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Bi-directional layer in Keras</h1>
                </header>
            
            <article>
                
<p>Therefore, the bi-directional layer in Keras processes a sequence of data in both the normal and reverse sequence, which allows us to pick up on words that come later on in the sequence to inform our prediction at the current time.</p>
<p><span>Essentially, the bi-directional layer duplicates any layer that's fed to it and uses one copy to process information in the normal sequential order, while the other processes data in the reverse order. Pretty neat, no? We can intuitively visualize what a bi-directional layer actually does by going through a simple example. Suppose you were modeling the two-word sequence <strong>Whats up</strong>, with a bi-directional GRU:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/179d4b85-f770-4bd3-bfb2-bfeb4ba5e7b1.png" style="width:23.83em;height:7.33em;" width="358" height="110"/></div>
<p>To do this, you will nest the GRU in a bi-directional layer, which allows Keras to generates two versions of the bi-directional model. In the preceding image, we stacked two bi-directional layers on top of each other before connecting them to a dense output layer, as we did previously:</p>
<pre><span class="k">def</span> <span class="nf">Bi_directional_GRU</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">))))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span></pre>
<p><span>The model that processes the sequence in the normal order is shown in red. Similarly, the blue model processes the same sequence in reverse order. Both of these models collaborate at each time step to produce a predicted output, with respect to the current time step. We can see how these two models receive input values and work together to produce the predicted output (</span><span><img src="Images/5a07aa4f-cdcc-4d84-96af-8024ce385aa7.png" style="width:1.33em;height:1.25em;" width="20" height="19"/>, which</span> corresponds to the two respective time steps of our input:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/353bfcae-f247-43a6-a7bb-b9699b84c1fc.png" style="width:52.42em;height:14.42em;" width="1165" height="321"/></div>
<p>The equations governing the forward propagation of information can be altered slightly to account for data entering our RNN, from both the forward and reverse sequence layers, at each time step. The backward propagation of errors through time is still achieved in the same manner and is done for each orientation of GRU layer (red and blue). In the following formulation, we can see how activations from both the forward and reverse sequence layers are used to compute a predicted output (<span><img src="Images/5c108a8b-2fe1-40e2-a65a-75cbbc5f1ba6.png" style="width:0.92em;height:1.25em;" width="14" height="19"/></span>) for a given time step (<em>t</em>):</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/d977fa08-9d31-4a09-a9f0-43130a7c0a7c.png" style="width:18.25em;height:2.58em;" width="285" height="41"/></div>
<p>The activation and weight matrices here are simply defined by the model nested within the bi-directional layer. As we saw earlier, they will be initialized at the first time step and updated by backpropagating errors through time. Hence, these are the implemented processes that let us generate a bi-directional network, which is an acyclical network where predictions are informed by information flowing both forward and backward, corresponding to the ordering of the sequence. One key disadvantage with implementing the bi-directional layer is that our network needs to see the entire sequence of data before it is able to make a prediction. In use cases such as speech recognition, this becomes problematic, since we must ensure that the target has ceased to speak before we perform our predictions to classify each sound byte as a word. One way to solve this is to keep performing predictions on an input sequence iteratively, and update the previous prediction iteratively as new information flows in.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Implementing recurrent dropout</h1>
                </header>
            
            <article>
                
<p>In earlier chapters, we saw how we can drop out the prediction of a few neurons randomly to better distribute representations over our network and avoid the problem of overfitting. While our current task at hand does not have much of a negative consequence in regards to overfitting, we could not help but briefly introduce the specific case of mitigating overfitting in RNNs. This will help our model better generate novel sequences, instead of copy-pasting segments from the training data.</p>
<p><span>However, adding a normal dropout layer here just doesn't do the trick. It introduces too much randomness. This often prohibits our model from converging to ideal loss values and encoding useful representations. Instead, we may find a confused model that fails to keep track of relevant time-dependent data. What does seem to work, on the other hand, is the notion of applying the same dropout scheme (or mask) at each time step. This is different from the classic dropout operation, which drops neurons on a random basis for each time step. We can use this recurrent dropout technique to capture regularized representations, since a constant dropout mask is maintained through time. This is one of the most significant techniques that helps to prevent overfitting in recurrent layers and is known as a <strong>recurrent dropout strategy</strong>. Doing so essentially permits our model to representatively encode sequential data without losing valuable information via the randomized dropout process:</span></p>
<pre><span class="k">def</span> <span class="nf">larger_GRU</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">)),</span>
                       <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                       <span class="n">recurrent_dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                       <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                  <span class="n">recurrent_dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                  <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                  <span class="n">recurrent_dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">characters</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model<br/></span><span class="c1"># All defined models</span>
<span class="n">all_models</span> <span class="o">=</span> <span class="p">[</span><span class="n">SimpleRNN_model</span><span class="p">,</span>
              <span class="n">SimpleRNN_stacked_model</span><span class="p">,</span>
              <span class="n">GRU_stacked_model</span><span class="p">,</span>
              <span class="n">Bi_directional_GRU</span><span class="p">,</span> 
              <span class="n">Bi_directional_GRU</span><span class="p">,</span>
              <span class="n">larger_GRU</span><span class="p">]</span></pre>
<p><span>The designers of Keras have kindly implemented two dropout-related arguments that may be passed when constructing a recurrent layer. The <kbd>recurrent_dropout</kbd> argument accepts a float value that refers to the fraction of neurons upon which the same dropout mask will be applied. You can also specify the fraction of input values entering a recurrent layer to be randomly dropped to control random noise in the data. This can be achieved by passing a float value to the dropout argument (different from <kbd>recurrent_dropout</kbd>), while defining the RNN layer.</span></p>
<p>For reference you can read the following papers:</p>
<ul>
<li><strong>A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</strong>: <a href="https://arxiv.org/pdf/1512.05287.pdf" target="_blank">https://arxiv.org/pdf/1512.05287</a><a href="https://arxiv.org/pdf/1512.05287.pdf" target="_blank">.pdf</a></li>
<li><a href="http://mlg.eng.cam.ac.uk/yarin/blog_2248.html">http://mlg.eng.cam.ac.uk/yarin/blog_2248.html</a></li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Visualizing output values</h1>
                </header>
            
            <article>
                
<p>For the sake of entertainment, we will display some of the more interesting results from our own training experiments to conclude this chapter. The first screenshot shows the output that's generated by our SimpleRNN model at the end of the first epoch (note that the output prints out the first epoch as epoch 0). This is simply an implementational issue, denoting the first index position in range of <em>n</em> epochs. As we can see, even after the very first epoch, the SimpleRNN seems to have picked up on word morphology and generates real English words at low sampling thresholds.</p>
<p>This is just as we expected. Similarly, higher entropy samples (with a threshold of 1.2, for example) produce more stochastic results and generate (from a subjective perspective) interesting sounding words (such as <em>eresdoin</em>, <em>harereus</em>, and <em>nimhte</em>):</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/76592355-55cd-4b81-ab60-f20f772b6127.png" style="width:51.42em;height:49.17em;" width="633" height="605"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Visualizing the output of heavier GRU models</h1>
                </header>
            
            <article>
                
<p>In the following screenshot, we present the output from our heavier GRU model, which started to produce pretty Shakespeare-sounding strings only after two training epochs. It even throws in Hamlet's name here and there. Note that the loss of your network is not the best assessment metric for the purpose of our illustration. The models that are shown here had a loss of 1.3, which is still pretty far from what we would normally require. You may, of course, keep training your model to produce even more comprehensible bits of Shakespeare. However, comparing the performance of any model with the loss metric is akin to judging apples and oranges in this use case. Intuitively, having reached a loss close to zero simply means that the model has memorized Shakespeare's Hamlet, and won't really generate novel sequences as we want it to do. At the end of the day, you shall remain the best judge of its performance for generative tasks such as this one:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/e7fa7810-3b8f-4212-a42a-c23aae919ec4.png" style="width:52.58em;height:36.92em;" width="838" height="588"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we learned about recurren6t neural networks and their aptness at processing sequential time-dependent data. The concepts that you have learned can now be applied to any time-series dataset that you may stumble upon. While this holds true for use cases such as stock market data and time-series in nature, it would be unreasonable to expect fantastic results from feeding your network real time price changes only. This is simply because the elements that affect the market price of stocks (such as investor perception, information networks, and available resources) are not nearly reflected to the level that would allow proper statistical modeling. The key is representing all relevant information in the most <em>learnable</em> manner possible for your network to successfully encode valuable representations therefrom.</p>
<p>While we did extensively explore the learning mechanisms behind several types of RNNs, we also implemented a generative modeling use case in Keras and learned to construct custom callbacks that let us generate sequences of data at the end of each epoch. Due to spatial limitations, we were forced to leave out some concepts from this chapter on RNNs. However, rest assured, these are yet to be elaborated upon in the upcoming chapter.</p>
<p>In the following chapter, we will learn more about a very popular RNN architecture known as the <strong>LSTM network</strong>, and implement it for other exciting use cases. These networks are as versatile as RNNs get, and allow us to produce very detailed statistical models of languages for use cases such as speech and entity recognition, translation, and machine question-answering. For natural language understanding, LSTMs (and other RNNs) are often implemented by leveraging concepts such as word embeddings, which are dense word vectors that are capable of encoding their semantic meaning. LSTMs also tend to do much better at generating novel sequences such as pieces of music, but hopefully you will be able to listen for yourself. We will also explore the intuition behind attention models briefly and revisit this concept in more detail, in a later chapter.</p>
<p class="mce-root">Finally, before concluding this chapter, we will note a similarity between RNNs and a type of CNN we mentioned in earlier chapters. RNNs are a popular choice when modeling time series data, yet <strong>one-dimensional convolutional layers</strong> (<strong>Conv1D</strong>) also do the trick. The drawback here comes from the fact that CNNs process input values independently, not sequentially. As we will see, we can even overcome this by combining both convolutional and recurrent layers. This lets the former perform a sort of preprocessing on the input sequence before reduced representations are passed forward to the RNN layer for sequential processing. But more on that later.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<ul>
<li><strong>GRUs</strong><span>: <span class="MsoHyperlink"><a href="https://arxiv.org/abs/1412.3555">https://arxiv.org/abs/1412.3555</a></span></span></li>
<li><strong>Neural machine translation</strong><span>: <span class="MsoHyperlink"><a href="https://arxiv.org/abs/1409.1259">https://arxiv.org/abs/1409.1259</a></span></span></li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Exercise</h1>
                </header>
            
            <article>
                
<ul>
<li>Train each model on the Hamlet text and use their history objects to compare their relative losses. Which one converges faster? What do they learn?</li>
<li>Examine the samples that are generated at different entropy distributions, at each epoch, to see how each RNN improves upon its language model through time.</li>
</ul>


            </article>

            
        </section>
    </div>



  </body></html>