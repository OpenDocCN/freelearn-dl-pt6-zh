- en: '*Chapter 9*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Computer Vision forÂ Robotics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluate objects using artificial vision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combine external frameworks with ROS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a robot to interact with objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a robot to understand natural language
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Develop your own end-to-end robotics applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, you'll learn how to work with Darknet and YOLO. You'll also
    evaluate objects using AI and integrate YOLO and ROS to enable your virtual robot
    to predict objects in the virtual environment.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In previous chapters, you came across many technologies and techniques that
    may be new to you. You have learned many concepts and techniques that help solve
    real-world problems. Now, you are going to use all the acquired skills to complete
    this last chapter and build your own end-to-end robotics application.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you'll use a deep learning framework, Darknet, to build robots
    that recognize objects in real time. This framework will be integrated with ROS
    so that the final application can be applied to any robot. Furthermore, it's important
    to say that object recognition can be used for building different kinds of robotics
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: The end-to-end applications you are going to build will not only have academic
    value but will also be useful for real-world problems and live situations. You
    will even be able to adapt how the application functions depending on circumstances.
    This will give you a lot of opportunities to solve real-world problems when working
    with robots.
  prefs: []
  type: TYPE_NORMAL
- en: Darknet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Darknet is an open source neural network framework, which has been written in
    C and CUDA. It is very fast, as it allows GPU as well as CPU computation. It was
    developed by Joseph Redmon, a computer scientist focused on artificial vision.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although we are not going to study all of the functionalities in this chapter,
    Darknet includes a lot of interesting applications. As we mentioned earlier, we
    are going to use YOLO, but the following is a list of other Darknet functionalities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**ImageNet Classification**: This is an image classifier, which uses known
    models such as AlexNet, ResNet, and ResNeXt. After classifying some ImageNet images
    with all these models, a comparison between them is performed. They are based
    on time, accuracy, weights etc..'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RNN''s**: Recurrent neural networks are used for generating and managing
    natural language. They use an architecture called a vanilla RNN with three recurrent
    modules, which achieves good results in tasks such as speech recognition and natural
    language processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tiny Darknet**: Consists of another image classifier, but this time, the
    generated model is much lighter. This network obtains similar results to Darknet,
    but the model weight is only 4 MB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Apart from the preceding, Darknet has some other applications as well. You
    can get more information about the framework by heading to its website: [https://pjreddie.com/darknet/](https://pjreddie.com/darknet/).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Basic Installation of Darknet
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Darknet basic installation won't let you use the entire YOLO power, but
    it will be enough to check how it works and make your first few object detection
    predictions. It won't let you use GPU computation to make real-time predictions.
    For more complex tasks, go to the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For detailed steps regarding the basic and advanced installation of Darknet,
    refer to the preface, page vii.
  prefs: []
  type: TYPE_NORMAL
- en: YOLO
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: YOLO is a real-time object detection system based on deep learning and is included
    in the Darknet framework. Its name comes from the acronym *You Only Look Once*,
    which references to how fast YOLO can work.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the website ([https://pjreddie.com/darknet/yolo/](https://pjreddie.com/darknet/yolo/)),
    the author has added an image where this system is compared to others with the
    same purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1: A comparison of object detection systems](img/C13550_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.1: A comparison of object detection systems'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the preceding graphic, the **y** axis represents the **mAP** (mean Average
    Precision), and the **x** axis represents the time in milliseconds. So, you can
    see that YOLO achieves a higher mAP in lesser time than the other systems.
  prefs: []
  type: TYPE_NORMAL
- en: It is also important to understand how YOLO works. It uses a neural network,
    which is applied to the entire image and splits it into different parts, predicting
    the bounding boxes. These bounding boxes are similar to rectangles marking off
    certain objects, which will be identified later in the process. YOLO is fast,
    because it is able to make predictions with only an evaluation of the neural network,
    while other recognition systems need several evaluations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mentioned network has 53 convolutional layers, alternating 3x3 and 1x1
    layers. Here''s an image of the architecture extracted from a YOLO author''s paper
    ([https://pjreddie.com/media/files/papers/YOLOv3.pdf](https://pjreddie.com/media/files/papers/YOLOv3.pdf)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2: The YOLO architecture](img/C13550_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.2: The YOLO architecture'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: First Steps in Image Classification with YOLO
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we are going to make our first predictions with YOLO. You
    are required to complete the basic installation. Let''s start recognizing objects
    in a single image:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to use a pretrained model in order to avoid the training process,
    so the first step is to download the network weights in the Darknet directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After that, we are going to make predictions with YOLO. In this first example,
    we are trying to recognize a single object, a dog. This is the sample image we
    are using:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.3: Sample image to predict](img/C13550_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.3: Sample image to predict'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Save this image as a .jpg file in the Darknet directory and run YOLO on it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'When the execution is finished, you should see an output like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4: The predicted output](img/C13550_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.4: The predicted output'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As you can see, YOLO detects that there''s a dog in the image with 100% accuracy.
    It also generates a new file named `predictions.jpg`, where it is possible to
    see the location of the dog in the image. You can open it from the Darknet directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5: Recognized objects in the image](img/Image47221.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.5: Recognized objects in the image'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Another possibility when using YOLO is to make predictions for several images
    with a single execution. To do this, you must enter the same command as before,
    but this time do not enter the image path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, you will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C13550_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.6: The prediction command output'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As you can see, it is asking you to enter an image. You could enter, for instance,
    the same image as before by typing `dog.jpg`. You''ll then be asked to enter another
    image path. This way, you can make predictions for all the images you want. This
    could be an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.7: The output after image prediction](img/C13550_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.7: The output after image prediction'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If you do so, you will obtain this image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.8: Image prediction](img/C13550_09_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.8: Image prediction'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: There's one more interesting command to know when working with YOLO. It can
    be used to modify the detection threshold.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The detection threshold is an accuracy limit to consider if a prediction is
    incorrect. For example, if you set your threshold to 0.75, objects detected with
    a lower accuracy won't be considered as a correct prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, YOLO includes an object in its output when it is predicted with
    an accuracy of 0.25 or higher. You can change the threshold value using the last
    flag of the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As you may suppose, the preceding command sets the threshold to 0.5\. Let''s
    look at a practical example of this. Follow these steps to test the functioning
    of the threshold modification:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make predictions for images until you find one where an object is predicted
    with less than 100% accuracy. We are going to use this as an example, where the
    dog is recognized with 60% accuracy:![Figure 9.9: Example image with less than
    100% accuracy](img/C13550_09_09.jpg)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 9.9: Example image with less than 100% accuracy'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, use the `predict` command modifying the detection threshold. As the dog
    is detected with 60% accuracy, if we change the threshold to 70%, no object should
    be detected:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we check the `predictions` file, we can confirm that the dog was not detected.
    Hence, you can see how threshold plays an important role in recognition as well:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.10: The final prediction with the modified threshold](img/C13550_09_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.10: The final prediction with the modified threshold'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: YOLO on a Webcam
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once you have made your first predictions with YOLO, it''s time to try a more
    interesting feature of this system. You''re going to detect your own real objects
    by connecting YOLO to your personal webcam. To do this, you must complete the
    advanced installation because it needs a GPU and OpenCV:'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure your webcam is connected and can be detected by your system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enter the following command in the Darknet directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Try to recognize an object in your environment; for example, we have detected
    the books on our shelves:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.11: Books recognized using a webcam](img/C13550_09_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.11: Books recognized using a webcam'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 28: Programming with YOLO'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we are going to see how to make predictions with YOLO using
    Python. We will create a dataset and check how many images containing a certain
    object are present in the dataset. To build the dataset, check the following images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.12: Images contained in the dataset](img/C13550_09_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.12: Images contained in the dataset'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, it is a very simple dataset containing animals and landscape
    images. The Python program you are going to implement will have to obtain the
    number of images in which dogs appear.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin by cloning Darknet files from GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Create a new folder named `dataset` in the Darknet directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Place these images or others of your choice inside the new folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The images can be found in the Chapter 9/exercise28/dataset/ folder on GitHub
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'URL: [https://github.com/PacktPublishing/Artificial-Vision-and-Language-Processing-for-Robotics/tree/master/Lesson09/Exercise28/dataset](https://github.com/PacktPublishing/Artificial-Vision-and-Language-Processing-for-Robotics/tree/master/Lesson09/Exercise28/dataset)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a Python file, `excercise1.py`, and start the implementation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import Python itself and the required libraries:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Tell the system where to find the Darknet framework and then import it. If
    you have created a file inside the Darknet directory, you can do this as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Tell Darknet which GPU to use for the program execution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Configure the network you are going to use for making your predictions. In
    this case, we are using the same configuration as before:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: Pay attention to the paths entered here; they may change if your Python file
    is not inside Darknet's folder.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Declare the variables to count the total number of images and the number of
    images containing dogs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement a loop for iterating over the files in the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use Darknet''s `detect` method to recognize the objects of each image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Iterate over the recognized objects and check whether any of them are dogs.
    If they are, add one to the dog images counter and stop checking the rest of the
    objects. Add one to the total counter too:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, print the obtained results. For example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: Here the `cd ..` command switches to the directory where your file is located
    and downloads the weights and run the script.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For example `cd <your_script_location>`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can test whether it works as expected by running the script. If you used
    the proposed dataset, the output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.13: Exercise 1 final output](img/C13550_09_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.13: Exercise 28 final output'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: ROS Integration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, you have already learned how to use YOLO in a common Python program. It's
    time to see how to integrate it with Robot Operating System (ROS) so that you
    can use it in real robotics problems. You can combine it with any robot camera
    to allow the robot to detect and recognize objects, achieving the goal of artificial
    vision. After the completion of the following exercise, you will be able to do
    it by yourself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 29: ROS and YOLO Integration'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This exercise consists of a new ROS node implementation that uses YOLO to recognize
    objects. We will test it using TurtleBot, the ROS simulator we used in *Chapter
    6, Robot Operating System (ROS)*, but it will be easily adaptable for any robot
    with a camera. These are the steps that must be followed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new package in your catkin workspace to contain the integration node.
    Do it with this command to include the correct dependencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Switch to the package folder and create a new `scripts` directory. Then, create
    the Python file and make it executable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Begin with the implementation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the libraries you will use for node implementation. You will need `sys`
    and `os` to import Darknet from its path, `OpenCV` to process images, and `Image`
    from `sensor_msgs` to publish them:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Tell the system where to find Darknet:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the class where the node logic will be coded and its constructor:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Code the constructor:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we will initialize the node:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a bridge object:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Subscribe to the camera topic:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the variable to store the obtained images:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the corresponding paths for YOLO configuration:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the name that will be used for storing the images:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the callback function to obtain the images with the OpenCV format:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function for making predictions over the obtained images. The node
    must keep making predictions until the user stops the execution. This will be
    done by storing the image to the disk and making predictions over it using the
    detection function. Finally, the results will be constantly printed:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the main program entry. Here, you will have to initialize Darknet,
    make an instance of the created class, and call its main method:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Test whether the node works as it should.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open a terminal and start ROS:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Open another terminal and run Gazebo with TurtleBot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Insert YOLO recognizable objects and make TurtleBot **look at** them. You can
    insert new objects by clicking on the **insert** button located in the upper-left
    corner. You could insert, for example, a bowl:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.14: Inserted bowl in Gazebo](img/C13550_09_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 9.14: Inserted bowl in Gazebo'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Open a new terminal and run the created node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you used a bowl, check that you get an output like the one that follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.15: Object predicted by the node](img/C13550_09_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.15: Object predicted by the node'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Activity 9: A Robotic Security Guard'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s suppose a scenario similar to the one in the *Chapter 6, Activity 6,
    Simulator and Sensors* activity: You are working for a robotics company that has
    recently got a new client, a shopping center. The client wants your company to
    provide some robots for the shopping center at night to avoid robbery. These robots
    must consider any person a thief and alert the client if they detect one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use Gazebo to give the desired functionality to TurtleBot or any other simulator.
    You should follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a catkin package for storing the required nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, implement the first node. It should obtain the images from the robot camera
    and run YOLO on them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, it should publish the list of detected objects in string format.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement the second node. It should subscribe to the topic where the detected
    objects are being published and obtain them. Finally, it should check whether
    a person is one of these objects and print an alert message if it is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run both nodes simultaneously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: Although it's not the main goal of this activity, it would be interesting to
    combine the execution of these nodes with another one to move the robot (you can
    use the one implemented in *Chapter 6, Robot Operating System (ROS)*).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The solution of this activity can be found on page 330.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have now achieved the objective of this book and built an end-to-end application
    for a robot. This has only been an example application; however, you could use
    the techniques that you learned during this book to build other applications for
    robotics. In this chapter, you also learned how to install and work with Darknet
    and YOLO. You worked through evaluating objects using AI and integrating YOLO
    and ROS to enable your virtual robot to predict objects.
  prefs: []
  type: TYPE_NORMAL
- en: You have learned how to control the robot with natural language processing commands,
    along with studying various models in this book, such as Word2Vec, GloVe embedding
    techniques, and non-numeric data. After this, you worked with ROS and built a
    conversational agent to manage your virtual robot. You developed the skills needed
    to build a functional application that could integrate with ROS to extract useful
    information about your environment. You worked with tools that are not only useful
    for robotics; you can use artificial vision and language processing as well.
  prefs: []
  type: TYPE_NORMAL
- en: We end this book by encouraging you to start your own robotics projects and
    practicing with the technologies you most enjoyed during the book. You can now
    compare different methods used to work with robots and explore computer vision,
    algorithms, and limits. Always remember that a robot is a machine that can possess
    the behavior you want it to.
  prefs: []
  type: TYPE_NORMAL
